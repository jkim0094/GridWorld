{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5226 Project Stage 2\n",
    "\n",
    "## Group 8\n",
    "- **Members:**\n",
    "  - Jeeeun Kim\n",
    "  - Jinxu Tao\n",
    "  - Xiaolong Shen\n",
    "  - Zhihan Ye\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Introduction\n",
    "In this stage, the grid world environment from Stage 1 has been extended using Deep Q-Learning (DQN) instead of a Q-table. The agent now utilizes a deep neural network to predict Q-values for state-action pairs and updates its behavior accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Environment Setup\n",
    "**(The default grid size of 5x5 -> 4x4, goal location fixed-> random. Other than that, it is the same as in Stage 1.)**\n",
    "\n",
    "The environment is implemented as an `n x n` grid world. The agent, item, and goal are all placed randomly within the grid. The main components of the environment are as follows:\n",
    "\n",
    "- **Grid Size (n):** Initially set to 4x4, but can be adjusted to other sizes.\n",
    "- **Agent's Position:** A randomly initialized starting position within the grid.\n",
    "- **Item's Position:** A randomly placed position within the grid.\n",
    "- **Goal's Position:** A randomly placed position within the grid.\n",
    "  - *(The agent, item, and goal are all placed at different locations.)*\n",
    "- **State Space:** Defined by the agent's position `(n x n)`, the item's position `(n x n)`, the goal's position `(n x n)`, and whether the agent is carrying the item `(1)`.\n",
    "- **Action Space:** `'n', 's', 'e', 'w'` (north, south, east, west).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Reward Structure\n",
    "The agent receives rewards and penalties based on its proximity to the item and the goal. The rewards are structured as follows:\n",
    "\n",
    "- **Movement Penalty:** Each time the agent moves, a penalty of -0.1 is applied to discourage unnecessary movements.\n",
    "\n",
    "#### When Carrying the Item:\n",
    "- **Reaching the Goal:** The agent receives a large reward of 50 for successfully reaching the goal with the item.\n",
    "- **Closer to the Goal:** The reward increases as the agent gets closer to the goal, calculated as `(10 / (distance_to_target + 1))`.\n",
    "\n",
    "#### When Not Carrying the Item:\n",
    "- **Picking Up the Item:** The agent receives a reward of 20 for picking up the item.\n",
    "- **Reaching the Goal without the Item:** A penalty of -5 is applied if the agent reaches the goal without the item.\n",
    "- **Closer to the Item:** The reward increases as the agent gets closer to the item, calculated as `(5 / (distance_to_item + 1))`.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Training Procedure\n",
    "\n",
    "#### Before Batch Size\n",
    "In this phase, the agent interacts directly with the environment and collects data through its actions.\n",
    "\n",
    "1.Action Selection: The agent selects an action by choosing between exploration and exploitation.\n",
    "2.State Transition and Reward: After performing an action, the agent transitions to a new state and receives a corresponding reward.\n",
    "3.Experience Storage (Replay Buffer): Every time the agent takes a step, it stores the data consisting of the state, action, reward, next state, and whether the episode has terminated in the experience replay buffer. Learning begins only after the replay buffer has accumulated enough data equal to the batch size.\n",
    "\n",
    "#### After Batch Size\n",
    "In this phase, the agent uses the neural network to further optimize its behavior.\n",
    "\n",
    "1.Experience Sampling: The agent randomly samples data from the replay buffer and retrieves it as a batch.\n",
    "2.Q-value Calculation and Update: The Q-value for the sampled data (the predicted future rewards for each action) is calculated using the current model. The Q-value for the next state is calculated, and the Q-value is updated according to the Q-learning algorithm:\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max_{a'} Q(s', a')\n",
    "$$\n",
    "The loss function (MSE) is then calculated based on this updated Q-value, and the optimizer (Adam optimizer) is used to update the weights in order to minimize the loss.\n",
    "\n",
    "3.Target Network Update: Every fixed number of steps (500 steps), the target network is updated. The target network provides stability by not being updated too frequently. \n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max_{a'} Q(s', a')\n",
    "$$\n",
    "where the value $\\max_{a'} Q(s', a')$is obtained from the target network.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Evaluation\n",
    "The trained agent is evaluated over multiple episodes using the following metrics:\n",
    "Here are the results of the training with the hyperparameters set to EPSILON_DECAY_FACTOR = 0.6 and BATCH_SIZE = 50\n",
    "1. **Total reward** : While there was some fluctuation initially, the overall trend showed an increase in reward as the number of episodes increased.\n",
    "2. **Total Loss** : Although there were fluctuations in the loss values, a significant decrease was observed after a certain number of episodes.\n",
    "2. **Steps per episode** : Although the number of steps was expected to decrease as the number of episodes increased, even with an upper limit of 100 steps, significant fluctuations were observed and no clear trend was identified.\n",
    "3. **Exploration vs. Exploitation Ratio** : As the number of episodes increased, exploration decreased while exploitation increased.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T12:20:33.528626Z",
     "start_time": "2024-09-15T12:20:30.947460Z"
    },
    "id": "og1zx3TCi38O"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import copy\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0r8ac0aCcbG"
   },
   "outputs": [],
   "source": [
    "statespace_size=48\n",
    "\n",
    "def prepare_torch():\n",
    "  global statespace_size\n",
    "  global model, model2\n",
    "  global optimizer\n",
    "  global loss_fn\n",
    "  l1 = statespace_size\n",
    "  l2 = 150\n",
    "  l3 = 100\n",
    "  l4 = 4\n",
    "\n",
    "  model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(l1, l2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l2, l3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(l3,l4)).to(torch.device(\"cuda\"))\n",
    "  model2 = copy.deepcopy(model).to(torch.device(\"cuda\"))\n",
    "  model2.load_state_dict(model.state_dict())\n",
    "  loss_fn = torch.nn.MSELoss()\n",
    "  learning_rate = 1e-3\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  return model2\n",
    "\n",
    "def update_target():\n",
    "  global model, model2\n",
    "  model2.load_state_dict(model.state_dict())\n",
    "\n",
    "def get_qvals(state):\n",
    "    with torch.no_grad():\n",
    "        state1 = torch.from_numpy(state).float().to(torch.device(\"cuda\"))\n",
    "        qvals_torch = model(state1)\n",
    "        qvals = qvals_torch.cpu().detach().numpy()\n",
    "    return qvals\n",
    "\n",
    "def get_maxQ(s):\n",
    "    with torch.no_grad():\n",
    "        return torch.max(model2(torch.from_numpy(s).float().to(torch.device(\"cuda\")))).item()\n",
    "\n",
    "\n",
    "def train_one_step(states, actions, targets, gamma):\n",
    "    # pass to this function: state1_batch, action_batch, TD_batch\n",
    "    global model, model2, optimizer, loss_fn\n",
    "    state1_batch = torch.from_numpy(np.array(states)).float().to(torch.device(\"cuda\"))\n",
    "    action_batch = torch.LongTensor(actions).to(torch.device(\"cuda\"))\n",
    "    target_batch = torch.FloatTensor(targets).to(torch.device(\"cuda\"))\n",
    "    current_q_values = model(state1_batch)\n",
    "    current_q_values = current_q_values.gather(1, action_batch.unsqueeze(1))\n",
    "    loss = loss_fn(current_q_values, target_batch.unsqueeze(1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn2VjKycCgdK"
   },
   "source": [
    "### Environment Set-up\n",
    "\n",
    "The Environment class defined a n*n grid with movement of 'up', 'down', 'left', 'right' allowed. Both starting and pacel coordinates are randomly allocated in every episode. The reward are set with 100 for item pickup state, 500 for parcel delivered state and -3 for the rest of the state.\n",
    "\n",
    "Upon every new action taken, the environment generate a new 5-dimensional state of agent's coordinate, parcel's coordinate, and pick up status. The environment also return the corresponding reward and check if the task being completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nBSgQLdCkVD"
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, size):\n",
    "        # Initialize the environment with a given size\n",
    "        # size: integer representing the dimensions of the grid (size x size)\n",
    "        # Example: If size = 5, the grid will be 5x5\n",
    "        self.dimensions = size\n",
    "        # Define possible moves for the agent\n",
    "        self.possible_moves = ['Up', 'Down', 'Right', 'Left']\n",
    "        self.reset_environment()\n",
    "\n",
    "    def reset_environment(self):\n",
    "        # Reset the environment for a new episode\n",
    "        # This method randomizes the positions of the agent, item, and destination\n",
    "        # Example: In a 5x5 grid, we might have:\n",
    "        # agent_location = [0, 2], item_location = [3, 4], destination = [4, 1]\n",
    "        self.agent_location = self._place_randomly()\n",
    "        self.item_location = self._place_randomly()\n",
    "        self.destination = self._place_randomly()\n",
    "        self.item_carried = False\n",
    "\n",
    "        # Ensure agent, item, and destination are in different locations\n",
    "        # This while loop keeps regenerating positions until all three are unique\n",
    "        while np.array_equal(self.agent_location, self.item_location) or np.array_equal(self.agent_location, self.destination) or np.array_equal(self.item_location, self.destination):\n",
    "            self.agent_location = self._place_randomly()\n",
    "            self.item_location = self._place_randomly()\n",
    "            self.destination = self._place_randomly()\n",
    "\n",
    "        return self._get_state()\n",
    "\n",
    "    def _place_randomly(self):\n",
    "        # Generate a random position within the grid\n",
    "        # Returns: numpy array [x, y] where 0 <= x, y < self.dimensions\n",
    "        # Example: In a 5x5 grid, this might return [2, 3]\n",
    "        return np.array([random.randint(0, self.dimensions - 1), random.randint(0, self.dimensions - 1)])\n",
    "\n",
    "    def _get_state(self):\n",
    "        # Encode the current state of the environment as a binary array\n",
    "        # Returns: numpy array of length 48 representing the state\n",
    "        # The state is encoded as follows:\n",
    "        # - First 16 bits: agent position (one-hot encoded)\n",
    "        # - Next 16 bits: item position (one-hot encoded, or all 0 if item is carried)\n",
    "        # - Next 15 bits: destination position (one-hot encoded)\n",
    "        # - Last bit: whether the item is carried (1) or not (0)\n",
    "        state = np.zeros(48, dtype=int)\n",
    "\n",
    "        # Calculate positions in the flattened grid\n",
    "        # Example: In a 4x4 grid, position [1, 2] would be 1*4 + 2 = 6\n",
    "        agent_pos = int(self.agent_location[0] * self.dimensions + self.agent_location[1])\n",
    "        item_pos = int(self.item_location[0] * self.dimensions + self.item_location[1])\n",
    "        dest_pos = int(self.destination[0] * self.dimensions + self.destination[1])\n",
    "\n",
    "        # Set corresponding bits in the state array\n",
    "        state[agent_pos] = 1\n",
    "        state[item_pos + 16] = 1 if not self.item_carried else 0\n",
    "        state[dest_pos + 32] = 1\n",
    "        if self.item_carried:\n",
    "            state[48] = 1\n",
    "\n",
    "        return state\n",
    "\n",
    "    def execute_move(self, move):\n",
    "        # Execute a move and update the agent's position\n",
    "        # move: string, one of 'Up', 'Down', 'Right', 'Left'\n",
    "        # Returns: new agent location after the move\n",
    "        # Example: If agent is at [2, 2] and move is 'Up', new position is [1, 2]\n",
    "        move_effects = {\n",
    "            'Up': np.array([-1, 0]),\n",
    "            'Down': np.array([1, 0]),\n",
    "            'Right': np.array([0, 1]),\n",
    "            'Left': np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        if move in move_effects:\n",
    "            new_location = self.agent_location + move_effects[move]\n",
    "            # Check if the new location is within the grid boundaries\n",
    "            if np.all((new_location >= 0) & (new_location < self.dimensions)):\n",
    "                self.agent_location = new_location\n",
    "\n",
    "        return self.agent_location\n",
    "\n",
    "    def update_item_status(self):\n",
    "        # Update the status of the item (picked up or not)\n",
    "        # If the agent is at the item's location and hasn't picked it up yet, pick it up\n",
    "        # Example: If agent_location = [2, 3] and item_location = [2, 3], item_carried becomes True\n",
    "        if np.array_equal(self.agent_location, self.item_location) and not self.item_carried:\n",
    "            self.item_carried = True\n",
    "\n",
    "    def determine_reward(self):\n",
    "        # Calculate the reward based on the current state\n",
    "        # Returns: integer reward value\n",
    "        # Reward structure:\n",
    "        # - Picking up the item: +100\n",
    "        # - Reaching item location while carrying the item: -50 (discourages loitering)\n",
    "        # - Reaching destination with item: +500 (task completion)\n",
    "        # - Any other move: -3 (encourages efficiency)\n",
    "        if np.array_equal(self.agent_location, self.item_location) and not self.item_carried:\n",
    "            self.item_carried = True\n",
    "            return 100\n",
    "        elif np.array_equal(self.agent_location, self.item_location) and self.item_carried:\n",
    "            return -50\n",
    "        elif np.array_equal(self.agent_location, self.destination) and self.item_carried:\n",
    "            return 500\n",
    "        else:\n",
    "            return -3\n",
    "\n",
    "    def take_action(self, move):\n",
    "        # Execute a full action cycle: move, update state, calculate reward\n",
    "        # move: string, one of 'Up', 'Down', 'Right', 'Left'\n",
    "        # Returns: tuple (new_state, reward, task_complete, info)\n",
    "        # Example:\n",
    "        # - Initial state: agent at [1, 1], item at [1, 2], not carried\n",
    "        # - Action: 'Right'\n",
    "        # - Result: agent moves to [1, 2], picks up item, gets reward 100\n",
    "        #           new state reflects item being carried, task not complete yet\n",
    "        self.execute_move(move)\n",
    "        reward = self.determine_reward()\n",
    "        self.update_item_status()\n",
    "        task_complete = np.array_equal(self.agent_location, self.destination) and self.item_carried\n",
    "        state = self._get_state()\n",
    "        return state, reward, task_complete, {}\n",
    "\n",
    "    def manhattan_distance(self, point1, point2):\n",
    "        # Calculate the Manhattan distance between two points\n",
    "        # point1, point2: numpy arrays [x, y]\n",
    "        # Returns: integer distance\n",
    "        # Example: Distance between [1, 1] and [4, 3] is |4-1| + |3-1| = 5\n",
    "        return abs(point1[0] - point2[0]) + abs(point1[1] - point2[1])\n",
    "\n",
    "    def cal_best_performance(self):\n",
    "        # Calculate the optimal path length\n",
    "        # Returns: integer, minimum number of steps to complete the task\n",
    "        # Example: If agent is at [0, 0], item at [2, 2], and destination at [4, 4]\n",
    "        # Best performance would be: 4 (to item) + 4 (to destination) = 8 steps\n",
    "        to_item = self.manhattan_distance(self.agent_location, self.item_location)\n",
    "        to_goal = self.manhattan_distance(self.item_location, self.destination)\n",
    "        return to_item + to_goal\n",
    "\n",
    "    def cal_best_reward(self):\n",
    "        # Calculate the maximum possible reward for the current configuration\n",
    "        # Returns: integer, best possible reward\n",
    "        # Example: If best performance is 8 steps\n",
    "        # Best reward = 606 - (8 * 3) = 582\n",
    "        # 606 is the sum of rewards for pickup (100) and delivery (500)\n",
    "        # Each step costs 3, so we subtract (best_step * 3)\n",
    "        best_step = self.cal_best_performance()\n",
    "        return 606 - best_step * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9gsg2DCCn68"
   },
   "source": [
    "### Q-learning Agent class\n",
    "\n",
    "- Using DQN neural network model to train and solve the path selection problem of agents, mainly by minimizing the loss of predicted target Q value to update parameters, and using MSEloss to calculate the loss and backpropagation to perform gradient descent calculation, making the predicted Q value closer to the TD target value.\n",
    "In the early stage of training, the next action is randomly selected and the current state is recorded, and the data is stored in a buffer. After storing 400 steps of information, the previously stored information is randomly selected to update the Q-value network.\n",
    "The buffer follows the first in, first out principle. When the upper limit is reached, the first state to enter will be cleared and the loop will be repeated until the training is completed. The approximate structure is shown in the figure:\n",
    "\n",
    "  -\n",
    "   [](https://s2.loli.net/2024/09/15/x8BJhGzLqU5QeWp.png)\n",
    "  <img src = \"https://s2.loli.net/2024/09/15/x8BJhGzLqU5QeWp.png\" width = \"50%\" height = \"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP0ZzfuVCtxz"
   },
   "outputs": [],
   "source": [
    "class DeepQLearningAgent_A2:\n",
    "    def __init__(self, possible_moves, learning_rate, future_reward_discount, initial_exploration_rate, min_exploration_rate, exploration_rate_decay, replay_buffer_size, batch_size, copy_frequency):\n",
    "        # Initialize the Deep Q-learning agent with learning parameters\n",
    "\n",
    "        self.possible_moves = possible_moves  # List of actions the agent can take\n",
    "        # ['Up', 'Down', 'Left', 'Right']\n",
    "\n",
    "        self.learning_rate = learning_rate  # Learning rate for the neural network\n",
    "        # determines how much to adjust the model in response to the estimated error each time the model weights are updated\n",
    "\n",
    "        self.future_discount = future_reward_discount  # Discount factor for future rewards\n",
    "        # a high value (close to 1) means the agent cares more about long-term reward\n",
    "\n",
    "        self.exploration_rate = initial_exploration_rate  # Initial exploration rate for epsilon-greedy policy\n",
    "        # start with 100% random actions to encourage exploration\n",
    "\n",
    "        self.min_exploration_rate = min_exploration_rate  # Minimum exploration rate after decay\n",
    "        # ensure at least 1% of actions are random even after long training\n",
    "\n",
    "        self.exploration_decay = exploration_rate_decay  # Factor for exploration rate decay\n",
    "        #multiply exploration rate by this value after each episode\n",
    "\n",
    "        self.replay_buffer = deque(maxlen=replay_buffer_size)  # Experience replay buffer\n",
    "        # deque with maxlen=10000 to store the last 10000 experiences\n",
    "\n",
    "        self.batch_size = batch_size  # Size of minibatch for training\n",
    "        # train on 200 random samples from the replay buffer at each step\n",
    "\n",
    "        self.copy_frequency = copy_frequency  # Frequency of copying main network to target network\n",
    "        # copy weights every 500 steps to stabilize training\n",
    "\n",
    "        self.step_count = 0  # Counter for total steps taken\n",
    "\n",
    "        # Dictionaries to track agent's performance during training and testing\n",
    "        self.performance_history = {'rewards': [], 'best_rewards': [], 'steps': [], 'best_steps': [], 'exploration_rate': []}\n",
    "        self.test_history = {'rewards': [], 'best_rewards': [], 'steps': [], 'best_steps': []}\n",
    "\n",
    "        # Initialize neural network models, optimizer, and loss function\n",
    "        global model, model2, optimizer, loss_fn\n",
    "        model2 = prepare_torch()  # This initializes model, model2, optimizer, and loss_fn\n",
    "\n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        # Store a transition in the replay buffer\n",
    "        #\n",
    "        # Parameters:\n",
    "        # - state: Current state (e.g., [0,0,1,0,0,0,1,0] representing agent and item positions)\n",
    "        # - action: Action taken (e.g., 'Up')\n",
    "        # - reward: Reward received (e.g., -3 for a normal move, 100 for picking up the item)\n",
    "        # - next_state: Resulting state after taking the action\n",
    "        # - done: Boolean indicating if the episode has ended\n",
    "        #\n",
    "        # self.store_transition([0,0,1,0,0,0,1,0], 'Up', -3, [0,1,0,0,0,0,1,0], False)\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Choose an action using epsilon-greedy policy during training\n",
    "        if random.random() < self.exploration_rate:\n",
    "            return random.choice(self.possible_moves)  # Explore: choose random action\n",
    "        else:\n",
    "            q_values = get_qvals(state)  # Exploit: get Q-values from the neural network\n",
    "            return self.possible_moves[np.argmax(q_values)]  # Choose action with highest Q-value\n",
    "\n",
    "        # If exploration_rate is 0.1, there's a 10% chance of choosing a random action\n",
    "        # If not exploring, and Q-values are [0.1, 0.2, 0.15, 0.05] for ['Up', 'Down', 'Left', 'Right']\n",
    "        # The method will return 'Down' as it has the highest Q-value\n",
    "\n",
    "    def choose_action_test(self, state):\n",
    "        # Choose an action for testing (no exploration)\n",
    "        with torch.no_grad():\n",
    "            q_values = get_qvals(state)\n",
    "        return self.possible_moves[np.argmax(q_values)]\n",
    "\n",
    "        # If Q-values are [0.1, 0.2, 0.15, 0.05] for ['Up', 'Down', 'Left', 'Right']\n",
    "        # The method will always return 'Down' as it has the highest Q-value\n",
    "\n",
    "    def sample_minibatch(self, batch_size):\n",
    "        # Sample a minibatch of transitions from the replay buffer\n",
    "        minibatch = random.sample(self.replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "        return np.array(states), actions, np.array(rewards), np.array(next_states), np.array(dones)\n",
    "\n",
    "        # If batch_size is 2, it might return:\n",
    "        # states: np.array([[0,0,1,0,0,0,1,0], [0,1,0,0,0,0,1,0]])\n",
    "        # actions: ('Up', 'Down')\n",
    "        # rewards: np.array([-3, 100])\n",
    "        # next_states: np.array([[0,1,0,0,0,0,1,0], [0,0,0,1,0,0,1,0]])\n",
    "        # dones: np.array([False, False])\n",
    "\n",
    "    def update_q_network(self, states, actions, td_targets):\n",
    "        # Update the Q-network using a batch of experiences\n",
    "        #\n",
    "        # Parameters:\n",
    "        # - states: Batch of states\n",
    "        # - actions: Batch of actions taken\n",
    "        # - td_targets: Batch of TD targets (Q-learning targets)\n",
    "        action_indices = [self.possible_moves.index(a) for a in actions]\n",
    "        loss = train_one_step(states, action_indices, td_targets, self.future_discount)\n",
    "        return loss\n",
    "\n",
    "        # If states = [[0,0,1,0,0,0,1,0], [0,1,0,0,0,0,1,0]]\n",
    "        # actions = ['Up', 'Down']\n",
    "        # td_targets = [97, 95]  (calculated from reward + future_discount * max future Q-value)\n",
    "        # This will update the Q-network to better predict these TD targets for the given states and actions\n",
    "\n",
    "    def update_target_network(self):\n",
    "        # Update the target network by copying weights from the main network\n",
    "        update_target()\n",
    "\n",
    "        # This stabilizes training by providing a stable target for Q-value updates\n",
    "        # It's typically called every `copy_frequency` steps\n",
    "\n",
    "    def adjust_learning_parameters(self):\n",
    "        # Adjust the exploration rate (decay epsilon)\n",
    "        self.exploration_rate = max(self.min_exploration_rate, self.exploration_rate * self.exploration_decay)\n",
    "\n",
    "        # If current exploration_rate is 0.5 and exploration_decay is 0.995:\n",
    "        # New exploration_rate = max(0.01, 0.5 * 0.995) = 0.4975\n",
    "        # This gradually reduces random actions as the agent learns\n",
    "\n",
    "    def record_performance(self, reward, best_reward, steps, best_steps):\n",
    "        # Record performance metrics for the current training episode\n",
    "        self.performance_history['rewards'].append(reward)\n",
    "        self.performance_history['best_rewards'].append(best_reward)\n",
    "        self.performance_history['steps'].append(steps)\n",
    "        self.performance_history['best_steps'].append(best_steps)\n",
    "        self.performance_history['exploration_rate'].append(self.exploration_rate)\n",
    "\n",
    "        # After an episode where the agent got a total reward of 450 in 20 steps,\n",
    "        # and the best possible reward was 500 in 15 steps:\n",
    "        # record_performance(450, 500, 20, 15)\n",
    "\n",
    "    def record_performance_test(self, reward, best_reward, steps, best_steps):\n",
    "        # Record performance metrics for the current testing episode\n",
    "        self.test_history['rewards'].append(reward)\n",
    "        self.test_history['best_rewards'].append(best_reward)\n",
    "        self.test_history['steps'].append(steps)\n",
    "        self.test_history['best_steps'].append(best_steps)\n",
    "\n",
    "        # Similar to record_performance, but used during testing phases\n",
    "        # This allows comparison between training and testing performance\n",
    "\n",
    "    def get_q_values(self, state):\n",
    "        # Get Q-values for all actions in the given state\n",
    "        return get_qvals(state)\n",
    "\n",
    "        # For state [0,0,1,0,0,0,1,0], it might return:\n",
    "        # [0.1, 0.2, 0.15, 0.05] for actions ['Up', 'Down', 'Left', 'Right']\n",
    "\n",
    "    def get_max_q_value(self, state):\n",
    "        # Get the maximum Q-value for the given state\n",
    "        return get_maxQ(state)\n",
    "\n",
    "        # If get_q_values(state) returns [0.1, 0.2, 0.15, 0.05]\n",
    "        # This method will return 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfl4RgstCzge"
   },
   "outputs": [],
   "source": [
    "#A2 parameters\n",
    "\n",
    "grid_size = 4\n",
    "learning_rate = 0.997\n",
    "future_reward_discount = 0.9\n",
    "initial_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.1\n",
    "exploration_rate_decay = 0.997\n",
    "num_training_episodes = 10000\n",
    "max_step_limit = 100\n",
    "replay_buffer_size = 1000\n",
    "batch_size = 200\n",
    "copy_frequency = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFnca_o6C1n6"
   },
   "source": [
    "### Main Training phase\n",
    "Main training phases for updating q-values for the q-table upon each steps being exacuted. Metrics including steps taken for termination and cumulative rewards are stored for further performance evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2nDl-LgC4lx"
   },
   "outputs": [],
   "source": [
    "def train_intelligent_agent_A2(environment, agent, num_training_episodes, max_step_limit, print_interval=1):\n",
    "    total_steps = 0\n",
    "    episode_train_count = 0\n",
    "    for episode in range(num_training_episodes):\n",
    "        agent.adjust_learning_parameters()\n",
    "        state = environment.reset_environment()\n",
    "        best_steps = environment.cal_best_performance()\n",
    "        episode_best_reward = environment.cal_best_reward()\n",
    "        episode_reward = 0\n",
    "        episode_loss = 0\n",
    "\n",
    "        for step in range(max_step_limit):\n",
    "            # Sample phase\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done, _ = environment.take_action(action)\n",
    "\n",
    "            # Store transition in the experience replay buffer\n",
    "            agent.store_transition(state, action, reward, next_state, done)\n",
    "\n",
    "            total_steps += 1\n",
    "            episode_reward += reward\n",
    "\n",
    "            # Learn phase when step is greater than 200 which mean each step will train ones\n",
    "            if total_steps > agent.batch_size:\n",
    "                states, actions, rewards, next_states, dones = agent.sample_minibatch(agent.batch_size)\n",
    "\n",
    "                td_targets = []\n",
    "                for i in range(agent.batch_size):\n",
    "                    best_future_value = get_maxQ(next_states[i])\n",
    "                    td_target = rewards[i] + agent.future_discount * best_future_value * (1 - dones[i])\n",
    "                    td_targets.append(td_target)\n",
    "\n",
    "                action_idxs = [environment.possible_moves.index(j) for j in actions]\n",
    "\n",
    "                loss = train_one_step(states, action_idxs, td_targets, agent.future_discount)\n",
    "\n",
    "                episode_loss += loss\n",
    "                episode_train_count += 1\n",
    "\n",
    "            # Update target network every 500 steps\n",
    "            if total_steps % agent.copy_frequency == 0:\n",
    "                update_target()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        # End of episode\n",
    "        agent.record_performance(episode_reward, episode_best_reward, step + 1, best_steps)\n",
    "        # print summary of the tranning\n",
    "        if episode % print_interval == 0:\n",
    "            print(f\"Episode {episode + 1}: Reward = {episode_reward:.2f}, \"\n",
    "                  f\"Steps = {step + 1}, Loss = {episode_loss / (step + 1):.4f}, \"\n",
    "                  f\"Exploration Rate = {agent.exploration_rate:.4f}, \"\n",
    "                  f\"Train Count = {episode_train_count}\")\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtBBeIBJC70D"
   },
   "source": [
    "### Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NC18USxD4Ae",
    "outputId": "ee711617-cd32-42c0-f127-182574e923a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = 263.00, Steps = 36, Loss = 0.0000, Exploration Rate = 0.9970, Train Count = 0\n",
      "Episode 2: Reward = 273.00, Steps = 64, Loss = 0.0000, Exploration Rate = 0.9940, Train Count = 0\n",
      "Episode 3: Reward = -761.00, Steps = 100, Loss = 0.0000, Exploration Rate = 0.9910, Train Count = 0\n",
      "Episode 4: Reward = -385.00, Steps = 100, Loss = 2393.3536, Exploration Rate = 0.9881, Train Count = 100\n",
      "Episode 5: Reward = 399.00, Steps = 69, Loss = 1555.2474, Exploration Rate = 0.9851, Train Count = 169\n",
      "Episode 6: Reward = 484.00, Steps = 25, Loss = 1805.0140, Exploration Rate = 0.9821, Train Count = 194\n",
      "Episode 7: Reward = -300.00, Steps = 100, Loss = 1787.3928, Exploration Rate = 0.9792, Train Count = 294\n",
      "Episode 8: Reward = -300.00, Steps = 100, Loss = 1314.8373, Exploration Rate = 0.9763, Train Count = 394\n",
      "Episode 9: Reward = 75.00, Steps = 83, Loss = 1085.3635, Exploration Rate = 0.9733, Train Count = 477\n",
      "Episode 10: Reward = 443.00, Steps = 23, Loss = 1044.2874, Exploration Rate = 0.9704, Train Count = 500\n",
      "Episode 11: Reward = 203.00, Steps = 56, Loss = 1317.7242, Exploration Rate = 0.9675, Train Count = 556\n",
      "Episode 12: Reward = 442.00, Steps = 39, Loss = 1464.9162, Exploration Rate = 0.9646, Train Count = 595\n",
      "Episode 13: Reward = -244.00, Steps = 100, Loss = 1409.3329, Exploration Rate = 0.9617, Train Count = 695\n",
      "Episode 14: Reward = 597.00, Steps = 3, Loss = 1830.4243, Exploration Rate = 0.9588, Train Count = 698\n",
      "Episode 15: Reward = 520.00, Steps = 13, Loss = 1631.2559, Exploration Rate = 0.9559, Train Count = 711\n",
      "Episode 16: Reward = 240.00, Steps = 75, Loss = 1592.2346, Exploration Rate = 0.9531, Train Count = 786\n",
      "Episode 17: Reward = 450.00, Steps = 52, Loss = 2352.0257, Exploration Rate = 0.9502, Train Count = 838\n",
      "Episode 18: Reward = 582.00, Steps = 8, Loss = 2222.0982, Exploration Rate = 0.9474, Train Count = 846\n",
      "Episode 19: Reward = 260.00, Steps = 37, Loss = 1835.5898, Exploration Rate = 0.9445, Train Count = 883\n",
      "Episode 20: Reward = 304.00, Steps = 85, Loss = 1733.9104, Exploration Rate = 0.9417, Train Count = 968\n",
      "Episode 21: Reward = 346.00, Steps = 24, Loss = 1819.6981, Exploration Rate = 0.9389, Train Count = 992\n",
      "Episode 22: Reward = 489.00, Steps = 39, Loss = 1594.2961, Exploration Rate = 0.9360, Train Count = 1031\n",
      "Episode 23: Reward = 423.00, Steps = 14, Loss = 1608.7441, Exploration Rate = 0.9332, Train Count = 1045\n",
      "Episode 24: Reward = 362.00, Steps = 50, Loss = 1770.5159, Exploration Rate = 0.9304, Train Count = 1095\n",
      "Episode 25: Reward = 207.00, Steps = 39, Loss = 1587.8247, Exploration Rate = 0.9276, Train Count = 1134\n",
      "Episode 26: Reward = -714.00, Steps = 100, Loss = 1534.5592, Exploration Rate = 0.9249, Train Count = 1234\n",
      "Episode 27: Reward = 395.00, Steps = 39, Loss = 1363.7111, Exploration Rate = 0.9221, Train Count = 1273\n",
      "Episode 28: Reward = 582.00, Steps = 8, Loss = 1687.9467, Exploration Rate = 0.9193, Train Count = 1281\n",
      "Episode 29: Reward = -653.00, Steps = 75, Loss = 2191.7347, Exploration Rate = 0.9166, Train Count = 1356\n",
      "Episode 30: Reward = 354.00, Steps = 84, Loss = 1781.6477, Exploration Rate = 0.9138, Train Count = 1440\n",
      "Episode 31: Reward = 510.00, Steps = 32, Loss = 1669.2581, Exploration Rate = 0.9111, Train Count = 1472\n",
      "Episode 32: Reward = 458.00, Steps = 18, Loss = 1632.8219, Exploration Rate = 0.9083, Train Count = 1490\n",
      "Episode 33: Reward = 451.00, Steps = 36, Loss = 1559.3978, Exploration Rate = 0.9056, Train Count = 1526\n",
      "Episode 34: Reward = 408.00, Steps = 66, Loss = 1467.1500, Exploration Rate = 0.9029, Train Count = 1592\n",
      "Episode 35: Reward = 311.00, Steps = 67, Loss = 1323.9627, Exploration Rate = 0.9002, Train Count = 1659\n",
      "Episode 36: Reward = 364.00, Steps = 65, Loss = 1254.9333, Exploration Rate = 0.8975, Train Count = 1724\n",
      "Episode 37: Reward = -300.00, Steps = 100, Loss = 1402.2654, Exploration Rate = 0.8948, Train Count = 1824\n",
      "Episode 38: Reward = 466.00, Steps = 31, Loss = 1559.5133, Exploration Rate = 0.8921, Train Count = 1855\n",
      "Episode 39: Reward = 558.00, Steps = 16, Loss = 1308.5525, Exploration Rate = 0.8894, Train Count = 1871\n",
      "Episode 40: Reward = 272.00, Steps = 33, Loss = 1214.7026, Exploration Rate = 0.8868, Train Count = 1904\n",
      "Episode 41: Reward = 458.00, Steps = 18, Loss = 1140.2756, Exploration Rate = 0.8841, Train Count = 1922\n",
      "Episode 42: Reward = 511.00, Steps = 16, Loss = 1278.1458, Exploration Rate = 0.8814, Train Count = 1938\n",
      "Episode 43: Reward = 558.00, Steps = 16, Loss = 1418.6480, Exploration Rate = 0.8788, Train Count = 1954\n",
      "Episode 44: Reward = 425.00, Steps = 29, Loss = 1159.7058, Exploration Rate = 0.8762, Train Count = 1983\n",
      "Episode 45: Reward = 396.00, Steps = 70, Loss = 1030.3082, Exploration Rate = 0.8735, Train Count = 2053\n",
      "Episode 46: Reward = 467.00, Steps = 15, Loss = 961.0240, Exploration Rate = 0.8709, Train Count = 2068\n",
      "Episode 47: Reward = 463.00, Steps = 32, Loss = 923.4490, Exploration Rate = 0.8683, Train Count = 2100\n",
      "Episode 48: Reward = 540.00, Steps = 22, Loss = 848.1728, Exploration Rate = 0.8657, Train Count = 2122\n",
      "Episode 49: Reward = 404.00, Steps = 36, Loss = 816.6832, Exploration Rate = 0.8631, Train Count = 2158\n",
      "Episode 50: Reward = 383.00, Steps = 43, Loss = 913.8856, Exploration Rate = 0.8605, Train Count = 2201\n",
      "Episode 51: Reward = 454.00, Steps = 35, Loss = 771.6643, Exploration Rate = 0.8579, Train Count = 2236\n",
      "Episode 52: Reward = 265.00, Steps = 51, Loss = 783.5271, Exploration Rate = 0.8554, Train Count = 2287\n",
      "Episode 53: Reward = -479.00, Steps = 100, Loss = 1174.1624, Exploration Rate = 0.8528, Train Count = 2387\n",
      "Episode 54: Reward = -300.00, Steps = 100, Loss = 681.8545, Exploration Rate = 0.8502, Train Count = 2487\n",
      "Episode 55: Reward = -385.00, Steps = 100, Loss = 483.1323, Exploration Rate = 0.8477, Train Count = 2587\n",
      "Episode 56: Reward = 534.00, Steps = 24, Loss = 546.8388, Exploration Rate = 0.8451, Train Count = 2611\n",
      "Episode 57: Reward = 96.00, Steps = 76, Loss = 437.6571, Exploration Rate = 0.8426, Train Count = 2687\n",
      "Episode 58: Reward = -27.00, Steps = 70, Loss = 470.7590, Exploration Rate = 0.8401, Train Count = 2757\n",
      "Episode 59: Reward = 501.00, Steps = 35, Loss = 429.6307, Exploration Rate = 0.8376, Train Count = 2792\n",
      "Episode 60: Reward = 489.00, Steps = 39, Loss = 1099.4531, Exploration Rate = 0.8350, Train Count = 2831\n",
      "Episode 61: Reward = 131.00, Steps = 80, Loss = 683.6430, Exploration Rate = 0.8325, Train Count = 2911\n",
      "Episode 62: Reward = 276.00, Steps = 63, Loss = 626.7079, Exploration Rate = 0.8300, Train Count = 2974\n",
      "Episode 63: Reward = 469.00, Steps = 30, Loss = 517.0678, Exploration Rate = 0.8276, Train Count = 3004\n",
      "Episode 64: Reward = 331.00, Steps = 29, Loss = 559.4204, Exploration Rate = 0.8251, Train Count = 3033\n",
      "Episode 65: Reward = 525.00, Steps = 27, Loss = 651.0935, Exploration Rate = 0.8226, Train Count = 3060\n",
      "Episode 66: Reward = 248.00, Steps = 88, Loss = 501.9813, Exploration Rate = 0.8201, Train Count = 3148\n",
      "Episode 67: Reward = 271.00, Steps = 49, Loss = 412.3514, Exploration Rate = 0.8177, Train Count = 3197\n",
      "Episode 68: Reward = 445.00, Steps = 38, Loss = 385.5284, Exploration Rate = 0.8152, Train Count = 3235\n",
      "Episode 69: Reward = 361.00, Steps = 19, Loss = 446.8658, Exploration Rate = 0.8128, Train Count = 3254\n",
      "Episode 70: Reward = 483.00, Steps = 41, Loss = 475.6198, Exploration Rate = 0.8103, Train Count = 3295\n",
      "Episode 71: Reward = 388.00, Steps = 57, Loss = 990.4736, Exploration Rate = 0.8079, Train Count = 3352\n",
      "Episode 72: Reward = 409.00, Steps = 50, Loss = 573.2491, Exploration Rate = 0.8055, Train Count = 3402\n",
      "Episode 73: Reward = 327.00, Steps = 46, Loss = 506.9907, Exploration Rate = 0.8031, Train Count = 3448\n",
      "Episode 74: Reward = 478.00, Steps = 27, Loss = 465.1849, Exploration Rate = 0.8006, Train Count = 3475\n",
      "Episode 75: Reward = 209.00, Steps = 54, Loss = 463.5375, Exploration Rate = 0.7982, Train Count = 3529\n",
      "Episode 76: Reward = 414.00, Steps = 64, Loss = 370.7315, Exploration Rate = 0.7959, Train Count = 3593\n",
      "Episode 77: Reward = 570.00, Steps = 12, Loss = 341.1468, Exploration Rate = 0.7935, Train Count = 3605\n",
      "Episode 78: Reward = 405.00, Steps = 67, Loss = 426.9560, Exploration Rate = 0.7911, Train Count = 3672\n",
      "Episode 79: Reward = 546.00, Steps = 20, Loss = 357.8419, Exploration Rate = 0.7887, Train Count = 3692\n",
      "Episode 80: Reward = 437.00, Steps = 25, Loss = 479.4591, Exploration Rate = 0.7863, Train Count = 3717\n",
      "Episode 81: Reward = 420.00, Steps = 62, Loss = 456.7923, Exploration Rate = 0.7840, Train Count = 3779\n",
      "Episode 82: Reward = 417.00, Steps = 16, Loss = 482.6387, Exploration Rate = 0.7816, Train Count = 3795\n",
      "Episode 83: Reward = 549.00, Steps = 19, Loss = 987.9070, Exploration Rate = 0.7793, Train Count = 3814\n",
      "Episode 84: Reward = 600.00, Steps = 2, Loss = 745.9183, Exploration Rate = 0.7770, Train Count = 3816\n",
      "Episode 85: Reward = 416.00, Steps = 32, Loss = 732.1174, Exploration Rate = 0.7746, Train Count = 3848\n",
      "Episode 86: Reward = 429.00, Steps = 59, Loss = 489.2265, Exploration Rate = 0.7723, Train Count = 3907\n",
      "Episode 87: Reward = 464.00, Steps = 16, Loss = 367.4051, Exploration Rate = 0.7700, Train Count = 3923\n",
      "Episode 88: Reward = 394.00, Steps = 55, Loss = 359.6508, Exploration Rate = 0.7677, Train Count = 3978\n",
      "Episode 89: Reward = 437.00, Steps = 25, Loss = 302.8680, Exploration Rate = 0.7654, Train Count = 4003\n",
      "Episode 90: Reward = 210.00, Steps = 38, Loss = 323.4802, Exploration Rate = 0.7631, Train Count = 4041\n",
      "Episode 91: Reward = 502.00, Steps = 19, Loss = 350.3557, Exploration Rate = 0.7608, Train Count = 4060\n",
      "Episode 92: Reward = 151.00, Steps = 89, Loss = 335.2369, Exploration Rate = 0.7585, Train Count = 4149\n",
      "Episode 93: Reward = 436.00, Steps = 41, Loss = 303.0543, Exploration Rate = 0.7562, Train Count = 4190\n",
      "Episode 94: Reward = 240.00, Steps = 28, Loss = 301.8997, Exploration Rate = 0.7540, Train Count = 4218\n",
      "Episode 95: Reward = 546.00, Steps = 20, Loss = 287.3250, Exploration Rate = 0.7517, Train Count = 4238\n",
      "Episode 96: Reward = 531.00, Steps = 25, Loss = 269.8568, Exploration Rate = 0.7494, Train Count = 4263\n",
      "Episode 97: Reward = 414.00, Steps = 17, Loss = 236.3506, Exploration Rate = 0.7472, Train Count = 4280\n",
      "Episode 98: Reward = 461.00, Steps = 17, Loss = 277.2353, Exploration Rate = 0.7449, Train Count = 4297\n",
      "Episode 99: Reward = 325.00, Steps = 31, Loss = 734.2682, Exploration Rate = 0.7427, Train Count = 4328\n",
      "Episode 100: Reward = 390.00, Steps = 72, Loss = 412.9040, Exploration Rate = 0.7405, Train Count = 4400\n",
      "Episode 101: Reward = 483.00, Steps = 41, Loss = 261.2531, Exploration Rate = 0.7383, Train Count = 4441\n",
      "Episode 102: Reward = 496.00, Steps = 21, Loss = 222.3223, Exploration Rate = 0.7360, Train Count = 4462\n",
      "Episode 103: Reward = 21.00, Steps = 54, Loss = 251.5580, Exploration Rate = 0.7338, Train Count = 4516\n",
      "Episode 104: Reward = 532.00, Steps = 9, Loss = 235.9003, Exploration Rate = 0.7316, Train Count = 4525\n",
      "Episode 105: Reward = 369.00, Steps = 79, Loss = 256.3270, Exploration Rate = 0.7294, Train Count = 4604\n",
      "Episode 106: Reward = 335.00, Steps = 12, Loss = 231.2569, Exploration Rate = 0.7273, Train Count = 4616\n",
      "Episode 107: Reward = 522.00, Steps = 28, Loss = 201.6843, Exploration Rate = 0.7251, Train Count = 4644\n",
      "Episode 108: Reward = 466.00, Steps = 31, Loss = 212.6163, Exploration Rate = 0.7229, Train Count = 4675\n",
      "Episode 109: Reward = 416.00, Steps = 32, Loss = 186.9684, Exploration Rate = 0.7207, Train Count = 4707\n",
      "Episode 110: Reward = 343.00, Steps = 72, Loss = 243.0528, Exploration Rate = 0.7186, Train Count = 4779\n",
      "Episode 111: Reward = 514.00, Steps = 15, Loss = 223.1837, Exploration Rate = 0.7164, Train Count = 4794\n",
      "Episode 112: Reward = 588.00, Steps = 6, Loss = 280.4760, Exploration Rate = 0.7143, Train Count = 4800\n",
      "Episode 113: Reward = 505.00, Steps = 18, Loss = 717.2303, Exploration Rate = 0.7121, Train Count = 4818\n",
      "Episode 114: Reward = 323.00, Steps = 16, Loss = 480.2789, Exploration Rate = 0.7100, Train Count = 4834\n",
      "Episode 115: Reward = 573.00, Steps = 11, Loss = 432.3385, Exploration Rate = 0.7079, Train Count = 4845\n",
      "Episode 116: Reward = 426.00, Steps = 13, Loss = 348.7231, Exploration Rate = 0.7057, Train Count = 4858\n",
      "Episode 117: Reward = -291.00, Steps = 100, Loss = 266.2780, Exploration Rate = 0.7036, Train Count = 4958\n",
      "Episode 118: Reward = 525.00, Steps = 27, Loss = 248.7660, Exploration Rate = 0.7015, Train Count = 4985\n",
      "Episode 119: Reward = 419.00, Steps = 31, Loss = 226.9170, Exploration Rate = 0.6994, Train Count = 5016\n",
      "Episode 120: Reward = 354.00, Steps = 84, Loss = 204.1105, Exploration Rate = 0.6973, Train Count = 5100\n",
      "Episode 121: Reward = 594.00, Steps = 4, Loss = 168.2447, Exploration Rate = 0.6952, Train Count = 5104\n",
      "Episode 122: Reward = 385.00, Steps = 11, Loss = 187.7888, Exploration Rate = 0.6931, Train Count = 5115\n",
      "Episode 123: Reward = 549.00, Steps = 19, Loss = 188.6395, Exploration Rate = 0.6910, Train Count = 5134\n",
      "Episode 124: Reward = 567.00, Steps = 13, Loss = 156.4210, Exploration Rate = 0.6890, Train Count = 5147\n",
      "Episode 125: Reward = 492.00, Steps = 38, Loss = 215.8806, Exploration Rate = 0.6869, Train Count = 5185\n",
      "Episode 126: Reward = 576.00, Steps = 10, Loss = 205.8255, Exploration Rate = 0.6848, Train Count = 5195\n",
      "Episode 127: Reward = 534.00, Steps = 24, Loss = 235.6607, Exploration Rate = 0.6828, Train Count = 5219\n",
      "Episode 128: Reward = 582.00, Steps = 8, Loss = 207.0215, Exploration Rate = 0.6807, Train Count = 5227\n",
      "Episode 129: Reward = 298.00, Steps = 40, Loss = 200.3025, Exploration Rate = 0.6787, Train Count = 5267\n",
      "Episode 130: Reward = -300.00, Steps = 100, Loss = 366.5444, Exploration Rate = 0.6767, Train Count = 5367\n",
      "Episode 131: Reward = 540.00, Steps = 22, Loss = 284.6644, Exploration Rate = 0.6746, Train Count = 5389\n",
      "Episode 132: Reward = 501.00, Steps = 35, Loss = 234.6046, Exploration Rate = 0.6726, Train Count = 5424\n",
      "Episode 133: Reward = 404.00, Steps = 36, Loss = 221.6240, Exploration Rate = 0.6706, Train Count = 5460\n",
      "Episode 134: Reward = 585.00, Steps = 7, Loss = 198.8829, Exploration Rate = 0.6686, Train Count = 5467\n",
      "Episode 135: Reward = 385.00, Steps = 11, Loss = 220.0950, Exploration Rate = 0.6666, Train Count = 5478\n",
      "Episode 136: Reward = 491.00, Steps = 7, Loss = 203.6019, Exploration Rate = 0.6646, Train Count = 5485\n",
      "Episode 137: Reward = 525.00, Steps = 27, Loss = 219.7784, Exploration Rate = 0.6626, Train Count = 5512\n",
      "Episode 138: Reward = 535.00, Steps = 8, Loss = 197.2583, Exploration Rate = 0.6606, Train Count = 5520\n",
      "Episode 139: Reward = 585.00, Steps = 7, Loss = 196.5337, Exploration Rate = 0.6586, Train Count = 5527\n",
      "Episode 140: Reward = 498.00, Steps = 36, Loss = 217.3092, Exploration Rate = 0.6566, Train Count = 5563\n",
      "Episode 141: Reward = 594.00, Steps = 4, Loss = 193.6010, Exploration Rate = 0.6547, Train Count = 5567\n",
      "Episode 142: Reward = 534.00, Steps = 24, Loss = 191.1816, Exploration Rate = 0.6527, Train Count = 5591\n",
      "Episode 143: Reward = 470.00, Steps = 14, Loss = 171.1988, Exploration Rate = 0.6507, Train Count = 5605\n",
      "Episode 144: Reward = 529.00, Steps = 10, Loss = 157.2617, Exploration Rate = 0.6488, Train Count = 5615\n",
      "Episode 145: Reward = 522.00, Steps = 28, Loss = 166.9586, Exploration Rate = 0.6468, Train Count = 5643\n",
      "Episode 146: Reward = 342.00, Steps = 41, Loss = 177.5191, Exploration Rate = 0.6449, Train Count = 5684\n",
      "Episode 147: Reward = 449.00, Steps = 21, Loss = 163.8960, Exploration Rate = 0.6430, Train Count = 5705\n",
      "Episode 148: Reward = 552.00, Steps = 18, Loss = 175.1897, Exploration Rate = 0.6410, Train Count = 5723\n",
      "Episode 149: Reward = 540.00, Steps = 22, Loss = 157.2319, Exploration Rate = 0.6391, Train Count = 5745\n",
      "Episode 150: Reward = 579.00, Steps = 9, Loss = 165.5756, Exploration Rate = 0.6372, Train Count = 5754\n",
      "Episode 151: Reward = 513.00, Steps = 31, Loss = 196.5930, Exploration Rate = 0.6353, Train Count = 5785\n",
      "Episode 152: Reward = 442.00, Steps = 39, Loss = 451.8709, Exploration Rate = 0.6334, Train Count = 5824\n",
      "Episode 153: Reward = 532.00, Steps = 9, Loss = 388.7129, Exploration Rate = 0.6315, Train Count = 5833\n",
      "Episode 154: Reward = 233.00, Steps = 93, Loss = 225.3826, Exploration Rate = 0.6296, Train Count = 5926\n",
      "Episode 155: Reward = 374.00, Steps = 46, Loss = 165.7859, Exploration Rate = 0.6277, Train Count = 5972\n",
      "Episode 156: Reward = 546.00, Steps = 20, Loss = 154.2608, Exploration Rate = 0.6258, Train Count = 5992\n",
      "Episode 157: Reward = 585.00, Steps = 7, Loss = 148.7531, Exploration Rate = 0.6239, Train Count = 5999\n",
      "Episode 158: Reward = 496.00, Steps = 21, Loss = 172.7401, Exploration Rate = 0.6221, Train Count = 6020\n",
      "Episode 159: Reward = 567.00, Steps = 13, Loss = 164.3147, Exploration Rate = 0.6202, Train Count = 6033\n",
      "Episode 160: Reward = -291.00, Steps = 100, Loss = 172.6574, Exploration Rate = 0.6183, Train Count = 6133\n",
      "Episode 161: Reward = 514.00, Steps = 15, Loss = 162.5989, Exploration Rate = 0.6165, Train Count = 6148\n",
      "Episode 162: Reward = 432.00, Steps = 11, Loss = 159.8661, Exploration Rate = 0.6146, Train Count = 6159\n",
      "Episode 163: Reward = 439.00, Steps = 40, Loss = 218.2337, Exploration Rate = 0.6128, Train Count = 6199\n",
      "Episode 164: Reward = 525.00, Steps = 27, Loss = 167.8158, Exploration Rate = 0.6110, Train Count = 6226\n",
      "Episode 165: Reward = 588.00, Steps = 6, Loss = 148.8727, Exploration Rate = 0.6091, Train Count = 6232\n",
      "Episode 166: Reward = 486.00, Steps = 40, Loss = 171.3538, Exploration Rate = 0.6073, Train Count = 6272\n",
      "Episode 167: Reward = 576.00, Steps = 10, Loss = 151.5336, Exploration Rate = 0.6055, Train Count = 6282\n",
      "Episode 168: Reward = 561.00, Steps = 15, Loss = 147.9864, Exploration Rate = 0.6037, Train Count = 6297\n",
      "Episode 169: Reward = 470.00, Steps = 14, Loss = 546.5211, Exploration Rate = 0.6018, Train Count = 6311\n",
      "Episode 170: Reward = 396.00, Steps = 23, Loss = 385.6615, Exploration Rate = 0.6000, Train Count = 6334\n",
      "Episode 171: Reward = 579.00, Steps = 9, Loss = 300.4596, Exploration Rate = 0.5982, Train Count = 6343\n",
      "Episode 172: Reward = 591.00, Steps = 5, Loss = 266.5555, Exploration Rate = 0.5964, Train Count = 6348\n",
      "Episode 173: Reward = 458.00, Steps = 18, Loss = 277.9928, Exploration Rate = 0.5947, Train Count = 6366\n",
      "Episode 174: Reward = 446.00, Steps = 22, Loss = 256.4658, Exploration Rate = 0.5929, Train Count = 6388\n",
      "Episode 175: Reward = 597.00, Steps = 3, Loss = 222.1522, Exploration Rate = 0.5911, Train Count = 6391\n",
      "Episode 176: Reward = 508.00, Steps = 17, Loss = 209.2232, Exploration Rate = 0.5893, Train Count = 6408\n",
      "Episode 177: Reward = 477.00, Steps = 43, Loss = 199.9320, Exploration Rate = 0.5875, Train Count = 6451\n",
      "Episode 178: Reward = 489.00, Steps = 39, Loss = 152.9587, Exploration Rate = 0.5858, Train Count = 6490\n",
      "Episode 179: Reward = 510.00, Steps = 32, Loss = 158.8709, Exploration Rate = 0.5840, Train Count = 6522\n",
      "Episode 180: Reward = 582.00, Steps = 8, Loss = 133.0803, Exploration Rate = 0.5823, Train Count = 6530\n",
      "Episode 181: Reward = 460.00, Steps = 33, Loss = 128.1794, Exploration Rate = 0.5805, Train Count = 6563\n",
      "Episode 182: Reward = 546.00, Steps = 20, Loss = 121.6065, Exploration Rate = 0.5788, Train Count = 6583\n",
      "Episode 183: Reward = 529.00, Steps = 10, Loss = 132.1022, Exploration Rate = 0.5771, Train Count = 6593\n",
      "Episode 184: Reward = 591.00, Steps = 5, Loss = 127.5236, Exploration Rate = 0.5753, Train Count = 6598\n",
      "Episode 185: Reward = 579.00, Steps = 9, Loss = 137.0640, Exploration Rate = 0.5736, Train Count = 6607\n",
      "Episode 186: Reward = 507.00, Steps = 33, Loss = 135.8252, Exploration Rate = 0.5719, Train Count = 6640\n",
      "Episode 187: Reward = 457.00, Steps = 34, Loss = 149.0385, Exploration Rate = 0.5702, Train Count = 6674\n",
      "Episode 188: Reward = 540.00, Steps = 22, Loss = 120.7465, Exploration Rate = 0.5684, Train Count = 6696\n",
      "Episode 189: Reward = 594.00, Steps = 4, Loss = 118.5111, Exploration Rate = 0.5667, Train Count = 6700\n",
      "Episode 190: Reward = 549.00, Steps = 19, Loss = 141.4310, Exploration Rate = 0.5650, Train Count = 6719\n",
      "Episode 191: Reward = 538.00, Steps = 7, Loss = 184.2566, Exploration Rate = 0.5633, Train Count = 6726\n",
      "Episode 192: Reward = 588.00, Steps = 6, Loss = 180.6962, Exploration Rate = 0.5617, Train Count = 6732\n",
      "Episode 193: Reward = 597.00, Steps = 3, Loss = 199.9768, Exploration Rate = 0.5600, Train Count = 6735\n",
      "Episode 194: Reward = 516.00, Steps = 30, Loss = 166.4079, Exploration Rate = 0.5583, Train Count = 6765\n",
      "Episode 195: Reward = 519.00, Steps = 29, Loss = 136.4405, Exploration Rate = 0.5566, Train Count = 6794\n",
      "Episode 196: Reward = 543.00, Steps = 21, Loss = 468.7605, Exploration Rate = 0.5549, Train Count = 6815\n",
      "Episode 197: Reward = 576.00, Steps = 10, Loss = 441.9516, Exploration Rate = 0.5533, Train Count = 6825\n",
      "Episode 198: Reward = 418.00, Steps = 47, Loss = 317.7921, Exploration Rate = 0.5516, Train Count = 6872\n",
      "Episode 199: Reward = 564.00, Steps = 14, Loss = 259.4230, Exploration Rate = 0.5500, Train Count = 6886\n",
      "Episode 200: Reward = 558.00, Steps = 16, Loss = 241.7433, Exploration Rate = 0.5483, Train Count = 6902\n",
      "Episode 201: Reward = 343.00, Steps = 72, Loss = 204.8332, Exploration Rate = 0.5467, Train Count = 6974\n",
      "Episode 202: Reward = 570.00, Steps = 12, Loss = 168.1951, Exploration Rate = 0.5450, Train Count = 6986\n",
      "Episode 203: Reward = 582.00, Steps = 8, Loss = 152.7860, Exploration Rate = 0.5434, Train Count = 6994\n",
      "Episode 204: Reward = 585.00, Steps = 7, Loss = 164.8378, Exploration Rate = 0.5418, Train Count = 7001\n",
      "Episode 205: Reward = 489.00, Steps = 39, Loss = 212.6446, Exploration Rate = 0.5401, Train Count = 7040\n",
      "Episode 206: Reward = 472.00, Steps = 29, Loss = 212.5752, Exploration Rate = 0.5385, Train Count = 7069\n",
      "Episode 207: Reward = 597.00, Steps = 3, Loss = 235.1763, Exploration Rate = 0.5369, Train Count = 7072\n",
      "Episode 208: Reward = 540.00, Steps = 22, Loss = 181.8080, Exploration Rate = 0.5353, Train Count = 7094\n",
      "Episode 209: Reward = 543.00, Steps = 21, Loss = 186.5038, Exploration Rate = 0.5337, Train Count = 7115\n",
      "Episode 210: Reward = 564.00, Steps = 14, Loss = 176.1782, Exploration Rate = 0.5321, Train Count = 7129\n",
      "Episode 211: Reward = 582.00, Steps = 8, Loss = 168.2552, Exploration Rate = 0.5305, Train Count = 7137\n",
      "Episode 212: Reward = 516.00, Steps = 30, Loss = 162.3697, Exploration Rate = 0.5289, Train Count = 7167\n",
      "Episode 213: Reward = 363.00, Steps = 34, Loss = 171.5121, Exploration Rate = 0.5273, Train Count = 7201\n",
      "Episode 214: Reward = 597.00, Steps = 3, Loss = 182.2781, Exploration Rate = 0.5257, Train Count = 7204\n",
      "Episode 215: Reward = 544.00, Steps = 5, Loss = 120.6412, Exploration Rate = 0.5242, Train Count = 7209\n",
      "Episode 216: Reward = 485.00, Steps = 9, Loss = 144.1248, Exploration Rate = 0.5226, Train Count = 7218\n",
      "Episode 217: Reward = 267.00, Steps = 19, Loss = 157.9285, Exploration Rate = 0.5210, Train Count = 7237\n",
      "Episode 218: Reward = 525.00, Steps = 27, Loss = 134.4010, Exploration Rate = 0.5195, Train Count = 7264\n",
      "Episode 219: Reward = 594.00, Steps = 4, Loss = 103.8381, Exploration Rate = 0.5179, Train Count = 7268\n",
      "Episode 220: Reward = 436.00, Steps = 41, Loss = 233.2646, Exploration Rate = 0.5163, Train Count = 7309\n",
      "Episode 221: Reward = 582.00, Steps = 8, Loss = 467.0557, Exploration Rate = 0.5148, Train Count = 7317\n",
      "Episode 222: Reward = 579.00, Steps = 9, Loss = 388.9000, Exploration Rate = 0.5132, Train Count = 7326\n",
      "Episode 223: Reward = 573.00, Steps = 11, Loss = 353.5151, Exploration Rate = 0.5117, Train Count = 7337\n",
      "Episode 224: Reward = 516.00, Steps = 30, Loss = 270.8361, Exploration Rate = 0.5102, Train Count = 7367\n",
      "Episode 225: Reward = 496.00, Steps = 21, Loss = 218.2788, Exploration Rate = 0.5086, Train Count = 7388\n",
      "Episode 226: Reward = 472.00, Steps = 29, Loss = 184.2962, Exploration Rate = 0.5071, Train Count = 7417\n",
      "Episode 227: Reward = 546.00, Steps = 20, Loss = 162.5482, Exploration Rate = 0.5056, Train Count = 7437\n",
      "Episode 228: Reward = 579.00, Steps = 9, Loss = 145.8706, Exploration Rate = 0.5041, Train Count = 7446\n",
      "Episode 229: Reward = 514.00, Steps = 15, Loss = 169.9408, Exploration Rate = 0.5026, Train Count = 7461\n",
      "Episode 230: Reward = 520.00, Steps = 13, Loss = 169.2738, Exploration Rate = 0.5011, Train Count = 7474\n",
      "Episode 231: Reward = 340.00, Steps = 26, Loss = 170.2963, Exploration Rate = 0.4996, Train Count = 7500\n",
      "Episode 232: Reward = 591.00, Steps = 5, Loss = 142.5499, Exploration Rate = 0.4981, Train Count = 7505\n",
      "Episode 233: Reward = 424.00, Steps = 45, Loss = 126.1295, Exploration Rate = 0.4966, Train Count = 7550\n",
      "Episode 234: Reward = 529.00, Steps = 10, Loss = 108.9497, Exploration Rate = 0.4951, Train Count = 7560\n",
      "Episode 235: Reward = 558.00, Steps = 16, Loss = 101.6913, Exploration Rate = 0.4936, Train Count = 7576\n",
      "Episode 236: Reward = 423.00, Steps = 61, Loss = 94.8933, Exploration Rate = 0.4921, Train Count = 7637\n",
      "Episode 237: Reward = 591.00, Steps = 5, Loss = 74.2849, Exploration Rate = 0.4906, Train Count = 7642\n",
      "Episode 238: Reward = 585.00, Steps = 7, Loss = 90.3699, Exploration Rate = 0.4892, Train Count = 7649\n",
      "Episode 239: Reward = 573.00, Steps = 11, Loss = 90.9425, Exploration Rate = 0.4877, Train Count = 7660\n",
      "Episode 240: Reward = 451.00, Steps = 36, Loss = 117.1873, Exploration Rate = 0.4862, Train Count = 7696\n",
      "Episode 241: Reward = 440.00, Steps = 24, Loss = 115.8239, Exploration Rate = 0.4848, Train Count = 7720\n",
      "Episode 242: Reward = 585.00, Steps = 7, Loss = 95.8492, Exploration Rate = 0.4833, Train Count = 7727\n",
      "Episode 243: Reward = 591.00, Steps = 5, Loss = 80.4055, Exploration Rate = 0.4819, Train Count = 7732\n",
      "Episode 244: Reward = 576.00, Steps = 10, Loss = 98.6992, Exploration Rate = 0.4804, Train Count = 7742\n",
      "Episode 245: Reward = 585.00, Steps = 7, Loss = 125.5494, Exploration Rate = 0.4790, Train Count = 7749\n",
      "Episode 246: Reward = 528.00, Steps = 26, Loss = 142.1281, Exploration Rate = 0.4775, Train Count = 7775\n",
      "Episode 247: Reward = 567.00, Steps = 13, Loss = 114.8853, Exploration Rate = 0.4761, Train Count = 7788\n",
      "Episode 248: Reward = 591.00, Steps = 5, Loss = 116.5624, Exploration Rate = 0.4747, Train Count = 7793\n",
      "Episode 249: Reward = 567.00, Steps = 13, Loss = 292.9127, Exploration Rate = 0.4733, Train Count = 7806\n",
      "Episode 250: Reward = 504.00, Steps = 34, Loss = 314.6314, Exploration Rate = 0.4718, Train Count = 7840\n",
      "Episode 251: Reward = 597.00, Steps = 3, Loss = 214.6471, Exploration Rate = 0.4704, Train Count = 7843\n",
      "Episode 252: Reward = 535.00, Steps = 8, Loss = 221.5435, Exploration Rate = 0.4690, Train Count = 7851\n",
      "Episode 253: Reward = 600.00, Steps = 2, Loss = 214.1485, Exploration Rate = 0.4676, Train Count = 7853\n",
      "Episode 254: Reward = 597.00, Steps = 3, Loss = 255.3250, Exploration Rate = 0.4662, Train Count = 7856\n",
      "Episode 255: Reward = 546.00, Steps = 20, Loss = 233.3629, Exploration Rate = 0.4648, Train Count = 7876\n",
      "Episode 256: Reward = 549.00, Steps = 19, Loss = 182.6940, Exploration Rate = 0.4634, Train Count = 7895\n",
      "Episode 257: Reward = 591.00, Steps = 5, Loss = 195.2700, Exploration Rate = 0.4620, Train Count = 7900\n",
      "Episode 258: Reward = 535.00, Steps = 8, Loss = 169.2677, Exploration Rate = 0.4606, Train Count = 7908\n",
      "Episode 259: Reward = 579.00, Steps = 9, Loss = 193.3117, Exploration Rate = 0.4592, Train Count = 7917\n",
      "Episode 260: Reward = 588.00, Steps = 6, Loss = 170.0047, Exploration Rate = 0.4579, Train Count = 7923\n",
      "Episode 261: Reward = 591.00, Steps = 5, Loss = 166.5357, Exploration Rate = 0.4565, Train Count = 7928\n",
      "Episode 262: Reward = 573.00, Steps = 11, Loss = 200.5194, Exploration Rate = 0.4551, Train Count = 7939\n",
      "Episode 263: Reward = 504.00, Steps = 34, Loss = 170.4943, Exploration Rate = 0.4538, Train Count = 7973\n",
      "Episode 264: Reward = 552.00, Steps = 18, Loss = 242.3774, Exploration Rate = 0.4524, Train Count = 7991\n",
      "Episode 265: Reward = 588.00, Steps = 6, Loss = 219.1171, Exploration Rate = 0.4510, Train Count = 7997\n",
      "Episode 266: Reward = 591.00, Steps = 5, Loss = 203.0557, Exploration Rate = 0.4497, Train Count = 8002\n",
      "Episode 267: Reward = 464.00, Steps = 16, Loss = 166.7417, Exploration Rate = 0.4483, Train Count = 8018\n",
      "Episode 268: Reward = 469.00, Steps = 30, Loss = 180.8506, Exploration Rate = 0.4470, Train Count = 8048\n",
      "Episode 269: Reward = 591.00, Steps = 5, Loss = 169.5960, Exploration Rate = 0.4457, Train Count = 8053\n",
      "Episode 270: Reward = 576.00, Steps = 10, Loss = 157.0433, Exploration Rate = 0.4443, Train Count = 8063\n",
      "Episode 271: Reward = 428.00, Steps = 28, Loss = 149.7900, Exploration Rate = 0.4430, Train Count = 8091\n",
      "Episode 272: Reward = 453.00, Steps = 51, Loss = 144.4029, Exploration Rate = 0.4417, Train Count = 8142\n",
      "Episode 273: Reward = 573.00, Steps = 11, Loss = 147.6911, Exploration Rate = 0.4403, Train Count = 8153\n",
      "Episode 274: Reward = 582.00, Steps = 8, Loss = 147.9205, Exploration Rate = 0.4390, Train Count = 8161\n",
      "Episode 275: Reward = 519.00, Steps = 29, Loss = 130.3576, Exploration Rate = 0.4377, Train Count = 8190\n",
      "Episode 276: Reward = 523.00, Steps = 12, Loss = 113.2014, Exploration Rate = 0.4364, Train Count = 8202\n",
      "Episode 277: Reward = 488.00, Steps = 8, Loss = 148.0677, Exploration Rate = 0.4351, Train Count = 8210\n",
      "Episode 278: Reward = 520.00, Steps = 13, Loss = 116.8417, Exploration Rate = 0.4338, Train Count = 8223\n",
      "Episode 279: Reward = 329.00, Steps = 14, Loss = 141.9364, Exploration Rate = 0.4325, Train Count = 8237\n",
      "Episode 280: Reward = 538.00, Steps = 7, Loss = 124.1742, Exploration Rate = 0.4312, Train Count = 8244\n",
      "Episode 281: Reward = 582.00, Steps = 8, Loss = 119.0646, Exploration Rate = 0.4299, Train Count = 8252\n",
      "Episode 282: Reward = 582.00, Steps = 8, Loss = 119.6750, Exploration Rate = 0.4286, Train Count = 8260\n",
      "Episode 283: Reward = 567.00, Steps = 13, Loss = 143.1507, Exploration Rate = 0.4273, Train Count = 8273\n",
      "Episode 284: Reward = 461.00, Steps = 17, Loss = 123.0088, Exploration Rate = 0.4260, Train Count = 8290\n",
      "Episode 285: Reward = 561.00, Steps = 15, Loss = 252.1889, Exploration Rate = 0.4247, Train Count = 8305\n",
      "Episode 286: Reward = 558.00, Steps = 16, Loss = 406.3223, Exploration Rate = 0.4235, Train Count = 8321\n",
      "Episode 287: Reward = 555.00, Steps = 17, Loss = 302.8792, Exploration Rate = 0.4222, Train Count = 8338\n",
      "Episode 288: Reward = 585.00, Steps = 7, Loss = 230.2391, Exploration Rate = 0.4209, Train Count = 8345\n",
      "Episode 289: Reward = 576.00, Steps = 10, Loss = 239.1892, Exploration Rate = 0.4197, Train Count = 8355\n",
      "Episode 290: Reward = 582.00, Steps = 8, Loss = 270.5157, Exploration Rate = 0.4184, Train Count = 8363\n",
      "Episode 291: Reward = 508.00, Steps = 17, Loss = 204.2418, Exploration Rate = 0.4171, Train Count = 8380\n",
      "Episode 292: Reward = 582.00, Steps = 8, Loss = 199.4902, Exploration Rate = 0.4159, Train Count = 8388\n",
      "Episode 293: Reward = 579.00, Steps = 9, Loss = 166.1042, Exploration Rate = 0.4146, Train Count = 8397\n",
      "Episode 294: Reward = 528.00, Steps = 26, Loss = 148.5050, Exploration Rate = 0.4134, Train Count = 8423\n",
      "Episode 295: Reward = 552.00, Steps = 18, Loss = 137.5863, Exploration Rate = 0.4122, Train Count = 8441\n",
      "Episode 296: Reward = 567.00, Steps = 13, Loss = 121.9827, Exploration Rate = 0.4109, Train Count = 8454\n",
      "Episode 297: Reward = 378.00, Steps = 29, Loss = 136.2686, Exploration Rate = 0.4097, Train Count = 8483\n",
      "Episode 298: Reward = 265.00, Steps = 98, Loss = 92.2215, Exploration Rate = 0.4085, Train Count = 8581\n",
      "Episode 299: Reward = 522.00, Steps = 28, Loss = 66.8541, Exploration Rate = 0.4072, Train Count = 8609\n",
      "Episode 300: Reward = 600.00, Steps = 2, Loss = 62.6909, Exploration Rate = 0.4060, Train Count = 8611\n",
      "Episode 301: Reward = 516.00, Steps = 30, Loss = 82.7586, Exploration Rate = 0.4048, Train Count = 8641\n",
      "Episode 302: Reward = 570.00, Steps = 12, Loss = 92.8929, Exploration Rate = 0.4036, Train Count = 8653\n",
      "Episode 303: Reward = 576.00, Steps = 10, Loss = 74.7256, Exploration Rate = 0.4024, Train Count = 8663\n",
      "Episode 304: Reward = 458.00, Steps = 18, Loss = 85.1523, Exploration Rate = 0.4012, Train Count = 8681\n",
      "Episode 305: Reward = 168.00, Steps = 52, Loss = 81.0422, Exploration Rate = 0.4000, Train Count = 8733\n",
      "Episode 306: Reward = 585.00, Steps = 7, Loss = 74.0172, Exploration Rate = 0.3988, Train Count = 8740\n",
      "Episode 307: Reward = 445.00, Steps = 38, Loss = 80.1082, Exploration Rate = 0.3976, Train Count = 8778\n",
      "Episode 308: Reward = 479.00, Steps = 11, Loss = 76.7564, Exploration Rate = 0.3964, Train Count = 8789\n",
      "Episode 309: Reward = 532.00, Steps = 9, Loss = 79.5885, Exploration Rate = 0.3952, Train Count = 8798\n",
      "Episode 310: Reward = 546.00, Steps = 20, Loss = 413.2358, Exploration Rate = 0.3940, Train Count = 8818\n",
      "Episode 311: Reward = 582.00, Steps = 8, Loss = 267.8910, Exploration Rate = 0.3928, Train Count = 8826\n",
      "Episode 312: Reward = 310.00, Steps = 83, Loss = 145.1819, Exploration Rate = 0.3916, Train Count = 8909\n",
      "Episode 313: Reward = 597.00, Steps = 3, Loss = 86.1046, Exploration Rate = 0.3905, Train Count = 8912\n",
      "Episode 314: Reward = 570.00, Steps = 12, Loss = 98.3582, Exploration Rate = 0.3893, Train Count = 8924\n",
      "Episode 315: Reward = 549.00, Steps = 19, Loss = 95.1749, Exploration Rate = 0.3881, Train Count = 8943\n",
      "Episode 316: Reward = 573.00, Steps = 11, Loss = 98.6288, Exploration Rate = 0.3870, Train Count = 8954\n",
      "Episode 317: Reward = 540.00, Steps = 22, Loss = 93.3736, Exploration Rate = 0.3858, Train Count = 8976\n",
      "Episode 318: Reward = 516.00, Steps = 30, Loss = 85.7461, Exploration Rate = 0.3846, Train Count = 9006\n",
      "Episode 319: Reward = 508.00, Steps = 17, Loss = 97.4172, Exploration Rate = 0.3835, Train Count = 9023\n",
      "Episode 320: Reward = 529.00, Steps = 10, Loss = 99.2464, Exploration Rate = 0.3823, Train Count = 9033\n",
      "Episode 321: Reward = 391.00, Steps = 9, Loss = 98.4583, Exploration Rate = 0.3812, Train Count = 9042\n",
      "Episode 322: Reward = 594.00, Steps = 4, Loss = 165.8981, Exploration Rate = 0.3801, Train Count = 9046\n",
      "Episode 323: Reward = 488.00, Steps = 8, Loss = 108.0753, Exploration Rate = 0.3789, Train Count = 9054\n",
      "Episode 324: Reward = 585.00, Steps = 7, Loss = 94.8116, Exploration Rate = 0.3778, Train Count = 9061\n",
      "Episode 325: Reward = 546.00, Steps = 20, Loss = 118.5705, Exploration Rate = 0.3766, Train Count = 9081\n",
      "Episode 326: Reward = 579.00, Steps = 9, Loss = 99.3923, Exploration Rate = 0.3755, Train Count = 9090\n",
      "Episode 327: Reward = 538.00, Steps = 7, Loss = 103.3044, Exploration Rate = 0.3744, Train Count = 9097\n",
      "Episode 328: Reward = 561.00, Steps = 15, Loss = 96.9670, Exploration Rate = 0.3733, Train Count = 9112\n",
      "Episode 329: Reward = 504.00, Steps = 34, Loss = 123.3717, Exploration Rate = 0.3721, Train Count = 9146\n",
      "Episode 330: Reward = 535.00, Steps = 8, Loss = 120.0701, Exploration Rate = 0.3710, Train Count = 9154\n",
      "Episode 331: Reward = 594.00, Steps = 4, Loss = 123.7478, Exploration Rate = 0.3699, Train Count = 9158\n",
      "Episode 332: Reward = 582.00, Steps = 8, Loss = 99.8195, Exploration Rate = 0.3688, Train Count = 9166\n",
      "Episode 333: Reward = 600.00, Steps = 2, Loss = 110.8426, Exploration Rate = 0.3677, Train Count = 9168\n",
      "Episode 334: Reward = 526.00, Steps = 11, Loss = 123.8320, Exploration Rate = 0.3666, Train Count = 9179\n",
      "Episode 335: Reward = 537.00, Steps = 23, Loss = 99.7666, Exploration Rate = 0.3655, Train Count = 9202\n",
      "Episode 336: Reward = 534.00, Steps = 24, Loss = 91.7476, Exploration Rate = 0.3644, Train Count = 9226\n",
      "Episode 337: Reward = 600.00, Steps = 2, Loss = 99.1254, Exploration Rate = 0.3633, Train Count = 9228\n",
      "Episode 338: Reward = 570.00, Steps = 12, Loss = 102.6968, Exploration Rate = 0.3622, Train Count = 9240\n",
      "Episode 339: Reward = 585.00, Steps = 7, Loss = 108.0563, Exploration Rate = 0.3611, Train Count = 9247\n",
      "Episode 340: Reward = 585.00, Steps = 7, Loss = 76.7214, Exploration Rate = 0.3600, Train Count = 9254\n",
      "Episode 341: Reward = 517.00, Steps = 14, Loss = 83.2755, Exploration Rate = 0.3590, Train Count = 9268\n",
      "Episode 342: Reward = 460.00, Steps = 33, Loss = 86.3426, Exploration Rate = 0.3579, Train Count = 9301\n",
      "Episode 343: Reward = 573.00, Steps = 11, Loss = 444.1564, Exploration Rate = 0.3568, Train Count = 9312\n",
      "Episode 344: Reward = 600.00, Steps = 2, Loss = 367.4591, Exploration Rate = 0.3557, Train Count = 9314\n",
      "Episode 345: Reward = 537.00, Steps = 23, Loss = 236.3259, Exploration Rate = 0.3547, Train Count = 9337\n",
      "Episode 346: Reward = 594.00, Steps = 4, Loss = 159.7087, Exploration Rate = 0.3536, Train Count = 9341\n",
      "Episode 347: Reward = 573.00, Steps = 11, Loss = 153.0560, Exploration Rate = 0.3525, Train Count = 9352\n",
      "Episode 348: Reward = 588.00, Steps = 6, Loss = 144.1252, Exploration Rate = 0.3515, Train Count = 9358\n",
      "Episode 349: Reward = 328.00, Steps = 30, Loss = 116.4557, Exploration Rate = 0.3504, Train Count = 9388\n",
      "Episode 350: Reward = 537.00, Steps = 23, Loss = 112.6944, Exploration Rate = 0.3494, Train Count = 9411\n",
      "Episode 351: Reward = 532.00, Steps = 9, Loss = 95.9820, Exploration Rate = 0.3483, Train Count = 9420\n",
      "Episode 352: Reward = 594.00, Steps = 4, Loss = 97.7713, Exploration Rate = 0.3473, Train Count = 9424\n",
      "Episode 353: Reward = 558.00, Steps = 16, Loss = 100.5252, Exploration Rate = 0.3463, Train Count = 9440\n",
      "Episode 354: Reward = 561.00, Steps = 15, Loss = 114.1879, Exploration Rate = 0.3452, Train Count = 9455\n",
      "Episode 355: Reward = 600.00, Steps = 2, Loss = 138.5972, Exploration Rate = 0.3442, Train Count = 9457\n",
      "Episode 356: Reward = 597.00, Steps = 3, Loss = 74.7210, Exploration Rate = 0.3431, Train Count = 9460\n",
      "Episode 357: Reward = 564.00, Steps = 14, Loss = 95.0308, Exploration Rate = 0.3421, Train Count = 9474\n",
      "Episode 358: Reward = 579.00, Steps = 9, Loss = 93.1079, Exploration Rate = 0.3411, Train Count = 9483\n",
      "Episode 359: Reward = 517.00, Steps = 14, Loss = 95.7181, Exploration Rate = 0.3401, Train Count = 9497\n",
      "Episode 360: Reward = 535.00, Steps = 8, Loss = 106.0930, Exploration Rate = 0.3390, Train Count = 9505\n",
      "Episode 361: Reward = 594.00, Steps = 4, Loss = 104.4612, Exploration Rate = 0.3380, Train Count = 9509\n",
      "Episode 362: Reward = 591.00, Steps = 5, Loss = 80.2192, Exploration Rate = 0.3370, Train Count = 9514\n",
      "Episode 363: Reward = 579.00, Steps = 9, Loss = 97.0052, Exploration Rate = 0.3360, Train Count = 9523\n",
      "Episode 364: Reward = 594.00, Steps = 4, Loss = 81.2528, Exploration Rate = 0.3350, Train Count = 9527\n",
      "Episode 365: Reward = 597.00, Steps = 3, Loss = 78.6688, Exploration Rate = 0.3340, Train Count = 9530\n",
      "Episode 366: Reward = 538.00, Steps = 7, Loss = 75.4981, Exploration Rate = 0.3330, Train Count = 9537\n",
      "Episode 367: Reward = 579.00, Steps = 9, Loss = 79.3828, Exploration Rate = 0.3320, Train Count = 9546\n",
      "Episode 368: Reward = 540.00, Steps = 22, Loss = 93.6354, Exploration Rate = 0.3310, Train Count = 9568\n",
      "Episode 369: Reward = 588.00, Steps = 6, Loss = 78.0649, Exploration Rate = 0.3300, Train Count = 9574\n",
      "Episode 370: Reward = 513.00, Steps = 31, Loss = 78.4102, Exploration Rate = 0.3290, Train Count = 9605\n",
      "Episode 371: Reward = 537.00, Steps = 23, Loss = 75.9423, Exploration Rate = 0.3280, Train Count = 9628\n",
      "Episode 372: Reward = 523.00, Steps = 12, Loss = 75.8936, Exploration Rate = 0.3270, Train Count = 9640\n",
      "Episode 373: Reward = 579.00, Steps = 9, Loss = 68.0015, Exploration Rate = 0.3261, Train Count = 9649\n",
      "Episode 374: Reward = 564.00, Steps = 14, Loss = 70.5930, Exploration Rate = 0.3251, Train Count = 9663\n",
      "Episode 375: Reward = 597.00, Steps = 3, Loss = 74.4845, Exploration Rate = 0.3241, Train Count = 9666\n",
      "Episode 376: Reward = 517.00, Steps = 14, Loss = 80.3366, Exploration Rate = 0.3231, Train Count = 9680\n",
      "Episode 377: Reward = 573.00, Steps = 11, Loss = 84.0979, Exploration Rate = 0.3222, Train Count = 9691\n",
      "Episode 378: Reward = 546.00, Steps = 20, Loss = 73.1042, Exploration Rate = 0.3212, Train Count = 9711\n",
      "Episode 379: Reward = 537.00, Steps = 23, Loss = 95.8137, Exploration Rate = 0.3202, Train Count = 9734\n",
      "Episode 380: Reward = 567.00, Steps = 13, Loss = 86.4289, Exploration Rate = 0.3193, Train Count = 9747\n",
      "Episode 381: Reward = 561.00, Steps = 15, Loss = 78.5212, Exploration Rate = 0.3183, Train Count = 9762\n",
      "Episode 382: Reward = 588.00, Steps = 6, Loss = 76.0107, Exploration Rate = 0.3174, Train Count = 9768\n",
      "Episode 383: Reward = 495.00, Steps = 37, Loss = 127.2853, Exploration Rate = 0.3164, Train Count = 9805\n",
      "Episode 384: Reward = 591.00, Steps = 5, Loss = 339.3112, Exploration Rate = 0.3155, Train Count = 9810\n",
      "Episode 385: Reward = 591.00, Steps = 5, Loss = 274.2554, Exploration Rate = 0.3145, Train Count = 9815\n",
      "Episode 386: Reward = 573.00, Steps = 11, Loss = 229.9889, Exploration Rate = 0.3136, Train Count = 9826\n",
      "Episode 387: Reward = 594.00, Steps = 4, Loss = 153.6609, Exploration Rate = 0.3126, Train Count = 9830\n",
      "Episode 388: Reward = 594.00, Steps = 4, Loss = 172.6142, Exploration Rate = 0.3117, Train Count = 9834\n",
      "Episode 389: Reward = 582.00, Steps = 8, Loss = 153.8415, Exploration Rate = 0.3108, Train Count = 9842\n",
      "Episode 390: Reward = 558.00, Steps = 16, Loss = 158.8460, Exploration Rate = 0.3098, Train Count = 9858\n",
      "Episode 391: Reward = 555.00, Steps = 17, Loss = 134.1439, Exploration Rate = 0.3089, Train Count = 9875\n",
      "Episode 392: Reward = 540.00, Steps = 22, Loss = 106.4058, Exploration Rate = 0.3080, Train Count = 9897\n",
      "Episode 393: Reward = 588.00, Steps = 6, Loss = 101.2500, Exploration Rate = 0.3070, Train Count = 9903\n",
      "Episode 394: Reward = 496.00, Steps = 21, Loss = 108.2355, Exploration Rate = 0.3061, Train Count = 9924\n",
      "Episode 395: Reward = 522.00, Steps = 28, Loss = 94.7062, Exploration Rate = 0.3052, Train Count = 9952\n",
      "Episode 396: Reward = 535.00, Steps = 8, Loss = 75.3291, Exploration Rate = 0.3043, Train Count = 9960\n",
      "Episode 397: Reward = 588.00, Steps = 6, Loss = 66.5822, Exploration Rate = 0.3034, Train Count = 9966\n",
      "Episode 398: Reward = 588.00, Steps = 6, Loss = 65.3515, Exploration Rate = 0.3025, Train Count = 9972\n",
      "Episode 399: Reward = 260.00, Steps = 37, Loss = 61.3129, Exploration Rate = 0.3016, Train Count = 10009\n",
      "Episode 400: Reward = 480.00, Steps = 42, Loss = 61.3708, Exploration Rate = 0.3007, Train Count = 10051\n",
      "Episode 401: Reward = 588.00, Steps = 6, Loss = 60.8453, Exploration Rate = 0.2997, Train Count = 10057\n",
      "Episode 402: Reward = 567.00, Steps = 13, Loss = 65.3081, Exploration Rate = 0.2989, Train Count = 10070\n",
      "Episode 403: Reward = 591.00, Steps = 5, Loss = 63.3876, Exploration Rate = 0.2980, Train Count = 10075\n",
      "Episode 404: Reward = 535.00, Steps = 8, Loss = 72.3540, Exploration Rate = 0.2971, Train Count = 10083\n",
      "Episode 405: Reward = 540.00, Steps = 22, Loss = 65.5998, Exploration Rate = 0.2962, Train Count = 10105\n",
      "Episode 406: Reward = 594.00, Steps = 4, Loss = 62.7608, Exploration Rate = 0.2953, Train Count = 10109\n",
      "Episode 407: Reward = 419.00, Steps = 31, Loss = 102.8561, Exploration Rate = 0.2944, Train Count = 10140\n",
      "Episode 408: Reward = 485.00, Steps = 9, Loss = 103.5839, Exploration Rate = 0.2935, Train Count = 10149\n",
      "Episode 409: Reward = 498.00, Steps = 36, Loss = 82.1465, Exploration Rate = 0.2926, Train Count = 10185\n",
      "Episode 410: Reward = 558.00, Steps = 16, Loss = 79.0975, Exploration Rate = 0.2918, Train Count = 10201\n",
      "Episode 411: Reward = 355.00, Steps = 21, Loss = 78.5422, Exploration Rate = 0.2909, Train Count = 10222\n",
      "Episode 412: Reward = 543.00, Steps = 21, Loss = 70.9580, Exploration Rate = 0.2900, Train Count = 10243\n",
      "Episode 413: Reward = 549.00, Steps = 19, Loss = 79.8329, Exploration Rate = 0.2891, Train Count = 10262\n",
      "Episode 414: Reward = 523.00, Steps = 12, Loss = 75.5577, Exploration Rate = 0.2883, Train Count = 10274\n",
      "Episode 415: Reward = 579.00, Steps = 9, Loss = 69.8741, Exploration Rate = 0.2874, Train Count = 10283\n",
      "Episode 416: Reward = 588.00, Steps = 6, Loss = 76.5210, Exploration Rate = 0.2865, Train Count = 10289\n",
      "Episode 417: Reward = 535.00, Steps = 8, Loss = 83.6343, Exploration Rate = 0.2857, Train Count = 10297\n",
      "Episode 418: Reward = 526.00, Steps = 11, Loss = 272.6441, Exploration Rate = 0.2848, Train Count = 10308\n",
      "Episode 419: Reward = 502.00, Steps = 19, Loss = 230.9345, Exploration Rate = 0.2840, Train Count = 10327\n",
      "Episode 420: Reward = 501.00, Steps = 35, Loss = 151.2235, Exploration Rate = 0.2831, Train Count = 10362\n",
      "Episode 421: Reward = 585.00, Steps = 7, Loss = 152.5366, Exploration Rate = 0.2823, Train Count = 10369\n",
      "Episode 422: Reward = 594.00, Steps = 4, Loss = 84.3442, Exploration Rate = 0.2814, Train Count = 10373\n",
      "Episode 423: Reward = 582.00, Steps = 8, Loss = 121.1480, Exploration Rate = 0.2806, Train Count = 10381\n",
      "Episode 424: Reward = 558.00, Steps = 16, Loss = 140.2305, Exploration Rate = 0.2797, Train Count = 10397\n",
      "Episode 425: Reward = 591.00, Steps = 5, Loss = 92.0085, Exploration Rate = 0.2789, Train Count = 10402\n",
      "Episode 426: Reward = 594.00, Steps = 4, Loss = 87.3789, Exploration Rate = 0.2781, Train Count = 10406\n",
      "Episode 427: Reward = 555.00, Steps = 17, Loss = 72.1524, Exploration Rate = 0.2772, Train Count = 10423\n",
      "Episode 428: Reward = 591.00, Steps = 5, Loss = 65.4806, Exploration Rate = 0.2764, Train Count = 10428\n",
      "Episode 429: Reward = 558.00, Steps = 16, Loss = 60.8536, Exploration Rate = 0.2756, Train Count = 10444\n",
      "Episode 430: Reward = 397.00, Steps = 54, Loss = 60.6829, Exploration Rate = 0.2747, Train Count = 10498\n",
      "Episode 431: Reward = 582.00, Steps = 8, Loss = 78.2607, Exploration Rate = 0.2739, Train Count = 10506\n",
      "Episode 432: Reward = 498.00, Steps = 36, Loss = 59.5658, Exploration Rate = 0.2731, Train Count = 10542\n",
      "Episode 433: Reward = 552.00, Steps = 18, Loss = 46.1768, Exploration Rate = 0.2723, Train Count = 10560\n",
      "Episode 434: Reward = 532.00, Steps = 9, Loss = 75.2964, Exploration Rate = 0.2715, Train Count = 10569\n",
      "Episode 435: Reward = 585.00, Steps = 7, Loss = 57.7770, Exploration Rate = 0.2706, Train Count = 10576\n",
      "Episode 436: Reward = 588.00, Steps = 6, Loss = 73.5259, Exploration Rate = 0.2698, Train Count = 10582\n",
      "Episode 437: Reward = 570.00, Steps = 12, Loss = 88.4272, Exploration Rate = 0.2690, Train Count = 10594\n",
      "Episode 438: Reward = 570.00, Steps = 12, Loss = 73.7006, Exploration Rate = 0.2682, Train Count = 10606\n",
      "Episode 439: Reward = 588.00, Steps = 6, Loss = 79.3461, Exploration Rate = 0.2674, Train Count = 10612\n",
      "Episode 440: Reward = 532.00, Steps = 9, Loss = 77.0332, Exploration Rate = 0.2666, Train Count = 10621\n",
      "Episode 441: Reward = 570.00, Steps = 12, Loss = 79.9889, Exploration Rate = 0.2658, Train Count = 10633\n",
      "Episode 442: Reward = 585.00, Steps = 7, Loss = 89.7410, Exploration Rate = 0.2650, Train Count = 10640\n",
      "Episode 443: Reward = 597.00, Steps = 3, Loss = 75.7576, Exploration Rate = 0.2642, Train Count = 10643\n",
      "Episode 444: Reward = 585.00, Steps = 7, Loss = 62.1566, Exploration Rate = 0.2634, Train Count = 10650\n",
      "Episode 445: Reward = 585.00, Steps = 7, Loss = 68.6471, Exploration Rate = 0.2626, Train Count = 10657\n",
      "Episode 446: Reward = 597.00, Steps = 3, Loss = 76.8684, Exploration Rate = 0.2618, Train Count = 10660\n",
      "Episode 447: Reward = 591.00, Steps = 5, Loss = 63.5583, Exploration Rate = 0.2611, Train Count = 10665\n",
      "Episode 448: Reward = 588.00, Steps = 6, Loss = 48.3460, Exploration Rate = 0.2603, Train Count = 10671\n",
      "Episode 449: Reward = 567.00, Steps = 13, Loss = 58.4348, Exploration Rate = 0.2595, Train Count = 10684\n",
      "Episode 450: Reward = 597.00, Steps = 3, Loss = 93.0727, Exploration Rate = 0.2587, Train Count = 10687\n",
      "Episode 451: Reward = 490.00, Steps = 23, Loss = 74.7967, Exploration Rate = 0.2579, Train Count = 10710\n",
      "Episode 452: Reward = 517.00, Steps = 14, Loss = 58.6937, Exploration Rate = 0.2572, Train Count = 10724\n",
      "Episode 453: Reward = 588.00, Steps = 6, Loss = 65.4557, Exploration Rate = 0.2564, Train Count = 10730\n",
      "Episode 454: Reward = 591.00, Steps = 5, Loss = 55.0446, Exploration Rate = 0.2556, Train Count = 10735\n",
      "Episode 455: Reward = 525.00, Steps = 27, Loss = 57.9110, Exploration Rate = 0.2549, Train Count = 10762\n",
      "Episode 456: Reward = 591.00, Steps = 5, Loss = 62.7375, Exploration Rate = 0.2541, Train Count = 10767\n",
      "Episode 457: Reward = 597.00, Steps = 3, Loss = 53.6363, Exploration Rate = 0.2533, Train Count = 10770\n",
      "Episode 458: Reward = 564.00, Steps = 14, Loss = 81.4484, Exploration Rate = 0.2526, Train Count = 10784\n",
      "Episode 459: Reward = 588.00, Steps = 6, Loss = 57.5713, Exploration Rate = 0.2518, Train Count = 10790\n",
      "Episode 460: Reward = -300.00, Steps = 100, Loss = 157.0948, Exploration Rate = 0.2511, Train Count = 10890\n",
      "Episode 461: Reward = 576.00, Steps = 10, Loss = 61.9233, Exploration Rate = 0.2503, Train Count = 10900\n",
      "Episode 462: Reward = 552.00, Steps = 18, Loss = 63.3941, Exploration Rate = 0.2496, Train Count = 10918\n",
      "Episode 463: Reward = 529.00, Steps = 10, Loss = 56.4875, Exploration Rate = 0.2488, Train Count = 10928\n",
      "Episode 464: Reward = -300.00, Steps = 100, Loss = 39.5881, Exploration Rate = 0.2481, Train Count = 11028\n",
      "Episode 465: Reward = 564.00, Steps = 14, Loss = 41.8305, Exploration Rate = 0.2473, Train Count = 11042\n",
      "Episode 466: Reward = 420.00, Steps = 62, Loss = 32.1288, Exploration Rate = 0.2466, Train Count = 11104\n",
      "Episode 467: Reward = 532.00, Steps = 9, Loss = 23.5964, Exploration Rate = 0.2458, Train Count = 11113\n",
      "Episode 468: Reward = -300.00, Steps = 100, Loss = 38.5289, Exploration Rate = 0.2451, Train Count = 11213\n",
      "Episode 469: Reward = 579.00, Steps = 9, Loss = 43.1869, Exploration Rate = 0.2444, Train Count = 11222\n",
      "Episode 470: Reward = 296.00, Steps = 72, Loss = 22.8707, Exploration Rate = 0.2436, Train Count = 11294\n",
      "Episode 471: Reward = 547.00, Steps = 4, Loss = 18.1450, Exploration Rate = 0.2429, Train Count = 11298\n",
      "Episode 472: Reward = 588.00, Steps = 6, Loss = 369.5088, Exploration Rate = 0.2422, Train Count = 11304\n",
      "Episode 473: Reward = 591.00, Steps = 5, Loss = 322.1987, Exploration Rate = 0.2414, Train Count = 11309\n",
      "Episode 474: Reward = 588.00, Steps = 6, Loss = 250.1588, Exploration Rate = 0.2407, Train Count = 11315\n",
      "Episode 475: Reward = 538.00, Steps = 7, Loss = 206.3553, Exploration Rate = 0.2400, Train Count = 11322\n",
      "Episode 476: Reward = 600.00, Steps = 2, Loss = 154.8437, Exploration Rate = 0.2393, Train Count = 11324\n",
      "Episode 477: Reward = 585.00, Steps = 7, Loss = 126.4725, Exploration Rate = 0.2386, Train Count = 11331\n",
      "Episode 478: Reward = 588.00, Steps = 6, Loss = 103.7302, Exploration Rate = 0.2378, Train Count = 11337\n",
      "Episode 479: Reward = 525.00, Steps = 27, Loss = 94.6685, Exploration Rate = 0.2371, Train Count = 11364\n",
      "Episode 480: Reward = 535.00, Steps = 8, Loss = 64.5228, Exploration Rate = 0.2364, Train Count = 11372\n",
      "Episode 481: Reward = 591.00, Steps = 5, Loss = 59.3876, Exploration Rate = 0.2357, Train Count = 11377\n",
      "Episode 482: Reward = 555.00, Steps = 17, Loss = 56.3230, Exploration Rate = 0.2350, Train Count = 11394\n",
      "Episode 483: Reward = 579.00, Steps = 9, Loss = 50.9459, Exploration Rate = 0.2343, Train Count = 11403\n",
      "Episode 484: Reward = 585.00, Steps = 7, Loss = 86.9865, Exploration Rate = 0.2336, Train Count = 11410\n",
      "Episode 485: Reward = 594.00, Steps = 4, Loss = 51.7852, Exploration Rate = 0.2329, Train Count = 11414\n",
      "Episode 486: Reward = 504.00, Steps = 34, Loss = 63.3809, Exploration Rate = 0.2322, Train Count = 11448\n",
      "Episode 487: Reward = 591.00, Steps = 5, Loss = 63.3430, Exploration Rate = 0.2315, Train Count = 11453\n",
      "Episode 488: Reward = 555.00, Steps = 17, Loss = 53.4171, Exploration Rate = 0.2308, Train Count = 11470\n",
      "Episode 489: Reward = 588.00, Steps = 6, Loss = 54.9992, Exploration Rate = 0.2301, Train Count = 11476\n",
      "Episode 490: Reward = 594.00, Steps = 4, Loss = 65.8219, Exploration Rate = 0.2294, Train Count = 11480\n",
      "Episode 491: Reward = 526.00, Steps = 11, Loss = 67.2279, Exploration Rate = 0.2287, Train Count = 11491\n",
      "Episode 492: Reward = 579.00, Steps = 9, Loss = 86.3266, Exploration Rate = 0.2280, Train Count = 11500\n",
      "Episode 493: Reward = 585.00, Steps = 7, Loss = 59.6329, Exploration Rate = 0.2274, Train Count = 11507\n",
      "Episode 494: Reward = 534.00, Steps = 24, Loss = 73.5032, Exploration Rate = 0.2267, Train Count = 11531\n",
      "Episode 495: Reward = 591.00, Steps = 5, Loss = 55.5482, Exploration Rate = 0.2260, Train Count = 11536\n",
      "Episode 496: Reward = 549.00, Steps = 19, Loss = 97.2220, Exploration Rate = 0.2253, Train Count = 11555\n",
      "Episode 497: Reward = 570.00, Steps = 12, Loss = 54.0876, Exploration Rate = 0.2246, Train Count = 11567\n",
      "Episode 498: Reward = 523.00, Steps = 12, Loss = 48.3754, Exploration Rate = 0.2240, Train Count = 11579\n",
      "Episode 499: Reward = 484.00, Steps = 25, Loss = 41.9768, Exploration Rate = 0.2233, Train Count = 11604\n",
      "Episode 500: Reward = 585.00, Steps = 7, Loss = 51.6155, Exploration Rate = 0.2226, Train Count = 11611\n",
      "Episode 501: Reward = 582.00, Steps = 8, Loss = 57.1717, Exploration Rate = 0.2220, Train Count = 11619\n",
      "Episode 502: Reward = 585.00, Steps = 7, Loss = 45.0360, Exploration Rate = 0.2213, Train Count = 11626\n",
      "Episode 503: Reward = 511.00, Steps = 16, Loss = 40.9463, Exploration Rate = 0.2206, Train Count = 11642\n",
      "Episode 504: Reward = 576.00, Steps = 10, Loss = 38.3177, Exploration Rate = 0.2200, Train Count = 11652\n",
      "Episode 505: Reward = 597.00, Steps = 3, Loss = 52.7595, Exploration Rate = 0.2193, Train Count = 11655\n",
      "Episode 506: Reward = 594.00, Steps = 4, Loss = 41.4423, Exploration Rate = 0.2187, Train Count = 11659\n",
      "Episode 507: Reward = 540.00, Steps = 22, Loss = 61.0737, Exploration Rate = 0.2180, Train Count = 11681\n",
      "Episode 508: Reward = 588.00, Steps = 6, Loss = 40.8268, Exploration Rate = 0.2173, Train Count = 11687\n",
      "Episode 509: Reward = 525.00, Steps = 27, Loss = 37.1763, Exploration Rate = 0.2167, Train Count = 11714\n",
      "Episode 510: Reward = 600.00, Steps = 2, Loss = 24.2963, Exploration Rate = 0.2160, Train Count = 11716\n",
      "Episode 511: Reward = 532.00, Steps = 9, Loss = 31.1998, Exploration Rate = 0.2154, Train Count = 11725\n",
      "Episode 512: Reward = 489.00, Steps = 39, Loss = 28.8747, Exploration Rate = 0.2147, Train Count = 11764\n",
      "Episode 513: Reward = 535.00, Steps = 8, Loss = 38.7779, Exploration Rate = 0.2141, Train Count = 11772\n",
      "Episode 514: Reward = 588.00, Steps = 6, Loss = 48.3606, Exploration Rate = 0.2135, Train Count = 11778\n",
      "Episode 515: Reward = 528.00, Steps = 26, Loss = 103.2705, Exploration Rate = 0.2128, Train Count = 11804\n",
      "Episode 516: Reward = 573.00, Steps = 11, Loss = 293.4948, Exploration Rate = 0.2122, Train Count = 11815\n",
      "Episode 517: Reward = 528.00, Steps = 26, Loss = 156.3688, Exploration Rate = 0.2115, Train Count = 11841\n",
      "Episode 518: Reward = 582.00, Steps = 8, Loss = 116.2751, Exploration Rate = 0.2109, Train Count = 11849\n",
      "Episode 519: Reward = 594.00, Steps = 4, Loss = 108.0269, Exploration Rate = 0.2103, Train Count = 11853\n",
      "Episode 520: Reward = 582.00, Steps = 8, Loss = 102.9076, Exploration Rate = 0.2096, Train Count = 11861\n",
      "Episode 521: Reward = 591.00, Steps = 5, Loss = 109.2145, Exploration Rate = 0.2090, Train Count = 11866\n",
      "Episode 522: Reward = 585.00, Steps = 7, Loss = 87.1773, Exploration Rate = 0.2084, Train Count = 11873\n",
      "Episode 523: Reward = 594.00, Steps = 4, Loss = 98.5789, Exploration Rate = 0.2078, Train Count = 11877\n",
      "Episode 524: Reward = 555.00, Steps = 17, Loss = 91.7230, Exploration Rate = 0.2071, Train Count = 11894\n",
      "Episode 525: Reward = 588.00, Steps = 6, Loss = 90.0750, Exploration Rate = 0.2065, Train Count = 11900\n",
      "Episode 526: Reward = 582.00, Steps = 8, Loss = 85.2110, Exploration Rate = 0.2059, Train Count = 11908\n",
      "Episode 527: Reward = 538.00, Steps = 7, Loss = 76.7741, Exploration Rate = 0.2053, Train Count = 11915\n",
      "Episode 528: Reward = 538.00, Steps = 7, Loss = 77.5168, Exploration Rate = 0.2047, Train Count = 11922\n",
      "Episode 529: Reward = 594.00, Steps = 4, Loss = 59.8690, Exploration Rate = 0.2041, Train Count = 11926\n",
      "Episode 530: Reward = 591.00, Steps = 5, Loss = 66.2144, Exploration Rate = 0.2034, Train Count = 11931\n",
      "Episode 531: Reward = 591.00, Steps = 5, Loss = 51.1282, Exploration Rate = 0.2028, Train Count = 11936\n",
      "Episode 532: Reward = 588.00, Steps = 6, Loss = 59.0936, Exploration Rate = 0.2022, Train Count = 11942\n",
      "Episode 533: Reward = 591.00, Steps = 5, Loss = 86.5941, Exploration Rate = 0.2016, Train Count = 11947\n",
      "Episode 534: Reward = 600.00, Steps = 2, Loss = 68.9056, Exploration Rate = 0.2010, Train Count = 11949\n",
      "Episode 535: Reward = 537.00, Steps = 23, Loss = 78.2315, Exploration Rate = 0.2004, Train Count = 11972\n",
      "Episode 536: Reward = 573.00, Steps = 11, Loss = 68.2684, Exploration Rate = 0.1998, Train Count = 11983\n",
      "Episode 537: Reward = 582.00, Steps = 8, Loss = 49.9001, Exploration Rate = 0.1992, Train Count = 11991\n",
      "Episode 538: Reward = 561.00, Steps = 15, Loss = 60.6793, Exploration Rate = 0.1986, Train Count = 12006\n",
      "Episode 539: Reward = 594.00, Steps = 4, Loss = 38.2168, Exploration Rate = 0.1980, Train Count = 12010\n",
      "Episode 540: Reward = 475.00, Steps = 28, Loss = 54.9106, Exploration Rate = 0.1974, Train Count = 12038\n",
      "Episode 541: Reward = 573.00, Steps = 11, Loss = 64.8637, Exploration Rate = 0.1968, Train Count = 12049\n",
      "Episode 542: Reward = 570.00, Steps = 12, Loss = 55.2150, Exploration Rate = 0.1962, Train Count = 12061\n",
      "Episode 543: Reward = 594.00, Steps = 4, Loss = 54.8423, Exploration Rate = 0.1956, Train Count = 12065\n",
      "Episode 544: Reward = 594.00, Steps = 4, Loss = 55.6689, Exploration Rate = 0.1951, Train Count = 12069\n",
      "Episode 545: Reward = 588.00, Steps = 6, Loss = 55.5789, Exploration Rate = 0.1945, Train Count = 12075\n",
      "Episode 546: Reward = 588.00, Steps = 6, Loss = 50.9805, Exploration Rate = 0.1939, Train Count = 12081\n",
      "Episode 547: Reward = 573.00, Steps = 11, Loss = 53.3569, Exploration Rate = 0.1933, Train Count = 12092\n",
      "Episode 548: Reward = 579.00, Steps = 9, Loss = 62.2684, Exploration Rate = 0.1927, Train Count = 12101\n",
      "Episode 549: Reward = 582.00, Steps = 8, Loss = 53.0399, Exploration Rate = 0.1922, Train Count = 12109\n",
      "Episode 550: Reward = 467.00, Steps = 15, Loss = 47.6339, Exploration Rate = 0.1916, Train Count = 12124\n",
      "Episode 551: Reward = 528.00, Steps = 26, Loss = 40.5634, Exploration Rate = 0.1910, Train Count = 12150\n",
      "Episode 552: Reward = 585.00, Steps = 7, Loss = 31.8201, Exploration Rate = 0.1904, Train Count = 12157\n",
      "Episode 553: Reward = 591.00, Steps = 5, Loss = 37.0343, Exploration Rate = 0.1899, Train Count = 12162\n",
      "Episode 554: Reward = 591.00, Steps = 5, Loss = 28.7081, Exploration Rate = 0.1893, Train Count = 12167\n",
      "Episode 555: Reward = 597.00, Steps = 3, Loss = 27.6716, Exploration Rate = 0.1887, Train Count = 12170\n",
      "Episode 556: Reward = 567.00, Steps = 13, Loss = 42.3241, Exploration Rate = 0.1882, Train Count = 12183\n",
      "Episode 557: Reward = 597.00, Steps = 3, Loss = 33.9578, Exploration Rate = 0.1876, Train Count = 12186\n",
      "Episode 558: Reward = 588.00, Steps = 6, Loss = 42.2712, Exploration Rate = 0.1870, Train Count = 12192\n",
      "Episode 559: Reward = 576.00, Steps = 10, Loss = 48.6140, Exploration Rate = 0.1865, Train Count = 12202\n",
      "Episode 560: Reward = 594.00, Steps = 4, Loss = 40.6285, Exploration Rate = 0.1859, Train Count = 12206\n",
      "Episode 561: Reward = 523.00, Steps = 12, Loss = 41.4741, Exploration Rate = 0.1853, Train Count = 12218\n",
      "Episode 562: Reward = 588.00, Steps = 6, Loss = 40.0190, Exploration Rate = 0.1848, Train Count = 12224\n",
      "Episode 563: Reward = 570.00, Steps = 12, Loss = 42.3818, Exploration Rate = 0.1842, Train Count = 12236\n",
      "Episode 564: Reward = 567.00, Steps = 13, Loss = 55.2554, Exploration Rate = 0.1837, Train Count = 12249\n",
      "Episode 565: Reward = 591.00, Steps = 5, Loss = 40.2350, Exploration Rate = 0.1831, Train Count = 12254\n",
      "Episode 566: Reward = 538.00, Steps = 7, Loss = 75.6830, Exploration Rate = 0.1826, Train Count = 12261\n",
      "Episode 567: Reward = 582.00, Steps = 8, Loss = 60.5851, Exploration Rate = 0.1820, Train Count = 12269\n",
      "Episode 568: Reward = 591.00, Steps = 5, Loss = 62.5830, Exploration Rate = 0.1815, Train Count = 12274\n",
      "Episode 569: Reward = 326.00, Steps = 15, Loss = 54.3280, Exploration Rate = 0.1809, Train Count = 12289\n",
      "Episode 570: Reward = 588.00, Steps = 6, Loss = 40.8242, Exploration Rate = 0.1804, Train Count = 12295\n",
      "Episode 571: Reward = 588.00, Steps = 6, Loss = 145.1925, Exploration Rate = 0.1799, Train Count = 12301\n",
      "Episode 572: Reward = 591.00, Steps = 5, Loss = 441.0509, Exploration Rate = 0.1793, Train Count = 12306\n",
      "Episode 573: Reward = 576.00, Steps = 10, Loss = 303.4126, Exploration Rate = 0.1788, Train Count = 12316\n",
      "Episode 574: Reward = 594.00, Steps = 4, Loss = 230.9064, Exploration Rate = 0.1782, Train Count = 12320\n",
      "Episode 575: Reward = 582.00, Steps = 8, Loss = 185.8233, Exploration Rate = 0.1777, Train Count = 12328\n",
      "Episode 576: Reward = 585.00, Steps = 7, Loss = 167.0741, Exploration Rate = 0.1772, Train Count = 12335\n",
      "Episode 577: Reward = -300.00, Steps = 100, Loss = 71.0082, Exploration Rate = 0.1766, Train Count = 12435\n",
      "Episode 578: Reward = 588.00, Steps = 6, Loss = 37.1339, Exploration Rate = 0.1761, Train Count = 12441\n",
      "Episode 579: Reward = 591.00, Steps = 5, Loss = 29.5409, Exploration Rate = 0.1756, Train Count = 12446\n",
      "Episode 580: Reward = 582.00, Steps = 8, Loss = 33.7854, Exploration Rate = 0.1751, Train Count = 12454\n",
      "Episode 581: Reward = 541.00, Steps = 6, Loss = 54.5754, Exploration Rate = 0.1745, Train Count = 12460\n",
      "Episode 582: Reward = 532.00, Steps = 9, Loss = 63.4626, Exploration Rate = 0.1740, Train Count = 12469\n",
      "Episode 583: Reward = 516.00, Steps = 30, Loss = 60.3839, Exploration Rate = 0.1735, Train Count = 12499\n",
      "Episode 584: Reward = 552.00, Steps = 18, Loss = 52.1026, Exploration Rate = 0.1730, Train Count = 12517\n",
      "Episode 585: Reward = 585.00, Steps = 7, Loss = 40.2754, Exploration Rate = 0.1725, Train Count = 12524\n",
      "Episode 586: Reward = 372.00, Steps = 78, Loss = 26.3277, Exploration Rate = 0.1719, Train Count = 12602\n",
      "Episode 587: Reward = 585.00, Steps = 7, Loss = 18.2597, Exploration Rate = 0.1714, Train Count = 12609\n",
      "Episode 588: Reward = 547.00, Steps = 4, Loss = 12.2326, Exploration Rate = 0.1709, Train Count = 12613\n",
      "Episode 589: Reward = 573.00, Steps = 11, Loss = 15.6490, Exploration Rate = 0.1704, Train Count = 12624\n",
      "Episode 590: Reward = 594.00, Steps = 4, Loss = 18.6958, Exploration Rate = 0.1699, Train Count = 12628\n",
      "Episode 591: Reward = 576.00, Steps = 10, Loss = 18.0122, Exploration Rate = 0.1694, Train Count = 12638\n",
      "Episode 592: Reward = 582.00, Steps = 8, Loss = 21.3202, Exploration Rate = 0.1689, Train Count = 12646\n",
      "Episode 593: Reward = 564.00, Steps = 14, Loss = 32.6194, Exploration Rate = 0.1684, Train Count = 12660\n",
      "Episode 594: Reward = 538.00, Steps = 7, Loss = 33.1781, Exploration Rate = 0.1679, Train Count = 12667\n",
      "Episode 595: Reward = 573.00, Steps = 11, Loss = 25.8876, Exploration Rate = 0.1673, Train Count = 12678\n",
      "Episode 596: Reward = 597.00, Steps = 3, Loss = 21.3305, Exploration Rate = 0.1668, Train Count = 12681\n",
      "Episode 597: Reward = 582.00, Steps = 8, Loss = 48.6299, Exploration Rate = 0.1663, Train Count = 12689\n",
      "Episode 598: Reward = 597.00, Steps = 3, Loss = 91.3460, Exploration Rate = 0.1658, Train Count = 12692\n",
      "Episode 599: Reward = 492.00, Steps = 38, Loss = 65.9524, Exploration Rate = 0.1653, Train Count = 12730\n",
      "Episode 600: Reward = 600.00, Steps = 2, Loss = 49.2641, Exploration Rate = 0.1649, Train Count = 12732\n",
      "Episode 601: Reward = 579.00, Steps = 9, Loss = 60.0600, Exploration Rate = 0.1644, Train Count = 12741\n",
      "Episode 602: Reward = 540.00, Steps = 22, Loss = 64.2339, Exploration Rate = 0.1639, Train Count = 12763\n",
      "Episode 603: Reward = 594.00, Steps = 4, Loss = 50.6990, Exploration Rate = 0.1634, Train Count = 12767\n",
      "Episode 604: Reward = 442.00, Steps = 39, Loss = 99.1133, Exploration Rate = 0.1629, Train Count = 12806\n",
      "Episode 605: Reward = 576.00, Steps = 10, Loss = 200.8580, Exploration Rate = 0.1624, Train Count = 12816\n",
      "Episode 606: Reward = 600.00, Steps = 2, Loss = 154.4943, Exploration Rate = 0.1619, Train Count = 12818\n",
      "Episode 607: Reward = 538.00, Steps = 7, Loss = 135.6733, Exploration Rate = 0.1614, Train Count = 12825\n",
      "Episode 608: Reward = 597.00, Steps = 3, Loss = 112.5439, Exploration Rate = 0.1609, Train Count = 12828\n",
      "Episode 609: Reward = 555.00, Steps = 17, Loss = 123.9030, Exploration Rate = 0.1605, Train Count = 12845\n",
      "Episode 610: Reward = 588.00, Steps = 6, Loss = 124.7513, Exploration Rate = 0.1600, Train Count = 12851\n",
      "Episode 611: Reward = 498.00, Steps = 36, Loss = 90.0250, Exploration Rate = 0.1595, Train Count = 12887\n",
      "Episode 612: Reward = 579.00, Steps = 9, Loss = 84.9773, Exploration Rate = 0.1590, Train Count = 12896\n",
      "Episode 613: Reward = 570.00, Steps = 12, Loss = 57.1565, Exploration Rate = 0.1585, Train Count = 12908\n",
      "Episode 614: Reward = 594.00, Steps = 4, Loss = 54.6641, Exploration Rate = 0.1581, Train Count = 12912\n",
      "Episode 615: Reward = 591.00, Steps = 5, Loss = 58.1138, Exploration Rate = 0.1576, Train Count = 12917\n",
      "Episode 616: Reward = 597.00, Steps = 3, Loss = 56.1632, Exploration Rate = 0.1571, Train Count = 12920\n",
      "Episode 617: Reward = 591.00, Steps = 5, Loss = 43.2093, Exploration Rate = 0.1566, Train Count = 12925\n",
      "Episode 618: Reward = 600.00, Steps = 2, Loss = 40.3503, Exploration Rate = 0.1562, Train Count = 12927\n",
      "Episode 619: Reward = 588.00, Steps = 6, Loss = 43.8497, Exploration Rate = 0.1557, Train Count = 12933\n",
      "Episode 620: Reward = 535.00, Steps = 8, Loss = 37.3349, Exploration Rate = 0.1552, Train Count = 12941\n",
      "Episode 621: Reward = 597.00, Steps = 3, Loss = 31.7618, Exploration Rate = 0.1548, Train Count = 12944\n",
      "Episode 622: Reward = 588.00, Steps = 6, Loss = 37.1356, Exploration Rate = 0.1543, Train Count = 12950\n",
      "Episode 623: Reward = 591.00, Steps = 5, Loss = 39.3214, Exploration Rate = 0.1538, Train Count = 12955\n",
      "Episode 624: Reward = 588.00, Steps = 6, Loss = 42.8396, Exploration Rate = 0.1534, Train Count = 12961\n",
      "Episode 625: Reward = 585.00, Steps = 7, Loss = 45.1248, Exploration Rate = 0.1529, Train Count = 12968\n",
      "Episode 626: Reward = 594.00, Steps = 4, Loss = 46.6318, Exploration Rate = 0.1525, Train Count = 12972\n",
      "Episode 627: Reward = 585.00, Steps = 7, Loss = 50.7283, Exploration Rate = 0.1520, Train Count = 12979\n",
      "Episode 628: Reward = 549.00, Steps = 19, Loss = 48.0625, Exploration Rate = 0.1516, Train Count = 12998\n",
      "Episode 629: Reward = 537.00, Steps = 23, Loss = 40.2077, Exploration Rate = 0.1511, Train Count = 13021\n",
      "Episode 630: Reward = 576.00, Steps = 10, Loss = 35.1580, Exploration Rate = 0.1506, Train Count = 13031\n",
      "Episode 631: Reward = 579.00, Steps = 9, Loss = 30.9262, Exploration Rate = 0.1502, Train Count = 13040\n",
      "Episode 632: Reward = 585.00, Steps = 7, Loss = 48.7553, Exploration Rate = 0.1497, Train Count = 13047\n",
      "Episode 633: Reward = 582.00, Steps = 8, Loss = 41.2520, Exploration Rate = 0.1493, Train Count = 13055\n",
      "Episode 634: Reward = 588.00, Steps = 6, Loss = 35.9785, Exploration Rate = 0.1488, Train Count = 13061\n",
      "Episode 635: Reward = 600.00, Steps = 2, Loss = 39.9353, Exploration Rate = 0.1484, Train Count = 13063\n",
      "Episode 636: Reward = 594.00, Steps = 4, Loss = 37.4992, Exploration Rate = 0.1480, Train Count = 13067\n",
      "Episode 637: Reward = 576.00, Steps = 10, Loss = 39.4162, Exploration Rate = 0.1475, Train Count = 13077\n",
      "Episode 638: Reward = 573.00, Steps = 11, Loss = 72.2579, Exploration Rate = 0.1471, Train Count = 13088\n",
      "Episode 639: Reward = 591.00, Steps = 5, Loss = 64.2489, Exploration Rate = 0.1466, Train Count = 13093\n",
      "Episode 640: Reward = 585.00, Steps = 7, Loss = 56.9908, Exploration Rate = 0.1462, Train Count = 13100\n",
      "Episode 641: Reward = 582.00, Steps = 8, Loss = 42.4631, Exploration Rate = 0.1457, Train Count = 13108\n",
      "Episode 642: Reward = 532.00, Steps = 9, Loss = 47.4044, Exploration Rate = 0.1453, Train Count = 13117\n",
      "Episode 643: Reward = 591.00, Steps = 5, Loss = 59.0518, Exploration Rate = 0.1449, Train Count = 13122\n",
      "Episode 644: Reward = 541.00, Steps = 6, Loss = 40.0615, Exploration Rate = 0.1444, Train Count = 13128\n",
      "Episode 645: Reward = 597.00, Steps = 3, Loss = 27.7648, Exploration Rate = 0.1440, Train Count = 13131\n",
      "Episode 646: Reward = 522.00, Steps = 28, Loss = 48.8001, Exploration Rate = 0.1436, Train Count = 13159\n",
      "Episode 647: Reward = 552.00, Steps = 18, Loss = 41.1331, Exploration Rate = 0.1431, Train Count = 13177\n",
      "Episode 648: Reward = 588.00, Steps = 6, Loss = 42.1594, Exploration Rate = 0.1427, Train Count = 13183\n",
      "Episode 649: Reward = 558.00, Steps = 16, Loss = 41.3894, Exploration Rate = 0.1423, Train Count = 13199\n",
      "Episode 650: Reward = 597.00, Steps = 3, Loss = 51.4161, Exploration Rate = 0.1419, Train Count = 13202\n",
      "Episode 651: Reward = 579.00, Steps = 9, Loss = 36.1877, Exploration Rate = 0.1414, Train Count = 13211\n",
      "Episode 652: Reward = 585.00, Steps = 7, Loss = 30.4534, Exploration Rate = 0.1410, Train Count = 13218\n",
      "Episode 653: Reward = 582.00, Steps = 8, Loss = 45.1701, Exploration Rate = 0.1406, Train Count = 13226\n",
      "Episode 654: Reward = 591.00, Steps = 5, Loss = 55.1500, Exploration Rate = 0.1402, Train Count = 13231\n",
      "Episode 655: Reward = 591.00, Steps = 5, Loss = 41.5633, Exploration Rate = 0.1397, Train Count = 13236\n",
      "Episode 656: Reward = 561.00, Steps = 15, Loss = 35.7975, Exploration Rate = 0.1393, Train Count = 13251\n",
      "Episode 657: Reward = 594.00, Steps = 4, Loss = 31.8473, Exploration Rate = 0.1389, Train Count = 13255\n",
      "Episode 658: Reward = 588.00, Steps = 6, Loss = 37.3282, Exploration Rate = 0.1385, Train Count = 13261\n",
      "Episode 659: Reward = 585.00, Steps = 7, Loss = 28.1824, Exploration Rate = 0.1381, Train Count = 13268\n",
      "Episode 660: Reward = 588.00, Steps = 6, Loss = 25.4485, Exploration Rate = 0.1377, Train Count = 13274\n",
      "Episode 661: Reward = 600.00, Steps = 2, Loss = 33.7809, Exploration Rate = 0.1372, Train Count = 13276\n",
      "Episode 662: Reward = 591.00, Steps = 5, Loss = 29.3598, Exploration Rate = 0.1368, Train Count = 13281\n",
      "Episode 663: Reward = 582.00, Steps = 8, Loss = 21.9432, Exploration Rate = 0.1364, Train Count = 13289\n",
      "Episode 664: Reward = 597.00, Steps = 3, Loss = 21.5048, Exploration Rate = 0.1360, Train Count = 13292\n",
      "Episode 665: Reward = 585.00, Steps = 7, Loss = 34.0166, Exploration Rate = 0.1356, Train Count = 13299\n",
      "Episode 666: Reward = 576.00, Steps = 10, Loss = 320.0471, Exploration Rate = 0.1352, Train Count = 13309\n",
      "Episode 667: Reward = 484.00, Steps = 25, Loss = 160.0800, Exploration Rate = 0.1348, Train Count = 13334\n",
      "Episode 668: Reward = 579.00, Steps = 9, Loss = 91.4128, Exploration Rate = 0.1344, Train Count = 13343\n",
      "Episode 669: Reward = 597.00, Steps = 3, Loss = 79.6026, Exploration Rate = 0.1340, Train Count = 13346\n",
      "Episode 670: Reward = 597.00, Steps = 3, Loss = 68.4888, Exploration Rate = 0.1336, Train Count = 13349\n",
      "Episode 671: Reward = 594.00, Steps = 4, Loss = 68.6989, Exploration Rate = 0.1332, Train Count = 13353\n",
      "Episode 672: Reward = 594.00, Steps = 4, Loss = 69.6334, Exploration Rate = 0.1328, Train Count = 13357\n",
      "Episode 673: Reward = 591.00, Steps = 5, Loss = 65.8517, Exploration Rate = 0.1324, Train Count = 13362\n",
      "Episode 674: Reward = 585.00, Steps = 7, Loss = 66.7417, Exploration Rate = 0.1320, Train Count = 13369\n",
      "Episode 675: Reward = 525.00, Steps = 27, Loss = 60.0477, Exploration Rate = 0.1316, Train Count = 13396\n",
      "Episode 676: Reward = 585.00, Steps = 7, Loss = 53.4320, Exploration Rate = 0.1312, Train Count = 13403\n",
      "Episode 677: Reward = 591.00, Steps = 5, Loss = 39.5755, Exploration Rate = 0.1308, Train Count = 13408\n",
      "Episode 678: Reward = 585.00, Steps = 7, Loss = 38.8968, Exploration Rate = 0.1304, Train Count = 13415\n",
      "Episode 679: Reward = 555.00, Steps = 17, Loss = 35.2631, Exploration Rate = 0.1300, Train Count = 13432\n",
      "Episode 680: Reward = 585.00, Steps = 7, Loss = 35.8712, Exploration Rate = 0.1296, Train Count = 13439\n",
      "Episode 681: Reward = 552.00, Steps = 18, Loss = 39.2755, Exploration Rate = 0.1292, Train Count = 13457\n",
      "Episode 682: Reward = 585.00, Steps = 7, Loss = 48.6480, Exploration Rate = 0.1289, Train Count = 13464\n",
      "Episode 683: Reward = 597.00, Steps = 3, Loss = 42.1987, Exploration Rate = 0.1285, Train Count = 13467\n",
      "Episode 684: Reward = 591.00, Steps = 5, Loss = 41.4417, Exploration Rate = 0.1281, Train Count = 13472\n",
      "Episode 685: Reward = 546.00, Steps = 20, Loss = 51.3161, Exploration Rate = 0.1277, Train Count = 13492\n",
      "Episode 686: Reward = 489.00, Steps = 39, Loss = 41.8122, Exploration Rate = 0.1273, Train Count = 13531\n",
      "Episode 687: Reward = 585.00, Steps = 7, Loss = 27.7687, Exploration Rate = 0.1269, Train Count = 13538\n",
      "Episode 688: Reward = 532.00, Steps = 9, Loss = 40.0498, Exploration Rate = 0.1266, Train Count = 13547\n",
      "Episode 689: Reward = 318.00, Steps = 96, Loss = 18.0629, Exploration Rate = 0.1262, Train Count = 13643\n",
      "Episode 690: Reward = 591.00, Steps = 5, Loss = 20.7594, Exploration Rate = 0.1258, Train Count = 13648\n",
      "Episode 691: Reward = 591.00, Steps = 5, Loss = 29.0631, Exploration Rate = 0.1254, Train Count = 13653\n",
      "Episode 692: Reward = 594.00, Steps = 4, Loss = 26.4914, Exploration Rate = 0.1250, Train Count = 13657\n",
      "Episode 693: Reward = 591.00, Steps = 5, Loss = 16.7238, Exploration Rate = 0.1247, Train Count = 13662\n",
      "Episode 694: Reward = 567.00, Steps = 13, Loss = 21.2093, Exploration Rate = 0.1243, Train Count = 13675\n",
      "Episode 695: Reward = 394.00, Steps = 55, Loss = 25.3508, Exploration Rate = 0.1239, Train Count = 13730\n",
      "Episode 696: Reward = 588.00, Steps = 6, Loss = 21.0014, Exploration Rate = 0.1235, Train Count = 13736\n",
      "Episode 697: Reward = 582.00, Steps = 8, Loss = 35.0606, Exploration Rate = 0.1232, Train Count = 13744\n",
      "Episode 698: Reward = 555.00, Steps = 17, Loss = 25.7708, Exploration Rate = 0.1228, Train Count = 13761\n",
      "Episode 699: Reward = 532.00, Steps = 9, Loss = 30.6979, Exploration Rate = 0.1224, Train Count = 13770\n",
      "Episode 700: Reward = 594.00, Steps = 4, Loss = 18.3192, Exploration Rate = 0.1221, Train Count = 13774\n",
      "Episode 701: Reward = 582.00, Steps = 8, Loss = 35.0920, Exploration Rate = 0.1217, Train Count = 13782\n",
      "Episode 702: Reward = 588.00, Steps = 6, Loss = 25.4135, Exploration Rate = 0.1213, Train Count = 13788\n",
      "Episode 703: Reward = 585.00, Steps = 7, Loss = 32.2522, Exploration Rate = 0.1210, Train Count = 13795\n",
      "Episode 704: Reward = 585.00, Steps = 7, Loss = 129.1797, Exploration Rate = 0.1206, Train Count = 13802\n",
      "Episode 705: Reward = 579.00, Steps = 9, Loss = 222.7646, Exploration Rate = 0.1203, Train Count = 13811\n",
      "Episode 706: Reward = 591.00, Steps = 5, Loss = 171.5161, Exploration Rate = 0.1199, Train Count = 13816\n",
      "Episode 707: Reward = 588.00, Steps = 6, Loss = 141.4273, Exploration Rate = 0.1195, Train Count = 13822\n",
      "Episode 708: Reward = 576.00, Steps = 10, Loss = 107.3959, Exploration Rate = 0.1192, Train Count = 13832\n",
      "Episode 709: Reward = 600.00, Steps = 2, Loss = 120.9227, Exploration Rate = 0.1188, Train Count = 13834\n",
      "Episode 710: Reward = 594.00, Steps = 4, Loss = 91.3801, Exploration Rate = 0.1185, Train Count = 13838\n",
      "Episode 711: Reward = 597.00, Steps = 3, Loss = 87.4529, Exploration Rate = 0.1181, Train Count = 13841\n",
      "Episode 712: Reward = 588.00, Steps = 6, Loss = 78.2597, Exploration Rate = 0.1177, Train Count = 13847\n",
      "Episode 713: Reward = 529.00, Steps = 10, Loss = 73.5708, Exploration Rate = 0.1174, Train Count = 13857\n",
      "Episode 714: Reward = 591.00, Steps = 5, Loss = 88.7166, Exploration Rate = 0.1170, Train Count = 13862\n",
      "Episode 715: Reward = 573.00, Steps = 11, Loss = 59.5138, Exploration Rate = 0.1167, Train Count = 13873\n",
      "Episode 716: Reward = 591.00, Steps = 5, Loss = 57.4167, Exploration Rate = 0.1163, Train Count = 13878\n",
      "Episode 717: Reward = 531.00, Steps = 25, Loss = 54.9068, Exploration Rate = 0.1160, Train Count = 13903\n",
      "Episode 718: Reward = 594.00, Steps = 4, Loss = 49.7762, Exploration Rate = 0.1156, Train Count = 13907\n",
      "Episode 719: Reward = 591.00, Steps = 5, Loss = 58.3170, Exploration Rate = 0.1153, Train Count = 13912\n",
      "Episode 720: Reward = 588.00, Steps = 6, Loss = 61.1504, Exploration Rate = 0.1150, Train Count = 13918\n",
      "Episode 721: Reward = 594.00, Steps = 4, Loss = 55.4274, Exploration Rate = 0.1146, Train Count = 13922\n",
      "Episode 722: Reward = 594.00, Steps = 4, Loss = 47.5912, Exploration Rate = 0.1143, Train Count = 13926\n",
      "Episode 723: Reward = 585.00, Steps = 7, Loss = 44.6108, Exploration Rate = 0.1139, Train Count = 13933\n",
      "Episode 724: Reward = 591.00, Steps = 5, Loss = 40.8390, Exploration Rate = 0.1136, Train Count = 13938\n",
      "Episode 725: Reward = 588.00, Steps = 6, Loss = 42.0788, Exploration Rate = 0.1132, Train Count = 13944\n",
      "Episode 726: Reward = 582.00, Steps = 8, Loss = 40.0052, Exploration Rate = 0.1129, Train Count = 13952\n",
      "Episode 727: Reward = 588.00, Steps = 6, Loss = 47.0292, Exploration Rate = 0.1126, Train Count = 13958\n",
      "Episode 728: Reward = 591.00, Steps = 5, Loss = 44.2967, Exploration Rate = 0.1122, Train Count = 13963\n",
      "Episode 729: Reward = 411.00, Steps = 65, Loss = 28.9198, Exploration Rate = 0.1119, Train Count = 14028\n",
      "Episode 730: Reward = 537.00, Steps = 23, Loss = 20.7448, Exploration Rate = 0.1115, Train Count = 14051\n",
      "Episode 731: Reward = 597.00, Steps = 3, Loss = 11.7829, Exploration Rate = 0.1112, Train Count = 14054\n",
      "Episode 732: Reward = 588.00, Steps = 6, Loss = 37.7423, Exploration Rate = 0.1109, Train Count = 14060\n",
      "Episode 733: Reward = 582.00, Steps = 8, Loss = 31.0563, Exploration Rate = 0.1105, Train Count = 14068\n",
      "Episode 734: Reward = 582.00, Steps = 8, Loss = 37.0863, Exploration Rate = 0.1102, Train Count = 14076\n",
      "Episode 735: Reward = 588.00, Steps = 6, Loss = 28.3317, Exploration Rate = 0.1099, Train Count = 14082\n",
      "Episode 736: Reward = 354.00, Steps = 84, Loss = 24.9415, Exploration Rate = 0.1096, Train Count = 14166\n",
      "Episode 737: Reward = 541.00, Steps = 6, Loss = 20.9969, Exploration Rate = 0.1092, Train Count = 14172\n",
      "Episode 738: Reward = 582.00, Steps = 8, Loss = 30.7323, Exploration Rate = 0.1089, Train Count = 14180\n",
      "Episode 739: Reward = 588.00, Steps = 6, Loss = 32.8923, Exploration Rate = 0.1086, Train Count = 14186\n",
      "Episode 740: Reward = 585.00, Steps = 7, Loss = 34.8711, Exploration Rate = 0.1082, Train Count = 14193\n",
      "Episode 741: Reward = 570.00, Steps = 12, Loss = 27.6391, Exploration Rate = 0.1079, Train Count = 14205\n",
      "Episode 742: Reward = 597.00, Steps = 3, Loss = 33.4141, Exploration Rate = 0.1076, Train Count = 14208\n",
      "Episode 743: Reward = 588.00, Steps = 6, Loss = 36.5736, Exploration Rate = 0.1073, Train Count = 14214\n",
      "Episode 744: Reward = 585.00, Steps = 7, Loss = 36.9429, Exploration Rate = 0.1070, Train Count = 14221\n",
      "Episode 745: Reward = 526.00, Steps = 11, Loss = 28.7986, Exploration Rate = 0.1066, Train Count = 14232\n",
      "Episode 746: Reward = 597.00, Steps = 3, Loss = 31.9731, Exploration Rate = 0.1063, Train Count = 14235\n",
      "Episode 747: Reward = 573.00, Steps = 11, Loss = 45.2499, Exploration Rate = 0.1060, Train Count = 14246\n",
      "Episode 748: Reward = 600.00, Steps = 2, Loss = 37.7690, Exploration Rate = 0.1057, Train Count = 14248\n",
      "Episode 749: Reward = 564.00, Steps = 14, Loss = 47.0473, Exploration Rate = 0.1054, Train Count = 14262\n",
      "Episode 750: Reward = 594.00, Steps = 4, Loss = 47.7574, Exploration Rate = 0.1050, Train Count = 14266\n",
      "Episode 751: Reward = 588.00, Steps = 6, Loss = 51.1065, Exploration Rate = 0.1047, Train Count = 14272\n",
      "Episode 752: Reward = 570.00, Steps = 12, Loss = 39.4715, Exploration Rate = 0.1044, Train Count = 14284\n",
      "Episode 753: Reward = 597.00, Steps = 3, Loss = 33.5975, Exploration Rate = 0.1041, Train Count = 14287\n",
      "Episode 754: Reward = 594.00, Steps = 4, Loss = 34.7619, Exploration Rate = 0.1038, Train Count = 14291\n",
      "Episode 755: Reward = 558.00, Steps = 16, Loss = 136.4838, Exploration Rate = 0.1035, Train Count = 14307\n",
      "Episode 756: Reward = 576.00, Steps = 10, Loss = 147.7560, Exploration Rate = 0.1032, Train Count = 14317\n",
      "Episode 757: Reward = 585.00, Steps = 7, Loss = 116.6248, Exploration Rate = 0.1029, Train Count = 14324\n",
      "Episode 758: Reward = 600.00, Steps = 2, Loss = 95.3116, Exploration Rate = 0.1025, Train Count = 14326\n",
      "Episode 759: Reward = 585.00, Steps = 7, Loss = 76.5332, Exploration Rate = 0.1022, Train Count = 14333\n",
      "Episode 760: Reward = 591.00, Steps = 5, Loss = 87.3315, Exploration Rate = 0.1019, Train Count = 14338\n",
      "Episode 761: Reward = 591.00, Steps = 5, Loss = 63.7302, Exploration Rate = 0.1016, Train Count = 14343\n",
      "Episode 762: Reward = 573.00, Steps = 11, Loss = 56.3828, Exploration Rate = 0.1013, Train Count = 14354\n",
      "Episode 763: Reward = 588.00, Steps = 6, Loss = 50.7414, Exploration Rate = 0.1010, Train Count = 14360\n",
      "Episode 764: Reward = 597.00, Steps = 3, Loss = 50.9855, Exploration Rate = 0.1007, Train Count = 14363\n",
      "Episode 765: Reward = 555.00, Steps = 17, Loss = 64.4144, Exploration Rate = 0.1004, Train Count = 14380\n",
      "Episode 766: Reward = 517.00, Steps = 14, Loss = 46.2604, Exploration Rate = 0.1001, Train Count = 14394\n",
      "Episode 767: Reward = 582.00, Steps = 8, Loss = 37.9222, Exploration Rate = 0.1000, Train Count = 14402\n",
      "Episode 768: Reward = 444.00, Steps = 54, Loss = 29.7504, Exploration Rate = 0.1000, Train Count = 14456\n",
      "Episode 769: Reward = 585.00, Steps = 7, Loss = 23.0613, Exploration Rate = 0.1000, Train Count = 14463\n",
      "Episode 770: Reward = 588.00, Steps = 6, Loss = 23.5810, Exploration Rate = 0.1000, Train Count = 14469\n",
      "Episode 771: Reward = 585.00, Steps = 7, Loss = 23.0787, Exploration Rate = 0.1000, Train Count = 14476\n",
      "Episode 772: Reward = 591.00, Steps = 5, Loss = 15.3006, Exploration Rate = 0.1000, Train Count = 14481\n",
      "Episode 773: Reward = 582.00, Steps = 8, Loss = 34.8575, Exploration Rate = 0.1000, Train Count = 14489\n",
      "Episode 774: Reward = 591.00, Steps = 5, Loss = 26.7454, Exploration Rate = 0.1000, Train Count = 14494\n",
      "Episode 775: Reward = 591.00, Steps = 5, Loss = 38.0370, Exploration Rate = 0.1000, Train Count = 14499\n",
      "Episode 776: Reward = 567.00, Steps = 13, Loss = 45.2908, Exploration Rate = 0.1000, Train Count = 14512\n",
      "Episode 777: Reward = 597.00, Steps = 3, Loss = 31.3030, Exploration Rate = 0.1000, Train Count = 14515\n",
      "Episode 778: Reward = 591.00, Steps = 5, Loss = 23.1529, Exploration Rate = 0.1000, Train Count = 14520\n",
      "Episode 779: Reward = 585.00, Steps = 7, Loss = 22.9416, Exploration Rate = 0.1000, Train Count = 14527\n",
      "Episode 780: Reward = 579.00, Steps = 9, Loss = 46.5133, Exploration Rate = 0.1000, Train Count = 14536\n",
      "Episode 781: Reward = 573.00, Steps = 11, Loss = 34.1375, Exploration Rate = 0.1000, Train Count = 14547\n",
      "Episode 782: Reward = 489.00, Steps = 39, Loss = 28.1094, Exploration Rate = 0.1000, Train Count = 14586\n",
      "Episode 783: Reward = 588.00, Steps = 6, Loss = 24.2834, Exploration Rate = 0.1000, Train Count = 14592\n",
      "Episode 784: Reward = 579.00, Steps = 9, Loss = 21.2575, Exploration Rate = 0.1000, Train Count = 14601\n",
      "Episode 785: Reward = 579.00, Steps = 9, Loss = 21.9283, Exploration Rate = 0.1000, Train Count = 14610\n",
      "Episode 786: Reward = 411.00, Steps = 65, Loss = 24.4416, Exploration Rate = 0.1000, Train Count = 14675\n",
      "Episode 787: Reward = 597.00, Steps = 3, Loss = 16.7831, Exploration Rate = 0.1000, Train Count = 14678\n",
      "Episode 788: Reward = 585.00, Steps = 7, Loss = 11.9199, Exploration Rate = 0.1000, Train Count = 14685\n",
      "Episode 789: Reward = 588.00, Steps = 6, Loss = 17.2219, Exploration Rate = 0.1000, Train Count = 14691\n",
      "Episode 790: Reward = 588.00, Steps = 6, Loss = 19.1482, Exploration Rate = 0.1000, Train Count = 14697\n",
      "Episode 791: Reward = 591.00, Steps = 5, Loss = 24.0154, Exploration Rate = 0.1000, Train Count = 14702\n",
      "Episode 792: Reward = 585.00, Steps = 7, Loss = 14.9847, Exploration Rate = 0.1000, Train Count = 14709\n",
      "Episode 793: Reward = 585.00, Steps = 7, Loss = 16.4478, Exploration Rate = 0.1000, Train Count = 14716\n",
      "Episode 794: Reward = 564.00, Steps = 14, Loss = 36.9245, Exploration Rate = 0.1000, Train Count = 14730\n",
      "Episode 795: Reward = 600.00, Steps = 2, Loss = 21.6241, Exploration Rate = 0.1000, Train Count = 14732\n",
      "Episode 796: Reward = 531.00, Steps = 25, Loss = 30.8303, Exploration Rate = 0.1000, Train Count = 14757\n",
      "Episode 797: Reward = 585.00, Steps = 7, Loss = 23.5506, Exploration Rate = 0.1000, Train Count = 14764\n",
      "Episode 798: Reward = 594.00, Steps = 4, Loss = 29.9746, Exploration Rate = 0.1000, Train Count = 14768\n",
      "Episode 799: Reward = 535.00, Steps = 8, Loss = 29.1702, Exploration Rate = 0.1000, Train Count = 14776\n",
      "Episode 800: Reward = 582.00, Steps = 8, Loss = 26.2205, Exploration Rate = 0.1000, Train Count = 14784\n",
      "Episode 801: Reward = 588.00, Steps = 6, Loss = 16.4998, Exploration Rate = 0.1000, Train Count = 14790\n",
      "Episode 802: Reward = 573.00, Steps = 11, Loss = 52.3144, Exploration Rate = 0.1000, Train Count = 14801\n",
      "Episode 803: Reward = 582.00, Steps = 8, Loss = 217.6792, Exploration Rate = 0.1000, Train Count = 14809\n",
      "Episode 804: Reward = 588.00, Steps = 6, Loss = 168.7600, Exploration Rate = 0.1000, Train Count = 14815\n",
      "Episode 805: Reward = 588.00, Steps = 6, Loss = 121.5047, Exploration Rate = 0.1000, Train Count = 14821\n",
      "Episode 806: Reward = 588.00, Steps = 6, Loss = 103.1590, Exploration Rate = 0.1000, Train Count = 14827\n",
      "Episode 807: Reward = 588.00, Steps = 6, Loss = 78.8175, Exploration Rate = 0.1000, Train Count = 14833\n",
      "Episode 808: Reward = 585.00, Steps = 7, Loss = 66.3269, Exploration Rate = 0.1000, Train Count = 14840\n",
      "Episode 809: Reward = 588.00, Steps = 6, Loss = 63.6723, Exploration Rate = 0.1000, Train Count = 14846\n",
      "Episode 810: Reward = 588.00, Steps = 6, Loss = 57.2550, Exploration Rate = 0.1000, Train Count = 14852\n",
      "Episode 811: Reward = 588.00, Steps = 6, Loss = 44.7483, Exploration Rate = 0.1000, Train Count = 14858\n",
      "Episode 812: Reward = 582.00, Steps = 8, Loss = 35.8023, Exploration Rate = 0.1000, Train Count = 14866\n",
      "Episode 813: Reward = 588.00, Steps = 6, Loss = 48.2979, Exploration Rate = 0.1000, Train Count = 14872\n",
      "Episode 814: Reward = 573.00, Steps = 11, Loss = 36.6866, Exploration Rate = 0.1000, Train Count = 14883\n",
      "Episode 815: Reward = 588.00, Steps = 6, Loss = 30.5694, Exploration Rate = 0.1000, Train Count = 14889\n",
      "Episode 816: Reward = 573.00, Steps = 11, Loss = 31.5320, Exploration Rate = 0.1000, Train Count = 14900\n",
      "Episode 817: Reward = 597.00, Steps = 3, Loss = 30.9807, Exploration Rate = 0.1000, Train Count = 14903\n",
      "Episode 818: Reward = 495.00, Steps = 37, Loss = 28.5558, Exploration Rate = 0.1000, Train Count = 14940\n",
      "Episode 819: Reward = 594.00, Steps = 4, Loss = 17.6086, Exploration Rate = 0.1000, Train Count = 14944\n",
      "Episode 820: Reward = 585.00, Steps = 7, Loss = 16.4885, Exploration Rate = 0.1000, Train Count = 14951\n",
      "Episode 821: Reward = 600.00, Steps = 2, Loss = 21.0382, Exploration Rate = 0.1000, Train Count = 14953\n",
      "Episode 822: Reward = 588.00, Steps = 6, Loss = 18.1858, Exploration Rate = 0.1000, Train Count = 14959\n",
      "Episode 823: Reward = 535.00, Steps = 8, Loss = 27.1128, Exploration Rate = 0.1000, Train Count = 14967\n",
      "Episode 824: Reward = 594.00, Steps = 4, Loss = 46.4458, Exploration Rate = 0.1000, Train Count = 14971\n",
      "Episode 825: Reward = 594.00, Steps = 4, Loss = 37.6197, Exploration Rate = 0.1000, Train Count = 14975\n",
      "Episode 826: Reward = 591.00, Steps = 5, Loss = 25.4286, Exploration Rate = 0.1000, Train Count = 14980\n",
      "Episode 827: Reward = 531.00, Steps = 25, Loss = 32.6137, Exploration Rate = 0.1000, Train Count = 15005\n",
      "Episode 828: Reward = 597.00, Steps = 3, Loss = 23.9150, Exploration Rate = 0.1000, Train Count = 15008\n",
      "Episode 829: Reward = 600.00, Steps = 2, Loss = 21.5666, Exploration Rate = 0.1000, Train Count = 15010\n",
      "Episode 830: Reward = 585.00, Steps = 7, Loss = 21.7451, Exploration Rate = 0.1000, Train Count = 15017\n",
      "Episode 831: Reward = 585.00, Steps = 7, Loss = 16.1709, Exploration Rate = 0.1000, Train Count = 15024\n",
      "Episode 832: Reward = 532.00, Steps = 9, Loss = 23.0525, Exploration Rate = 0.1000, Train Count = 15033\n",
      "Episode 833: Reward = 582.00, Steps = 8, Loss = 32.8150, Exploration Rate = 0.1000, Train Count = 15041\n",
      "Episode 834: Reward = 594.00, Steps = 4, Loss = 45.3645, Exploration Rate = 0.1000, Train Count = 15045\n",
      "Episode 835: Reward = 600.00, Steps = 2, Loss = 22.2999, Exploration Rate = 0.1000, Train Count = 15047\n",
      "Episode 836: Reward = 594.00, Steps = 4, Loss = 32.0033, Exploration Rate = 0.1000, Train Count = 15051\n",
      "Episode 837: Reward = 529.00, Steps = 10, Loss = 29.0715, Exploration Rate = 0.1000, Train Count = 15061\n",
      "Episode 838: Reward = 594.00, Steps = 4, Loss = 43.5647, Exploration Rate = 0.1000, Train Count = 15065\n",
      "Episode 839: Reward = 597.00, Steps = 3, Loss = 43.2600, Exploration Rate = 0.1000, Train Count = 15068\n",
      "Episode 840: Reward = 591.00, Steps = 5, Loss = 33.3705, Exploration Rate = 0.1000, Train Count = 15073\n",
      "Episode 841: Reward = 600.00, Steps = 2, Loss = 25.8827, Exploration Rate = 0.1000, Train Count = 15075\n",
      "Episode 842: Reward = 591.00, Steps = 5, Loss = 24.6492, Exploration Rate = 0.1000, Train Count = 15080\n",
      "Episode 843: Reward = 594.00, Steps = 4, Loss = 27.7618, Exploration Rate = 0.1000, Train Count = 15084\n",
      "Episode 844: Reward = 585.00, Steps = 7, Loss = 35.3463, Exploration Rate = 0.1000, Train Count = 15091\n",
      "Episode 845: Reward = 579.00, Steps = 9, Loss = 26.7245, Exploration Rate = 0.1000, Train Count = 15100\n",
      "Episode 846: Reward = 519.00, Steps = 29, Loss = 29.3272, Exploration Rate = 0.1000, Train Count = 15129\n",
      "Episode 847: Reward = 591.00, Steps = 5, Loss = 18.3288, Exploration Rate = 0.1000, Train Count = 15134\n",
      "Episode 848: Reward = 594.00, Steps = 4, Loss = 27.7495, Exploration Rate = 0.1000, Train Count = 15138\n",
      "Episode 849: Reward = 582.00, Steps = 8, Loss = 18.3543, Exploration Rate = 0.1000, Train Count = 15146\n",
      "Episode 850: Reward = 588.00, Steps = 6, Loss = 23.2805, Exploration Rate = 0.1000, Train Count = 15152\n",
      "Episode 851: Reward = 564.00, Steps = 14, Loss = 31.4309, Exploration Rate = 0.1000, Train Count = 15166\n",
      "Episode 852: Reward = 526.00, Steps = 11, Loss = 29.1377, Exploration Rate = 0.1000, Train Count = 15177\n",
      "Episode 853: Reward = 597.00, Steps = 3, Loss = 26.5374, Exploration Rate = 0.1000, Train Count = 15180\n",
      "Episode 854: Reward = 588.00, Steps = 6, Loss = 27.3223, Exploration Rate = 0.1000, Train Count = 15186\n",
      "Episode 855: Reward = 585.00, Steps = 7, Loss = 22.9193, Exploration Rate = 0.1000, Train Count = 15193\n",
      "Episode 856: Reward = 594.00, Steps = 4, Loss = 21.7383, Exploration Rate = 0.1000, Train Count = 15197\n",
      "Episode 857: Reward = 588.00, Steps = 6, Loss = 19.5369, Exploration Rate = 0.1000, Train Count = 15203\n",
      "Episode 858: Reward = 597.00, Steps = 3, Loss = 17.6737, Exploration Rate = 0.1000, Train Count = 15206\n",
      "Episode 859: Reward = 588.00, Steps = 6, Loss = 15.0590, Exploration Rate = 0.1000, Train Count = 15212\n",
      "Episode 860: Reward = 582.00, Steps = 8, Loss = 23.1563, Exploration Rate = 0.1000, Train Count = 15220\n",
      "Episode 861: Reward = 591.00, Steps = 5, Loss = 23.2108, Exploration Rate = 0.1000, Train Count = 15225\n",
      "Episode 862: Reward = 529.00, Steps = 10, Loss = 21.3695, Exploration Rate = 0.1000, Train Count = 15235\n",
      "Episode 863: Reward = 588.00, Steps = 6, Loss = 20.3022, Exploration Rate = 0.1000, Train Count = 15241\n",
      "Episode 864: Reward = 594.00, Steps = 4, Loss = 18.0112, Exploration Rate = 0.1000, Train Count = 15245\n",
      "Episode 865: Reward = 579.00, Steps = 9, Loss = 15.3245, Exploration Rate = 0.1000, Train Count = 15254\n",
      "Episode 866: Reward = 588.00, Steps = 6, Loss = 16.3390, Exploration Rate = 0.1000, Train Count = 15260\n",
      "Episode 867: Reward = 552.00, Steps = 18, Loss = 22.1752, Exploration Rate = 0.1000, Train Count = 15278\n",
      "Episode 868: Reward = 579.00, Steps = 9, Loss = 18.5341, Exploration Rate = 0.1000, Train Count = 15287\n",
      "Episode 869: Reward = 588.00, Steps = 6, Loss = 14.3033, Exploration Rate = 0.1000, Train Count = 15293\n",
      "Episode 870: Reward = 594.00, Steps = 4, Loss = 16.2904, Exploration Rate = 0.1000, Train Count = 15297\n",
      "Episode 871: Reward = 538.00, Steps = 7, Loss = 146.8458, Exploration Rate = 0.1000, Train Count = 15304\n",
      "Episode 872: Reward = 591.00, Steps = 5, Loss = 193.9664, Exploration Rate = 0.1000, Train Count = 15309\n",
      "Episode 873: Reward = 588.00, Steps = 6, Loss = 143.4421, Exploration Rate = 0.1000, Train Count = 15315\n",
      "Episode 874: Reward = 585.00, Steps = 7, Loss = 119.2483, Exploration Rate = 0.1000, Train Count = 15322\n",
      "Episode 875: Reward = 538.00, Steps = 7, Loss = 91.1268, Exploration Rate = 0.1000, Train Count = 15329\n",
      "Episode 876: Reward = 585.00, Steps = 7, Loss = 76.3035, Exploration Rate = 0.1000, Train Count = 15336\n",
      "Episode 877: Reward = 594.00, Steps = 4, Loss = 72.5301, Exploration Rate = 0.1000, Train Count = 15340\n",
      "Episode 878: Reward = 585.00, Steps = 7, Loss = 51.4777, Exploration Rate = 0.1000, Train Count = 15347\n",
      "Episode 879: Reward = 597.00, Steps = 3, Loss = 68.4074, Exploration Rate = 0.1000, Train Count = 15350\n",
      "Episode 880: Reward = 585.00, Steps = 7, Loss = 53.7658, Exploration Rate = 0.1000, Train Count = 15357\n",
      "Episode 881: Reward = 540.00, Steps = 22, Loss = 42.3579, Exploration Rate = 0.1000, Train Count = 15379\n",
      "Episode 882: Reward = 594.00, Steps = 4, Loss = 40.1068, Exploration Rate = 0.1000, Train Count = 15383\n",
      "Episode 883: Reward = 597.00, Steps = 3, Loss = 35.6395, Exploration Rate = 0.1000, Train Count = 15386\n",
      "Episode 884: Reward = 585.00, Steps = 7, Loss = 29.2986, Exploration Rate = 0.1000, Train Count = 15393\n",
      "Episode 885: Reward = 594.00, Steps = 4, Loss = 26.9960, Exploration Rate = 0.1000, Train Count = 15397\n",
      "Episode 886: Reward = 579.00, Steps = 9, Loss = 24.0894, Exploration Rate = 0.1000, Train Count = 15406\n",
      "Episode 887: Reward = 597.00, Steps = 3, Loss = 35.5288, Exploration Rate = 0.1000, Train Count = 15409\n",
      "Episode 888: Reward = 591.00, Steps = 5, Loss = 27.8171, Exploration Rate = 0.1000, Train Count = 15414\n",
      "Episode 889: Reward = 594.00, Steps = 4, Loss = 40.1355, Exploration Rate = 0.1000, Train Count = 15418\n",
      "Episode 890: Reward = 546.00, Steps = 20, Loss = 34.6043, Exploration Rate = 0.1000, Train Count = 15438\n",
      "Episode 891: Reward = 585.00, Steps = 7, Loss = 36.4767, Exploration Rate = 0.1000, Train Count = 15445\n",
      "Episode 892: Reward = 570.00, Steps = 12, Loss = 40.6604, Exploration Rate = 0.1000, Train Count = 15457\n",
      "Episode 893: Reward = 591.00, Steps = 5, Loss = 39.6667, Exploration Rate = 0.1000, Train Count = 15462\n",
      "Episode 894: Reward = 597.00, Steps = 3, Loss = 30.5093, Exploration Rate = 0.1000, Train Count = 15465\n",
      "Episode 895: Reward = 579.00, Steps = 9, Loss = 23.2234, Exploration Rate = 0.1000, Train Count = 15474\n",
      "Episode 896: Reward = 538.00, Steps = 7, Loss = 24.6260, Exploration Rate = 0.1000, Train Count = 15481\n",
      "Episode 897: Reward = 532.00, Steps = 9, Loss = 19.1310, Exploration Rate = 0.1000, Train Count = 15490\n",
      "Episode 898: Reward = 597.00, Steps = 3, Loss = 20.2138, Exploration Rate = 0.1000, Train Count = 15493\n",
      "Episode 899: Reward = 529.00, Steps = 10, Loss = 17.6101, Exploration Rate = 0.1000, Train Count = 15503\n",
      "Episode 900: Reward = 291.00, Steps = 11, Loss = 34.0572, Exploration Rate = 0.1000, Train Count = 15514\n",
      "Episode 901: Reward = 594.00, Steps = 4, Loss = 18.8956, Exploration Rate = 0.1000, Train Count = 15518\n",
      "Episode 902: Reward = 538.00, Steps = 7, Loss = 25.0145, Exploration Rate = 0.1000, Train Count = 15525\n",
      "Episode 903: Reward = 582.00, Steps = 8, Loss = 20.4953, Exploration Rate = 0.1000, Train Count = 15533\n",
      "Episode 904: Reward = 591.00, Steps = 5, Loss = 28.1134, Exploration Rate = 0.1000, Train Count = 15538\n",
      "Episode 905: Reward = 588.00, Steps = 6, Loss = 21.3538, Exploration Rate = 0.1000, Train Count = 15544\n",
      "Episode 906: Reward = 594.00, Steps = 4, Loss = 17.8015, Exploration Rate = 0.1000, Train Count = 15548\n",
      "Episode 907: Reward = 594.00, Steps = 4, Loss = 19.9740, Exploration Rate = 0.1000, Train Count = 15552\n",
      "Episode 908: Reward = 594.00, Steps = 4, Loss = 18.4012, Exploration Rate = 0.1000, Train Count = 15556\n",
      "Episode 909: Reward = 591.00, Steps = 5, Loss = 15.5278, Exploration Rate = 0.1000, Train Count = 15561\n",
      "Episode 910: Reward = 538.00, Steps = 7, Loss = 22.1247, Exploration Rate = 0.1000, Train Count = 15568\n",
      "Episode 911: Reward = 588.00, Steps = 6, Loss = 15.4492, Exploration Rate = 0.1000, Train Count = 15574\n",
      "Episode 912: Reward = 588.00, Steps = 6, Loss = 23.9671, Exploration Rate = 0.1000, Train Count = 15580\n",
      "Episode 913: Reward = 573.00, Steps = 11, Loss = 18.4232, Exploration Rate = 0.1000, Train Count = 15591\n",
      "Episode 914: Reward = 567.00, Steps = 13, Loss = 15.2851, Exploration Rate = 0.1000, Train Count = 15604\n",
      "Episode 915: Reward = 585.00, Steps = 7, Loss = 16.5136, Exploration Rate = 0.1000, Train Count = 15611\n",
      "Episode 916: Reward = 567.00, Steps = 13, Loss = 15.1481, Exploration Rate = 0.1000, Train Count = 15624\n",
      "Episode 917: Reward = 538.00, Steps = 7, Loss = 11.4298, Exploration Rate = 0.1000, Train Count = 15631\n",
      "Episode 918: Reward = 594.00, Steps = 4, Loss = 21.6422, Exploration Rate = 0.1000, Train Count = 15635\n",
      "Episode 919: Reward = 582.00, Steps = 8, Loss = 12.9964, Exploration Rate = 0.1000, Train Count = 15643\n",
      "Episode 920: Reward = 558.00, Steps = 16, Loss = 27.3254, Exploration Rate = 0.1000, Train Count = 15659\n",
      "Episode 921: Reward = 594.00, Steps = 4, Loss = 13.7564, Exploration Rate = 0.1000, Train Count = 15663\n",
      "Episode 922: Reward = 594.00, Steps = 4, Loss = 17.5438, Exploration Rate = 0.1000, Train Count = 15667\n",
      "Episode 923: Reward = 588.00, Steps = 6, Loss = 19.2690, Exploration Rate = 0.1000, Train Count = 15673\n",
      "Episode 924: Reward = 594.00, Steps = 4, Loss = 11.9234, Exploration Rate = 0.1000, Train Count = 15677\n",
      "Episode 925: Reward = 582.00, Steps = 8, Loss = 12.7076, Exploration Rate = 0.1000, Train Count = 15685\n",
      "Episode 926: Reward = 528.00, Steps = 26, Loss = 30.0608, Exploration Rate = 0.1000, Train Count = 15711\n",
      "Episode 927: Reward = 597.00, Steps = 3, Loss = 30.7608, Exploration Rate = 0.1000, Train Count = 15714\n",
      "Episode 928: Reward = 564.00, Steps = 14, Loss = 23.5935, Exploration Rate = 0.1000, Train Count = 15728\n",
      "Episode 929: Reward = 597.00, Steps = 3, Loss = 28.4081, Exploration Rate = 0.1000, Train Count = 15731\n",
      "Episode 930: Reward = 588.00, Steps = 6, Loss = 25.2186, Exploration Rate = 0.1000, Train Count = 15737\n",
      "Episode 931: Reward = 597.00, Steps = 3, Loss = 17.3407, Exploration Rate = 0.1000, Train Count = 15740\n",
      "Episode 932: Reward = 570.00, Steps = 12, Loss = 23.3921, Exploration Rate = 0.1000, Train Count = 15752\n",
      "Episode 933: Reward = 579.00, Steps = 9, Loss = 26.5648, Exploration Rate = 0.1000, Train Count = 15761\n",
      "Episode 934: Reward = 591.00, Steps = 5, Loss = 12.0463, Exploration Rate = 0.1000, Train Count = 15766\n",
      "Episode 935: Reward = 594.00, Steps = 4, Loss = 22.2773, Exploration Rate = 0.1000, Train Count = 15770\n",
      "Episode 936: Reward = 588.00, Steps = 6, Loss = 19.7434, Exploration Rate = 0.1000, Train Count = 15776\n",
      "Episode 937: Reward = 591.00, Steps = 5, Loss = 28.7643, Exploration Rate = 0.1000, Train Count = 15781\n",
      "Episode 938: Reward = 594.00, Steps = 4, Loss = 38.7785, Exploration Rate = 0.1000, Train Count = 15785\n",
      "Episode 939: Reward = 585.00, Steps = 7, Loss = 29.4809, Exploration Rate = 0.1000, Train Count = 15792\n",
      "Episode 940: Reward = 594.00, Steps = 4, Loss = 34.9306, Exploration Rate = 0.1000, Train Count = 15796\n",
      "Episode 941: Reward = 591.00, Steps = 5, Loss = 60.5443, Exploration Rate = 0.1000, Train Count = 15801\n",
      "Episode 942: Reward = 526.00, Steps = 11, Loss = 194.2453, Exploration Rate = 0.1000, Train Count = 15812\n",
      "Episode 943: Reward = 585.00, Steps = 7, Loss = 105.7487, Exploration Rate = 0.1000, Train Count = 15819\n",
      "Episode 944: Reward = 531.00, Steps = 25, Loss = 68.1923, Exploration Rate = 0.1000, Train Count = 15844\n",
      "Episode 945: Reward = 594.00, Steps = 4, Loss = 42.8427, Exploration Rate = 0.1000, Train Count = 15848\n",
      "Episode 946: Reward = 588.00, Steps = 6, Loss = 44.6400, Exploration Rate = 0.1000, Train Count = 15854\n",
      "Episode 947: Reward = 544.00, Steps = 5, Loss = 42.3062, Exploration Rate = 0.1000, Train Count = 15859\n",
      "Episode 948: Reward = 591.00, Steps = 5, Loss = 36.8030, Exploration Rate = 0.1000, Train Count = 15864\n",
      "Episode 949: Reward = 591.00, Steps = 5, Loss = 43.4858, Exploration Rate = 0.1000, Train Count = 15869\n",
      "Episode 950: Reward = 591.00, Steps = 5, Loss = 32.4329, Exploration Rate = 0.1000, Train Count = 15874\n",
      "Episode 951: Reward = 594.00, Steps = 4, Loss = 27.4602, Exploration Rate = 0.1000, Train Count = 15878\n",
      "Episode 952: Reward = 585.00, Steps = 7, Loss = 24.9371, Exploration Rate = 0.1000, Train Count = 15885\n",
      "Episode 953: Reward = 582.00, Steps = 8, Loss = 26.0989, Exploration Rate = 0.1000, Train Count = 15893\n",
      "Episode 954: Reward = 600.00, Steps = 2, Loss = 45.0581, Exploration Rate = 0.1000, Train Count = 15895\n",
      "Episode 955: Reward = 594.00, Steps = 4, Loss = 28.5240, Exploration Rate = 0.1000, Train Count = 15899\n",
      "Episode 956: Reward = 588.00, Steps = 6, Loss = 22.3302, Exploration Rate = 0.1000, Train Count = 15905\n",
      "Episode 957: Reward = 594.00, Steps = 4, Loss = 28.1545, Exploration Rate = 0.1000, Train Count = 15909\n",
      "Episode 958: Reward = 591.00, Steps = 5, Loss = 18.8827, Exploration Rate = 0.1000, Train Count = 15914\n",
      "Episode 959: Reward = 582.00, Steps = 8, Loss = 22.3020, Exploration Rate = 0.1000, Train Count = 15922\n",
      "Episode 960: Reward = 555.00, Steps = 17, Loss = 34.9683, Exploration Rate = 0.1000, Train Count = 15939\n",
      "Episode 961: Reward = 591.00, Steps = 5, Loss = 21.3964, Exploration Rate = 0.1000, Train Count = 15944\n",
      "Episode 962: Reward = 597.00, Steps = 3, Loss = 24.5362, Exploration Rate = 0.1000, Train Count = 15947\n",
      "Episode 963: Reward = 591.00, Steps = 5, Loss = 22.1517, Exploration Rate = 0.1000, Train Count = 15952\n",
      "Episode 964: Reward = 591.00, Steps = 5, Loss = 14.5180, Exploration Rate = 0.1000, Train Count = 15957\n",
      "Episode 965: Reward = 531.00, Steps = 25, Loss = 27.5071, Exploration Rate = 0.1000, Train Count = 15982\n",
      "Episode 966: Reward = 538.00, Steps = 7, Loss = 18.9381, Exploration Rate = 0.1000, Train Count = 15989\n",
      "Episode 967: Reward = 529.00, Steps = 10, Loss = 19.6826, Exploration Rate = 0.1000, Train Count = 15999\n",
      "Episode 968: Reward = 579.00, Steps = 9, Loss = 24.3976, Exploration Rate = 0.1000, Train Count = 16008\n",
      "Episode 969: Reward = 597.00, Steps = 3, Loss = 13.0636, Exploration Rate = 0.1000, Train Count = 16011\n",
      "Episode 970: Reward = 594.00, Steps = 4, Loss = 27.7334, Exploration Rate = 0.1000, Train Count = 16015\n",
      "Episode 971: Reward = 600.00, Steps = 2, Loss = 22.7147, Exploration Rate = 0.1000, Train Count = 16017\n",
      "Episode 972: Reward = 573.00, Steps = 11, Loss = 20.7443, Exploration Rate = 0.1000, Train Count = 16028\n",
      "Episode 973: Reward = 535.00, Steps = 8, Loss = 16.1699, Exploration Rate = 0.1000, Train Count = 16036\n",
      "Episode 974: Reward = 597.00, Steps = 3, Loss = 12.0303, Exploration Rate = 0.1000, Train Count = 16039\n",
      "Episode 975: Reward = 582.00, Steps = 8, Loss = 15.3353, Exploration Rate = 0.1000, Train Count = 16047\n",
      "Episode 976: Reward = 585.00, Steps = 7, Loss = 14.8081, Exploration Rate = 0.1000, Train Count = 16054\n",
      "Episode 977: Reward = 594.00, Steps = 4, Loss = 13.4329, Exploration Rate = 0.1000, Train Count = 16058\n",
      "Episode 978: Reward = 588.00, Steps = 6, Loss = 12.4747, Exploration Rate = 0.1000, Train Count = 16064\n",
      "Episode 979: Reward = 573.00, Steps = 11, Loss = 21.1404, Exploration Rate = 0.1000, Train Count = 16075\n",
      "Episode 980: Reward = 588.00, Steps = 6, Loss = 23.6753, Exploration Rate = 0.1000, Train Count = 16081\n",
      "Episode 981: Reward = 597.00, Steps = 3, Loss = 23.4445, Exploration Rate = 0.1000, Train Count = 16084\n",
      "Episode 982: Reward = 591.00, Steps = 5, Loss = 15.4039, Exploration Rate = 0.1000, Train Count = 16089\n",
      "Episode 983: Reward = 594.00, Steps = 4, Loss = 13.6176, Exploration Rate = 0.1000, Train Count = 16093\n",
      "Episode 984: Reward = 585.00, Steps = 7, Loss = 14.8762, Exploration Rate = 0.1000, Train Count = 16100\n",
      "Episode 985: Reward = 588.00, Steps = 6, Loss = 17.5859, Exploration Rate = 0.1000, Train Count = 16106\n",
      "Episode 986: Reward = 600.00, Steps = 2, Loss = 17.0572, Exploration Rate = 0.1000, Train Count = 16108\n",
      "Episode 987: Reward = 582.00, Steps = 8, Loss = 12.1094, Exploration Rate = 0.1000, Train Count = 16116\n",
      "Episode 988: Reward = 591.00, Steps = 5, Loss = 10.8217, Exploration Rate = 0.1000, Train Count = 16121\n",
      "Episode 989: Reward = 588.00, Steps = 6, Loss = 10.0081, Exploration Rate = 0.1000, Train Count = 16127\n",
      "Episode 990: Reward = 588.00, Steps = 6, Loss = 7.7588, Exploration Rate = 0.1000, Train Count = 16133\n",
      "Episode 991: Reward = 594.00, Steps = 4, Loss = 10.4866, Exploration Rate = 0.1000, Train Count = 16137\n",
      "Episode 992: Reward = 570.00, Steps = 12, Loss = 10.5776, Exploration Rate = 0.1000, Train Count = 16149\n",
      "Episode 993: Reward = 525.00, Steps = 27, Loss = 21.8437, Exploration Rate = 0.1000, Train Count = 16176\n",
      "Episode 994: Reward = 594.00, Steps = 4, Loss = 66.3084, Exploration Rate = 0.1000, Train Count = 16180\n",
      "Episode 995: Reward = 591.00, Steps = 5, Loss = 41.8119, Exploration Rate = 0.1000, Train Count = 16185\n",
      "Episode 996: Reward = 570.00, Steps = 12, Loss = 41.2929, Exploration Rate = 0.1000, Train Count = 16197\n",
      "Episode 997: Reward = 588.00, Steps = 6, Loss = 39.3348, Exploration Rate = 0.1000, Train Count = 16203\n",
      "Episode 998: Reward = 582.00, Steps = 8, Loss = 35.1377, Exploration Rate = 0.1000, Train Count = 16211\n",
      "Episode 999: Reward = 597.00, Steps = 3, Loss = 28.2363, Exploration Rate = 0.1000, Train Count = 16214\n",
      "Episode 1000: Reward = 585.00, Steps = 7, Loss = 26.7341, Exploration Rate = 0.1000, Train Count = 16221\n",
      "Episode 1001: Reward = 585.00, Steps = 7, Loss = 21.6520, Exploration Rate = 0.1000, Train Count = 16228\n",
      "Episode 1002: Reward = 591.00, Steps = 5, Loss = 16.0038, Exploration Rate = 0.1000, Train Count = 16233\n",
      "Episode 1003: Reward = 588.00, Steps = 6, Loss = 22.1370, Exploration Rate = 0.1000, Train Count = 16239\n",
      "Episode 1004: Reward = 597.00, Steps = 3, Loss = 23.6319, Exploration Rate = 0.1000, Train Count = 16242\n",
      "Episode 1005: Reward = 558.00, Steps = 16, Loss = 31.4051, Exploration Rate = 0.1000, Train Count = 16258\n",
      "Episode 1006: Reward = 585.00, Steps = 7, Loss = 22.8128, Exploration Rate = 0.1000, Train Count = 16265\n",
      "Episode 1007: Reward = 591.00, Steps = 5, Loss = 15.7134, Exploration Rate = 0.1000, Train Count = 16270\n",
      "Episode 1008: Reward = 594.00, Steps = 4, Loss = 28.1535, Exploration Rate = 0.1000, Train Count = 16274\n",
      "Episode 1009: Reward = 591.00, Steps = 5, Loss = 15.5720, Exploration Rate = 0.1000, Train Count = 16279\n",
      "Episode 1010: Reward = 537.00, Steps = 23, Loss = 59.2509, Exploration Rate = 0.1000, Train Count = 16302\n",
      "Episode 1011: Reward = 535.00, Steps = 8, Loss = 164.7731, Exploration Rate = 0.1000, Train Count = 16310\n",
      "Episode 1012: Reward = 585.00, Steps = 7, Loss = 106.5540, Exploration Rate = 0.1000, Train Count = 16317\n",
      "Episode 1013: Reward = 588.00, Steps = 6, Loss = 72.1964, Exploration Rate = 0.1000, Train Count = 16323\n",
      "Episode 1014: Reward = 597.00, Steps = 3, Loss = 76.6951, Exploration Rate = 0.1000, Train Count = 16326\n",
      "Episode 1015: Reward = 579.00, Steps = 9, Loss = 66.8348, Exploration Rate = 0.1000, Train Count = 16335\n",
      "Episode 1016: Reward = 591.00, Steps = 5, Loss = 49.4492, Exploration Rate = 0.1000, Train Count = 16340\n",
      "Episode 1017: Reward = 594.00, Steps = 4, Loss = 39.9575, Exploration Rate = 0.1000, Train Count = 16344\n",
      "Episode 1018: Reward = 585.00, Steps = 7, Loss = 45.6255, Exploration Rate = 0.1000, Train Count = 16351\n",
      "Episode 1019: Reward = 597.00, Steps = 3, Loss = 39.1476, Exploration Rate = 0.1000, Train Count = 16354\n",
      "Episode 1020: Reward = 582.00, Steps = 8, Loss = 34.3000, Exploration Rate = 0.1000, Train Count = 16362\n",
      "Episode 1021: Reward = 600.00, Steps = 2, Loss = 31.5387, Exploration Rate = 0.1000, Train Count = 16364\n",
      "Episode 1022: Reward = 588.00, Steps = 6, Loss = 33.9287, Exploration Rate = 0.1000, Train Count = 16370\n",
      "Episode 1023: Reward = 561.00, Steps = 15, Loss = 36.1164, Exploration Rate = 0.1000, Train Count = 16385\n",
      "Episode 1024: Reward = 591.00, Steps = 5, Loss = 28.3622, Exploration Rate = 0.1000, Train Count = 16390\n",
      "Episode 1025: Reward = 588.00, Steps = 6, Loss = 33.6456, Exploration Rate = 0.1000, Train Count = 16396\n",
      "Episode 1026: Reward = 570.00, Steps = 12, Loss = 35.1502, Exploration Rate = 0.1000, Train Count = 16408\n",
      "Episode 1027: Reward = 585.00, Steps = 7, Loss = 25.2159, Exploration Rate = 0.1000, Train Count = 16415\n",
      "Episode 1028: Reward = 588.00, Steps = 6, Loss = 30.5815, Exploration Rate = 0.1000, Train Count = 16421\n",
      "Episode 1029: Reward = 573.00, Steps = 11, Loss = 19.9040, Exploration Rate = 0.1000, Train Count = 16432\n",
      "Episode 1030: Reward = 491.00, Steps = 7, Loss = 17.0761, Exploration Rate = 0.1000, Train Count = 16439\n",
      "Episode 1031: Reward = 585.00, Steps = 7, Loss = 21.6939, Exploration Rate = 0.1000, Train Count = 16446\n",
      "Episode 1032: Reward = 591.00, Steps = 5, Loss = 18.4407, Exploration Rate = 0.1000, Train Count = 16451\n",
      "Episode 1033: Reward = 591.00, Steps = 5, Loss = 27.3115, Exploration Rate = 0.1000, Train Count = 16456\n",
      "Episode 1034: Reward = 597.00, Steps = 3, Loss = 26.4560, Exploration Rate = 0.1000, Train Count = 16459\n",
      "Episode 1035: Reward = 588.00, Steps = 6, Loss = 20.4180, Exploration Rate = 0.1000, Train Count = 16465\n",
      "Episode 1036: Reward = 541.00, Steps = 6, Loss = 20.8991, Exploration Rate = 0.1000, Train Count = 16471\n",
      "Episode 1037: Reward = 594.00, Steps = 4, Loss = 19.7631, Exploration Rate = 0.1000, Train Count = 16475\n",
      "Episode 1038: Reward = 600.00, Steps = 2, Loss = 22.4923, Exploration Rate = 0.1000, Train Count = 16477\n",
      "Episode 1039: Reward = 585.00, Steps = 7, Loss = 28.6149, Exploration Rate = 0.1000, Train Count = 16484\n",
      "Episode 1040: Reward = 597.00, Steps = 3, Loss = 24.9419, Exploration Rate = 0.1000, Train Count = 16487\n",
      "Episode 1041: Reward = 591.00, Steps = 5, Loss = 17.0246, Exploration Rate = 0.1000, Train Count = 16492\n",
      "Episode 1042: Reward = 532.00, Steps = 9, Loss = 39.8292, Exploration Rate = 0.1000, Train Count = 16501\n",
      "Episode 1043: Reward = 479.00, Steps = 11, Loss = 62.0159, Exploration Rate = 0.1000, Train Count = 16512\n",
      "Episode 1044: Reward = 573.00, Steps = 11, Loss = 67.9347, Exploration Rate = 0.1000, Train Count = 16523\n",
      "Episode 1045: Reward = 588.00, Steps = 6, Loss = 39.0016, Exploration Rate = 0.1000, Train Count = 16529\n",
      "Episode 1046: Reward = 591.00, Steps = 5, Loss = 41.0482, Exploration Rate = 0.1000, Train Count = 16534\n",
      "Episode 1047: Reward = 528.00, Steps = 26, Loss = 36.0992, Exploration Rate = 0.1000, Train Count = 16560\n",
      "Episode 1048: Reward = 588.00, Steps = 6, Loss = 32.5933, Exploration Rate = 0.1000, Train Count = 16566\n",
      "Episode 1049: Reward = 537.00, Steps = 23, Loss = 48.3746, Exploration Rate = 0.1000, Train Count = 16589\n",
      "Episode 1050: Reward = 582.00, Steps = 8, Loss = 30.1352, Exploration Rate = 0.1000, Train Count = 16597\n",
      "Episode 1051: Reward = 573.00, Steps = 11, Loss = 33.3377, Exploration Rate = 0.1000, Train Count = 16608\n",
      "Episode 1052: Reward = 597.00, Steps = 3, Loss = 16.5104, Exploration Rate = 0.1000, Train Count = 16611\n",
      "Episode 1053: Reward = 594.00, Steps = 4, Loss = 21.0433, Exploration Rate = 0.1000, Train Count = 16615\n",
      "Episode 1054: Reward = 582.00, Steps = 8, Loss = 17.5213, Exploration Rate = 0.1000, Train Count = 16623\n",
      "Episode 1055: Reward = 600.00, Steps = 2, Loss = 14.7732, Exploration Rate = 0.1000, Train Count = 16625\n",
      "Episode 1056: Reward = 588.00, Steps = 6, Loss = 24.9788, Exploration Rate = 0.1000, Train Count = 16631\n",
      "Episode 1057: Reward = 579.00, Steps = 9, Loss = 26.8550, Exploration Rate = 0.1000, Train Count = 16640\n",
      "Episode 1058: Reward = 594.00, Steps = 4, Loss = 26.1718, Exploration Rate = 0.1000, Train Count = 16644\n",
      "Episode 1059: Reward = 543.00, Steps = 21, Loss = 20.7960, Exploration Rate = 0.1000, Train Count = 16665\n",
      "Episode 1060: Reward = 544.00, Steps = 5, Loss = 24.6746, Exploration Rate = 0.1000, Train Count = 16670\n",
      "Episode 1061: Reward = 573.00, Steps = 11, Loss = 19.6013, Exploration Rate = 0.1000, Train Count = 16681\n",
      "Episode 1062: Reward = 591.00, Steps = 5, Loss = 25.1786, Exploration Rate = 0.1000, Train Count = 16686\n",
      "Episode 1063: Reward = 591.00, Steps = 5, Loss = 21.9353, Exploration Rate = 0.1000, Train Count = 16691\n",
      "Episode 1064: Reward = 591.00, Steps = 5, Loss = 22.0146, Exploration Rate = 0.1000, Train Count = 16696\n",
      "Episode 1065: Reward = 591.00, Steps = 5, Loss = 22.0295, Exploration Rate = 0.1000, Train Count = 16701\n",
      "Episode 1066: Reward = 582.00, Steps = 8, Loss = 26.3557, Exploration Rate = 0.1000, Train Count = 16709\n",
      "Episode 1067: Reward = 591.00, Steps = 5, Loss = 23.8803, Exploration Rate = 0.1000, Train Count = 16714\n",
      "Episode 1068: Reward = 588.00, Steps = 6, Loss = 20.7367, Exploration Rate = 0.1000, Train Count = 16720\n",
      "Episode 1069: Reward = 588.00, Steps = 6, Loss = 15.6503, Exploration Rate = 0.1000, Train Count = 16726\n",
      "Episode 1070: Reward = 597.00, Steps = 3, Loss = 15.0443, Exploration Rate = 0.1000, Train Count = 16729\n",
      "Episode 1071: Reward = 532.00, Steps = 9, Loss = 19.9123, Exploration Rate = 0.1000, Train Count = 16738\n",
      "Episode 1072: Reward = 576.00, Steps = 10, Loss = 19.8895, Exploration Rate = 0.1000, Train Count = 16748\n",
      "Episode 1073: Reward = 573.00, Steps = 11, Loss = 17.8172, Exploration Rate = 0.1000, Train Count = 16759\n",
      "Episode 1074: Reward = 526.00, Steps = 11, Loss = 26.9091, Exploration Rate = 0.1000, Train Count = 16770\n",
      "Episode 1075: Reward = 597.00, Steps = 3, Loss = 35.2047, Exploration Rate = 0.1000, Train Count = 16773\n",
      "Episode 1076: Reward = 588.00, Steps = 6, Loss = 25.6958, Exploration Rate = 0.1000, Train Count = 16779\n",
      "Episode 1077: Reward = 588.00, Steps = 6, Loss = 21.8457, Exploration Rate = 0.1000, Train Count = 16785\n",
      "Episode 1078: Reward = 582.00, Steps = 8, Loss = 19.3787, Exploration Rate = 0.1000, Train Count = 16793\n",
      "Episode 1079: Reward = 576.00, Steps = 10, Loss = 86.4219, Exploration Rate = 0.1000, Train Count = 16803\n",
      "Episode 1080: Reward = 379.00, Steps = 13, Loss = 162.6866, Exploration Rate = 0.1000, Train Count = 16816\n",
      "Episode 1081: Reward = 591.00, Steps = 5, Loss = 100.5841, Exploration Rate = 0.1000, Train Count = 16821\n",
      "Episode 1082: Reward = 579.00, Steps = 9, Loss = 84.0466, Exploration Rate = 0.1000, Train Count = 16830\n",
      "Episode 1083: Reward = 579.00, Steps = 9, Loss = 59.7115, Exploration Rate = 0.1000, Train Count = 16839\n",
      "Episode 1084: Reward = 591.00, Steps = 5, Loss = 51.1469, Exploration Rate = 0.1000, Train Count = 16844\n",
      "Episode 1085: Reward = 588.00, Steps = 6, Loss = 53.5188, Exploration Rate = 0.1000, Train Count = 16850\n",
      "Episode 1086: Reward = 579.00, Steps = 9, Loss = 37.5035, Exploration Rate = 0.1000, Train Count = 16859\n",
      "Episode 1087: Reward = 591.00, Steps = 5, Loss = 34.6005, Exploration Rate = 0.1000, Train Count = 16864\n",
      "Episode 1088: Reward = 597.00, Steps = 3, Loss = 31.6965, Exploration Rate = 0.1000, Train Count = 16867\n",
      "Episode 1089: Reward = 594.00, Steps = 4, Loss = 39.9798, Exploration Rate = 0.1000, Train Count = 16871\n",
      "Episode 1090: Reward = 591.00, Steps = 5, Loss = 32.9150, Exploration Rate = 0.1000, Train Count = 16876\n",
      "Episode 1091: Reward = 591.00, Steps = 5, Loss = 32.8715, Exploration Rate = 0.1000, Train Count = 16881\n",
      "Episode 1092: Reward = 591.00, Steps = 5, Loss = 35.6560, Exploration Rate = 0.1000, Train Count = 16886\n",
      "Episode 1093: Reward = 585.00, Steps = 7, Loss = 29.1170, Exploration Rate = 0.1000, Train Count = 16893\n",
      "Episode 1094: Reward = 532.00, Steps = 9, Loss = 32.6233, Exploration Rate = 0.1000, Train Count = 16902\n",
      "Episode 1095: Reward = 594.00, Steps = 4, Loss = 23.0563, Exploration Rate = 0.1000, Train Count = 16906\n",
      "Episode 1096: Reward = 588.00, Steps = 6, Loss = 56.8882, Exploration Rate = 0.1000, Train Count = 16912\n",
      "Episode 1097: Reward = 591.00, Steps = 5, Loss = 32.6781, Exploration Rate = 0.1000, Train Count = 16917\n",
      "Episode 1098: Reward = 591.00, Steps = 5, Loss = 32.1811, Exploration Rate = 0.1000, Train Count = 16922\n",
      "Episode 1099: Reward = 291.00, Steps = 11, Loss = 52.5272, Exploration Rate = 0.1000, Train Count = 16933\n",
      "Episode 1100: Reward = 550.00, Steps = 3, Loss = 42.4172, Exploration Rate = 0.1000, Train Count = 16936\n",
      "Episode 1101: Reward = 597.00, Steps = 3, Loss = 46.5429, Exploration Rate = 0.1000, Train Count = 16939\n",
      "Episode 1102: Reward = 541.00, Steps = 6, Loss = 39.0469, Exploration Rate = 0.1000, Train Count = 16945\n",
      "Episode 1103: Reward = 552.00, Steps = 18, Loss = 32.6022, Exploration Rate = 0.1000, Train Count = 16963\n",
      "Episode 1104: Reward = 597.00, Steps = 3, Loss = 26.9745, Exploration Rate = 0.1000, Train Count = 16966\n",
      "Episode 1105: Reward = 594.00, Steps = 4, Loss = 36.9060, Exploration Rate = 0.1000, Train Count = 16970\n",
      "Episode 1106: Reward = 585.00, Steps = 7, Loss = 20.6402, Exploration Rate = 0.1000, Train Count = 16977\n",
      "Episode 1107: Reward = 591.00, Steps = 5, Loss = 23.1711, Exploration Rate = 0.1000, Train Count = 16982\n",
      "Episode 1108: Reward = 579.00, Steps = 9, Loss = 20.2587, Exploration Rate = 0.1000, Train Count = 16991\n",
      "Episode 1109: Reward = 597.00, Steps = 3, Loss = 16.9853, Exploration Rate = 0.1000, Train Count = 16994\n",
      "Episode 1110: Reward = 582.00, Steps = 8, Loss = 16.8835, Exploration Rate = 0.1000, Train Count = 17002\n",
      "Episode 1111: Reward = 594.00, Steps = 4, Loss = 14.0542, Exploration Rate = 0.1000, Train Count = 17006\n",
      "Episode 1112: Reward = 594.00, Steps = 4, Loss = 22.0556, Exploration Rate = 0.1000, Train Count = 17010\n",
      "Episode 1113: Reward = 594.00, Steps = 4, Loss = 23.4154, Exploration Rate = 0.1000, Train Count = 17014\n",
      "Episode 1114: Reward = 532.00, Steps = 9, Loss = 20.5403, Exploration Rate = 0.1000, Train Count = 17023\n",
      "Episode 1115: Reward = 531.00, Steps = 25, Loss = 20.6333, Exploration Rate = 0.1000, Train Count = 17048\n",
      "Episode 1116: Reward = 594.00, Steps = 4, Loss = 28.5920, Exploration Rate = 0.1000, Train Count = 17052\n",
      "Episode 1117: Reward = 546.00, Steps = 20, Loss = 37.8568, Exploration Rate = 0.1000, Train Count = 17072\n",
      "Episode 1118: Reward = 585.00, Steps = 7, Loss = 36.3259, Exploration Rate = 0.1000, Train Count = 17079\n",
      "Episode 1119: Reward = 582.00, Steps = 8, Loss = 24.6932, Exploration Rate = 0.1000, Train Count = 17087\n",
      "Episode 1120: Reward = 594.00, Steps = 4, Loss = 21.5155, Exploration Rate = 0.1000, Train Count = 17091\n",
      "Episode 1121: Reward = 585.00, Steps = 7, Loss = 18.7898, Exploration Rate = 0.1000, Train Count = 17098\n",
      "Episode 1122: Reward = 591.00, Steps = 5, Loss = 12.3589, Exploration Rate = 0.1000, Train Count = 17103\n",
      "Episode 1123: Reward = 585.00, Steps = 7, Loss = 21.3508, Exploration Rate = 0.1000, Train Count = 17110\n",
      "Episode 1124: Reward = 591.00, Steps = 5, Loss = 14.9147, Exploration Rate = 0.1000, Train Count = 17115\n",
      "Episode 1125: Reward = 529.00, Steps = 10, Loss = 21.5197, Exploration Rate = 0.1000, Train Count = 17125\n",
      "Episode 1126: Reward = 579.00, Steps = 9, Loss = 24.1030, Exploration Rate = 0.1000, Train Count = 17134\n",
      "Episode 1127: Reward = 588.00, Steps = 6, Loss = 20.6280, Exploration Rate = 0.1000, Train Count = 17140\n",
      "Episode 1128: Reward = 485.00, Steps = 9, Loss = 17.5204, Exploration Rate = 0.1000, Train Count = 17149\n",
      "Episode 1129: Reward = 579.00, Steps = 9, Loss = 21.8962, Exploration Rate = 0.1000, Train Count = 17158\n",
      "Episode 1130: Reward = 585.00, Steps = 7, Loss = 19.9034, Exploration Rate = 0.1000, Train Count = 17165\n",
      "Episode 1131: Reward = 591.00, Steps = 5, Loss = 13.7483, Exploration Rate = 0.1000, Train Count = 17170\n",
      "Episode 1132: Reward = 594.00, Steps = 4, Loss = 13.1991, Exploration Rate = 0.1000, Train Count = 17174\n",
      "Episode 1133: Reward = 573.00, Steps = 11, Loss = 16.6864, Exploration Rate = 0.1000, Train Count = 17185\n",
      "Episode 1134: Reward = 585.00, Steps = 7, Loss = 14.0412, Exploration Rate = 0.1000, Train Count = 17192\n",
      "Episode 1135: Reward = 579.00, Steps = 9, Loss = 11.9645, Exploration Rate = 0.1000, Train Count = 17201\n",
      "Episode 1136: Reward = 582.00, Steps = 8, Loss = 18.0330, Exploration Rate = 0.1000, Train Count = 17209\n",
      "Episode 1137: Reward = 582.00, Steps = 8, Loss = 17.9855, Exploration Rate = 0.1000, Train Count = 17217\n",
      "Episode 1138: Reward = 558.00, Steps = 16, Loss = 23.4942, Exploration Rate = 0.1000, Train Count = 17233\n",
      "Episode 1139: Reward = 588.00, Steps = 6, Loss = 21.0478, Exploration Rate = 0.1000, Train Count = 17239\n",
      "Episode 1140: Reward = 585.00, Steps = 7, Loss = 16.4642, Exploration Rate = 0.1000, Train Count = 17246\n",
      "Episode 1141: Reward = 591.00, Steps = 5, Loss = 17.6261, Exploration Rate = 0.1000, Train Count = 17251\n",
      "Episode 1142: Reward = 597.00, Steps = 3, Loss = 19.8495, Exploration Rate = 0.1000, Train Count = 17254\n",
      "Episode 1143: Reward = 588.00, Steps = 6, Loss = 17.4903, Exploration Rate = 0.1000, Train Count = 17260\n",
      "Episode 1144: Reward = 579.00, Steps = 9, Loss = 15.7148, Exploration Rate = 0.1000, Train Count = 17269\n",
      "Episode 1145: Reward = 570.00, Steps = 12, Loss = 21.9053, Exploration Rate = 0.1000, Train Count = 17281\n",
      "Episode 1146: Reward = 597.00, Steps = 3, Loss = 13.6588, Exploration Rate = 0.1000, Train Count = 17284\n",
      "Episode 1147: Reward = 588.00, Steps = 6, Loss = 15.2464, Exploration Rate = 0.1000, Train Count = 17290\n",
      "Episode 1148: Reward = 585.00, Steps = 7, Loss = 21.6888, Exploration Rate = 0.1000, Train Count = 17297\n",
      "Episode 1149: Reward = 594.00, Steps = 4, Loss = 73.5743, Exploration Rate = 0.1000, Train Count = 17301\n",
      "Episode 1150: Reward = 541.00, Steps = 6, Loss = 159.5210, Exploration Rate = 0.1000, Train Count = 17307\n",
      "Episode 1151: Reward = 591.00, Steps = 5, Loss = 118.4969, Exploration Rate = 0.1000, Train Count = 17312\n",
      "Episode 1152: Reward = 591.00, Steps = 5, Loss = 117.1901, Exploration Rate = 0.1000, Train Count = 17317\n",
      "Episode 1153: Reward = 585.00, Steps = 7, Loss = 85.6562, Exploration Rate = 0.1000, Train Count = 17324\n",
      "Episode 1154: Reward = 582.00, Steps = 8, Loss = 78.2954, Exploration Rate = 0.1000, Train Count = 17332\n",
      "Episode 1155: Reward = 582.00, Steps = 8, Loss = 66.8983, Exploration Rate = 0.1000, Train Count = 17340\n",
      "Episode 1156: Reward = 591.00, Steps = 5, Loss = 62.3843, Exploration Rate = 0.1000, Train Count = 17345\n",
      "Episode 1157: Reward = 588.00, Steps = 6, Loss = 45.9666, Exploration Rate = 0.1000, Train Count = 17351\n",
      "Episode 1158: Reward = 467.00, Steps = 15, Loss = 46.3981, Exploration Rate = 0.1000, Train Count = 17366\n",
      "Episode 1159: Reward = 576.00, Steps = 10, Loss = 37.9467, Exploration Rate = 0.1000, Train Count = 17376\n",
      "Episode 1160: Reward = 582.00, Steps = 8, Loss = 52.1786, Exploration Rate = 0.1000, Train Count = 17384\n",
      "Episode 1161: Reward = 591.00, Steps = 5, Loss = 34.8699, Exploration Rate = 0.1000, Train Count = 17389\n",
      "Episode 1162: Reward = 591.00, Steps = 5, Loss = 37.8148, Exploration Rate = 0.1000, Train Count = 17394\n",
      "Episode 1163: Reward = 579.00, Steps = 9, Loss = 28.2226, Exploration Rate = 0.1000, Train Count = 17403\n",
      "Episode 1164: Reward = 582.00, Steps = 8, Loss = 25.7509, Exploration Rate = 0.1000, Train Count = 17411\n",
      "Episode 1165: Reward = 522.00, Steps = 28, Loss = 24.2962, Exploration Rate = 0.1000, Train Count = 17439\n",
      "Episode 1166: Reward = 570.00, Steps = 12, Loss = 31.6020, Exploration Rate = 0.1000, Train Count = 17451\n",
      "Episode 1167: Reward = 541.00, Steps = 6, Loss = 25.6328, Exploration Rate = 0.1000, Train Count = 17457\n",
      "Episode 1168: Reward = 588.00, Steps = 6, Loss = 27.8294, Exploration Rate = 0.1000, Train Count = 17463\n",
      "Episode 1169: Reward = 588.00, Steps = 6, Loss = 35.4960, Exploration Rate = 0.1000, Train Count = 17469\n",
      "Episode 1170: Reward = 591.00, Steps = 5, Loss = 29.3330, Exploration Rate = 0.1000, Train Count = 17474\n",
      "Episode 1171: Reward = 585.00, Steps = 7, Loss = 20.7050, Exploration Rate = 0.1000, Train Count = 17481\n",
      "Episode 1172: Reward = 537.00, Steps = 23, Loss = 24.5418, Exploration Rate = 0.1000, Train Count = 17504\n",
      "Episode 1173: Reward = 594.00, Steps = 4, Loss = 18.7458, Exploration Rate = 0.1000, Train Count = 17508\n",
      "Episode 1174: Reward = 585.00, Steps = 7, Loss = 25.4500, Exploration Rate = 0.1000, Train Count = 17515\n",
      "Episode 1175: Reward = 588.00, Steps = 6, Loss = 32.9996, Exploration Rate = 0.1000, Train Count = 17521\n",
      "Episode 1176: Reward = 594.00, Steps = 4, Loss = 21.3966, Exploration Rate = 0.1000, Train Count = 17525\n",
      "Episode 1177: Reward = 541.00, Steps = 6, Loss = 21.3630, Exploration Rate = 0.1000, Train Count = 17531\n",
      "Episode 1178: Reward = 591.00, Steps = 5, Loss = 18.5480, Exploration Rate = 0.1000, Train Count = 17536\n",
      "Episode 1179: Reward = 594.00, Steps = 4, Loss = 26.8691, Exploration Rate = 0.1000, Train Count = 17540\n",
      "Episode 1180: Reward = 591.00, Steps = 5, Loss = 27.3823, Exploration Rate = 0.1000, Train Count = 17545\n",
      "Episode 1181: Reward = 594.00, Steps = 4, Loss = 23.3569, Exploration Rate = 0.1000, Train Count = 17549\n",
      "Episode 1182: Reward = 588.00, Steps = 6, Loss = 20.9391, Exploration Rate = 0.1000, Train Count = 17555\n",
      "Episode 1183: Reward = 588.00, Steps = 6, Loss = 19.7763, Exploration Rate = 0.1000, Train Count = 17561\n",
      "Episode 1184: Reward = 597.00, Steps = 3, Loss = 24.2365, Exploration Rate = 0.1000, Train Count = 17564\n",
      "Episode 1185: Reward = 555.00, Steps = 17, Loss = 27.1285, Exploration Rate = 0.1000, Train Count = 17581\n",
      "Episode 1186: Reward = 579.00, Steps = 9, Loss = 21.8372, Exploration Rate = 0.1000, Train Count = 17590\n",
      "Episode 1187: Reward = 585.00, Steps = 7, Loss = 19.7143, Exploration Rate = 0.1000, Train Count = 17597\n",
      "Episode 1188: Reward = 597.00, Steps = 3, Loss = 25.8657, Exploration Rate = 0.1000, Train Count = 17600\n",
      "Episode 1189: Reward = 588.00, Steps = 6, Loss = 18.0658, Exploration Rate = 0.1000, Train Count = 17606\n",
      "Episode 1190: Reward = 591.00, Steps = 5, Loss = 28.9467, Exploration Rate = 0.1000, Train Count = 17611\n",
      "Episode 1191: Reward = 588.00, Steps = 6, Loss = 31.1060, Exploration Rate = 0.1000, Train Count = 17617\n",
      "Episode 1192: Reward = 579.00, Steps = 9, Loss = 27.9444, Exploration Rate = 0.1000, Train Count = 17626\n",
      "Episode 1193: Reward = 552.00, Steps = 18, Loss = 33.8321, Exploration Rate = 0.1000, Train Count = 17644\n",
      "Episode 1194: Reward = 585.00, Steps = 7, Loss = 22.6860, Exploration Rate = 0.1000, Train Count = 17651\n",
      "Episode 1195: Reward = 582.00, Steps = 8, Loss = 22.1859, Exploration Rate = 0.1000, Train Count = 17659\n",
      "Episode 1196: Reward = 591.00, Steps = 5, Loss = 17.1633, Exploration Rate = 0.1000, Train Count = 17664\n",
      "Episode 1197: Reward = 588.00, Steps = 6, Loss = 17.1158, Exploration Rate = 0.1000, Train Count = 17670\n",
      "Episode 1198: Reward = 573.00, Steps = 11, Loss = 20.4016, Exploration Rate = 0.1000, Train Count = 17681\n",
      "Episode 1199: Reward = 485.00, Steps = 9, Loss = 15.4656, Exploration Rate = 0.1000, Train Count = 17690\n",
      "Episode 1200: Reward = 561.00, Steps = 15, Loss = 15.4918, Exploration Rate = 0.1000, Train Count = 17705\n",
      "Episode 1201: Reward = 529.00, Steps = 10, Loss = 14.7209, Exploration Rate = 0.1000, Train Count = 17715\n",
      "Episode 1202: Reward = 582.00, Steps = 8, Loss = 13.2533, Exploration Rate = 0.1000, Train Count = 17723\n",
      "Episode 1203: Reward = 585.00, Steps = 7, Loss = 15.7445, Exploration Rate = 0.1000, Train Count = 17730\n",
      "Episode 1204: Reward = 573.00, Steps = 11, Loss = 23.7173, Exploration Rate = 0.1000, Train Count = 17741\n",
      "Episode 1205: Reward = 558.00, Steps = 16, Loss = 26.2885, Exploration Rate = 0.1000, Train Count = 17757\n",
      "Episode 1206: Reward = 582.00, Steps = 8, Loss = 20.6014, Exploration Rate = 0.1000, Train Count = 17765\n",
      "Episode 1207: Reward = 594.00, Steps = 4, Loss = 12.9825, Exploration Rate = 0.1000, Train Count = 17769\n",
      "Episode 1208: Reward = 594.00, Steps = 4, Loss = 12.4827, Exploration Rate = 0.1000, Train Count = 17773\n",
      "Episode 1209: Reward = 588.00, Steps = 6, Loss = 9.9135, Exploration Rate = 0.1000, Train Count = 17779\n",
      "Episode 1210: Reward = 576.00, Steps = 10, Loss = 16.6151, Exploration Rate = 0.1000, Train Count = 17789\n",
      "Episode 1211: Reward = 591.00, Steps = 5, Loss = 17.3949, Exploration Rate = 0.1000, Train Count = 17794\n",
      "Episode 1212: Reward = 576.00, Steps = 10, Loss = 62.8987, Exploration Rate = 0.1000, Train Count = 17804\n",
      "Episode 1213: Reward = 499.00, Steps = 20, Loss = 78.6811, Exploration Rate = 0.1000, Train Count = 17824\n",
      "Episode 1214: Reward = 594.00, Steps = 4, Loss = 49.4475, Exploration Rate = 0.1000, Train Count = 17828\n",
      "Episode 1215: Reward = 591.00, Steps = 5, Loss = 42.2719, Exploration Rate = 0.1000, Train Count = 17833\n",
      "Episode 1216: Reward = 570.00, Steps = 12, Loss = 38.0052, Exploration Rate = 0.1000, Train Count = 17845\n",
      "Episode 1217: Reward = 594.00, Steps = 4, Loss = 29.0900, Exploration Rate = 0.1000, Train Count = 17849\n",
      "Episode 1218: Reward = 591.00, Steps = 5, Loss = 26.9677, Exploration Rate = 0.1000, Train Count = 17854\n",
      "Episode 1219: Reward = 591.00, Steps = 5, Loss = 23.2082, Exploration Rate = 0.1000, Train Count = 17859\n",
      "Episode 1220: Reward = 579.00, Steps = 9, Loss = 27.3251, Exploration Rate = 0.1000, Train Count = 17868\n",
      "Episode 1221: Reward = 585.00, Steps = 7, Loss = 27.6428, Exploration Rate = 0.1000, Train Count = 17875\n",
      "Episode 1222: Reward = 285.00, Steps = 13, Loss = 51.8425, Exploration Rate = 0.1000, Train Count = 17888\n",
      "Episode 1223: Reward = 594.00, Steps = 4, Loss = 34.4722, Exploration Rate = 0.1000, Train Count = 17892\n",
      "Episode 1224: Reward = 594.00, Steps = 4, Loss = 33.9862, Exploration Rate = 0.1000, Train Count = 17896\n",
      "Episode 1225: Reward = 588.00, Steps = 6, Loss = 37.5628, Exploration Rate = 0.1000, Train Count = 17902\n",
      "Episode 1226: Reward = 591.00, Steps = 5, Loss = 22.2032, Exploration Rate = 0.1000, Train Count = 17907\n",
      "Episode 1227: Reward = 588.00, Steps = 6, Loss = 26.0542, Exploration Rate = 0.1000, Train Count = 17913\n",
      "Episode 1228: Reward = 585.00, Steps = 7, Loss = 24.4709, Exploration Rate = 0.1000, Train Count = 17920\n",
      "Episode 1229: Reward = 547.00, Steps = 4, Loss = 22.9513, Exploration Rate = 0.1000, Train Count = 17924\n",
      "Episode 1230: Reward = 582.00, Steps = 8, Loss = 25.5611, Exploration Rate = 0.1000, Train Count = 17932\n",
      "Episode 1231: Reward = 588.00, Steps = 6, Loss = 20.9807, Exploration Rate = 0.1000, Train Count = 17938\n",
      "Episode 1232: Reward = 570.00, Steps = 12, Loss = 23.0922, Exploration Rate = 0.1000, Train Count = 17950\n",
      "Episode 1233: Reward = 585.00, Steps = 7, Loss = 21.0801, Exploration Rate = 0.1000, Train Count = 17957\n",
      "Episode 1234: Reward = 591.00, Steps = 5, Loss = 19.2039, Exploration Rate = 0.1000, Train Count = 17962\n",
      "Episode 1235: Reward = 600.00, Steps = 2, Loss = 20.2356, Exploration Rate = 0.1000, Train Count = 17964\n",
      "Episode 1236: Reward = 597.00, Steps = 3, Loss = 14.1065, Exploration Rate = 0.1000, Train Count = 17967\n",
      "Episode 1237: Reward = 591.00, Steps = 5, Loss = 18.9748, Exploration Rate = 0.1000, Train Count = 17972\n",
      "Episode 1238: Reward = 585.00, Steps = 7, Loss = 17.0450, Exploration Rate = 0.1000, Train Count = 17979\n",
      "Episode 1239: Reward = 588.00, Steps = 6, Loss = 13.1514, Exploration Rate = 0.1000, Train Count = 17985\n",
      "Episode 1240: Reward = 597.00, Steps = 3, Loss = 12.8633, Exploration Rate = 0.1000, Train Count = 17988\n",
      "Episode 1241: Reward = 588.00, Steps = 6, Loss = 20.7419, Exploration Rate = 0.1000, Train Count = 17994\n",
      "Episode 1242: Reward = 582.00, Steps = 8, Loss = 27.8367, Exploration Rate = 0.1000, Train Count = 18002\n",
      "Episode 1243: Reward = 594.00, Steps = 4, Loss = 30.5575, Exploration Rate = 0.1000, Train Count = 18006\n",
      "Episode 1244: Reward = 588.00, Steps = 6, Loss = 24.9884, Exploration Rate = 0.1000, Train Count = 18012\n",
      "Episode 1245: Reward = 579.00, Steps = 9, Loss = 22.9447, Exploration Rate = 0.1000, Train Count = 18021\n",
      "Episode 1246: Reward = 547.00, Steps = 4, Loss = 27.0489, Exploration Rate = 0.1000, Train Count = 18025\n",
      "Episode 1247: Reward = 585.00, Steps = 7, Loss = 21.7497, Exploration Rate = 0.1000, Train Count = 18032\n",
      "Episode 1248: Reward = 588.00, Steps = 6, Loss = 29.9650, Exploration Rate = 0.1000, Train Count = 18038\n",
      "Episode 1249: Reward = 591.00, Steps = 5, Loss = 28.6246, Exploration Rate = 0.1000, Train Count = 18043\n",
      "Episode 1250: Reward = 582.00, Steps = 8, Loss = 36.7274, Exploration Rate = 0.1000, Train Count = 18051\n",
      "Episode 1251: Reward = 585.00, Steps = 7, Loss = 23.0483, Exploration Rate = 0.1000, Train Count = 18058\n",
      "Episode 1252: Reward = 525.00, Steps = 27, Loss = 33.6526, Exploration Rate = 0.1000, Train Count = 18085\n",
      "Episode 1253: Reward = 594.00, Steps = 4, Loss = 23.1439, Exploration Rate = 0.1000, Train Count = 18089\n",
      "Episode 1254: Reward = 597.00, Steps = 3, Loss = 20.4558, Exploration Rate = 0.1000, Train Count = 18092\n",
      "Episode 1255: Reward = 540.00, Steps = 22, Loss = 21.4452, Exploration Rate = 0.1000, Train Count = 18114\n",
      "Episode 1256: Reward = 535.00, Steps = 8, Loss = 31.4443, Exploration Rate = 0.1000, Train Count = 18122\n",
      "Episode 1257: Reward = 591.00, Steps = 5, Loss = 13.2278, Exploration Rate = 0.1000, Train Count = 18127\n",
      "Episode 1258: Reward = 594.00, Steps = 4, Loss = 32.6907, Exploration Rate = 0.1000, Train Count = 18131\n",
      "Episode 1259: Reward = 597.00, Steps = 3, Loss = 21.7753, Exploration Rate = 0.1000, Train Count = 18134\n",
      "Episode 1260: Reward = 561.00, Steps = 15, Loss = 40.3311, Exploration Rate = 0.1000, Train Count = 18149\n",
      "Episode 1261: Reward = 532.00, Steps = 9, Loss = 26.2072, Exploration Rate = 0.1000, Train Count = 18158\n",
      "Episode 1262: Reward = 597.00, Steps = 3, Loss = 24.3228, Exploration Rate = 0.1000, Train Count = 18161\n",
      "Episode 1263: Reward = 588.00, Steps = 6, Loss = 27.2550, Exploration Rate = 0.1000, Train Count = 18167\n",
      "Episode 1264: Reward = 594.00, Steps = 4, Loss = 15.2573, Exploration Rate = 0.1000, Train Count = 18171\n",
      "Episode 1265: Reward = 591.00, Steps = 5, Loss = 18.1227, Exploration Rate = 0.1000, Train Count = 18176\n",
      "Episode 1266: Reward = 591.00, Steps = 5, Loss = 18.1653, Exploration Rate = 0.1000, Train Count = 18181\n",
      "Episode 1267: Reward = 588.00, Steps = 6, Loss = 9.4016, Exploration Rate = 0.1000, Train Count = 18187\n",
      "Episode 1268: Reward = 591.00, Steps = 5, Loss = 12.4371, Exploration Rate = 0.1000, Train Count = 18192\n",
      "Episode 1269: Reward = 588.00, Steps = 6, Loss = 11.9038, Exploration Rate = 0.1000, Train Count = 18198\n",
      "Episode 1270: Reward = 588.00, Steps = 6, Loss = 15.1139, Exploration Rate = 0.1000, Train Count = 18204\n",
      "Episode 1271: Reward = 594.00, Steps = 4, Loss = 12.3844, Exploration Rate = 0.1000, Train Count = 18208\n",
      "Episode 1272: Reward = 594.00, Steps = 4, Loss = 12.3662, Exploration Rate = 0.1000, Train Count = 18212\n",
      "Episode 1273: Reward = 588.00, Steps = 6, Loss = 11.6415, Exploration Rate = 0.1000, Train Count = 18218\n",
      "Episode 1274: Reward = 594.00, Steps = 4, Loss = 9.9715, Exploration Rate = 0.1000, Train Count = 18222\n",
      "Episode 1275: Reward = 600.00, Steps = 2, Loss = 13.7195, Exploration Rate = 0.1000, Train Count = 18224\n",
      "Episode 1276: Reward = 600.00, Steps = 2, Loss = 11.4977, Exploration Rate = 0.1000, Train Count = 18226\n",
      "Episode 1277: Reward = 576.00, Steps = 10, Loss = 9.8379, Exploration Rate = 0.1000, Train Count = 18236\n",
      "Episode 1278: Reward = 582.00, Steps = 8, Loss = 10.8022, Exploration Rate = 0.1000, Train Count = 18244\n",
      "Episode 1279: Reward = 585.00, Steps = 7, Loss = 11.1371, Exploration Rate = 0.1000, Train Count = 18251\n",
      "Episode 1280: Reward = 597.00, Steps = 3, Loss = 11.5120, Exploration Rate = 0.1000, Train Count = 18254\n",
      "Episode 1281: Reward = 585.00, Steps = 7, Loss = 9.5570, Exploration Rate = 0.1000, Train Count = 18261\n",
      "Episode 1282: Reward = 597.00, Steps = 3, Loss = 10.2184, Exploration Rate = 0.1000, Train Count = 18264\n",
      "Episode 1283: Reward = 594.00, Steps = 4, Loss = 7.8887, Exploration Rate = 0.1000, Train Count = 18268\n",
      "Episode 1284: Reward = 585.00, Steps = 7, Loss = 7.9217, Exploration Rate = 0.1000, Train Count = 18275\n",
      "Episode 1285: Reward = 588.00, Steps = 6, Loss = 9.4837, Exploration Rate = 0.1000, Train Count = 18281\n",
      "Episode 1286: Reward = 591.00, Steps = 5, Loss = 6.3435, Exploration Rate = 0.1000, Train Count = 18286\n",
      "Episode 1287: Reward = 597.00, Steps = 3, Loss = 5.2060, Exploration Rate = 0.1000, Train Count = 18289\n",
      "Episode 1288: Reward = 576.00, Steps = 10, Loss = 10.2758, Exploration Rate = 0.1000, Train Count = 18299\n",
      "Episode 1289: Reward = 594.00, Steps = 4, Loss = 91.3582, Exploration Rate = 0.1000, Train Count = 18303\n",
      "Episode 1290: Reward = 535.00, Steps = 8, Loss = 105.9497, Exploration Rate = 0.1000, Train Count = 18311\n",
      "Episode 1291: Reward = 588.00, Steps = 6, Loss = 106.1188, Exploration Rate = 0.1000, Train Count = 18317\n",
      "Episode 1292: Reward = 591.00, Steps = 5, Loss = 76.1890, Exploration Rate = 0.1000, Train Count = 18322\n",
      "Episode 1293: Reward = 573.00, Steps = 11, Loss = 76.6290, Exploration Rate = 0.1000, Train Count = 18333\n",
      "Episode 1294: Reward = 585.00, Steps = 7, Loss = 58.1885, Exploration Rate = 0.1000, Train Count = 18340\n",
      "Episode 1295: Reward = 591.00, Steps = 5, Loss = 48.1960, Exploration Rate = 0.1000, Train Count = 18345\n",
      "Episode 1296: Reward = 532.00, Steps = 9, Loss = 44.2582, Exploration Rate = 0.1000, Train Count = 18354\n",
      "Episode 1297: Reward = 594.00, Steps = 4, Loss = 33.4052, Exploration Rate = 0.1000, Train Count = 18358\n",
      "Episode 1298: Reward = 591.00, Steps = 5, Loss = 38.4579, Exploration Rate = 0.1000, Train Count = 18363\n",
      "Episode 1299: Reward = 594.00, Steps = 4, Loss = 25.4927, Exploration Rate = 0.1000, Train Count = 18367\n",
      "Episode 1300: Reward = 540.00, Steps = 22, Loss = 29.1706, Exploration Rate = 0.1000, Train Count = 18389\n",
      "Episode 1301: Reward = 538.00, Steps = 7, Loss = 30.5286, Exploration Rate = 0.1000, Train Count = 18396\n",
      "Episode 1302: Reward = 597.00, Steps = 3, Loss = 18.8317, Exploration Rate = 0.1000, Train Count = 18399\n",
      "Episode 1303: Reward = 591.00, Steps = 5, Loss = 46.1322, Exploration Rate = 0.1000, Train Count = 18404\n",
      "Episode 1304: Reward = 594.00, Steps = 4, Loss = 20.2713, Exploration Rate = 0.1000, Train Count = 18408\n",
      "Episode 1305: Reward = 597.00, Steps = 3, Loss = 17.3685, Exploration Rate = 0.1000, Train Count = 18411\n",
      "Episode 1306: Reward = 588.00, Steps = 6, Loss = 30.3972, Exploration Rate = 0.1000, Train Count = 18417\n",
      "Episode 1307: Reward = 549.00, Steps = 19, Loss = 18.4646, Exploration Rate = 0.1000, Train Count = 18436\n",
      "Episode 1308: Reward = 597.00, Steps = 3, Loss = 16.2972, Exploration Rate = 0.1000, Train Count = 18439\n",
      "Episode 1309: Reward = 582.00, Steps = 8, Loss = 20.8425, Exploration Rate = 0.1000, Train Count = 18447\n",
      "Episode 1310: Reward = 588.00, Steps = 6, Loss = 23.8422, Exploration Rate = 0.1000, Train Count = 18453\n",
      "Episode 1311: Reward = 600.00, Steps = 2, Loss = 18.0817, Exploration Rate = 0.1000, Train Count = 18455\n",
      "Episode 1312: Reward = 588.00, Steps = 6, Loss = 15.3443, Exploration Rate = 0.1000, Train Count = 18461\n",
      "Episode 1313: Reward = 588.00, Steps = 6, Loss = 12.0866, Exploration Rate = 0.1000, Train Count = 18467\n",
      "Episode 1314: Reward = 594.00, Steps = 4, Loss = 10.7351, Exploration Rate = 0.1000, Train Count = 18471\n",
      "Episode 1315: Reward = 558.00, Steps = 16, Loss = 16.8246, Exploration Rate = 0.1000, Train Count = 18487\n",
      "Episode 1316: Reward = 564.00, Steps = 14, Loss = 23.0446, Exploration Rate = 0.1000, Train Count = 18501\n",
      "Episode 1317: Reward = 573.00, Steps = 11, Loss = 11.2936, Exploration Rate = 0.1000, Train Count = 18512\n",
      "Episode 1318: Reward = 588.00, Steps = 6, Loss = 13.3376, Exploration Rate = 0.1000, Train Count = 18518\n",
      "Episode 1319: Reward = 594.00, Steps = 4, Loss = 12.3442, Exploration Rate = 0.1000, Train Count = 18522\n",
      "Episode 1320: Reward = 594.00, Steps = 4, Loss = 15.7806, Exploration Rate = 0.1000, Train Count = 18526\n",
      "Episode 1321: Reward = 597.00, Steps = 3, Loss = 10.4517, Exploration Rate = 0.1000, Train Count = 18529\n",
      "Episode 1322: Reward = 594.00, Steps = 4, Loss = 14.7677, Exploration Rate = 0.1000, Train Count = 18533\n",
      "Episode 1323: Reward = 582.00, Steps = 8, Loss = 11.0392, Exploration Rate = 0.1000, Train Count = 18541\n",
      "Episode 1324: Reward = 579.00, Steps = 9, Loss = 8.3942, Exploration Rate = 0.1000, Train Count = 18550\n",
      "Episode 1325: Reward = 591.00, Steps = 5, Loss = 12.0983, Exploration Rate = 0.1000, Train Count = 18555\n",
      "Episode 1326: Reward = 591.00, Steps = 5, Loss = 10.0139, Exploration Rate = 0.1000, Train Count = 18560\n",
      "Episode 1327: Reward = 594.00, Steps = 4, Loss = 10.4653, Exploration Rate = 0.1000, Train Count = 18564\n",
      "Episode 1328: Reward = 591.00, Steps = 5, Loss = 15.2644, Exploration Rate = 0.1000, Train Count = 18569\n",
      "Episode 1329: Reward = 594.00, Steps = 4, Loss = 13.5886, Exploration Rate = 0.1000, Train Count = 18573\n",
      "Episode 1330: Reward = 582.00, Steps = 8, Loss = 18.4395, Exploration Rate = 0.1000, Train Count = 18581\n",
      "Episode 1331: Reward = 591.00, Steps = 5, Loss = 16.7871, Exploration Rate = 0.1000, Train Count = 18586\n",
      "Episode 1332: Reward = 582.00, Steps = 8, Loss = 13.0388, Exploration Rate = 0.1000, Train Count = 18594\n",
      "Episode 1333: Reward = 588.00, Steps = 6, Loss = 13.2164, Exploration Rate = 0.1000, Train Count = 18600\n",
      "Episode 1334: Reward = 591.00, Steps = 5, Loss = 10.6593, Exploration Rate = 0.1000, Train Count = 18605\n",
      "Episode 1335: Reward = 579.00, Steps = 9, Loss = 25.2298, Exploration Rate = 0.1000, Train Count = 18614\n",
      "Episode 1336: Reward = 591.00, Steps = 5, Loss = 32.0882, Exploration Rate = 0.1000, Train Count = 18619\n",
      "Episode 1337: Reward = 576.00, Steps = 10, Loss = 32.5948, Exploration Rate = 0.1000, Train Count = 18629\n",
      "Episode 1338: Reward = 573.00, Steps = 11, Loss = 20.7410, Exploration Rate = 0.1000, Train Count = 18640\n",
      "Episode 1339: Reward = 597.00, Steps = 3, Loss = 30.3682, Exploration Rate = 0.1000, Train Count = 18643\n",
      "Episode 1340: Reward = 588.00, Steps = 6, Loss = 20.1767, Exploration Rate = 0.1000, Train Count = 18649\n",
      "Episode 1341: Reward = 585.00, Steps = 7, Loss = 28.2024, Exploration Rate = 0.1000, Train Count = 18656\n",
      "Episode 1342: Reward = 582.00, Steps = 8, Loss = 23.7122, Exploration Rate = 0.1000, Train Count = 18664\n",
      "Episode 1343: Reward = 588.00, Steps = 6, Loss = 20.1656, Exploration Rate = 0.1000, Train Count = 18670\n",
      "Episode 1344: Reward = 582.00, Steps = 8, Loss = 19.5020, Exploration Rate = 0.1000, Train Count = 18678\n",
      "Episode 1345: Reward = 558.00, Steps = 16, Loss = 24.0846, Exploration Rate = 0.1000, Train Count = 18694\n",
      "Episode 1346: Reward = 597.00, Steps = 3, Loss = 17.6146, Exploration Rate = 0.1000, Train Count = 18697\n",
      "Episode 1347: Reward = 594.00, Steps = 4, Loss = 21.3051, Exploration Rate = 0.1000, Train Count = 18701\n",
      "Episode 1348: Reward = 538.00, Steps = 7, Loss = 15.2302, Exploration Rate = 0.1000, Train Count = 18708\n",
      "Episode 1349: Reward = 538.00, Steps = 7, Loss = 20.2139, Exploration Rate = 0.1000, Train Count = 18715\n",
      "Episode 1350: Reward = 585.00, Steps = 7, Loss = 17.2474, Exploration Rate = 0.1000, Train Count = 18722\n",
      "Episode 1351: Reward = 588.00, Steps = 6, Loss = 19.0011, Exploration Rate = 0.1000, Train Count = 18728\n",
      "Episode 1352: Reward = 591.00, Steps = 5, Loss = 14.8535, Exploration Rate = 0.1000, Train Count = 18733\n",
      "Episode 1353: Reward = 585.00, Steps = 7, Loss = 13.4270, Exploration Rate = 0.1000, Train Count = 18740\n",
      "Episode 1354: Reward = 591.00, Steps = 5, Loss = 10.6456, Exploration Rate = 0.1000, Train Count = 18745\n",
      "Episode 1355: Reward = 579.00, Steps = 9, Loss = 12.3614, Exploration Rate = 0.1000, Train Count = 18754\n",
      "Episode 1356: Reward = 594.00, Steps = 4, Loss = 11.3684, Exploration Rate = 0.1000, Train Count = 18758\n",
      "Episode 1357: Reward = 573.00, Steps = 11, Loss = 14.2520, Exploration Rate = 0.1000, Train Count = 18769\n",
      "Episode 1358: Reward = 594.00, Steps = 4, Loss = 8.7757, Exploration Rate = 0.1000, Train Count = 18773\n",
      "Episode 1359: Reward = 588.00, Steps = 6, Loss = 14.6221, Exploration Rate = 0.1000, Train Count = 18779\n",
      "Episode 1360: Reward = 597.00, Steps = 3, Loss = 8.1554, Exploration Rate = 0.1000, Train Count = 18782\n",
      "Episode 1361: Reward = 573.00, Steps = 11, Loss = 17.6553, Exploration Rate = 0.1000, Train Count = 18793\n",
      "Episode 1362: Reward = 591.00, Steps = 5, Loss = 12.7712, Exploration Rate = 0.1000, Train Count = 18798\n",
      "Episode 1363: Reward = 529.00, Steps = 10, Loss = 116.8140, Exploration Rate = 0.1000, Train Count = 18808\n",
      "Episode 1364: Reward = 597.00, Steps = 3, Loss = 108.0036, Exploration Rate = 0.1000, Train Count = 18811\n",
      "Episode 1365: Reward = 591.00, Steps = 5, Loss = 83.9999, Exploration Rate = 0.1000, Train Count = 18816\n",
      "Episode 1366: Reward = 585.00, Steps = 7, Loss = 76.5759, Exploration Rate = 0.1000, Train Count = 18823\n",
      "Episode 1367: Reward = 538.00, Steps = 7, Loss = 52.5811, Exploration Rate = 0.1000, Train Count = 18830\n",
      "Episode 1368: Reward = 513.00, Steps = 31, Loss = 46.0165, Exploration Rate = 0.1000, Train Count = 18861\n",
      "Episode 1369: Reward = 588.00, Steps = 6, Loss = 35.0804, Exploration Rate = 0.1000, Train Count = 18867\n",
      "Episode 1370: Reward = 591.00, Steps = 5, Loss = 22.8941, Exploration Rate = 0.1000, Train Count = 18872\n",
      "Episode 1371: Reward = 591.00, Steps = 5, Loss = 22.4975, Exploration Rate = 0.1000, Train Count = 18877\n",
      "Episode 1372: Reward = 570.00, Steps = 12, Loss = 49.7869, Exploration Rate = 0.1000, Train Count = 18889\n",
      "Episode 1373: Reward = 582.00, Steps = 8, Loss = 33.0802, Exploration Rate = 0.1000, Train Count = 18897\n",
      "Episode 1374: Reward = 600.00, Steps = 2, Loss = 21.5846, Exploration Rate = 0.1000, Train Count = 18899\n",
      "Episode 1375: Reward = 532.00, Steps = 9, Loss = 23.1406, Exploration Rate = 0.1000, Train Count = 18908\n",
      "Episode 1376: Reward = 573.00, Steps = 11, Loss = 28.4590, Exploration Rate = 0.1000, Train Count = 18919\n",
      "Episode 1377: Reward = 597.00, Steps = 3, Loss = 30.6010, Exploration Rate = 0.1000, Train Count = 18922\n",
      "Episode 1378: Reward = 582.00, Steps = 8, Loss = 22.9642, Exploration Rate = 0.1000, Train Count = 18930\n",
      "Episode 1379: Reward = 576.00, Steps = 10, Loss = 19.7680, Exploration Rate = 0.1000, Train Count = 18940\n",
      "Episode 1380: Reward = 600.00, Steps = 2, Loss = 19.5964, Exploration Rate = 0.1000, Train Count = 18942\n",
      "Episode 1381: Reward = 591.00, Steps = 5, Loss = 15.7700, Exploration Rate = 0.1000, Train Count = 18947\n",
      "Episode 1382: Reward = 597.00, Steps = 3, Loss = 14.0695, Exploration Rate = 0.1000, Train Count = 18950\n",
      "Episode 1383: Reward = 573.00, Steps = 11, Loss = 13.7876, Exploration Rate = 0.1000, Train Count = 18961\n",
      "Episode 1384: Reward = 588.00, Steps = 6, Loss = 16.8674, Exploration Rate = 0.1000, Train Count = 18967\n",
      "Episode 1385: Reward = 588.00, Steps = 6, Loss = 12.8759, Exploration Rate = 0.1000, Train Count = 18973\n",
      "Episode 1386: Reward = 594.00, Steps = 4, Loss = 14.1418, Exploration Rate = 0.1000, Train Count = 18977\n",
      "Episode 1387: Reward = 600.00, Steps = 2, Loss = 9.3368, Exploration Rate = 0.1000, Train Count = 18979\n",
      "Episode 1388: Reward = 588.00, Steps = 6, Loss = 14.7660, Exploration Rate = 0.1000, Train Count = 18985\n",
      "Episode 1389: Reward = 573.00, Steps = 11, Loss = 12.9566, Exploration Rate = 0.1000, Train Count = 18996\n",
      "Episode 1390: Reward = 588.00, Steps = 6, Loss = 21.4772, Exploration Rate = 0.1000, Train Count = 19002\n",
      "Episode 1391: Reward = 579.00, Steps = 9, Loss = 15.3991, Exploration Rate = 0.1000, Train Count = 19011\n",
      "Episode 1392: Reward = 588.00, Steps = 6, Loss = 11.2238, Exploration Rate = 0.1000, Train Count = 19017\n",
      "Episode 1393: Reward = 585.00, Steps = 7, Loss = 11.4896, Exploration Rate = 0.1000, Train Count = 19024\n",
      "Episode 1394: Reward = 591.00, Steps = 5, Loss = 21.9964, Exploration Rate = 0.1000, Train Count = 19029\n",
      "Episode 1395: Reward = 588.00, Steps = 6, Loss = 15.3160, Exploration Rate = 0.1000, Train Count = 19035\n",
      "Episode 1396: Reward = 538.00, Steps = 7, Loss = 13.0842, Exploration Rate = 0.1000, Train Count = 19042\n",
      "Episode 1397: Reward = 594.00, Steps = 4, Loss = 15.6942, Exploration Rate = 0.1000, Train Count = 19046\n",
      "Episode 1398: Reward = 582.00, Steps = 8, Loss = 15.6639, Exploration Rate = 0.1000, Train Count = 19054\n",
      "Episode 1399: Reward = 585.00, Steps = 7, Loss = 14.8761, Exploration Rate = 0.1000, Train Count = 19061\n",
      "Episode 1400: Reward = 588.00, Steps = 6, Loss = 15.0069, Exploration Rate = 0.1000, Train Count = 19067\n",
      "Episode 1401: Reward = 588.00, Steps = 6, Loss = 11.8366, Exploration Rate = 0.1000, Train Count = 19073\n",
      "Episode 1402: Reward = 588.00, Steps = 6, Loss = 13.8206, Exploration Rate = 0.1000, Train Count = 19079\n",
      "Episode 1403: Reward = 579.00, Steps = 9, Loss = 19.2391, Exploration Rate = 0.1000, Train Count = 19088\n",
      "Episode 1404: Reward = 561.00, Steps = 15, Loss = 33.2047, Exploration Rate = 0.1000, Train Count = 19103\n",
      "Episode 1405: Reward = 579.00, Steps = 9, Loss = 23.6964, Exploration Rate = 0.1000, Train Count = 19112\n",
      "Episode 1406: Reward = 579.00, Steps = 9, Loss = 21.6404, Exploration Rate = 0.1000, Train Count = 19121\n",
      "Episode 1407: Reward = 582.00, Steps = 8, Loss = 18.0076, Exploration Rate = 0.1000, Train Count = 19129\n",
      "Episode 1408: Reward = 597.00, Steps = 3, Loss = 13.0899, Exploration Rate = 0.1000, Train Count = 19132\n",
      "Episode 1409: Reward = 600.00, Steps = 2, Loss = 22.9752, Exploration Rate = 0.1000, Train Count = 19134\n",
      "Episode 1410: Reward = 591.00, Steps = 5, Loss = 12.9763, Exploration Rate = 0.1000, Train Count = 19139\n",
      "Episode 1411: Reward = 591.00, Steps = 5, Loss = 11.7909, Exploration Rate = 0.1000, Train Count = 19144\n",
      "Episode 1412: Reward = 591.00, Steps = 5, Loss = 11.7982, Exploration Rate = 0.1000, Train Count = 19149\n",
      "Episode 1413: Reward = 529.00, Steps = 10, Loss = 11.9900, Exploration Rate = 0.1000, Train Count = 19159\n",
      "Episode 1414: Reward = 591.00, Steps = 5, Loss = 9.5407, Exploration Rate = 0.1000, Train Count = 19164\n",
      "Episode 1415: Reward = 597.00, Steps = 3, Loss = 8.9429, Exploration Rate = 0.1000, Train Count = 19167\n",
      "Episode 1416: Reward = 564.00, Steps = 14, Loss = 13.4209, Exploration Rate = 0.1000, Train Count = 19181\n",
      "Episode 1417: Reward = 573.00, Steps = 11, Loss = 12.0415, Exploration Rate = 0.1000, Train Count = 19192\n",
      "Episode 1418: Reward = 588.00, Steps = 6, Loss = 12.0529, Exploration Rate = 0.1000, Train Count = 19198\n",
      "Episode 1419: Reward = 582.00, Steps = 8, Loss = 12.1100, Exploration Rate = 0.1000, Train Count = 19206\n",
      "Episode 1420: Reward = 582.00, Steps = 8, Loss = 17.6461, Exploration Rate = 0.1000, Train Count = 19214\n",
      "Episode 1421: Reward = 582.00, Steps = 8, Loss = 12.0971, Exploration Rate = 0.1000, Train Count = 19222\n",
      "Episode 1422: Reward = 597.00, Steps = 3, Loss = 17.1659, Exploration Rate = 0.1000, Train Count = 19225\n",
      "Episode 1423: Reward = 594.00, Steps = 4, Loss = 15.0717, Exploration Rate = 0.1000, Train Count = 19229\n",
      "Episode 1424: Reward = 588.00, Steps = 6, Loss = 19.0277, Exploration Rate = 0.1000, Train Count = 19235\n",
      "Episode 1425: Reward = 585.00, Steps = 7, Loss = 16.1211, Exploration Rate = 0.1000, Train Count = 19242\n",
      "Episode 1426: Reward = 594.00, Steps = 4, Loss = 7.4955, Exploration Rate = 0.1000, Train Count = 19246\n",
      "Episode 1427: Reward = 549.00, Steps = 19, Loss = 17.6054, Exploration Rate = 0.1000, Train Count = 19265\n",
      "Episode 1428: Reward = 591.00, Steps = 5, Loss = 15.0468, Exploration Rate = 0.1000, Train Count = 19270\n",
      "Episode 1429: Reward = 573.00, Steps = 11, Loss = 16.3057, Exploration Rate = 0.1000, Train Count = 19281\n",
      "Episode 1430: Reward = 582.00, Steps = 8, Loss = 13.9227, Exploration Rate = 0.1000, Train Count = 19289\n",
      "Episode 1431: Reward = 594.00, Steps = 4, Loss = 13.6825, Exploration Rate = 0.1000, Train Count = 19293\n",
      "Episode 1432: Reward = 588.00, Steps = 6, Loss = 13.5105, Exploration Rate = 0.1000, Train Count = 19299\n",
      "Episode 1433: Reward = 582.00, Steps = 8, Loss = 94.3684, Exploration Rate = 0.1000, Train Count = 19307\n",
      "Episode 1434: Reward = 591.00, Steps = 5, Loss = 82.5103, Exploration Rate = 0.1000, Train Count = 19312\n",
      "Episode 1435: Reward = 555.00, Steps = 17, Loss = 61.9277, Exploration Rate = 0.1000, Train Count = 19329\n",
      "Episode 1436: Reward = 594.00, Steps = 4, Loss = 36.6358, Exploration Rate = 0.1000, Train Count = 19333\n",
      "Episode 1437: Reward = 585.00, Steps = 7, Loss = 29.7475, Exploration Rate = 0.1000, Train Count = 19340\n",
      "Episode 1438: Reward = 597.00, Steps = 3, Loss = 23.8675, Exploration Rate = 0.1000, Train Count = 19343\n",
      "Episode 1439: Reward = 594.00, Steps = 4, Loss = 24.4813, Exploration Rate = 0.1000, Train Count = 19347\n",
      "Episode 1440: Reward = 594.00, Steps = 4, Loss = 25.5071, Exploration Rate = 0.1000, Train Count = 19351\n",
      "Episode 1441: Reward = 591.00, Steps = 5, Loss = 20.7746, Exploration Rate = 0.1000, Train Count = 19356\n",
      "Episode 1442: Reward = 588.00, Steps = 6, Loss = 18.5862, Exploration Rate = 0.1000, Train Count = 19362\n",
      "Episode 1443: Reward = 579.00, Steps = 9, Loss = 20.6624, Exploration Rate = 0.1000, Train Count = 19371\n",
      "Episode 1444: Reward = 570.00, Steps = 12, Loss = 23.6324, Exploration Rate = 0.1000, Train Count = 19383\n",
      "Episode 1445: Reward = 511.00, Steps = 16, Loss = 25.5987, Exploration Rate = 0.1000, Train Count = 19399\n",
      "Episode 1446: Reward = 594.00, Steps = 4, Loss = 14.9583, Exploration Rate = 0.1000, Train Count = 19403\n",
      "Episode 1447: Reward = 585.00, Steps = 7, Loss = 15.8096, Exploration Rate = 0.1000, Train Count = 19410\n",
      "Episode 1448: Reward = 576.00, Steps = 10, Loss = 14.2136, Exploration Rate = 0.1000, Train Count = 19420\n",
      "Episode 1449: Reward = 591.00, Steps = 5, Loss = 15.7357, Exploration Rate = 0.1000, Train Count = 19425\n",
      "Episode 1450: Reward = 591.00, Steps = 5, Loss = 10.5788, Exploration Rate = 0.1000, Train Count = 19430\n",
      "Episode 1451: Reward = 591.00, Steps = 5, Loss = 7.4880, Exploration Rate = 0.1000, Train Count = 19435\n",
      "Episode 1452: Reward = 591.00, Steps = 5, Loss = 7.4261, Exploration Rate = 0.1000, Train Count = 19440\n",
      "Episode 1453: Reward = 588.00, Steps = 6, Loss = 8.9416, Exploration Rate = 0.1000, Train Count = 19446\n",
      "Episode 1454: Reward = 585.00, Steps = 7, Loss = 24.5146, Exploration Rate = 0.1000, Train Count = 19453\n",
      "Episode 1455: Reward = 597.00, Steps = 3, Loss = 7.5485, Exploration Rate = 0.1000, Train Count = 19456\n",
      "Episode 1456: Reward = 582.00, Steps = 8, Loss = 21.1314, Exploration Rate = 0.1000, Train Count = 19464\n",
      "Episode 1457: Reward = 576.00, Steps = 10, Loss = 22.2865, Exploration Rate = 0.1000, Train Count = 19474\n",
      "Episode 1458: Reward = 594.00, Steps = 4, Loss = 15.2224, Exploration Rate = 0.1000, Train Count = 19478\n",
      "Episode 1459: Reward = 585.00, Steps = 7, Loss = 20.5181, Exploration Rate = 0.1000, Train Count = 19485\n",
      "Episode 1460: Reward = 588.00, Steps = 6, Loss = 12.0196, Exploration Rate = 0.1000, Train Count = 19491\n",
      "Episode 1461: Reward = 591.00, Steps = 5, Loss = 13.1840, Exploration Rate = 0.1000, Train Count = 19496\n",
      "Episode 1462: Reward = 597.00, Steps = 3, Loss = 12.1485, Exploration Rate = 0.1000, Train Count = 19499\n",
      "Episode 1463: Reward = 591.00, Steps = 5, Loss = 15.2792, Exploration Rate = 0.1000, Train Count = 19504\n",
      "Episode 1464: Reward = 582.00, Steps = 8, Loss = 19.1947, Exploration Rate = 0.1000, Train Count = 19512\n",
      "Episode 1465: Reward = 594.00, Steps = 4, Loss = 18.1383, Exploration Rate = 0.1000, Train Count = 19516\n",
      "Episode 1466: Reward = 594.00, Steps = 4, Loss = 15.0519, Exploration Rate = 0.1000, Train Count = 19520\n",
      "Episode 1467: Reward = 573.00, Steps = 11, Loss = 11.7815, Exploration Rate = 0.1000, Train Count = 19531\n",
      "Episode 1468: Reward = 594.00, Steps = 4, Loss = 8.5267, Exploration Rate = 0.1000, Train Count = 19535\n",
      "Episode 1469: Reward = 579.00, Steps = 9, Loss = 10.8806, Exploration Rate = 0.1000, Train Count = 19544\n",
      "Episode 1470: Reward = 576.00, Steps = 10, Loss = 8.9211, Exploration Rate = 0.1000, Train Count = 19554\n",
      "Episode 1471: Reward = 567.00, Steps = 13, Loss = 9.4038, Exploration Rate = 0.1000, Train Count = 19567\n",
      "Episode 1472: Reward = 597.00, Steps = 3, Loss = 28.9378, Exploration Rate = 0.1000, Train Count = 19570\n",
      "Episode 1473: Reward = 597.00, Steps = 3, Loss = 12.9657, Exploration Rate = 0.1000, Train Count = 19573\n",
      "Episode 1474: Reward = 588.00, Steps = 6, Loss = 10.8215, Exploration Rate = 0.1000, Train Count = 19579\n",
      "Episode 1475: Reward = 594.00, Steps = 4, Loss = 12.0081, Exploration Rate = 0.1000, Train Count = 19583\n",
      "Episode 1476: Reward = 582.00, Steps = 8, Loss = 19.6059, Exploration Rate = 0.1000, Train Count = 19591\n",
      "Episode 1477: Reward = 585.00, Steps = 7, Loss = 13.2156, Exploration Rate = 0.1000, Train Count = 19598\n",
      "Episode 1478: Reward = 594.00, Steps = 4, Loss = 17.6950, Exploration Rate = 0.1000, Train Count = 19602\n",
      "Episode 1479: Reward = 567.00, Steps = 13, Loss = 13.6000, Exploration Rate = 0.1000, Train Count = 19615\n",
      "Episode 1480: Reward = 585.00, Steps = 7, Loss = 12.3534, Exploration Rate = 0.1000, Train Count = 19622\n",
      "Episode 1481: Reward = 588.00, Steps = 6, Loss = 12.8811, Exploration Rate = 0.1000, Train Count = 19628\n",
      "Episode 1482: Reward = 582.00, Steps = 8, Loss = 13.0651, Exploration Rate = 0.1000, Train Count = 19636\n",
      "Episode 1483: Reward = 544.00, Steps = 5, Loss = 14.8485, Exploration Rate = 0.1000, Train Count = 19641\n",
      "Episode 1484: Reward = 597.00, Steps = 3, Loss = 14.7148, Exploration Rate = 0.1000, Train Count = 19644\n",
      "Episode 1485: Reward = 585.00, Steps = 7, Loss = 14.2192, Exploration Rate = 0.1000, Train Count = 19651\n",
      "Episode 1486: Reward = 541.00, Steps = 6, Loss = 21.5124, Exploration Rate = 0.1000, Train Count = 19657\n",
      "Episode 1487: Reward = 594.00, Steps = 4, Loss = 29.1235, Exploration Rate = 0.1000, Train Count = 19661\n",
      "Episode 1488: Reward = 597.00, Steps = 3, Loss = 15.8348, Exploration Rate = 0.1000, Train Count = 19664\n",
      "Episode 1489: Reward = 549.00, Steps = 19, Loss = 17.7178, Exploration Rate = 0.1000, Train Count = 19683\n",
      "Episode 1490: Reward = 597.00, Steps = 3, Loss = 17.4631, Exploration Rate = 0.1000, Train Count = 19686\n",
      "Episode 1491: Reward = 585.00, Steps = 7, Loss = 17.4435, Exploration Rate = 0.1000, Train Count = 19693\n",
      "Episode 1492: Reward = 588.00, Steps = 6, Loss = 14.3316, Exploration Rate = 0.1000, Train Count = 19699\n",
      "Episode 1493: Reward = 591.00, Steps = 5, Loss = 16.4371, Exploration Rate = 0.1000, Train Count = 19704\n",
      "Episode 1494: Reward = 585.00, Steps = 7, Loss = 32.7125, Exploration Rate = 0.1000, Train Count = 19711\n",
      "Episode 1495: Reward = 585.00, Steps = 7, Loss = 13.5414, Exploration Rate = 0.1000, Train Count = 19718\n",
      "Episode 1496: Reward = 588.00, Steps = 6, Loss = 12.8414, Exploration Rate = 0.1000, Train Count = 19724\n",
      "Episode 1497: Reward = 591.00, Steps = 5, Loss = 19.9971, Exploration Rate = 0.1000, Train Count = 19729\n",
      "Episode 1498: Reward = 579.00, Steps = 9, Loss = 13.9378, Exploration Rate = 0.1000, Train Count = 19738\n",
      "Episode 1499: Reward = 585.00, Steps = 7, Loss = 22.4565, Exploration Rate = 0.1000, Train Count = 19745\n",
      "Episode 1500: Reward = 585.00, Steps = 7, Loss = 16.8497, Exploration Rate = 0.1000, Train Count = 19752\n",
      "Episode 1501: Reward = 585.00, Steps = 7, Loss = 16.8770, Exploration Rate = 0.1000, Train Count = 19759\n",
      "Episode 1502: Reward = 555.00, Steps = 17, Loss = 17.3244, Exploration Rate = 0.1000, Train Count = 19776\n",
      "Episode 1503: Reward = 585.00, Steps = 7, Loss = 13.3737, Exploration Rate = 0.1000, Train Count = 19783\n",
      "Episode 1504: Reward = 432.00, Steps = 11, Loss = 32.5719, Exploration Rate = 0.1000, Train Count = 19794\n",
      "Episode 1505: Reward = 582.00, Steps = 8, Loss = 75.8720, Exploration Rate = 0.1000, Train Count = 19802\n",
      "Episode 1506: Reward = 591.00, Steps = 5, Loss = 124.6634, Exploration Rate = 0.1000, Train Count = 19807\n",
      "Episode 1507: Reward = 585.00, Steps = 7, Loss = 80.9645, Exploration Rate = 0.1000, Train Count = 19814\n",
      "Episode 1508: Reward = 591.00, Steps = 5, Loss = 69.7965, Exploration Rate = 0.1000, Train Count = 19819\n",
      "Episode 1509: Reward = 594.00, Steps = 4, Loss = 74.5459, Exploration Rate = 0.1000, Train Count = 19823\n",
      "Episode 1510: Reward = 588.00, Steps = 6, Loss = 56.9438, Exploration Rate = 0.1000, Train Count = 19829\n",
      "Episode 1511: Reward = 579.00, Steps = 9, Loss = 43.5872, Exploration Rate = 0.1000, Train Count = 19838\n",
      "Episode 1512: Reward = 594.00, Steps = 4, Loss = 30.3075, Exploration Rate = 0.1000, Train Count = 19842\n",
      "Episode 1513: Reward = 582.00, Steps = 8, Loss = 34.3130, Exploration Rate = 0.1000, Train Count = 19850\n",
      "Episode 1514: Reward = 532.00, Steps = 9, Loss = 28.5017, Exploration Rate = 0.1000, Train Count = 19859\n",
      "Episode 1515: Reward = 591.00, Steps = 5, Loss = 25.1898, Exploration Rate = 0.1000, Train Count = 19864\n",
      "Episode 1516: Reward = 588.00, Steps = 6, Loss = 17.5023, Exploration Rate = 0.1000, Train Count = 19870\n",
      "Episode 1517: Reward = 582.00, Steps = 8, Loss = 15.6383, Exploration Rate = 0.1000, Train Count = 19878\n",
      "Episode 1518: Reward = 597.00, Steps = 3, Loss = 18.4316, Exploration Rate = 0.1000, Train Count = 19881\n",
      "Episode 1519: Reward = 564.00, Steps = 14, Loss = 23.5764, Exploration Rate = 0.1000, Train Count = 19895\n",
      "Episode 1520: Reward = 594.00, Steps = 4, Loss = 27.6142, Exploration Rate = 0.1000, Train Count = 19899\n",
      "Episode 1521: Reward = 597.00, Steps = 3, Loss = 31.3575, Exploration Rate = 0.1000, Train Count = 19902\n",
      "Episode 1522: Reward = 585.00, Steps = 7, Loss = 22.6428, Exploration Rate = 0.1000, Train Count = 19909\n",
      "Episode 1523: Reward = 585.00, Steps = 7, Loss = 20.4760, Exploration Rate = 0.1000, Train Count = 19916\n",
      "Episode 1524: Reward = 597.00, Steps = 3, Loss = 12.4887, Exploration Rate = 0.1000, Train Count = 19919\n",
      "Episode 1525: Reward = 588.00, Steps = 6, Loss = 17.8305, Exploration Rate = 0.1000, Train Count = 19925\n",
      "Episode 1526: Reward = 547.00, Steps = 4, Loss = 14.2849, Exploration Rate = 0.1000, Train Count = 19929\n",
      "Episode 1527: Reward = 537.00, Steps = 23, Loss = 20.2894, Exploration Rate = 0.1000, Train Count = 19952\n",
      "Episode 1528: Reward = 588.00, Steps = 6, Loss = 17.2671, Exploration Rate = 0.1000, Train Count = 19958\n",
      "Episode 1529: Reward = 491.00, Steps = 7, Loss = 15.0022, Exploration Rate = 0.1000, Train Count = 19965\n",
      "Episode 1530: Reward = 588.00, Steps = 6, Loss = 18.3402, Exploration Rate = 0.1000, Train Count = 19971\n",
      "Episode 1531: Reward = 600.00, Steps = 2, Loss = 12.0324, Exploration Rate = 0.1000, Train Count = 19973\n",
      "Episode 1532: Reward = 576.00, Steps = 10, Loss = 17.5420, Exploration Rate = 0.1000, Train Count = 19983\n",
      "Episode 1533: Reward = 579.00, Steps = 9, Loss = 15.0626, Exploration Rate = 0.1000, Train Count = 19992\n",
      "Episode 1534: Reward = 576.00, Steps = 10, Loss = 9.4121, Exploration Rate = 0.1000, Train Count = 20002\n",
      "Episode 1535: Reward = 594.00, Steps = 4, Loss = 16.0769, Exploration Rate = 0.1000, Train Count = 20006\n",
      "Episode 1536: Reward = 579.00, Steps = 9, Loss = 15.3860, Exploration Rate = 0.1000, Train Count = 20015\n",
      "Episode 1537: Reward = 582.00, Steps = 8, Loss = 13.7552, Exploration Rate = 0.1000, Train Count = 20023\n",
      "Episode 1538: Reward = 582.00, Steps = 8, Loss = 18.7017, Exploration Rate = 0.1000, Train Count = 20031\n",
      "Episode 1539: Reward = 570.00, Steps = 12, Loss = 15.2575, Exploration Rate = 0.1000, Train Count = 20043\n",
      "Episode 1540: Reward = 594.00, Steps = 4, Loss = 16.6928, Exploration Rate = 0.1000, Train Count = 20047\n",
      "Episode 1541: Reward = 597.00, Steps = 3, Loss = 11.9500, Exploration Rate = 0.1000, Train Count = 20050\n",
      "Episode 1542: Reward = 585.00, Steps = 7, Loss = 17.0218, Exploration Rate = 0.1000, Train Count = 20057\n",
      "Episode 1543: Reward = 585.00, Steps = 7, Loss = 16.8659, Exploration Rate = 0.1000, Train Count = 20064\n",
      "Episode 1544: Reward = 591.00, Steps = 5, Loss = 12.5292, Exploration Rate = 0.1000, Train Count = 20069\n",
      "Episode 1545: Reward = 588.00, Steps = 6, Loss = 22.1281, Exploration Rate = 0.1000, Train Count = 20075\n",
      "Episode 1546: Reward = 588.00, Steps = 6, Loss = 16.8857, Exploration Rate = 0.1000, Train Count = 20081\n",
      "Episode 1547: Reward = 582.00, Steps = 8, Loss = 14.5331, Exploration Rate = 0.1000, Train Count = 20089\n",
      "Episode 1548: Reward = 585.00, Steps = 7, Loss = 15.7049, Exploration Rate = 0.1000, Train Count = 20096\n",
      "Episode 1549: Reward = 591.00, Steps = 5, Loss = 8.4736, Exploration Rate = 0.1000, Train Count = 20101\n",
      "Episode 1550: Reward = 550.00, Steps = 3, Loss = 12.5515, Exploration Rate = 0.1000, Train Count = 20104\n",
      "Episode 1551: Reward = 591.00, Steps = 5, Loss = 9.0468, Exploration Rate = 0.1000, Train Count = 20109\n",
      "Episode 1552: Reward = 588.00, Steps = 6, Loss = 10.5578, Exploration Rate = 0.1000, Train Count = 20115\n",
      "Episode 1553: Reward = 594.00, Steps = 4, Loss = 11.9194, Exploration Rate = 0.1000, Train Count = 20119\n",
      "Episode 1554: Reward = 585.00, Steps = 7, Loss = 15.5874, Exploration Rate = 0.1000, Train Count = 20126\n",
      "Episode 1555: Reward = 588.00, Steps = 6, Loss = 10.7426, Exploration Rate = 0.1000, Train Count = 20132\n",
      "Episode 1556: Reward = 591.00, Steps = 5, Loss = 11.4603, Exploration Rate = 0.1000, Train Count = 20137\n",
      "Episode 1557: Reward = 585.00, Steps = 7, Loss = 12.4191, Exploration Rate = 0.1000, Train Count = 20144\n",
      "Episode 1558: Reward = 585.00, Steps = 7, Loss = 10.3882, Exploration Rate = 0.1000, Train Count = 20151\n",
      "Episode 1559: Reward = 588.00, Steps = 6, Loss = 27.3378, Exploration Rate = 0.1000, Train Count = 20157\n",
      "Episode 1560: Reward = 582.00, Steps = 8, Loss = 16.0929, Exploration Rate = 0.1000, Train Count = 20165\n",
      "Episode 1561: Reward = 552.00, Steps = 18, Loss = 24.3826, Exploration Rate = 0.1000, Train Count = 20183\n",
      "Episode 1562: Reward = 529.00, Steps = 10, Loss = 17.4284, Exploration Rate = 0.1000, Train Count = 20193\n",
      "Episode 1563: Reward = 585.00, Steps = 7, Loss = 14.7121, Exploration Rate = 0.1000, Train Count = 20200\n",
      "Episode 1564: Reward = 535.00, Steps = 8, Loss = 14.1936, Exploration Rate = 0.1000, Train Count = 20208\n",
      "Episode 1565: Reward = 591.00, Steps = 5, Loss = 12.1850, Exploration Rate = 0.1000, Train Count = 20213\n",
      "Episode 1566: Reward = 552.00, Steps = 18, Loss = 16.6039, Exploration Rate = 0.1000, Train Count = 20231\n",
      "Episode 1567: Reward = 465.00, Steps = 47, Loss = 26.7263, Exploration Rate = 0.1000, Train Count = 20278\n",
      "Episode 1568: Reward = 594.00, Steps = 4, Loss = 16.9764, Exploration Rate = 0.1000, Train Count = 20282\n",
      "Episode 1569: Reward = 597.00, Steps = 3, Loss = 18.8672, Exploration Rate = 0.1000, Train Count = 20285\n",
      "Episode 1570: Reward = 594.00, Steps = 4, Loss = 24.6497, Exploration Rate = 0.1000, Train Count = 20289\n",
      "Episode 1571: Reward = 591.00, Steps = 5, Loss = 15.3124, Exploration Rate = 0.1000, Train Count = 20294\n",
      "Episode 1572: Reward = 594.00, Steps = 4, Loss = 12.6807, Exploration Rate = 0.1000, Train Count = 20298\n",
      "Episode 1573: Reward = 588.00, Steps = 6, Loss = 101.1362, Exploration Rate = 0.1000, Train Count = 20304\n",
      "Episode 1574: Reward = 597.00, Steps = 3, Loss = 92.7755, Exploration Rate = 0.1000, Train Count = 20307\n",
      "Episode 1575: Reward = 591.00, Steps = 5, Loss = 91.9001, Exploration Rate = 0.1000, Train Count = 20312\n",
      "Episode 1576: Reward = 591.00, Steps = 5, Loss = 69.4284, Exploration Rate = 0.1000, Train Count = 20317\n",
      "Episode 1577: Reward = 585.00, Steps = 7, Loss = 65.2103, Exploration Rate = 0.1000, Train Count = 20324\n",
      "Episode 1578: Reward = 594.00, Steps = 4, Loss = 58.1603, Exploration Rate = 0.1000, Train Count = 20328\n",
      "Episode 1579: Reward = 597.00, Steps = 3, Loss = 45.2878, Exploration Rate = 0.1000, Train Count = 20331\n",
      "Episode 1580: Reward = 591.00, Steps = 5, Loss = 47.2049, Exploration Rate = 0.1000, Train Count = 20336\n",
      "Episode 1581: Reward = 576.00, Steps = 10, Loss = 47.5915, Exploration Rate = 0.1000, Train Count = 20346\n",
      "Episode 1582: Reward = 600.00, Steps = 2, Loss = 31.5424, Exploration Rate = 0.1000, Train Count = 20348\n",
      "Episode 1583: Reward = 579.00, Steps = 9, Loss = 31.6698, Exploration Rate = 0.1000, Train Count = 20357\n",
      "Episode 1584: Reward = 582.00, Steps = 8, Loss = 29.7686, Exploration Rate = 0.1000, Train Count = 20365\n",
      "Episode 1585: Reward = 597.00, Steps = 3, Loss = 25.9925, Exploration Rate = 0.1000, Train Count = 20368\n",
      "Episode 1586: Reward = 591.00, Steps = 5, Loss = 20.4240, Exploration Rate = 0.1000, Train Count = 20373\n",
      "Episode 1587: Reward = 597.00, Steps = 3, Loss = 22.9246, Exploration Rate = 0.1000, Train Count = 20376\n",
      "Episode 1588: Reward = 585.00, Steps = 7, Loss = 31.1218, Exploration Rate = 0.1000, Train Count = 20383\n",
      "Episode 1589: Reward = 600.00, Steps = 2, Loss = 38.6942, Exploration Rate = 0.1000, Train Count = 20385\n",
      "Episode 1590: Reward = 585.00, Steps = 7, Loss = 25.8616, Exploration Rate = 0.1000, Train Count = 20392\n",
      "Episode 1591: Reward = 582.00, Steps = 8, Loss = 27.6756, Exploration Rate = 0.1000, Train Count = 20400\n",
      "Episode 1592: Reward = 588.00, Steps = 6, Loss = 22.2946, Exploration Rate = 0.1000, Train Count = 20406\n",
      "Episode 1593: Reward = 585.00, Steps = 7, Loss = 21.4318, Exploration Rate = 0.1000, Train Count = 20413\n",
      "Episode 1594: Reward = 597.00, Steps = 3, Loss = 28.9999, Exploration Rate = 0.1000, Train Count = 20416\n",
      "Episode 1595: Reward = 564.00, Steps = 14, Loss = 27.0913, Exploration Rate = 0.1000, Train Count = 20430\n",
      "Episode 1596: Reward = 591.00, Steps = 5, Loss = 20.2175, Exploration Rate = 0.1000, Train Count = 20435\n",
      "Episode 1597: Reward = 591.00, Steps = 5, Loss = 23.7180, Exploration Rate = 0.1000, Train Count = 20440\n",
      "Episode 1598: Reward = 538.00, Steps = 7, Loss = 24.1444, Exploration Rate = 0.1000, Train Count = 20447\n",
      "Episode 1599: Reward = 597.00, Steps = 3, Loss = 26.5803, Exploration Rate = 0.1000, Train Count = 20450\n",
      "Episode 1600: Reward = 594.00, Steps = 4, Loss = 17.9012, Exploration Rate = 0.1000, Train Count = 20454\n",
      "Episode 1601: Reward = 588.00, Steps = 6, Loss = 21.6948, Exploration Rate = 0.1000, Train Count = 20460\n",
      "Episode 1602: Reward = 582.00, Steps = 8, Loss = 27.4517, Exploration Rate = 0.1000, Train Count = 20468\n",
      "Episode 1603: Reward = 579.00, Steps = 9, Loss = 28.2418, Exploration Rate = 0.1000, Train Count = 20477\n",
      "Episode 1604: Reward = 523.00, Steps = 12, Loss = 24.6325, Exploration Rate = 0.1000, Train Count = 20489\n",
      "Episode 1605: Reward = 531.00, Steps = 25, Loss = 23.2129, Exploration Rate = 0.1000, Train Count = 20514\n",
      "Episode 1606: Reward = 588.00, Steps = 6, Loss = 25.0176, Exploration Rate = 0.1000, Train Count = 20520\n",
      "Episode 1607: Reward = 588.00, Steps = 6, Loss = 20.5015, Exploration Rate = 0.1000, Train Count = 20526\n",
      "Episode 1608: Reward = 591.00, Steps = 5, Loss = 23.7541, Exploration Rate = 0.1000, Train Count = 20531\n",
      "Episode 1609: Reward = 591.00, Steps = 5, Loss = 22.6138, Exploration Rate = 0.1000, Train Count = 20536\n",
      "Episode 1610: Reward = 591.00, Steps = 5, Loss = 17.9678, Exploration Rate = 0.1000, Train Count = 20541\n",
      "Episode 1611: Reward = 585.00, Steps = 7, Loss = 15.2182, Exploration Rate = 0.1000, Train Count = 20548\n",
      "Episode 1612: Reward = 573.00, Steps = 11, Loss = 24.4844, Exploration Rate = 0.1000, Train Count = 20559\n",
      "Episode 1613: Reward = 594.00, Steps = 4, Loss = 17.1903, Exploration Rate = 0.1000, Train Count = 20563\n",
      "Episode 1614: Reward = 588.00, Steps = 6, Loss = 17.6860, Exploration Rate = 0.1000, Train Count = 20569\n",
      "Episode 1615: Reward = 544.00, Steps = 5, Loss = 22.8744, Exploration Rate = 0.1000, Train Count = 20574\n",
      "Episode 1616: Reward = 597.00, Steps = 3, Loss = 24.2335, Exploration Rate = 0.1000, Train Count = 20577\n",
      "Episode 1617: Reward = 588.00, Steps = 6, Loss = 22.2745, Exploration Rate = 0.1000, Train Count = 20583\n",
      "Episode 1618: Reward = 591.00, Steps = 5, Loss = 24.7264, Exploration Rate = 0.1000, Train Count = 20588\n",
      "Episode 1619: Reward = 597.00, Steps = 3, Loss = 26.9592, Exploration Rate = 0.1000, Train Count = 20591\n",
      "Episode 1620: Reward = 591.00, Steps = 5, Loss = 22.4578, Exploration Rate = 0.1000, Train Count = 20596\n",
      "Episode 1621: Reward = 585.00, Steps = 7, Loss = 22.2428, Exploration Rate = 0.1000, Train Count = 20603\n",
      "Episode 1622: Reward = 585.00, Steps = 7, Loss = 17.7278, Exploration Rate = 0.1000, Train Count = 20610\n",
      "Episode 1623: Reward = 582.00, Steps = 8, Loss = 17.9252, Exploration Rate = 0.1000, Train Count = 20618\n",
      "Episode 1624: Reward = 588.00, Steps = 6, Loss = 20.6677, Exploration Rate = 0.1000, Train Count = 20624\n",
      "Episode 1625: Reward = 588.00, Steps = 6, Loss = 19.9384, Exploration Rate = 0.1000, Train Count = 20630\n",
      "Episode 1626: Reward = 535.00, Steps = 8, Loss = 22.0465, Exploration Rate = 0.1000, Train Count = 20638\n",
      "Episode 1627: Reward = 579.00, Steps = 9, Loss = 22.4693, Exploration Rate = 0.1000, Train Count = 20647\n",
      "Episode 1628: Reward = 585.00, Steps = 7, Loss = 16.5229, Exploration Rate = 0.1000, Train Count = 20654\n",
      "Episode 1629: Reward = 579.00, Steps = 9, Loss = 16.2745, Exploration Rate = 0.1000, Train Count = 20663\n",
      "Episode 1630: Reward = 585.00, Steps = 7, Loss = 18.3151, Exploration Rate = 0.1000, Train Count = 20670\n",
      "Episode 1631: Reward = 570.00, Steps = 12, Loss = 20.2501, Exploration Rate = 0.1000, Train Count = 20682\n",
      "Episode 1632: Reward = 591.00, Steps = 5, Loss = 20.5737, Exploration Rate = 0.1000, Train Count = 20687\n",
      "Episode 1633: Reward = 594.00, Steps = 4, Loss = 17.6138, Exploration Rate = 0.1000, Train Count = 20691\n",
      "Episode 1634: Reward = 597.00, Steps = 3, Loss = 18.8133, Exploration Rate = 0.1000, Train Count = 20694\n",
      "Episode 1635: Reward = 582.00, Steps = 8, Loss = 18.7519, Exploration Rate = 0.1000, Train Count = 20702\n",
      "Episode 1636: Reward = 579.00, Steps = 9, Loss = 16.2163, Exploration Rate = 0.1000, Train Count = 20711\n",
      "Episode 1637: Reward = 594.00, Steps = 4, Loss = 22.5607, Exploration Rate = 0.1000, Train Count = 20715\n",
      "Episode 1638: Reward = 591.00, Steps = 5, Loss = 21.0484, Exploration Rate = 0.1000, Train Count = 20720\n",
      "Episode 1639: Reward = 591.00, Steps = 5, Loss = 28.7850, Exploration Rate = 0.1000, Train Count = 20725\n",
      "Episode 1640: Reward = 585.00, Steps = 7, Loss = 21.2036, Exploration Rate = 0.1000, Train Count = 20732\n",
      "Episode 1641: Reward = 576.00, Steps = 10, Loss = 18.4346, Exploration Rate = 0.1000, Train Count = 20742\n",
      "Episode 1642: Reward = 594.00, Steps = 4, Loss = 18.0996, Exploration Rate = 0.1000, Train Count = 20746\n",
      "Episode 1643: Reward = 588.00, Steps = 6, Loss = 14.1696, Exploration Rate = 0.1000, Train Count = 20752\n",
      "Episode 1644: Reward = 573.00, Steps = 11, Loss = 25.2447, Exploration Rate = 0.1000, Train Count = 20763\n",
      "Episode 1645: Reward = 594.00, Steps = 4, Loss = 20.7125, Exploration Rate = 0.1000, Train Count = 20767\n",
      "Episode 1646: Reward = 582.00, Steps = 8, Loss = 26.5426, Exploration Rate = 0.1000, Train Count = 20775\n",
      "Episode 1647: Reward = 591.00, Steps = 5, Loss = 18.9897, Exploration Rate = 0.1000, Train Count = 20780\n",
      "Episode 1648: Reward = 597.00, Steps = 3, Loss = 19.3060, Exploration Rate = 0.1000, Train Count = 20783\n",
      "Episode 1649: Reward = 594.00, Steps = 4, Loss = 17.6901, Exploration Rate = 0.1000, Train Count = 20787\n",
      "Episode 1650: Reward = 591.00, Steps = 5, Loss = 17.2325, Exploration Rate = 0.1000, Train Count = 20792\n",
      "Episode 1651: Reward = 597.00, Steps = 3, Loss = 16.9779, Exploration Rate = 0.1000, Train Count = 20795\n",
      "Episode 1652: Reward = 585.00, Steps = 7, Loss = 55.2222, Exploration Rate = 0.1000, Train Count = 20802\n",
      "Episode 1653: Reward = 597.00, Steps = 3, Loss = 118.7730, Exploration Rate = 0.1000, Train Count = 20805\n",
      "Episode 1654: Reward = 594.00, Steps = 4, Loss = 85.5927, Exploration Rate = 0.1000, Train Count = 20809\n",
      "Episode 1655: Reward = 588.00, Steps = 6, Loss = 75.3112, Exploration Rate = 0.1000, Train Count = 20815\n",
      "Episode 1656: Reward = 588.00, Steps = 6, Loss = 65.3977, Exploration Rate = 0.1000, Train Count = 20821\n",
      "Episode 1657: Reward = 594.00, Steps = 4, Loss = 54.2814, Exploration Rate = 0.1000, Train Count = 20825\n",
      "Episode 1658: Reward = 594.00, Steps = 4, Loss = 54.8142, Exploration Rate = 0.1000, Train Count = 20829\n",
      "Episode 1659: Reward = 585.00, Steps = 7, Loss = 42.8933, Exploration Rate = 0.1000, Train Count = 20836\n",
      "Episode 1660: Reward = 535.00, Steps = 8, Loss = 38.4223, Exploration Rate = 0.1000, Train Count = 20844\n",
      "Episode 1661: Reward = 591.00, Steps = 5, Loss = 29.3829, Exploration Rate = 0.1000, Train Count = 20849\n",
      "Episode 1662: Reward = 591.00, Steps = 5, Loss = 29.3641, Exploration Rate = 0.1000, Train Count = 20854\n",
      "Episode 1663: Reward = 594.00, Steps = 4, Loss = 29.1102, Exploration Rate = 0.1000, Train Count = 20858\n",
      "Episode 1664: Reward = 585.00, Steps = 7, Loss = 34.2900, Exploration Rate = 0.1000, Train Count = 20865\n",
      "Episode 1665: Reward = 585.00, Steps = 7, Loss = 21.3660, Exploration Rate = 0.1000, Train Count = 20872\n",
      "Episode 1666: Reward = 597.00, Steps = 3, Loss = 19.7613, Exploration Rate = 0.1000, Train Count = 20875\n",
      "Episode 1667: Reward = 594.00, Steps = 4, Loss = 18.7361, Exploration Rate = 0.1000, Train Count = 20879\n",
      "Episode 1668: Reward = 594.00, Steps = 4, Loss = 19.4314, Exploration Rate = 0.1000, Train Count = 20883\n",
      "Episode 1669: Reward = 597.00, Steps = 3, Loss = 15.0511, Exploration Rate = 0.1000, Train Count = 20886\n",
      "Episode 1670: Reward = 579.00, Steps = 9, Loss = 12.6588, Exploration Rate = 0.1000, Train Count = 20895\n",
      "Episode 1671: Reward = 594.00, Steps = 4, Loss = 22.8048, Exploration Rate = 0.1000, Train Count = 20899\n",
      "Episode 1672: Reward = 588.00, Steps = 6, Loss = 18.7880, Exploration Rate = 0.1000, Train Count = 20905\n",
      "Episode 1673: Reward = 558.00, Steps = 16, Loss = 17.0542, Exploration Rate = 0.1000, Train Count = 20921\n",
      "Episode 1674: Reward = 582.00, Steps = 8, Loss = 17.6369, Exploration Rate = 0.1000, Train Count = 20929\n",
      "Episode 1675: Reward = 588.00, Steps = 6, Loss = 14.7881, Exploration Rate = 0.1000, Train Count = 20935\n",
      "Episode 1676: Reward = 573.00, Steps = 11, Loss = 24.3149, Exploration Rate = 0.1000, Train Count = 20946\n",
      "Episode 1677: Reward = 594.00, Steps = 4, Loss = 26.0911, Exploration Rate = 0.1000, Train Count = 20950\n",
      "Episode 1678: Reward = 591.00, Steps = 5, Loss = 21.9100, Exploration Rate = 0.1000, Train Count = 20955\n",
      "Episode 1679: Reward = 576.00, Steps = 10, Loss = 17.8968, Exploration Rate = 0.1000, Train Count = 20965\n",
      "Episode 1680: Reward = 591.00, Steps = 5, Loss = 18.8216, Exploration Rate = 0.1000, Train Count = 20970\n",
      "Episode 1681: Reward = 585.00, Steps = 7, Loss = 17.2826, Exploration Rate = 0.1000, Train Count = 20977\n",
      "Episode 1682: Reward = 594.00, Steps = 4, Loss = 16.0423, Exploration Rate = 0.1000, Train Count = 20981\n",
      "Episode 1683: Reward = 591.00, Steps = 5, Loss = 18.9443, Exploration Rate = 0.1000, Train Count = 20986\n",
      "Episode 1684: Reward = 597.00, Steps = 3, Loss = 19.0277, Exploration Rate = 0.1000, Train Count = 20989\n",
      "Episode 1685: Reward = 594.00, Steps = 4, Loss = 7.1218, Exploration Rate = 0.1000, Train Count = 20993\n",
      "Episode 1686: Reward = 582.00, Steps = 8, Loss = 14.8143, Exploration Rate = 0.1000, Train Count = 21001\n",
      "Episode 1687: Reward = 591.00, Steps = 5, Loss = 19.2799, Exploration Rate = 0.1000, Train Count = 21006\n",
      "Episode 1688: Reward = 594.00, Steps = 4, Loss = 12.9053, Exploration Rate = 0.1000, Train Count = 21010\n",
      "Episode 1689: Reward = 523.00, Steps = 12, Loss = 13.1398, Exploration Rate = 0.1000, Train Count = 21022\n",
      "Episode 1690: Reward = 582.00, Steps = 8, Loss = 9.6393, Exploration Rate = 0.1000, Train Count = 21030\n",
      "Episode 1691: Reward = 591.00, Steps = 5, Loss = 10.6228, Exploration Rate = 0.1000, Train Count = 21035\n",
      "Episode 1692: Reward = 582.00, Steps = 8, Loss = 12.0941, Exploration Rate = 0.1000, Train Count = 21043\n",
      "Episode 1693: Reward = 600.00, Steps = 2, Loss = 14.0465, Exploration Rate = 0.1000, Train Count = 21045\n",
      "Episode 1694: Reward = 597.00, Steps = 3, Loss = 15.6104, Exploration Rate = 0.1000, Train Count = 21048\n",
      "Episode 1695: Reward = 591.00, Steps = 5, Loss = 13.5248, Exploration Rate = 0.1000, Train Count = 21053\n",
      "Episode 1696: Reward = 585.00, Steps = 7, Loss = 15.4032, Exploration Rate = 0.1000, Train Count = 21060\n",
      "Episode 1697: Reward = 588.00, Steps = 6, Loss = 12.0420, Exploration Rate = 0.1000, Train Count = 21066\n",
      "Episode 1698: Reward = 594.00, Steps = 4, Loss = 15.7145, Exploration Rate = 0.1000, Train Count = 21070\n",
      "Episode 1699: Reward = 585.00, Steps = 7, Loss = 13.4657, Exploration Rate = 0.1000, Train Count = 21077\n",
      "Episode 1700: Reward = 594.00, Steps = 4, Loss = 15.8047, Exploration Rate = 0.1000, Train Count = 21081\n",
      "Episode 1701: Reward = 582.00, Steps = 8, Loss = 12.1783, Exploration Rate = 0.1000, Train Count = 21089\n",
      "Episode 1702: Reward = 573.00, Steps = 11, Loss = 13.7452, Exploration Rate = 0.1000, Train Count = 21100\n",
      "Episode 1703: Reward = 573.00, Steps = 11, Loss = 12.7689, Exploration Rate = 0.1000, Train Count = 21111\n",
      "Episode 1704: Reward = 582.00, Steps = 8, Loss = 8.5469, Exploration Rate = 0.1000, Train Count = 21119\n",
      "Episode 1705: Reward = 496.00, Steps = 21, Loss = 11.9183, Exploration Rate = 0.1000, Train Count = 21140\n",
      "Episode 1706: Reward = 585.00, Steps = 7, Loss = 9.0168, Exploration Rate = 0.1000, Train Count = 21147\n",
      "Episode 1707: Reward = 579.00, Steps = 9, Loss = 18.1422, Exploration Rate = 0.1000, Train Count = 21156\n",
      "Episode 1708: Reward = 582.00, Steps = 8, Loss = 15.7424, Exploration Rate = 0.1000, Train Count = 21164\n",
      "Episode 1709: Reward = 582.00, Steps = 8, Loss = 10.1493, Exploration Rate = 0.1000, Train Count = 21172\n",
      "Episode 1710: Reward = 588.00, Steps = 6, Loss = 15.3979, Exploration Rate = 0.1000, Train Count = 21178\n",
      "Episode 1711: Reward = 387.00, Steps = 73, Loss = 27.8972, Exploration Rate = 0.1000, Train Count = 21251\n",
      "Episode 1712: Reward = 591.00, Steps = 5, Loss = 10.9003, Exploration Rate = 0.1000, Train Count = 21256\n",
      "Episode 1713: Reward = 582.00, Steps = 8, Loss = 9.2151, Exploration Rate = 0.1000, Train Count = 21264\n",
      "Episode 1714: Reward = 585.00, Steps = 7, Loss = 7.3125, Exploration Rate = 0.1000, Train Count = 21271\n",
      "Episode 1715: Reward = 594.00, Steps = 4, Loss = 6.2400, Exploration Rate = 0.1000, Train Count = 21275\n",
      "Episode 1716: Reward = 582.00, Steps = 8, Loss = 6.9956, Exploration Rate = 0.1000, Train Count = 21283\n",
      "Episode 1717: Reward = 585.00, Steps = 7, Loss = 7.7684, Exploration Rate = 0.1000, Train Count = 21290\n",
      "Episode 1718: Reward = 588.00, Steps = 6, Loss = 8.8283, Exploration Rate = 0.1000, Train Count = 21296\n",
      "Episode 1719: Reward = 579.00, Steps = 9, Loss = 82.1052, Exploration Rate = 0.1000, Train Count = 21305\n",
      "Episode 1720: Reward = 591.00, Steps = 5, Loss = 91.1169, Exploration Rate = 0.1000, Train Count = 21310\n",
      "Episode 1721: Reward = 570.00, Steps = 12, Loss = 69.8719, Exploration Rate = 0.1000, Train Count = 21322\n",
      "Episode 1722: Reward = 591.00, Steps = 5, Loss = 53.5816, Exploration Rate = 0.1000, Train Count = 21327\n",
      "Episode 1723: Reward = 588.00, Steps = 6, Loss = 46.2607, Exploration Rate = 0.1000, Train Count = 21333\n",
      "Episode 1724: Reward = 585.00, Steps = 7, Loss = 34.1720, Exploration Rate = 0.1000, Train Count = 21340\n",
      "Episode 1725: Reward = 538.00, Steps = 7, Loss = 29.1660, Exploration Rate = 0.1000, Train Count = 21347\n",
      "Episode 1726: Reward = 582.00, Steps = 8, Loss = 31.9337, Exploration Rate = 0.1000, Train Count = 21355\n",
      "Episode 1727: Reward = 594.00, Steps = 4, Loss = 29.8838, Exploration Rate = 0.1000, Train Count = 21359\n",
      "Episode 1728: Reward = 597.00, Steps = 3, Loss = 18.5116, Exploration Rate = 0.1000, Train Count = 21362\n",
      "Episode 1729: Reward = 576.00, Steps = 10, Loss = 24.7586, Exploration Rate = 0.1000, Train Count = 21372\n",
      "Episode 1730: Reward = 585.00, Steps = 7, Loss = 24.4455, Exploration Rate = 0.1000, Train Count = 21379\n",
      "Episode 1731: Reward = 597.00, Steps = 3, Loss = 21.2646, Exploration Rate = 0.1000, Train Count = 21382\n",
      "Episode 1732: Reward = 591.00, Steps = 5, Loss = 21.6329, Exploration Rate = 0.1000, Train Count = 21387\n",
      "Episode 1733: Reward = 588.00, Steps = 6, Loss = 17.9390, Exploration Rate = 0.1000, Train Count = 21393\n",
      "Episode 1734: Reward = 588.00, Steps = 6, Loss = 18.0201, Exploration Rate = 0.1000, Train Count = 21399\n",
      "Episode 1735: Reward = 591.00, Steps = 5, Loss = 14.3483, Exploration Rate = 0.1000, Train Count = 21404\n",
      "Episode 1736: Reward = 597.00, Steps = 3, Loss = 21.8058, Exploration Rate = 0.1000, Train Count = 21407\n",
      "Episode 1737: Reward = 535.00, Steps = 8, Loss = 22.8815, Exploration Rate = 0.1000, Train Count = 21415\n",
      "Episode 1738: Reward = 591.00, Steps = 5, Loss = 27.1906, Exploration Rate = 0.1000, Train Count = 21420\n",
      "Episode 1739: Reward = 520.00, Steps = 13, Loss = 26.9620, Exploration Rate = 0.1000, Train Count = 21433\n",
      "Episode 1740: Reward = 600.00, Steps = 2, Loss = 19.4327, Exploration Rate = 0.1000, Train Count = 21435\n",
      "Episode 1741: Reward = 594.00, Steps = 4, Loss = 19.0131, Exploration Rate = 0.1000, Train Count = 21439\n",
      "Episode 1742: Reward = 597.00, Steps = 3, Loss = 17.4435, Exploration Rate = 0.1000, Train Count = 21442\n",
      "Episode 1743: Reward = 588.00, Steps = 6, Loss = 14.0087, Exploration Rate = 0.1000, Train Count = 21448\n",
      "Episode 1744: Reward = 541.00, Steps = 6, Loss = 16.3080, Exploration Rate = 0.1000, Train Count = 21454\n",
      "Episode 1745: Reward = 597.00, Steps = 3, Loss = 10.4615, Exploration Rate = 0.1000, Train Count = 21457\n",
      "Episode 1746: Reward = 576.00, Steps = 10, Loss = 15.0266, Exploration Rate = 0.1000, Train Count = 21467\n",
      "Episode 1747: Reward = 594.00, Steps = 4, Loss = 10.9089, Exploration Rate = 0.1000, Train Count = 21471\n",
      "Episode 1748: Reward = 588.00, Steps = 6, Loss = 16.2247, Exploration Rate = 0.1000, Train Count = 21477\n",
      "Episode 1749: Reward = 591.00, Steps = 5, Loss = 8.7267, Exploration Rate = 0.1000, Train Count = 21482\n",
      "Episode 1750: Reward = 588.00, Steps = 6, Loss = 14.7587, Exploration Rate = 0.1000, Train Count = 21488\n",
      "Episode 1751: Reward = 541.00, Steps = 6, Loss = 14.1251, Exploration Rate = 0.1000, Train Count = 21494\n",
      "Episode 1752: Reward = 585.00, Steps = 7, Loss = 14.1877, Exploration Rate = 0.1000, Train Count = 21501\n",
      "Episode 1753: Reward = 585.00, Steps = 7, Loss = 16.9900, Exploration Rate = 0.1000, Train Count = 21508\n",
      "Episode 1754: Reward = 594.00, Steps = 4, Loss = 18.7836, Exploration Rate = 0.1000, Train Count = 21512\n",
      "Episode 1755: Reward = 591.00, Steps = 5, Loss = 18.4326, Exploration Rate = 0.1000, Train Count = 21517\n",
      "Episode 1756: Reward = 585.00, Steps = 7, Loss = 15.1466, Exploration Rate = 0.1000, Train Count = 21524\n",
      "Episode 1757: Reward = 585.00, Steps = 7, Loss = 14.1476, Exploration Rate = 0.1000, Train Count = 21531\n",
      "Episode 1758: Reward = 591.00, Steps = 5, Loss = 12.9207, Exploration Rate = 0.1000, Train Count = 21536\n",
      "Episode 1759: Reward = 597.00, Steps = 3, Loss = 10.6331, Exploration Rate = 0.1000, Train Count = 21539\n",
      "Episode 1760: Reward = 582.00, Steps = 8, Loss = 14.4851, Exploration Rate = 0.1000, Train Count = 21547\n",
      "Episode 1761: Reward = 582.00, Steps = 8, Loss = 12.6153, Exploration Rate = 0.1000, Train Count = 21555\n",
      "Episode 1762: Reward = 591.00, Steps = 5, Loss = 8.4381, Exploration Rate = 0.1000, Train Count = 21560\n",
      "Episode 1763: Reward = 594.00, Steps = 4, Loss = 13.6306, Exploration Rate = 0.1000, Train Count = 21564\n",
      "Episode 1764: Reward = 588.00, Steps = 6, Loss = 11.0497, Exploration Rate = 0.1000, Train Count = 21570\n",
      "Episode 1765: Reward = 591.00, Steps = 5, Loss = 10.4941, Exploration Rate = 0.1000, Train Count = 21575\n",
      "Episode 1766: Reward = 588.00, Steps = 6, Loss = 10.4052, Exploration Rate = 0.1000, Train Count = 21581\n",
      "Episode 1767: Reward = 591.00, Steps = 5, Loss = 10.9902, Exploration Rate = 0.1000, Train Count = 21586\n",
      "Episode 1768: Reward = 544.00, Steps = 5, Loss = 8.9825, Exploration Rate = 0.1000, Train Count = 21591\n",
      "Episode 1769: Reward = 538.00, Steps = 7, Loss = 11.6395, Exploration Rate = 0.1000, Train Count = 21598\n",
      "Episode 1770: Reward = 594.00, Steps = 4, Loss = 13.4380, Exploration Rate = 0.1000, Train Count = 21602\n",
      "Episode 1771: Reward = 585.00, Steps = 7, Loss = 9.1466, Exploration Rate = 0.1000, Train Count = 21609\n",
      "Episode 1772: Reward = 588.00, Steps = 6, Loss = 10.0130, Exploration Rate = 0.1000, Train Count = 21615\n",
      "Episode 1773: Reward = 591.00, Steps = 5, Loss = 6.7924, Exploration Rate = 0.1000, Train Count = 21620\n",
      "Episode 1774: Reward = 594.00, Steps = 4, Loss = 6.1978, Exploration Rate = 0.1000, Train Count = 21624\n",
      "Episode 1775: Reward = 594.00, Steps = 4, Loss = 8.9506, Exploration Rate = 0.1000, Train Count = 21628\n",
      "Episode 1776: Reward = 591.00, Steps = 5, Loss = 9.3159, Exploration Rate = 0.1000, Train Count = 21633\n",
      "Episode 1777: Reward = 585.00, Steps = 7, Loss = 9.7305, Exploration Rate = 0.1000, Train Count = 21640\n",
      "Episode 1778: Reward = 594.00, Steps = 4, Loss = 9.1524, Exploration Rate = 0.1000, Train Count = 21644\n",
      "Episode 1779: Reward = 594.00, Steps = 4, Loss = 6.7531, Exploration Rate = 0.1000, Train Count = 21648\n",
      "Episode 1780: Reward = 585.00, Steps = 7, Loss = 9.4178, Exploration Rate = 0.1000, Train Count = 21655\n",
      "Episode 1781: Reward = 585.00, Steps = 7, Loss = 12.2757, Exploration Rate = 0.1000, Train Count = 21662\n",
      "Episode 1782: Reward = 585.00, Steps = 7, Loss = 8.3518, Exploration Rate = 0.1000, Train Count = 21669\n",
      "Episode 1783: Reward = 541.00, Steps = 6, Loss = 14.4973, Exploration Rate = 0.1000, Train Count = 21675\n",
      "Episode 1784: Reward = 588.00, Steps = 6, Loss = 15.2068, Exploration Rate = 0.1000, Train Count = 21681\n",
      "Episode 1785: Reward = 600.00, Steps = 2, Loss = 10.2306, Exploration Rate = 0.1000, Train Count = 21683\n",
      "Episode 1786: Reward = 588.00, Steps = 6, Loss = 8.8065, Exploration Rate = 0.1000, Train Count = 21689\n",
      "Episode 1787: Reward = 588.00, Steps = 6, Loss = 9.9918, Exploration Rate = 0.1000, Train Count = 21695\n",
      "Episode 1788: Reward = 594.00, Steps = 4, Loss = 12.9785, Exploration Rate = 0.1000, Train Count = 21699\n",
      "Episode 1789: Reward = 591.00, Steps = 5, Loss = 19.6060, Exploration Rate = 0.1000, Train Count = 21704\n",
      "Episode 1790: Reward = 579.00, Steps = 9, Loss = 14.1029, Exploration Rate = 0.1000, Train Count = 21713\n",
      "Episode 1791: Reward = 567.00, Steps = 13, Loss = 11.6610, Exploration Rate = 0.1000, Train Count = 21726\n",
      "Episode 1792: Reward = 582.00, Steps = 8, Loss = 8.2424, Exploration Rate = 0.1000, Train Count = 21734\n",
      "Episode 1793: Reward = 579.00, Steps = 9, Loss = 8.7841, Exploration Rate = 0.1000, Train Count = 21743\n",
      "Episode 1794: Reward = 594.00, Steps = 4, Loss = 12.6285, Exploration Rate = 0.1000, Train Count = 21747\n",
      "Episode 1795: Reward = 591.00, Steps = 5, Loss = 7.9068, Exploration Rate = 0.1000, Train Count = 21752\n",
      "Episode 1796: Reward = 594.00, Steps = 4, Loss = 6.0804, Exploration Rate = 0.1000, Train Count = 21756\n",
      "Episode 1797: Reward = 594.00, Steps = 4, Loss = 4.6270, Exploration Rate = 0.1000, Train Count = 21760\n",
      "Episode 1798: Reward = 594.00, Steps = 4, Loss = 5.0403, Exploration Rate = 0.1000, Train Count = 21764\n",
      "Episode 1799: Reward = 591.00, Steps = 5, Loss = 7.1779, Exploration Rate = 0.1000, Train Count = 21769\n",
      "Episode 1800: Reward = 591.00, Steps = 5, Loss = 7.7913, Exploration Rate = 0.1000, Train Count = 21774\n",
      "Episode 1801: Reward = 585.00, Steps = 7, Loss = 6.1664, Exploration Rate = 0.1000, Train Count = 21781\n",
      "Episode 1802: Reward = 585.00, Steps = 7, Loss = 7.7252, Exploration Rate = 0.1000, Train Count = 21788\n",
      "Episode 1803: Reward = 597.00, Steps = 3, Loss = 7.6021, Exploration Rate = 0.1000, Train Count = 21791\n",
      "Episode 1804: Reward = 600.00, Steps = 2, Loss = 4.2752, Exploration Rate = 0.1000, Train Count = 21793\n",
      "Episode 1805: Reward = 537.00, Steps = 23, Loss = 53.8942, Exploration Rate = 0.1000, Train Count = 21816\n",
      "Episode 1806: Reward = 594.00, Steps = 4, Loss = 52.2872, Exploration Rate = 0.1000, Train Count = 21820\n",
      "Episode 1807: Reward = 591.00, Steps = 5, Loss = 34.3668, Exploration Rate = 0.1000, Train Count = 21825\n",
      "Episode 1808: Reward = 591.00, Steps = 5, Loss = 43.3725, Exploration Rate = 0.1000, Train Count = 21830\n",
      "Episode 1809: Reward = 591.00, Steps = 5, Loss = 28.1455, Exploration Rate = 0.1000, Train Count = 21835\n",
      "Episode 1810: Reward = 576.00, Steps = 10, Loss = 25.4342, Exploration Rate = 0.1000, Train Count = 21845\n",
      "Episode 1811: Reward = 585.00, Steps = 7, Loss = 20.4228, Exploration Rate = 0.1000, Train Count = 21852\n",
      "Episode 1812: Reward = 588.00, Steps = 6, Loss = 19.3701, Exploration Rate = 0.1000, Train Count = 21858\n",
      "Episode 1813: Reward = 588.00, Steps = 6, Loss = 18.1409, Exploration Rate = 0.1000, Train Count = 21864\n",
      "Episode 1814: Reward = 579.00, Steps = 9, Loss = 22.8102, Exploration Rate = 0.1000, Train Count = 21873\n",
      "Episode 1815: Reward = 582.00, Steps = 8, Loss = 24.1883, Exploration Rate = 0.1000, Train Count = 21881\n",
      "Episode 1816: Reward = 585.00, Steps = 7, Loss = 17.0839, Exploration Rate = 0.1000, Train Count = 21888\n",
      "Episode 1817: Reward = 591.00, Steps = 5, Loss = 24.0544, Exploration Rate = 0.1000, Train Count = 21893\n",
      "Episode 1818: Reward = 588.00, Steps = 6, Loss = 18.1318, Exploration Rate = 0.1000, Train Count = 21899\n",
      "Episode 1819: Reward = 582.00, Steps = 8, Loss = 13.1115, Exploration Rate = 0.1000, Train Count = 21907\n",
      "Episode 1820: Reward = 588.00, Steps = 6, Loss = 14.1009, Exploration Rate = 0.1000, Train Count = 21913\n",
      "Episode 1821: Reward = 591.00, Steps = 5, Loss = 17.0102, Exploration Rate = 0.1000, Train Count = 21918\n",
      "Episode 1822: Reward = 585.00, Steps = 7, Loss = 14.6564, Exploration Rate = 0.1000, Train Count = 21925\n",
      "Episode 1823: Reward = 597.00, Steps = 3, Loss = 14.8455, Exploration Rate = 0.1000, Train Count = 21928\n",
      "Episode 1824: Reward = 588.00, Steps = 6, Loss = 10.7482, Exploration Rate = 0.1000, Train Count = 21934\n",
      "Episode 1825: Reward = 582.00, Steps = 8, Loss = 21.8496, Exploration Rate = 0.1000, Train Count = 21942\n",
      "Episode 1826: Reward = 588.00, Steps = 6, Loss = 14.5265, Exploration Rate = 0.1000, Train Count = 21948\n",
      "Episode 1827: Reward = 588.00, Steps = 6, Loss = 9.1737, Exploration Rate = 0.1000, Train Count = 21954\n",
      "Episode 1828: Reward = 582.00, Steps = 8, Loss = 11.3156, Exploration Rate = 0.1000, Train Count = 21962\n",
      "Episode 1829: Reward = 597.00, Steps = 3, Loss = 7.2944, Exploration Rate = 0.1000, Train Count = 21965\n",
      "Episode 1830: Reward = 594.00, Steps = 4, Loss = 14.6147, Exploration Rate = 0.1000, Train Count = 21969\n",
      "Episode 1831: Reward = 588.00, Steps = 6, Loss = 13.2012, Exploration Rate = 0.1000, Train Count = 21975\n",
      "Episode 1832: Reward = 585.00, Steps = 7, Loss = 10.0643, Exploration Rate = 0.1000, Train Count = 21982\n",
      "Episode 1833: Reward = 591.00, Steps = 5, Loss = 8.3596, Exploration Rate = 0.1000, Train Count = 21987\n",
      "Episode 1834: Reward = 597.00, Steps = 3, Loss = 12.5725, Exploration Rate = 0.1000, Train Count = 21990\n",
      "Episode 1835: Reward = 594.00, Steps = 4, Loss = 8.4422, Exploration Rate = 0.1000, Train Count = 21994\n",
      "Episode 1836: Reward = 532.00, Steps = 9, Loss = 10.4215, Exploration Rate = 0.1000, Train Count = 22003\n",
      "Episode 1837: Reward = 585.00, Steps = 7, Loss = 13.8659, Exploration Rate = 0.1000, Train Count = 22010\n",
      "Episode 1838: Reward = 573.00, Steps = 11, Loss = 9.8207, Exploration Rate = 0.1000, Train Count = 22021\n",
      "Episode 1839: Reward = 591.00, Steps = 5, Loss = 8.9759, Exploration Rate = 0.1000, Train Count = 22026\n",
      "Episode 1840: Reward = 579.00, Steps = 9, Loss = 15.7719, Exploration Rate = 0.1000, Train Count = 22035\n",
      "Episode 1841: Reward = 585.00, Steps = 7, Loss = 14.1536, Exploration Rate = 0.1000, Train Count = 22042\n",
      "Episode 1842: Reward = 579.00, Steps = 9, Loss = 10.6623, Exploration Rate = 0.1000, Train Count = 22051\n",
      "Episode 1843: Reward = 597.00, Steps = 3, Loss = 13.9504, Exploration Rate = 0.1000, Train Count = 22054\n",
      "Episode 1844: Reward = 576.00, Steps = 10, Loss = 9.2666, Exploration Rate = 0.1000, Train Count = 22064\n",
      "Episode 1845: Reward = 588.00, Steps = 6, Loss = 23.6720, Exploration Rate = 0.1000, Train Count = 22070\n",
      "Episode 1846: Reward = 597.00, Steps = 3, Loss = 17.4167, Exploration Rate = 0.1000, Train Count = 22073\n",
      "Episode 1847: Reward = 600.00, Steps = 2, Loss = 7.1218, Exploration Rate = 0.1000, Train Count = 22075\n",
      "Episode 1848: Reward = 588.00, Steps = 6, Loss = 16.5115, Exploration Rate = 0.1000, Train Count = 22081\n",
      "Episode 1849: Reward = 594.00, Steps = 4, Loss = 20.3379, Exploration Rate = 0.1000, Train Count = 22085\n",
      "Episode 1850: Reward = 588.00, Steps = 6, Loss = 21.7828, Exploration Rate = 0.1000, Train Count = 22091\n",
      "Episode 1851: Reward = 597.00, Steps = 3, Loss = 25.4825, Exploration Rate = 0.1000, Train Count = 22094\n",
      "Episode 1852: Reward = 532.00, Steps = 9, Loss = 26.2977, Exploration Rate = 0.1000, Train Count = 22103\n",
      "Episode 1853: Reward = 582.00, Steps = 8, Loss = 18.9583, Exploration Rate = 0.1000, Train Count = 22111\n",
      "Episode 1854: Reward = 594.00, Steps = 4, Loss = 23.2359, Exploration Rate = 0.1000, Train Count = 22115\n",
      "Episode 1855: Reward = 591.00, Steps = 5, Loss = 20.6856, Exploration Rate = 0.1000, Train Count = 22120\n",
      "Episode 1856: Reward = 588.00, Steps = 6, Loss = 19.5370, Exploration Rate = 0.1000, Train Count = 22126\n",
      "Episode 1857: Reward = 588.00, Steps = 6, Loss = 12.6538, Exploration Rate = 0.1000, Train Count = 22132\n",
      "Episode 1858: Reward = 532.00, Steps = 9, Loss = 21.9491, Exploration Rate = 0.1000, Train Count = 22141\n",
      "Episode 1859: Reward = 585.00, Steps = 7, Loss = 22.7149, Exploration Rate = 0.1000, Train Count = 22148\n",
      "Episode 1860: Reward = 576.00, Steps = 10, Loss = 17.1781, Exploration Rate = 0.1000, Train Count = 22158\n",
      "Episode 1861: Reward = 594.00, Steps = 4, Loss = 16.0354, Exploration Rate = 0.1000, Train Count = 22162\n",
      "Episode 1862: Reward = 588.00, Steps = 6, Loss = 13.2044, Exploration Rate = 0.1000, Train Count = 22168\n",
      "Episode 1863: Reward = 594.00, Steps = 4, Loss = 16.8430, Exploration Rate = 0.1000, Train Count = 22172\n",
      "Episode 1864: Reward = 591.00, Steps = 5, Loss = 25.1359, Exploration Rate = 0.1000, Train Count = 22177\n",
      "Episode 1865: Reward = 582.00, Steps = 8, Loss = 19.0605, Exploration Rate = 0.1000, Train Count = 22185\n",
      "Episode 1866: Reward = 582.00, Steps = 8, Loss = 25.3495, Exploration Rate = 0.1000, Train Count = 22193\n",
      "Episode 1867: Reward = 588.00, Steps = 6, Loss = 15.6364, Exploration Rate = 0.1000, Train Count = 22199\n",
      "Episode 1868: Reward = 591.00, Steps = 5, Loss = 10.1552, Exploration Rate = 0.1000, Train Count = 22204\n",
      "Episode 1869: Reward = 597.00, Steps = 3, Loss = 16.4269, Exploration Rate = 0.1000, Train Count = 22207\n",
      "Episode 1870: Reward = 594.00, Steps = 4, Loss = 13.3745, Exploration Rate = 0.1000, Train Count = 22211\n",
      "Episode 1871: Reward = 532.00, Steps = 9, Loss = 12.8114, Exploration Rate = 0.1000, Train Count = 22220\n",
      "Episode 1872: Reward = 541.00, Steps = 6, Loss = 17.5436, Exploration Rate = 0.1000, Train Count = 22226\n",
      "Episode 1873: Reward = 585.00, Steps = 7, Loss = 15.7307, Exploration Rate = 0.1000, Train Count = 22233\n",
      "Episode 1874: Reward = 585.00, Steps = 7, Loss = 9.1493, Exploration Rate = 0.1000, Train Count = 22240\n",
      "Episode 1875: Reward = 579.00, Steps = 9, Loss = 18.4440, Exploration Rate = 0.1000, Train Count = 22249\n",
      "Episode 1876: Reward = 582.00, Steps = 8, Loss = 15.5750, Exploration Rate = 0.1000, Train Count = 22257\n",
      "Episode 1877: Reward = 573.00, Steps = 11, Loss = 14.0423, Exploration Rate = 0.1000, Train Count = 22268\n",
      "Episode 1878: Reward = 597.00, Steps = 3, Loss = 12.2810, Exploration Rate = 0.1000, Train Count = 22271\n",
      "Episode 1879: Reward = 561.00, Steps = 15, Loss = 15.3777, Exploration Rate = 0.1000, Train Count = 22286\n",
      "Episode 1880: Reward = 561.00, Steps = 15, Loss = 20.4652, Exploration Rate = 0.1000, Train Count = 22301\n",
      "Episode 1881: Reward = 588.00, Steps = 6, Loss = 79.9950, Exploration Rate = 0.1000, Train Count = 22307\n",
      "Episode 1882: Reward = 591.00, Steps = 5, Loss = 63.1758, Exploration Rate = 0.1000, Train Count = 22312\n",
      "Episode 1883: Reward = 585.00, Steps = 7, Loss = 57.5997, Exploration Rate = 0.1000, Train Count = 22319\n",
      "Episode 1884: Reward = 576.00, Steps = 10, Loss = 41.5028, Exploration Rate = 0.1000, Train Count = 22329\n",
      "Episode 1885: Reward = 597.00, Steps = 3, Loss = 31.6647, Exploration Rate = 0.1000, Train Count = 22332\n",
      "Episode 1886: Reward = 585.00, Steps = 7, Loss = 25.9533, Exploration Rate = 0.1000, Train Count = 22339\n",
      "Episode 1887: Reward = 576.00, Steps = 10, Loss = 23.4100, Exploration Rate = 0.1000, Train Count = 22349\n",
      "Episode 1888: Reward = 594.00, Steps = 4, Loss = 18.4428, Exploration Rate = 0.1000, Train Count = 22353\n",
      "Episode 1889: Reward = 582.00, Steps = 8, Loss = 16.3583, Exploration Rate = 0.1000, Train Count = 22361\n",
      "Episode 1890: Reward = 588.00, Steps = 6, Loss = 28.0168, Exploration Rate = 0.1000, Train Count = 22367\n",
      "Episode 1891: Reward = 594.00, Steps = 4, Loss = 14.3332, Exploration Rate = 0.1000, Train Count = 22371\n",
      "Episode 1892: Reward = 582.00, Steps = 8, Loss = 14.3793, Exploration Rate = 0.1000, Train Count = 22379\n",
      "Episode 1893: Reward = 597.00, Steps = 3, Loss = 13.8835, Exploration Rate = 0.1000, Train Count = 22382\n",
      "Episode 1894: Reward = 585.00, Steps = 7, Loss = 13.8547, Exploration Rate = 0.1000, Train Count = 22389\n",
      "Episode 1895: Reward = 588.00, Steps = 6, Loss = 13.4861, Exploration Rate = 0.1000, Train Count = 22395\n",
      "Episode 1896: Reward = 591.00, Steps = 5, Loss = 11.4134, Exploration Rate = 0.1000, Train Count = 22400\n",
      "Episode 1897: Reward = 585.00, Steps = 7, Loss = 15.9516, Exploration Rate = 0.1000, Train Count = 22407\n",
      "Episode 1898: Reward = 588.00, Steps = 6, Loss = 17.2114, Exploration Rate = 0.1000, Train Count = 22413\n",
      "Episode 1899: Reward = 585.00, Steps = 7, Loss = 17.3608, Exploration Rate = 0.1000, Train Count = 22420\n",
      "Episode 1900: Reward = 576.00, Steps = 10, Loss = 27.3364, Exploration Rate = 0.1000, Train Count = 22430\n",
      "Episode 1901: Reward = 582.00, Steps = 8, Loss = 18.3154, Exploration Rate = 0.1000, Train Count = 22438\n",
      "Episode 1902: Reward = 526.00, Steps = 11, Loss = 18.3496, Exploration Rate = 0.1000, Train Count = 22449\n",
      "Episode 1903: Reward = 588.00, Steps = 6, Loss = 14.2204, Exploration Rate = 0.1000, Train Count = 22455\n",
      "Episode 1904: Reward = 585.00, Steps = 7, Loss = 19.5114, Exploration Rate = 0.1000, Train Count = 22462\n",
      "Episode 1905: Reward = 549.00, Steps = 19, Loss = 17.8757, Exploration Rate = 0.1000, Train Count = 22481\n",
      "Episode 1906: Reward = 594.00, Steps = 4, Loss = 12.0101, Exploration Rate = 0.1000, Train Count = 22485\n",
      "Episode 1907: Reward = 588.00, Steps = 6, Loss = 12.4339, Exploration Rate = 0.1000, Train Count = 22491\n",
      "Episode 1908: Reward = 594.00, Steps = 4, Loss = 11.0119, Exploration Rate = 0.1000, Train Count = 22495\n",
      "Episode 1909: Reward = 585.00, Steps = 7, Loss = 16.1540, Exploration Rate = 0.1000, Train Count = 22502\n",
      "Episode 1910: Reward = 585.00, Steps = 7, Loss = 11.0759, Exploration Rate = 0.1000, Train Count = 22509\n",
      "Episode 1911: Reward = 600.00, Steps = 2, Loss = 14.8690, Exploration Rate = 0.1000, Train Count = 22511\n",
      "Episode 1912: Reward = 585.00, Steps = 7, Loss = 12.4495, Exploration Rate = 0.1000, Train Count = 22518\n",
      "Episode 1913: Reward = 588.00, Steps = 6, Loss = 10.2642, Exploration Rate = 0.1000, Train Count = 22524\n",
      "Episode 1914: Reward = 532.00, Steps = 9, Loss = 12.3328, Exploration Rate = 0.1000, Train Count = 22533\n",
      "Episode 1915: Reward = 585.00, Steps = 7, Loss = 15.4300, Exploration Rate = 0.1000, Train Count = 22540\n",
      "Episode 1916: Reward = 594.00, Steps = 4, Loss = 10.0940, Exploration Rate = 0.1000, Train Count = 22544\n",
      "Episode 1917: Reward = 538.00, Steps = 7, Loss = 10.1806, Exploration Rate = 0.1000, Train Count = 22551\n",
      "Episode 1918: Reward = 597.00, Steps = 3, Loss = 7.9499, Exploration Rate = 0.1000, Train Count = 22554\n",
      "Episode 1919: Reward = 591.00, Steps = 5, Loss = 13.9420, Exploration Rate = 0.1000, Train Count = 22559\n",
      "Episode 1920: Reward = 576.00, Steps = 10, Loss = 12.4257, Exploration Rate = 0.1000, Train Count = 22569\n",
      "Episode 1921: Reward = 579.00, Steps = 9, Loss = 21.6709, Exploration Rate = 0.1000, Train Count = 22578\n",
      "Episode 1922: Reward = 588.00, Steps = 6, Loss = 17.5981, Exploration Rate = 0.1000, Train Count = 22584\n",
      "Episode 1923: Reward = 579.00, Steps = 9, Loss = 14.6128, Exploration Rate = 0.1000, Train Count = 22593\n",
      "Episode 1924: Reward = 591.00, Steps = 5, Loss = 13.5060, Exploration Rate = 0.1000, Train Count = 22598\n",
      "Episode 1925: Reward = 591.00, Steps = 5, Loss = 13.1872, Exploration Rate = 0.1000, Train Count = 22603\n",
      "Episode 1926: Reward = 588.00, Steps = 6, Loss = 12.4263, Exploration Rate = 0.1000, Train Count = 22609\n",
      "Episode 1927: Reward = 594.00, Steps = 4, Loss = 8.6177, Exploration Rate = 0.1000, Train Count = 22613\n",
      "Episode 1928: Reward = 588.00, Steps = 6, Loss = 11.9262, Exploration Rate = 0.1000, Train Count = 22619\n",
      "Episode 1929: Reward = 594.00, Steps = 4, Loss = 9.4662, Exploration Rate = 0.1000, Train Count = 22623\n",
      "Episode 1930: Reward = 588.00, Steps = 6, Loss = 5.6289, Exploration Rate = 0.1000, Train Count = 22629\n",
      "Episode 1931: Reward = 576.00, Steps = 10, Loss = 7.4531, Exploration Rate = 0.1000, Train Count = 22639\n",
      "Episode 1932: Reward = 585.00, Steps = 7, Loss = 6.6700, Exploration Rate = 0.1000, Train Count = 22646\n",
      "Episode 1933: Reward = 597.00, Steps = 3, Loss = 13.2518, Exploration Rate = 0.1000, Train Count = 22649\n",
      "Episode 1934: Reward = 579.00, Steps = 9, Loss = 7.0150, Exploration Rate = 0.1000, Train Count = 22658\n",
      "Episode 1935: Reward = 597.00, Steps = 3, Loss = 6.5567, Exploration Rate = 0.1000, Train Count = 22661\n",
      "Episode 1936: Reward = 585.00, Steps = 7, Loss = 8.0611, Exploration Rate = 0.1000, Train Count = 22668\n",
      "Episode 1937: Reward = 585.00, Steps = 7, Loss = 8.9005, Exploration Rate = 0.1000, Train Count = 22675\n",
      "Episode 1938: Reward = 585.00, Steps = 7, Loss = 6.7666, Exploration Rate = 0.1000, Train Count = 22682\n",
      "Episode 1939: Reward = 573.00, Steps = 11, Loss = 12.7732, Exploration Rate = 0.1000, Train Count = 22693\n",
      "Episode 1940: Reward = 600.00, Steps = 2, Loss = 10.1554, Exploration Rate = 0.1000, Train Count = 22695\n",
      "Episode 1941: Reward = 488.00, Steps = 8, Loss = 14.2840, Exploration Rate = 0.1000, Train Count = 22703\n",
      "Episode 1942: Reward = 597.00, Steps = 3, Loss = 11.3069, Exploration Rate = 0.1000, Train Count = 22706\n",
      "Episode 1943: Reward = 576.00, Steps = 10, Loss = 11.1656, Exploration Rate = 0.1000, Train Count = 22716\n",
      "Episode 1944: Reward = 597.00, Steps = 3, Loss = 4.6061, Exploration Rate = 0.1000, Train Count = 22719\n",
      "Episode 1945: Reward = 538.00, Steps = 7, Loss = 13.4244, Exploration Rate = 0.1000, Train Count = 22726\n",
      "Episode 1946: Reward = 588.00, Steps = 6, Loss = 11.7182, Exploration Rate = 0.1000, Train Count = 22732\n",
      "Episode 1947: Reward = 591.00, Steps = 5, Loss = 9.4392, Exploration Rate = 0.1000, Train Count = 22737\n",
      "Episode 1948: Reward = 597.00, Steps = 3, Loss = 8.0077, Exploration Rate = 0.1000, Train Count = 22740\n",
      "Episode 1949: Reward = 585.00, Steps = 7, Loss = 9.2272, Exploration Rate = 0.1000, Train Count = 22747\n",
      "Episode 1950: Reward = 600.00, Steps = 2, Loss = 16.3294, Exploration Rate = 0.1000, Train Count = 22749\n",
      "Episode 1951: Reward = 591.00, Steps = 5, Loss = 9.2325, Exploration Rate = 0.1000, Train Count = 22754\n",
      "Episode 1952: Reward = 591.00, Steps = 5, Loss = 11.1424, Exploration Rate = 0.1000, Train Count = 22759\n",
      "Episode 1953: Reward = 597.00, Steps = 3, Loss = 7.0003, Exploration Rate = 0.1000, Train Count = 22762\n",
      "Episode 1954: Reward = 591.00, Steps = 5, Loss = 7.2772, Exploration Rate = 0.1000, Train Count = 22767\n",
      "Episode 1955: Reward = 585.00, Steps = 7, Loss = 7.9500, Exploration Rate = 0.1000, Train Count = 22774\n",
      "Episode 1956: Reward = 594.00, Steps = 4, Loss = 4.6295, Exploration Rate = 0.1000, Train Count = 22778\n",
      "Episode 1957: Reward = 585.00, Steps = 7, Loss = 9.4264, Exploration Rate = 0.1000, Train Count = 22785\n",
      "Episode 1958: Reward = 597.00, Steps = 3, Loss = 4.1265, Exploration Rate = 0.1000, Train Count = 22788\n",
      "Episode 1959: Reward = 588.00, Steps = 6, Loss = 5.3507, Exploration Rate = 0.1000, Train Count = 22794\n",
      "Episode 1960: Reward = 597.00, Steps = 3, Loss = 9.2842, Exploration Rate = 0.1000, Train Count = 22797\n",
      "Episode 1961: Reward = 594.00, Steps = 4, Loss = 24.4494, Exploration Rate = 0.1000, Train Count = 22801\n",
      "Episode 1962: Reward = 588.00, Steps = 6, Loss = 61.3282, Exploration Rate = 0.1000, Train Count = 22807\n",
      "Episode 1963: Reward = 588.00, Steps = 6, Loss = 60.7829, Exploration Rate = 0.1000, Train Count = 22813\n",
      "Episode 1964: Reward = 600.00, Steps = 2, Loss = 52.9258, Exploration Rate = 0.1000, Train Count = 22815\n",
      "Episode 1965: Reward = 591.00, Steps = 5, Loss = 45.5069, Exploration Rate = 0.1000, Train Count = 22820\n",
      "Episode 1966: Reward = 588.00, Steps = 6, Loss = 39.0873, Exploration Rate = 0.1000, Train Count = 22826\n",
      "Episode 1967: Reward = 535.00, Steps = 8, Loss = 28.5843, Exploration Rate = 0.1000, Train Count = 22834\n",
      "Episode 1968: Reward = 597.00, Steps = 3, Loss = 22.7377, Exploration Rate = 0.1000, Train Count = 22837\n",
      "Episode 1969: Reward = 585.00, Steps = 7, Loss = 21.8949, Exploration Rate = 0.1000, Train Count = 22844\n",
      "Episode 1970: Reward = 597.00, Steps = 3, Loss = 16.9837, Exploration Rate = 0.1000, Train Count = 22847\n",
      "Episode 1971: Reward = 582.00, Steps = 8, Loss = 14.2503, Exploration Rate = 0.1000, Train Count = 22855\n",
      "Episode 1972: Reward = 588.00, Steps = 6, Loss = 16.1417, Exploration Rate = 0.1000, Train Count = 22861\n",
      "Episode 1973: Reward = 597.00, Steps = 3, Loss = 15.0878, Exploration Rate = 0.1000, Train Count = 22864\n",
      "Episode 1974: Reward = 585.00, Steps = 7, Loss = 12.5078, Exploration Rate = 0.1000, Train Count = 22871\n",
      "Episode 1975: Reward = 547.00, Steps = 4, Loss = 14.4645, Exploration Rate = 0.1000, Train Count = 22875\n",
      "Episode 1976: Reward = 535.00, Steps = 8, Loss = 18.5718, Exploration Rate = 0.1000, Train Count = 22883\n",
      "Episode 1977: Reward = 585.00, Steps = 7, Loss = 16.7831, Exploration Rate = 0.1000, Train Count = 22890\n",
      "Episode 1978: Reward = 585.00, Steps = 7, Loss = 14.7960, Exploration Rate = 0.1000, Train Count = 22897\n",
      "Episode 1979: Reward = 579.00, Steps = 9, Loss = 11.9412, Exploration Rate = 0.1000, Train Count = 22906\n",
      "Episode 1980: Reward = 585.00, Steps = 7, Loss = 10.5909, Exploration Rate = 0.1000, Train Count = 22913\n",
      "Episode 1981: Reward = 579.00, Steps = 9, Loss = 13.6389, Exploration Rate = 0.1000, Train Count = 22922\n",
      "Episode 1982: Reward = 591.00, Steps = 5, Loss = 15.0439, Exploration Rate = 0.1000, Train Count = 22927\n",
      "Episode 1983: Reward = 541.00, Steps = 6, Loss = 11.0787, Exploration Rate = 0.1000, Train Count = 22933\n",
      "Episode 1984: Reward = 579.00, Steps = 9, Loss = 11.4022, Exploration Rate = 0.1000, Train Count = 22942\n",
      "Episode 1985: Reward = 594.00, Steps = 4, Loss = 7.9885, Exploration Rate = 0.1000, Train Count = 22946\n",
      "Episode 1986: Reward = 585.00, Steps = 7, Loss = 10.2819, Exploration Rate = 0.1000, Train Count = 22953\n",
      "Episode 1987: Reward = 588.00, Steps = 6, Loss = 7.6726, Exploration Rate = 0.1000, Train Count = 22959\n",
      "Episode 1988: Reward = 582.00, Steps = 8, Loss = 7.9869, Exploration Rate = 0.1000, Train Count = 22967\n",
      "Episode 1989: Reward = 588.00, Steps = 6, Loss = 7.6666, Exploration Rate = 0.1000, Train Count = 22973\n",
      "Episode 1990: Reward = 585.00, Steps = 7, Loss = 10.4086, Exploration Rate = 0.1000, Train Count = 22980\n",
      "Episode 1991: Reward = 591.00, Steps = 5, Loss = 9.7814, Exploration Rate = 0.1000, Train Count = 22985\n",
      "Episode 1992: Reward = 597.00, Steps = 3, Loss = 8.3340, Exploration Rate = 0.1000, Train Count = 22988\n",
      "Episode 1993: Reward = 591.00, Steps = 5, Loss = 8.7951, Exploration Rate = 0.1000, Train Count = 22993\n",
      "Episode 1994: Reward = 585.00, Steps = 7, Loss = 11.6420, Exploration Rate = 0.1000, Train Count = 23000\n",
      "Episode 1995: Reward = 591.00, Steps = 5, Loss = 9.6898, Exploration Rate = 0.1000, Train Count = 23005\n",
      "Episode 1996: Reward = 594.00, Steps = 4, Loss = 9.5537, Exploration Rate = 0.1000, Train Count = 23009\n",
      "Episode 1997: Reward = 573.00, Steps = 11, Loss = 8.5829, Exploration Rate = 0.1000, Train Count = 23020\n",
      "Episode 1998: Reward = 597.00, Steps = 3, Loss = 6.1382, Exploration Rate = 0.1000, Train Count = 23023\n",
      "Episode 1999: Reward = 588.00, Steps = 6, Loss = 6.8429, Exploration Rate = 0.1000, Train Count = 23029\n",
      "Episode 2000: Reward = 594.00, Steps = 4, Loss = 6.1275, Exploration Rate = 0.1000, Train Count = 23033\n",
      "Episode 2001: Reward = 588.00, Steps = 6, Loss = 4.2900, Exploration Rate = 0.1000, Train Count = 23039\n",
      "Episode 2002: Reward = 591.00, Steps = 5, Loss = 3.7475, Exploration Rate = 0.1000, Train Count = 23044\n",
      "Episode 2003: Reward = 582.00, Steps = 8, Loss = 6.6921, Exploration Rate = 0.1000, Train Count = 23052\n",
      "Episode 2004: Reward = 591.00, Steps = 5, Loss = 4.2799, Exploration Rate = 0.1000, Train Count = 23057\n",
      "Episode 2005: Reward = 585.00, Steps = 7, Loss = 5.3088, Exploration Rate = 0.1000, Train Count = 23064\n",
      "Episode 2006: Reward = 579.00, Steps = 9, Loss = 5.4274, Exploration Rate = 0.1000, Train Count = 23073\n",
      "Episode 2007: Reward = 582.00, Steps = 8, Loss = 4.5147, Exploration Rate = 0.1000, Train Count = 23081\n",
      "Episode 2008: Reward = 588.00, Steps = 6, Loss = 4.5252, Exploration Rate = 0.1000, Train Count = 23087\n",
      "Episode 2009: Reward = 588.00, Steps = 6, Loss = 3.7656, Exploration Rate = 0.1000, Train Count = 23093\n",
      "Episode 2010: Reward = 591.00, Steps = 5, Loss = 2.4682, Exploration Rate = 0.1000, Train Count = 23098\n",
      "Episode 2011: Reward = 594.00, Steps = 4, Loss = 2.2745, Exploration Rate = 0.1000, Train Count = 23102\n",
      "Episode 2012: Reward = 582.00, Steps = 8, Loss = 1.9983, Exploration Rate = 0.1000, Train Count = 23110\n",
      "Episode 2013: Reward = 591.00, Steps = 5, Loss = 4.2294, Exploration Rate = 0.1000, Train Count = 23115\n",
      "Episode 2014: Reward = 538.00, Steps = 7, Loss = 15.4260, Exploration Rate = 0.1000, Train Count = 23122\n",
      "Episode 2015: Reward = 594.00, Steps = 4, Loss = 9.0964, Exploration Rate = 0.1000, Train Count = 23126\n",
      "Episode 2016: Reward = 597.00, Steps = 3, Loss = 13.0245, Exploration Rate = 0.1000, Train Count = 23129\n",
      "Episode 2017: Reward = 585.00, Steps = 7, Loss = 11.2858, Exploration Rate = 0.1000, Train Count = 23136\n",
      "Episode 2018: Reward = 535.00, Steps = 8, Loss = 12.0523, Exploration Rate = 0.1000, Train Count = 23144\n",
      "Episode 2019: Reward = 582.00, Steps = 8, Loss = 12.2512, Exploration Rate = 0.1000, Train Count = 23152\n",
      "Episode 2020: Reward = 594.00, Steps = 4, Loss = 14.6762, Exploration Rate = 0.1000, Train Count = 23156\n",
      "Episode 2021: Reward = 594.00, Steps = 4, Loss = 18.1873, Exploration Rate = 0.1000, Train Count = 23160\n",
      "Episode 2022: Reward = 594.00, Steps = 4, Loss = 11.2129, Exploration Rate = 0.1000, Train Count = 23164\n",
      "Episode 2023: Reward = 588.00, Steps = 6, Loss = 12.5799, Exploration Rate = 0.1000, Train Count = 23170\n",
      "Episode 2024: Reward = 541.00, Steps = 6, Loss = 8.1932, Exploration Rate = 0.1000, Train Count = 23176\n",
      "Episode 2025: Reward = 585.00, Steps = 7, Loss = 8.9802, Exploration Rate = 0.1000, Train Count = 23183\n",
      "Episode 2026: Reward = 579.00, Steps = 9, Loss = 16.2935, Exploration Rate = 0.1000, Train Count = 23192\n",
      "Episode 2027: Reward = 585.00, Steps = 7, Loss = 16.3920, Exploration Rate = 0.1000, Train Count = 23199\n",
      "Episode 2028: Reward = 591.00, Steps = 5, Loss = 16.3083, Exploration Rate = 0.1000, Train Count = 23204\n",
      "Episode 2029: Reward = 579.00, Steps = 9, Loss = 12.7590, Exploration Rate = 0.1000, Train Count = 23213\n",
      "Episode 2030: Reward = 597.00, Steps = 3, Loss = 9.3290, Exploration Rate = 0.1000, Train Count = 23216\n",
      "Episode 2031: Reward = 585.00, Steps = 7, Loss = 8.1375, Exploration Rate = 0.1000, Train Count = 23223\n",
      "Episode 2032: Reward = 591.00, Steps = 5, Loss = 10.5465, Exploration Rate = 0.1000, Train Count = 23228\n",
      "Episode 2033: Reward = 594.00, Steps = 4, Loss = 8.7802, Exploration Rate = 0.1000, Train Count = 23232\n",
      "Episode 2034: Reward = 588.00, Steps = 6, Loss = 11.1062, Exploration Rate = 0.1000, Train Count = 23238\n",
      "Episode 2035: Reward = 594.00, Steps = 4, Loss = 8.9366, Exploration Rate = 0.1000, Train Count = 23242\n",
      "Episode 2036: Reward = 597.00, Steps = 3, Loss = 12.4817, Exploration Rate = 0.1000, Train Count = 23245\n",
      "Episode 2037: Reward = 597.00, Steps = 3, Loss = 8.2154, Exploration Rate = 0.1000, Train Count = 23248\n",
      "Episode 2038: Reward = 544.00, Steps = 5, Loss = 11.9625, Exploration Rate = 0.1000, Train Count = 23253\n",
      "Episode 2039: Reward = 540.00, Steps = 22, Loss = 16.8132, Exploration Rate = 0.1000, Train Count = 23275\n",
      "Episode 2040: Reward = 582.00, Steps = 8, Loss = 5.8250, Exploration Rate = 0.1000, Train Count = 23283\n",
      "Episode 2041: Reward = 591.00, Steps = 5, Loss = 11.8577, Exploration Rate = 0.1000, Train Count = 23288\n",
      "Episode 2042: Reward = 594.00, Steps = 4, Loss = 7.4930, Exploration Rate = 0.1000, Train Count = 23292\n",
      "Episode 2043: Reward = 591.00, Steps = 5, Loss = 6.9821, Exploration Rate = 0.1000, Train Count = 23297\n",
      "Episode 2044: Reward = 597.00, Steps = 3, Loss = 3.9759, Exploration Rate = 0.1000, Train Count = 23300\n",
      "Episode 2045: Reward = 591.00, Steps = 5, Loss = 63.4750, Exploration Rate = 0.1000, Train Count = 23305\n",
      "Episode 2046: Reward = 585.00, Steps = 7, Loss = 55.9513, Exploration Rate = 0.1000, Train Count = 23312\n",
      "Episode 2047: Reward = 591.00, Steps = 5, Loss = 40.0782, Exploration Rate = 0.1000, Train Count = 23317\n",
      "Episode 2048: Reward = 579.00, Steps = 9, Loss = 40.2985, Exploration Rate = 0.1000, Train Count = 23326\n",
      "Episode 2049: Reward = 597.00, Steps = 3, Loss = 30.0235, Exploration Rate = 0.1000, Train Count = 23329\n",
      "Episode 2050: Reward = 591.00, Steps = 5, Loss = 32.1862, Exploration Rate = 0.1000, Train Count = 23334\n",
      "Episode 2051: Reward = 597.00, Steps = 3, Loss = 32.8796, Exploration Rate = 0.1000, Train Count = 23337\n",
      "Episode 2052: Reward = 597.00, Steps = 3, Loss = 20.1944, Exploration Rate = 0.1000, Train Count = 23340\n",
      "Episode 2053: Reward = 591.00, Steps = 5, Loss = 18.6970, Exploration Rate = 0.1000, Train Count = 23345\n",
      "Episode 2054: Reward = 588.00, Steps = 6, Loss = 16.9775, Exploration Rate = 0.1000, Train Count = 23351\n",
      "Episode 2055: Reward = 588.00, Steps = 6, Loss = 15.9407, Exploration Rate = 0.1000, Train Count = 23357\n",
      "Episode 2056: Reward = 591.00, Steps = 5, Loss = 14.1461, Exploration Rate = 0.1000, Train Count = 23362\n",
      "Episode 2057: Reward = 585.00, Steps = 7, Loss = 18.4143, Exploration Rate = 0.1000, Train Count = 23369\n",
      "Episode 2058: Reward = 594.00, Steps = 4, Loss = 10.9482, Exploration Rate = 0.1000, Train Count = 23373\n",
      "Episode 2059: Reward = 594.00, Steps = 4, Loss = 20.3584, Exploration Rate = 0.1000, Train Count = 23377\n",
      "Episode 2060: Reward = 597.00, Steps = 3, Loss = 21.7419, Exploration Rate = 0.1000, Train Count = 23380\n",
      "Episode 2061: Reward = 588.00, Steps = 6, Loss = 16.4938, Exploration Rate = 0.1000, Train Count = 23386\n",
      "Episode 2062: Reward = 597.00, Steps = 3, Loss = 13.7634, Exploration Rate = 0.1000, Train Count = 23389\n",
      "Episode 2063: Reward = 585.00, Steps = 7, Loss = 17.4491, Exploration Rate = 0.1000, Train Count = 23396\n",
      "Episode 2064: Reward = 582.00, Steps = 8, Loss = 13.4537, Exploration Rate = 0.1000, Train Count = 23404\n",
      "Episode 2065: Reward = 579.00, Steps = 9, Loss = 12.3659, Exploration Rate = 0.1000, Train Count = 23413\n",
      "Episode 2066: Reward = 597.00, Steps = 3, Loss = 15.1603, Exploration Rate = 0.1000, Train Count = 23416\n",
      "Episode 2067: Reward = 585.00, Steps = 7, Loss = 8.9862, Exploration Rate = 0.1000, Train Count = 23423\n",
      "Episode 2068: Reward = 582.00, Steps = 8, Loss = 9.9996, Exploration Rate = 0.1000, Train Count = 23431\n",
      "Episode 2069: Reward = 588.00, Steps = 6, Loss = 9.4038, Exploration Rate = 0.1000, Train Count = 23437\n",
      "Episode 2070: Reward = 597.00, Steps = 3, Loss = 11.1891, Exploration Rate = 0.1000, Train Count = 23440\n",
      "Episode 2071: Reward = 594.00, Steps = 4, Loss = 9.4779, Exploration Rate = 0.1000, Train Count = 23444\n",
      "Episode 2072: Reward = 597.00, Steps = 3, Loss = 7.2410, Exploration Rate = 0.1000, Train Count = 23447\n",
      "Episode 2073: Reward = 588.00, Steps = 6, Loss = 10.9579, Exploration Rate = 0.1000, Train Count = 23453\n",
      "Episode 2074: Reward = 540.00, Steps = 22, Loss = 9.8470, Exploration Rate = 0.1000, Train Count = 23475\n",
      "Episode 2075: Reward = 582.00, Steps = 8, Loss = 7.4958, Exploration Rate = 0.1000, Train Count = 23483\n",
      "Episode 2076: Reward = 579.00, Steps = 9, Loss = 10.4815, Exploration Rate = 0.1000, Train Count = 23492\n",
      "Episode 2077: Reward = 591.00, Steps = 5, Loss = 21.0902, Exploration Rate = 0.1000, Train Count = 23497\n",
      "Episode 2078: Reward = 591.00, Steps = 5, Loss = 7.2803, Exploration Rate = 0.1000, Train Count = 23502\n",
      "Episode 2079: Reward = 538.00, Steps = 7, Loss = 23.7817, Exploration Rate = 0.1000, Train Count = 23509\n",
      "Episode 2080: Reward = 594.00, Steps = 4, Loss = 30.0601, Exploration Rate = 0.1000, Train Count = 23513\n",
      "Episode 2081: Reward = 579.00, Steps = 9, Loss = 21.9395, Exploration Rate = 0.1000, Train Count = 23522\n",
      "Episode 2082: Reward = 588.00, Steps = 6, Loss = 15.6806, Exploration Rate = 0.1000, Train Count = 23528\n",
      "Episode 2083: Reward = 591.00, Steps = 5, Loss = 14.4607, Exploration Rate = 0.1000, Train Count = 23533\n",
      "Episode 2084: Reward = 588.00, Steps = 6, Loss = 12.7066, Exploration Rate = 0.1000, Train Count = 23539\n",
      "Episode 2085: Reward = 582.00, Steps = 8, Loss = 16.2429, Exploration Rate = 0.1000, Train Count = 23547\n",
      "Episode 2086: Reward = 591.00, Steps = 5, Loss = 13.0389, Exploration Rate = 0.1000, Train Count = 23552\n",
      "Episode 2087: Reward = 591.00, Steps = 5, Loss = 10.3009, Exploration Rate = 0.1000, Train Count = 23557\n",
      "Episode 2088: Reward = 594.00, Steps = 4, Loss = 14.0972, Exploration Rate = 0.1000, Train Count = 23561\n",
      "Episode 2089: Reward = 597.00, Steps = 3, Loss = 13.8521, Exploration Rate = 0.1000, Train Count = 23564\n",
      "Episode 2090: Reward = 582.00, Steps = 8, Loss = 10.3765, Exploration Rate = 0.1000, Train Count = 23572\n",
      "Episode 2091: Reward = 585.00, Steps = 7, Loss = 13.1619, Exploration Rate = 0.1000, Train Count = 23579\n",
      "Episode 2092: Reward = 570.00, Steps = 12, Loss = 11.3971, Exploration Rate = 0.1000, Train Count = 23591\n",
      "Episode 2093: Reward = 600.00, Steps = 2, Loss = 7.6789, Exploration Rate = 0.1000, Train Count = 23593\n",
      "Episode 2094: Reward = 582.00, Steps = 8, Loss = 8.2195, Exploration Rate = 0.1000, Train Count = 23601\n",
      "Episode 2095: Reward = 588.00, Steps = 6, Loss = 8.4563, Exploration Rate = 0.1000, Train Count = 23607\n",
      "Episode 2096: Reward = 600.00, Steps = 2, Loss = 10.0486, Exploration Rate = 0.1000, Train Count = 23609\n",
      "Episode 2097: Reward = 591.00, Steps = 5, Loss = 6.1944, Exploration Rate = 0.1000, Train Count = 23614\n",
      "Episode 2098: Reward = 558.00, Steps = 16, Loss = 13.0919, Exploration Rate = 0.1000, Train Count = 23630\n",
      "Episode 2099: Reward = 579.00, Steps = 9, Loss = 10.3679, Exploration Rate = 0.1000, Train Count = 23639\n",
      "Episode 2100: Reward = 531.00, Steps = 25, Loss = 25.4886, Exploration Rate = 0.1000, Train Count = 23664\n",
      "Episode 2101: Reward = 588.00, Steps = 6, Loss = 33.7027, Exploration Rate = 0.1000, Train Count = 23670\n",
      "Episode 2102: Reward = 532.00, Steps = 9, Loss = 24.0620, Exploration Rate = 0.1000, Train Count = 23679\n",
      "Episode 2103: Reward = 591.00, Steps = 5, Loss = 26.6710, Exploration Rate = 0.1000, Train Count = 23684\n",
      "Episode 2104: Reward = 564.00, Steps = 14, Loss = 22.4081, Exploration Rate = 0.1000, Train Count = 23698\n",
      "Episode 2105: Reward = 594.00, Steps = 4, Loss = 19.0836, Exploration Rate = 0.1000, Train Count = 23702\n",
      "Episode 2106: Reward = 588.00, Steps = 6, Loss = 15.9095, Exploration Rate = 0.1000, Train Count = 23708\n",
      "Episode 2107: Reward = 585.00, Steps = 7, Loss = 19.4208, Exploration Rate = 0.1000, Train Count = 23715\n",
      "Episode 2108: Reward = 597.00, Steps = 3, Loss = 17.1900, Exploration Rate = 0.1000, Train Count = 23718\n",
      "Episode 2109: Reward = 591.00, Steps = 5, Loss = 14.8907, Exploration Rate = 0.1000, Train Count = 23723\n",
      "Episode 2110: Reward = 582.00, Steps = 8, Loss = 15.3170, Exploration Rate = 0.1000, Train Count = 23731\n",
      "Episode 2111: Reward = 597.00, Steps = 3, Loss = 11.1342, Exploration Rate = 0.1000, Train Count = 23734\n",
      "Episode 2112: Reward = 579.00, Steps = 9, Loss = 11.8195, Exploration Rate = 0.1000, Train Count = 23743\n",
      "Episode 2113: Reward = 585.00, Steps = 7, Loss = 14.7706, Exploration Rate = 0.1000, Train Count = 23750\n",
      "Episode 2114: Reward = 591.00, Steps = 5, Loss = 10.0260, Exploration Rate = 0.1000, Train Count = 23755\n",
      "Episode 2115: Reward = 588.00, Steps = 6, Loss = 13.4732, Exploration Rate = 0.1000, Train Count = 23761\n",
      "Episode 2116: Reward = 579.00, Steps = 9, Loss = 15.7140, Exploration Rate = 0.1000, Train Count = 23770\n",
      "Episode 2117: Reward = 591.00, Steps = 5, Loss = 12.8632, Exploration Rate = 0.1000, Train Count = 23775\n",
      "Episode 2118: Reward = 594.00, Steps = 4, Loss = 11.8029, Exploration Rate = 0.1000, Train Count = 23779\n",
      "Episode 2119: Reward = 591.00, Steps = 5, Loss = 13.0567, Exploration Rate = 0.1000, Train Count = 23784\n",
      "Episode 2120: Reward = 591.00, Steps = 5, Loss = 11.7996, Exploration Rate = 0.1000, Train Count = 23789\n",
      "Episode 2121: Reward = 594.00, Steps = 4, Loss = 11.6238, Exploration Rate = 0.1000, Train Count = 23793\n",
      "Episode 2122: Reward = 573.00, Steps = 11, Loss = 44.4704, Exploration Rate = 0.1000, Train Count = 23804\n",
      "Episode 2123: Reward = 588.00, Steps = 6, Loss = 76.9636, Exploration Rate = 0.1000, Train Count = 23810\n",
      "Episode 2124: Reward = 594.00, Steps = 4, Loss = 60.5680, Exploration Rate = 0.1000, Train Count = 23814\n",
      "Episode 2125: Reward = 585.00, Steps = 7, Loss = 48.4980, Exploration Rate = 0.1000, Train Count = 23821\n",
      "Episode 2126: Reward = 588.00, Steps = 6, Loss = 43.7313, Exploration Rate = 0.1000, Train Count = 23827\n",
      "Episode 2127: Reward = 585.00, Steps = 7, Loss = 32.7995, Exploration Rate = 0.1000, Train Count = 23834\n",
      "Episode 2128: Reward = 588.00, Steps = 6, Loss = 30.7571, Exploration Rate = 0.1000, Train Count = 23840\n",
      "Episode 2129: Reward = 594.00, Steps = 4, Loss = 22.3506, Exploration Rate = 0.1000, Train Count = 23844\n",
      "Episode 2130: Reward = 576.00, Steps = 10, Loss = 22.3025, Exploration Rate = 0.1000, Train Count = 23854\n",
      "Episode 2131: Reward = 561.00, Steps = 15, Loss = 21.3092, Exploration Rate = 0.1000, Train Count = 23869\n",
      "Episode 2132: Reward = 594.00, Steps = 4, Loss = 14.1082, Exploration Rate = 0.1000, Train Count = 23873\n",
      "Episode 2133: Reward = 585.00, Steps = 7, Loss = 10.6977, Exploration Rate = 0.1000, Train Count = 23880\n",
      "Episode 2134: Reward = 591.00, Steps = 5, Loss = 10.3077, Exploration Rate = 0.1000, Train Count = 23885\n",
      "Episode 2135: Reward = 585.00, Steps = 7, Loss = 7.9072, Exploration Rate = 0.1000, Train Count = 23892\n",
      "Episode 2136: Reward = 591.00, Steps = 5, Loss = 8.9202, Exploration Rate = 0.1000, Train Count = 23897\n",
      "Episode 2137: Reward = 582.00, Steps = 8, Loss = 15.8367, Exploration Rate = 0.1000, Train Count = 23905\n",
      "Episode 2138: Reward = 517.00, Steps = 14, Loss = 16.0969, Exploration Rate = 0.1000, Train Count = 23919\n",
      "Episode 2139: Reward = 591.00, Steps = 5, Loss = 12.1398, Exploration Rate = 0.1000, Train Count = 23924\n",
      "Episode 2140: Reward = 470.00, Steps = 14, Loss = 13.8635, Exploration Rate = 0.1000, Train Count = 23938\n",
      "Episode 2141: Reward = 585.00, Steps = 7, Loss = 16.3091, Exploration Rate = 0.1000, Train Count = 23945\n",
      "Episode 2142: Reward = 582.00, Steps = 8, Loss = 13.5106, Exploration Rate = 0.1000, Train Count = 23953\n",
      "Episode 2143: Reward = 576.00, Steps = 10, Loss = 13.9766, Exploration Rate = 0.1000, Train Count = 23963\n",
      "Episode 2144: Reward = 597.00, Steps = 3, Loss = 10.7209, Exploration Rate = 0.1000, Train Count = 23966\n",
      "Episode 2145: Reward = 591.00, Steps = 5, Loss = 14.3198, Exploration Rate = 0.1000, Train Count = 23971\n",
      "Episode 2146: Reward = 588.00, Steps = 6, Loss = 8.2464, Exploration Rate = 0.1000, Train Count = 23977\n",
      "Episode 2147: Reward = 597.00, Steps = 3, Loss = 14.3910, Exploration Rate = 0.1000, Train Count = 23980\n",
      "Episode 2148: Reward = 543.00, Steps = 21, Loss = 12.9322, Exploration Rate = 0.1000, Train Count = 24001\n",
      "Episode 2149: Reward = 579.00, Steps = 9, Loss = 11.8400, Exploration Rate = 0.1000, Train Count = 24010\n",
      "Episode 2150: Reward = 582.00, Steps = 8, Loss = 8.8696, Exploration Rate = 0.1000, Train Count = 24018\n",
      "Episode 2151: Reward = 597.00, Steps = 3, Loss = 12.1785, Exploration Rate = 0.1000, Train Count = 24021\n",
      "Episode 2152: Reward = 597.00, Steps = 3, Loss = 11.2381, Exploration Rate = 0.1000, Train Count = 24024\n",
      "Episode 2153: Reward = 588.00, Steps = 6, Loss = 9.8421, Exploration Rate = 0.1000, Train Count = 24030\n",
      "Episode 2154: Reward = 594.00, Steps = 4, Loss = 10.6731, Exploration Rate = 0.1000, Train Count = 24034\n",
      "Episode 2155: Reward = 591.00, Steps = 5, Loss = 11.1617, Exploration Rate = 0.1000, Train Count = 24039\n",
      "Episode 2156: Reward = 585.00, Steps = 7, Loss = 10.1574, Exploration Rate = 0.1000, Train Count = 24046\n",
      "Episode 2157: Reward = 597.00, Steps = 3, Loss = 12.2543, Exploration Rate = 0.1000, Train Count = 24049\n",
      "Episode 2158: Reward = 591.00, Steps = 5, Loss = 6.3189, Exploration Rate = 0.1000, Train Count = 24054\n",
      "Episode 2159: Reward = 588.00, Steps = 6, Loss = 9.9115, Exploration Rate = 0.1000, Train Count = 24060\n",
      "Episode 2160: Reward = 591.00, Steps = 5, Loss = 10.4929, Exploration Rate = 0.1000, Train Count = 24065\n",
      "Episode 2161: Reward = 597.00, Steps = 3, Loss = 7.1933, Exploration Rate = 0.1000, Train Count = 24068\n",
      "Episode 2162: Reward = 594.00, Steps = 4, Loss = 6.6306, Exploration Rate = 0.1000, Train Count = 24072\n",
      "Episode 2163: Reward = 585.00, Steps = 7, Loss = 14.1676, Exploration Rate = 0.1000, Train Count = 24079\n",
      "Episode 2164: Reward = 576.00, Steps = 10, Loss = 12.5288, Exploration Rate = 0.1000, Train Count = 24089\n",
      "Episode 2165: Reward = 532.00, Steps = 9, Loss = 12.1102, Exploration Rate = 0.1000, Train Count = 24098\n",
      "Episode 2166: Reward = 588.00, Steps = 6, Loss = 8.0504, Exploration Rate = 0.1000, Train Count = 24104\n",
      "Episode 2167: Reward = 594.00, Steps = 4, Loss = 29.1413, Exploration Rate = 0.1000, Train Count = 24108\n",
      "Episode 2168: Reward = 588.00, Steps = 6, Loss = 19.5345, Exploration Rate = 0.1000, Train Count = 24114\n",
      "Episode 2169: Reward = 547.00, Steps = 4, Loss = 16.9172, Exploration Rate = 0.1000, Train Count = 24118\n",
      "Episode 2170: Reward = 591.00, Steps = 5, Loss = 15.4865, Exploration Rate = 0.1000, Train Count = 24123\n",
      "Episode 2171: Reward = 591.00, Steps = 5, Loss = 13.2836, Exploration Rate = 0.1000, Train Count = 24128\n",
      "Episode 2172: Reward = 585.00, Steps = 7, Loss = 12.3980, Exploration Rate = 0.1000, Train Count = 24135\n",
      "Episode 2173: Reward = 594.00, Steps = 4, Loss = 11.2390, Exploration Rate = 0.1000, Train Count = 24139\n",
      "Episode 2174: Reward = 582.00, Steps = 8, Loss = 8.4689, Exploration Rate = 0.1000, Train Count = 24147\n",
      "Episode 2175: Reward = 570.00, Steps = 12, Loss = 12.2999, Exploration Rate = 0.1000, Train Count = 24159\n",
      "Episode 2176: Reward = 597.00, Steps = 3, Loss = 19.7768, Exploration Rate = 0.1000, Train Count = 24162\n",
      "Episode 2177: Reward = 588.00, Steps = 6, Loss = 14.6194, Exploration Rate = 0.1000, Train Count = 24168\n",
      "Episode 2178: Reward = 591.00, Steps = 5, Loss = 10.1077, Exploration Rate = 0.1000, Train Count = 24173\n",
      "Episode 2179: Reward = 591.00, Steps = 5, Loss = 16.0893, Exploration Rate = 0.1000, Train Count = 24178\n",
      "Episode 2180: Reward = 600.00, Steps = 2, Loss = 7.4372, Exploration Rate = 0.1000, Train Count = 24180\n",
      "Episode 2181: Reward = 585.00, Steps = 7, Loss = 10.5853, Exploration Rate = 0.1000, Train Count = 24187\n",
      "Episode 2182: Reward = 585.00, Steps = 7, Loss = 28.0533, Exploration Rate = 0.1000, Train Count = 24194\n",
      "Episode 2183: Reward = 600.00, Steps = 2, Loss = 9.1836, Exploration Rate = 0.1000, Train Count = 24196\n",
      "Episode 2184: Reward = 597.00, Steps = 3, Loss = 9.1805, Exploration Rate = 0.1000, Train Count = 24199\n",
      "Episode 2185: Reward = 573.00, Steps = 11, Loss = 12.8349, Exploration Rate = 0.1000, Train Count = 24210\n",
      "Episode 2186: Reward = 591.00, Steps = 5, Loss = 14.4169, Exploration Rate = 0.1000, Train Count = 24215\n",
      "Episode 2187: Reward = 576.00, Steps = 10, Loss = 15.8390, Exploration Rate = 0.1000, Train Count = 24225\n",
      "Episode 2188: Reward = 594.00, Steps = 4, Loss = 10.0748, Exploration Rate = 0.1000, Train Count = 24229\n",
      "Episode 2189: Reward = 591.00, Steps = 5, Loss = 13.0023, Exploration Rate = 0.1000, Train Count = 24234\n",
      "Episode 2190: Reward = 585.00, Steps = 7, Loss = 12.0983, Exploration Rate = 0.1000, Train Count = 24241\n",
      "Episode 2191: Reward = 588.00, Steps = 6, Loss = 9.4837, Exploration Rate = 0.1000, Train Count = 24247\n",
      "Episode 2192: Reward = 591.00, Steps = 5, Loss = 10.3317, Exploration Rate = 0.1000, Train Count = 24252\n",
      "Episode 2193: Reward = 585.00, Steps = 7, Loss = 9.2326, Exploration Rate = 0.1000, Train Count = 24259\n",
      "Episode 2194: Reward = 597.00, Steps = 3, Loss = 5.9779, Exploration Rate = 0.1000, Train Count = 24262\n",
      "Episode 2195: Reward = 594.00, Steps = 4, Loss = 12.2426, Exploration Rate = 0.1000, Train Count = 24266\n",
      "Episode 2196: Reward = 576.00, Steps = 10, Loss = 13.2521, Exploration Rate = 0.1000, Train Count = 24276\n",
      "Episode 2197: Reward = 576.00, Steps = 10, Loss = 10.9386, Exploration Rate = 0.1000, Train Count = 24286\n",
      "Episode 2198: Reward = 591.00, Steps = 5, Loss = 7.6559, Exploration Rate = 0.1000, Train Count = 24291\n",
      "Episode 2199: Reward = 591.00, Steps = 5, Loss = 7.5655, Exploration Rate = 0.1000, Train Count = 24296\n",
      "Episode 2200: Reward = 561.00, Steps = 15, Loss = 47.3647, Exploration Rate = 0.1000, Train Count = 24311\n",
      "Episode 2201: Reward = 588.00, Steps = 6, Loss = 37.3037, Exploration Rate = 0.1000, Train Count = 24317\n",
      "Episode 2202: Reward = 597.00, Steps = 3, Loss = 27.7687, Exploration Rate = 0.1000, Train Count = 24320\n",
      "Episode 2203: Reward = 597.00, Steps = 3, Loss = 25.7195, Exploration Rate = 0.1000, Train Count = 24323\n",
      "Episode 2204: Reward = 549.00, Steps = 19, Loss = 25.6643, Exploration Rate = 0.1000, Train Count = 24342\n",
      "Episode 2205: Reward = 585.00, Steps = 7, Loss = 14.7616, Exploration Rate = 0.1000, Train Count = 24349\n",
      "Episode 2206: Reward = 576.00, Steps = 10, Loss = 14.2964, Exploration Rate = 0.1000, Train Count = 24359\n",
      "Episode 2207: Reward = 591.00, Steps = 5, Loss = 10.8924, Exploration Rate = 0.1000, Train Count = 24364\n",
      "Episode 2208: Reward = 535.00, Steps = 8, Loss = 11.8547, Exploration Rate = 0.1000, Train Count = 24372\n",
      "Episode 2209: Reward = 597.00, Steps = 3, Loss = 7.8491, Exploration Rate = 0.1000, Train Count = 24375\n",
      "Episode 2210: Reward = 591.00, Steps = 5, Loss = 7.3053, Exploration Rate = 0.1000, Train Count = 24380\n",
      "Episode 2211: Reward = 564.00, Steps = 14, Loss = 12.2759, Exploration Rate = 0.1000, Train Count = 24394\n",
      "Episode 2212: Reward = 585.00, Steps = 7, Loss = 6.0955, Exploration Rate = 0.1000, Train Count = 24401\n",
      "Episode 2213: Reward = 591.00, Steps = 5, Loss = 6.6316, Exploration Rate = 0.1000, Train Count = 24406\n",
      "Episode 2214: Reward = 576.00, Steps = 10, Loss = 8.0682, Exploration Rate = 0.1000, Train Count = 24416\n",
      "Episode 2215: Reward = 579.00, Steps = 9, Loss = 6.0388, Exploration Rate = 0.1000, Train Count = 24425\n",
      "Episode 2216: Reward = 600.00, Steps = 2, Loss = 6.5760, Exploration Rate = 0.1000, Train Count = 24427\n",
      "Episode 2217: Reward = 588.00, Steps = 6, Loss = 5.9900, Exploration Rate = 0.1000, Train Count = 24433\n",
      "Episode 2218: Reward = 597.00, Steps = 3, Loss = 5.1544, Exploration Rate = 0.1000, Train Count = 24436\n",
      "Episode 2219: Reward = 579.00, Steps = 9, Loss = 4.6594, Exploration Rate = 0.1000, Train Count = 24445\n",
      "Episode 2220: Reward = 579.00, Steps = 9, Loss = 4.8929, Exploration Rate = 0.1000, Train Count = 24454\n",
      "Episode 2221: Reward = 585.00, Steps = 7, Loss = 5.8362, Exploration Rate = 0.1000, Train Count = 24461\n",
      "Episode 2222: Reward = 594.00, Steps = 4, Loss = 4.1119, Exploration Rate = 0.1000, Train Count = 24465\n",
      "Episode 2223: Reward = 594.00, Steps = 4, Loss = 9.0981, Exploration Rate = 0.1000, Train Count = 24469\n",
      "Episode 2224: Reward = 588.00, Steps = 6, Loss = 5.3400, Exploration Rate = 0.1000, Train Count = 24475\n",
      "Episode 2225: Reward = 538.00, Steps = 7, Loss = 5.5805, Exploration Rate = 0.1000, Train Count = 24482\n",
      "Episode 2226: Reward = 541.00, Steps = 6, Loss = 9.2313, Exploration Rate = 0.1000, Train Count = 24488\n",
      "Episode 2227: Reward = 582.00, Steps = 8, Loss = 6.2956, Exploration Rate = 0.1000, Train Count = 24496\n",
      "Episode 2228: Reward = 597.00, Steps = 3, Loss = 9.1449, Exploration Rate = 0.1000, Train Count = 24499\n",
      "Episode 2229: Reward = 594.00, Steps = 4, Loss = 16.6229, Exploration Rate = 0.1000, Train Count = 24503\n",
      "Episode 2230: Reward = 594.00, Steps = 4, Loss = 9.0415, Exploration Rate = 0.1000, Train Count = 24507\n",
      "Episode 2231: Reward = 591.00, Steps = 5, Loss = 8.2833, Exploration Rate = 0.1000, Train Count = 24512\n",
      "Episode 2232: Reward = 597.00, Steps = 3, Loss = 6.2610, Exploration Rate = 0.1000, Train Count = 24515\n",
      "Episode 2233: Reward = 582.00, Steps = 8, Loss = 7.4880, Exploration Rate = 0.1000, Train Count = 24523\n",
      "Episode 2234: Reward = 579.00, Steps = 9, Loss = 7.4520, Exploration Rate = 0.1000, Train Count = 24532\n",
      "Episode 2235: Reward = 576.00, Steps = 10, Loss = 6.2535, Exploration Rate = 0.1000, Train Count = 24542\n",
      "Episode 2236: Reward = 588.00, Steps = 6, Loss = 10.1478, Exploration Rate = 0.1000, Train Count = 24548\n",
      "Episode 2237: Reward = 582.00, Steps = 8, Loss = 5.9084, Exploration Rate = 0.1000, Train Count = 24556\n",
      "Episode 2238: Reward = 585.00, Steps = 7, Loss = 4.6535, Exploration Rate = 0.1000, Train Count = 24563\n",
      "Episode 2239: Reward = 588.00, Steps = 6, Loss = 8.3195, Exploration Rate = 0.1000, Train Count = 24569\n",
      "Episode 2240: Reward = 585.00, Steps = 7, Loss = 7.4655, Exploration Rate = 0.1000, Train Count = 24576\n",
      "Episode 2241: Reward = 579.00, Steps = 9, Loss = 5.6337, Exploration Rate = 0.1000, Train Count = 24585\n",
      "Episode 2242: Reward = 588.00, Steps = 6, Loss = 8.9966, Exploration Rate = 0.1000, Train Count = 24591\n",
      "Episode 2243: Reward = 597.00, Steps = 3, Loss = 8.0827, Exploration Rate = 0.1000, Train Count = 24594\n",
      "Episode 2244: Reward = 585.00, Steps = 7, Loss = 8.3309, Exploration Rate = 0.1000, Train Count = 24601\n",
      "Episode 2245: Reward = 597.00, Steps = 3, Loss = 11.3505, Exploration Rate = 0.1000, Train Count = 24604\n",
      "Episode 2246: Reward = 588.00, Steps = 6, Loss = 8.9049, Exploration Rate = 0.1000, Train Count = 24610\n",
      "Episode 2247: Reward = 585.00, Steps = 7, Loss = 11.6741, Exploration Rate = 0.1000, Train Count = 24617\n",
      "Episode 2248: Reward = 588.00, Steps = 6, Loss = 7.1496, Exploration Rate = 0.1000, Train Count = 24623\n",
      "Episode 2249: Reward = 591.00, Steps = 5, Loss = 7.7786, Exploration Rate = 0.1000, Train Count = 24628\n",
      "Episode 2250: Reward = 585.00, Steps = 7, Loss = 11.3701, Exploration Rate = 0.1000, Train Count = 24635\n",
      "Episode 2251: Reward = 591.00, Steps = 5, Loss = 17.4558, Exploration Rate = 0.1000, Train Count = 24640\n",
      "Episode 2252: Reward = 579.00, Steps = 9, Loss = 9.8165, Exploration Rate = 0.1000, Train Count = 24649\n",
      "Episode 2253: Reward = 451.00, Steps = 36, Loss = 9.2085, Exploration Rate = 0.1000, Train Count = 24685\n",
      "Episode 2254: Reward = 588.00, Steps = 6, Loss = 7.7538, Exploration Rate = 0.1000, Train Count = 24691\n",
      "Episode 2255: Reward = 591.00, Steps = 5, Loss = 4.2356, Exploration Rate = 0.1000, Train Count = 24696\n",
      "Episode 2256: Reward = 597.00, Steps = 3, Loss = 7.7116, Exploration Rate = 0.1000, Train Count = 24699\n",
      "Episode 2257: Reward = 538.00, Steps = 7, Loss = 7.0926, Exploration Rate = 0.1000, Train Count = 24706\n",
      "Episode 2258: Reward = 558.00, Steps = 16, Loss = 12.7485, Exploration Rate = 0.1000, Train Count = 24722\n",
      "Episode 2259: Reward = 597.00, Steps = 3, Loss = 15.6017, Exploration Rate = 0.1000, Train Count = 24725\n",
      "Episode 2260: Reward = 591.00, Steps = 5, Loss = 8.2834, Exploration Rate = 0.1000, Train Count = 24730\n",
      "Episode 2261: Reward = 585.00, Steps = 7, Loss = 5.0221, Exploration Rate = 0.1000, Train Count = 24737\n",
      "Episode 2262: Reward = 585.00, Steps = 7, Loss = 7.2454, Exploration Rate = 0.1000, Train Count = 24744\n",
      "Episode 2263: Reward = 597.00, Steps = 3, Loss = 4.3892, Exploration Rate = 0.1000, Train Count = 24747\n",
      "Episode 2264: Reward = 579.00, Steps = 9, Loss = 4.6907, Exploration Rate = 0.1000, Train Count = 24756\n",
      "Episode 2265: Reward = 594.00, Steps = 4, Loss = 6.3947, Exploration Rate = 0.1000, Train Count = 24760\n",
      "Episode 2266: Reward = 541.00, Steps = 6, Loss = 11.5669, Exploration Rate = 0.1000, Train Count = 24766\n",
      "Episode 2267: Reward = 585.00, Steps = 7, Loss = 13.0012, Exploration Rate = 0.1000, Train Count = 24773\n",
      "Episode 2268: Reward = 585.00, Steps = 7, Loss = 14.2268, Exploration Rate = 0.1000, Train Count = 24780\n",
      "Episode 2269: Reward = 582.00, Steps = 8, Loss = 11.1293, Exploration Rate = 0.1000, Train Count = 24788\n",
      "Episode 2270: Reward = 591.00, Steps = 5, Loss = 5.2282, Exploration Rate = 0.1000, Train Count = 24793\n",
      "Episode 2271: Reward = 594.00, Steps = 4, Loss = 7.2343, Exploration Rate = 0.1000, Train Count = 24797\n",
      "Episode 2272: Reward = 591.00, Steps = 5, Loss = 35.1634, Exploration Rate = 0.1000, Train Count = 24802\n",
      "Episode 2273: Reward = 585.00, Steps = 7, Loss = 44.7993, Exploration Rate = 0.1000, Train Count = 24809\n",
      "Episode 2274: Reward = 579.00, Steps = 9, Loss = 38.1759, Exploration Rate = 0.1000, Train Count = 24818\n",
      "Episode 2275: Reward = 585.00, Steps = 7, Loss = 25.1388, Exploration Rate = 0.1000, Train Count = 24825\n",
      "Episode 2276: Reward = 579.00, Steps = 9, Loss = 25.9331, Exploration Rate = 0.1000, Train Count = 24834\n",
      "Episode 2277: Reward = 594.00, Steps = 4, Loss = 27.7733, Exploration Rate = 0.1000, Train Count = 24838\n",
      "Episode 2278: Reward = 582.00, Steps = 8, Loss = 26.4516, Exploration Rate = 0.1000, Train Count = 24846\n",
      "Episode 2279: Reward = 594.00, Steps = 4, Loss = 19.7201, Exploration Rate = 0.1000, Train Count = 24850\n",
      "Episode 2280: Reward = 541.00, Steps = 6, Loss = 18.2401, Exploration Rate = 0.1000, Train Count = 24856\n",
      "Episode 2281: Reward = 579.00, Steps = 9, Loss = 21.1776, Exploration Rate = 0.1000, Train Count = 24865\n",
      "Episode 2282: Reward = 594.00, Steps = 4, Loss = 18.7062, Exploration Rate = 0.1000, Train Count = 24869\n",
      "Episode 2283: Reward = 597.00, Steps = 3, Loss = 19.1393, Exploration Rate = 0.1000, Train Count = 24872\n",
      "Episode 2284: Reward = 591.00, Steps = 5, Loss = 19.4397, Exploration Rate = 0.1000, Train Count = 24877\n",
      "Episode 2285: Reward = 597.00, Steps = 3, Loss = 16.8115, Exploration Rate = 0.1000, Train Count = 24880\n",
      "Episode 2286: Reward = 585.00, Steps = 7, Loss = 23.3035, Exploration Rate = 0.1000, Train Count = 24887\n",
      "Episode 2287: Reward = 594.00, Steps = 4, Loss = 17.6487, Exploration Rate = 0.1000, Train Count = 24891\n",
      "Episode 2288: Reward = 591.00, Steps = 5, Loss = 16.5247, Exploration Rate = 0.1000, Train Count = 24896\n",
      "Episode 2289: Reward = 582.00, Steps = 8, Loss = 13.0534, Exploration Rate = 0.1000, Train Count = 24904\n",
      "Episode 2290: Reward = 570.00, Steps = 12, Loss = 11.8988, Exploration Rate = 0.1000, Train Count = 24916\n",
      "Episode 2291: Reward = 597.00, Steps = 3, Loss = 12.3343, Exploration Rate = 0.1000, Train Count = 24919\n",
      "Episode 2292: Reward = 576.00, Steps = 10, Loss = 16.6787, Exploration Rate = 0.1000, Train Count = 24929\n",
      "Episode 2293: Reward = 585.00, Steps = 7, Loss = 19.4690, Exploration Rate = 0.1000, Train Count = 24936\n",
      "Episode 2294: Reward = 591.00, Steps = 5, Loss = 18.8293, Exploration Rate = 0.1000, Train Count = 24941\n",
      "Episode 2295: Reward = 594.00, Steps = 4, Loss = 18.2463, Exploration Rate = 0.1000, Train Count = 24945\n",
      "Episode 2296: Reward = 520.00, Steps = 13, Loss = 15.9745, Exploration Rate = 0.1000, Train Count = 24958\n",
      "Episode 2297: Reward = 582.00, Steps = 8, Loss = 11.4157, Exploration Rate = 0.1000, Train Count = 24966\n",
      "Episode 2298: Reward = 591.00, Steps = 5, Loss = 7.5111, Exploration Rate = 0.1000, Train Count = 24971\n",
      "Episode 2299: Reward = 582.00, Steps = 8, Loss = 6.3215, Exploration Rate = 0.1000, Train Count = 24979\n",
      "Episode 2300: Reward = 576.00, Steps = 10, Loss = 8.1553, Exploration Rate = 0.1000, Train Count = 24989\n",
      "Episode 2301: Reward = 588.00, Steps = 6, Loss = 8.7581, Exploration Rate = 0.1000, Train Count = 24995\n",
      "Episode 2302: Reward = 564.00, Steps = 14, Loss = 8.8859, Exploration Rate = 0.1000, Train Count = 25009\n",
      "Episode 2303: Reward = 594.00, Steps = 4, Loss = 10.3213, Exploration Rate = 0.1000, Train Count = 25013\n",
      "Episode 2304: Reward = 582.00, Steps = 8, Loss = 8.3332, Exploration Rate = 0.1000, Train Count = 25021\n",
      "Episode 2305: Reward = 585.00, Steps = 7, Loss = 8.5005, Exploration Rate = 0.1000, Train Count = 25028\n",
      "Episode 2306: Reward = 585.00, Steps = 7, Loss = 6.8389, Exploration Rate = 0.1000, Train Count = 25035\n",
      "Episode 2307: Reward = 540.00, Steps = 22, Loss = 9.9016, Exploration Rate = 0.1000, Train Count = 25057\n",
      "Episode 2308: Reward = 588.00, Steps = 6, Loss = 7.0219, Exploration Rate = 0.1000, Train Count = 25063\n",
      "Episode 2309: Reward = 582.00, Steps = 8, Loss = 7.5595, Exploration Rate = 0.1000, Train Count = 25071\n",
      "Episode 2310: Reward = 582.00, Steps = 8, Loss = 4.8788, Exploration Rate = 0.1000, Train Count = 25079\n",
      "Episode 2311: Reward = 585.00, Steps = 7, Loss = 5.4437, Exploration Rate = 0.1000, Train Count = 25086\n",
      "Episode 2312: Reward = 600.00, Steps = 2, Loss = 5.6803, Exploration Rate = 0.1000, Train Count = 25088\n",
      "Episode 2313: Reward = 579.00, Steps = 9, Loss = 4.4954, Exploration Rate = 0.1000, Train Count = 25097\n",
      "Episode 2314: Reward = 535.00, Steps = 8, Loss = 5.6080, Exploration Rate = 0.1000, Train Count = 25105\n",
      "Episode 2315: Reward = 591.00, Steps = 5, Loss = 7.5474, Exploration Rate = 0.1000, Train Count = 25110\n",
      "Episode 2316: Reward = 585.00, Steps = 7, Loss = 11.3625, Exploration Rate = 0.1000, Train Count = 25117\n",
      "Episode 2317: Reward = 585.00, Steps = 7, Loss = 7.8990, Exploration Rate = 0.1000, Train Count = 25124\n",
      "Episode 2318: Reward = 597.00, Steps = 3, Loss = 6.4544, Exploration Rate = 0.1000, Train Count = 25127\n",
      "Episode 2319: Reward = 588.00, Steps = 6, Loss = 5.9906, Exploration Rate = 0.1000, Train Count = 25133\n",
      "Episode 2320: Reward = 570.00, Steps = 12, Loss = 6.4929, Exploration Rate = 0.1000, Train Count = 25145\n",
      "Episode 2321: Reward = 585.00, Steps = 7, Loss = 6.9438, Exploration Rate = 0.1000, Train Count = 25152\n",
      "Episode 2322: Reward = 585.00, Steps = 7, Loss = 12.2714, Exploration Rate = 0.1000, Train Count = 25159\n",
      "Episode 2323: Reward = 591.00, Steps = 5, Loss = 12.5617, Exploration Rate = 0.1000, Train Count = 25164\n",
      "Episode 2324: Reward = 585.00, Steps = 7, Loss = 11.9421, Exploration Rate = 0.1000, Train Count = 25171\n",
      "Episode 2325: Reward = 573.00, Steps = 11, Loss = 11.4169, Exploration Rate = 0.1000, Train Count = 25182\n",
      "Episode 2326: Reward = 579.00, Steps = 9, Loss = 9.3590, Exploration Rate = 0.1000, Train Count = 25191\n",
      "Episode 2327: Reward = 588.00, Steps = 6, Loss = 8.8796, Exploration Rate = 0.1000, Train Count = 25197\n",
      "Episode 2328: Reward = 591.00, Steps = 5, Loss = 7.6068, Exploration Rate = 0.1000, Train Count = 25202\n",
      "Episode 2329: Reward = 594.00, Steps = 4, Loss = 14.3992, Exploration Rate = 0.1000, Train Count = 25206\n",
      "Episode 2330: Reward = 588.00, Steps = 6, Loss = 8.6347, Exploration Rate = 0.1000, Train Count = 25212\n",
      "Episode 2331: Reward = 597.00, Steps = 3, Loss = 10.5982, Exploration Rate = 0.1000, Train Count = 25215\n",
      "Episode 2332: Reward = 544.00, Steps = 5, Loss = 14.4373, Exploration Rate = 0.1000, Train Count = 25220\n",
      "Episode 2333: Reward = 585.00, Steps = 7, Loss = 8.1766, Exploration Rate = 0.1000, Train Count = 25227\n",
      "Episode 2334: Reward = 391.00, Steps = 9, Loss = 31.6412, Exploration Rate = 0.1000, Train Count = 25236\n",
      "Episode 2335: Reward = 594.00, Steps = 4, Loss = 19.8484, Exploration Rate = 0.1000, Train Count = 25240\n",
      "Episode 2336: Reward = 594.00, Steps = 4, Loss = 16.3966, Exploration Rate = 0.1000, Train Count = 25244\n",
      "Episode 2337: Reward = 591.00, Steps = 5, Loss = 17.8423, Exploration Rate = 0.1000, Train Count = 25249\n",
      "Episode 2338: Reward = 591.00, Steps = 5, Loss = 16.0798, Exploration Rate = 0.1000, Train Count = 25254\n",
      "Episode 2339: Reward = 591.00, Steps = 5, Loss = 12.0736, Exploration Rate = 0.1000, Train Count = 25259\n",
      "Episode 2340: Reward = 585.00, Steps = 7, Loss = 12.6685, Exploration Rate = 0.1000, Train Count = 25266\n",
      "Episode 2341: Reward = 594.00, Steps = 4, Loss = 15.9818, Exploration Rate = 0.1000, Train Count = 25270\n",
      "Episode 2342: Reward = 547.00, Steps = 4, Loss = 17.1093, Exploration Rate = 0.1000, Train Count = 25274\n",
      "Episode 2343: Reward = 594.00, Steps = 4, Loss = 8.6573, Exploration Rate = 0.1000, Train Count = 25278\n",
      "Episode 2344: Reward = 570.00, Steps = 12, Loss = 10.2948, Exploration Rate = 0.1000, Train Count = 25290\n",
      "Episode 2345: Reward = 588.00, Steps = 6, Loss = 8.6323, Exploration Rate = 0.1000, Train Count = 25296\n",
      "Episode 2346: Reward = 597.00, Steps = 3, Loss = 14.9347, Exploration Rate = 0.1000, Train Count = 25299\n",
      "Episode 2347: Reward = 591.00, Steps = 5, Loss = 50.8090, Exploration Rate = 0.1000, Train Count = 25304\n",
      "Episode 2348: Reward = 588.00, Steps = 6, Loss = 50.1662, Exploration Rate = 0.1000, Train Count = 25310\n",
      "Episode 2349: Reward = 529.00, Steps = 10, Loss = 43.2767, Exploration Rate = 0.1000, Train Count = 25320\n",
      "Episode 2350: Reward = 570.00, Steps = 12, Loss = 28.8536, Exploration Rate = 0.1000, Train Count = 25332\n",
      "Episode 2351: Reward = 591.00, Steps = 5, Loss = 20.9785, Exploration Rate = 0.1000, Train Count = 25337\n",
      "Episode 2352: Reward = 591.00, Steps = 5, Loss = 21.8946, Exploration Rate = 0.1000, Train Count = 25342\n",
      "Episode 2353: Reward = 591.00, Steps = 5, Loss = 19.2556, Exploration Rate = 0.1000, Train Count = 25347\n",
      "Episode 2354: Reward = 594.00, Steps = 4, Loss = 18.4884, Exploration Rate = 0.1000, Train Count = 25351\n",
      "Episode 2355: Reward = 585.00, Steps = 7, Loss = 12.9995, Exploration Rate = 0.1000, Train Count = 25358\n",
      "Episode 2356: Reward = 588.00, Steps = 6, Loss = 13.8266, Exploration Rate = 0.1000, Train Count = 25364\n",
      "Episode 2357: Reward = 585.00, Steps = 7, Loss = 12.4621, Exploration Rate = 0.1000, Train Count = 25371\n",
      "Episode 2358: Reward = 588.00, Steps = 6, Loss = 16.2332, Exploration Rate = 0.1000, Train Count = 25377\n",
      "Episode 2359: Reward = 582.00, Steps = 8, Loss = 10.8268, Exploration Rate = 0.1000, Train Count = 25385\n",
      "Episode 2360: Reward = 544.00, Steps = 5, Loss = 9.2039, Exploration Rate = 0.1000, Train Count = 25390\n",
      "Episode 2361: Reward = 591.00, Steps = 5, Loss = 15.3163, Exploration Rate = 0.1000, Train Count = 25395\n",
      "Episode 2362: Reward = 597.00, Steps = 3, Loss = 20.7492, Exploration Rate = 0.1000, Train Count = 25398\n",
      "Episode 2363: Reward = 591.00, Steps = 5, Loss = 7.9245, Exploration Rate = 0.1000, Train Count = 25403\n",
      "Episode 2364: Reward = 597.00, Steps = 3, Loss = 34.0457, Exploration Rate = 0.1000, Train Count = 25406\n",
      "Episode 2365: Reward = 600.00, Steps = 2, Loss = 33.2930, Exploration Rate = 0.1000, Train Count = 25408\n",
      "Episode 2366: Reward = 582.00, Steps = 8, Loss = 16.5818, Exploration Rate = 0.1000, Train Count = 25416\n",
      "Episode 2367: Reward = 597.00, Steps = 3, Loss = 8.5183, Exploration Rate = 0.1000, Train Count = 25419\n",
      "Episode 2368: Reward = 570.00, Steps = 12, Loss = 18.8216, Exploration Rate = 0.1000, Train Count = 25431\n",
      "Episode 2369: Reward = 576.00, Steps = 10, Loss = 14.6421, Exploration Rate = 0.1000, Train Count = 25441\n",
      "Episode 2370: Reward = 588.00, Steps = 6, Loss = 13.5055, Exploration Rate = 0.1000, Train Count = 25447\n",
      "Episode 2371: Reward = 591.00, Steps = 5, Loss = 12.0344, Exploration Rate = 0.1000, Train Count = 25452\n",
      "Episode 2372: Reward = 585.00, Steps = 7, Loss = 10.1322, Exploration Rate = 0.1000, Train Count = 25459\n",
      "Episode 2373: Reward = 594.00, Steps = 4, Loss = 6.6529, Exploration Rate = 0.1000, Train Count = 25463\n",
      "Episode 2374: Reward = 588.00, Steps = 6, Loss = 9.1524, Exploration Rate = 0.1000, Train Count = 25469\n",
      "Episode 2375: Reward = 594.00, Steps = 4, Loss = 10.1508, Exploration Rate = 0.1000, Train Count = 25473\n",
      "Episode 2376: Reward = 585.00, Steps = 7, Loss = 6.8191, Exploration Rate = 0.1000, Train Count = 25480\n",
      "Episode 2377: Reward = 588.00, Steps = 6, Loss = 5.8900, Exploration Rate = 0.1000, Train Count = 25486\n",
      "Episode 2378: Reward = 588.00, Steps = 6, Loss = 5.4222, Exploration Rate = 0.1000, Train Count = 25492\n",
      "Episode 2379: Reward = 570.00, Steps = 12, Loss = 6.3693, Exploration Rate = 0.1000, Train Count = 25504\n",
      "Episode 2380: Reward = 594.00, Steps = 4, Loss = 6.6639, Exploration Rate = 0.1000, Train Count = 25508\n",
      "Episode 2381: Reward = 570.00, Steps = 12, Loss = 9.0771, Exploration Rate = 0.1000, Train Count = 25520\n",
      "Episode 2382: Reward = 591.00, Steps = 5, Loss = 6.0658, Exploration Rate = 0.1000, Train Count = 25525\n",
      "Episode 2383: Reward = 597.00, Steps = 3, Loss = 5.2086, Exploration Rate = 0.1000, Train Count = 25528\n",
      "Episode 2384: Reward = 588.00, Steps = 6, Loss = 7.7807, Exploration Rate = 0.1000, Train Count = 25534\n",
      "Episode 2385: Reward = 591.00, Steps = 5, Loss = 5.4919, Exploration Rate = 0.1000, Train Count = 25539\n",
      "Episode 2386: Reward = 573.00, Steps = 11, Loss = 22.2153, Exploration Rate = 0.1000, Train Count = 25550\n",
      "Episode 2387: Reward = 597.00, Steps = 3, Loss = 16.4544, Exploration Rate = 0.1000, Train Count = 25553\n",
      "Episode 2388: Reward = 547.00, Steps = 4, Loss = 20.0274, Exploration Rate = 0.1000, Train Count = 25557\n",
      "Episode 2389: Reward = 600.00, Steps = 2, Loss = 8.5355, Exploration Rate = 0.1000, Train Count = 25559\n",
      "Episode 2390: Reward = 600.00, Steps = 2, Loss = 18.4993, Exploration Rate = 0.1000, Train Count = 25561\n",
      "Episode 2391: Reward = 594.00, Steps = 4, Loss = 13.9361, Exploration Rate = 0.1000, Train Count = 25565\n",
      "Episode 2392: Reward = 597.00, Steps = 3, Loss = 8.0577, Exploration Rate = 0.1000, Train Count = 25568\n",
      "Episode 2393: Reward = 585.00, Steps = 7, Loss = 11.4406, Exploration Rate = 0.1000, Train Count = 25575\n",
      "Episode 2394: Reward = 594.00, Steps = 4, Loss = 13.8542, Exploration Rate = 0.1000, Train Count = 25579\n",
      "Episode 2395: Reward = 597.00, Steps = 3, Loss = 17.9927, Exploration Rate = 0.1000, Train Count = 25582\n",
      "Episode 2396: Reward = 582.00, Steps = 8, Loss = 11.1024, Exploration Rate = 0.1000, Train Count = 25590\n",
      "Episode 2397: Reward = 594.00, Steps = 4, Loss = 12.1774, Exploration Rate = 0.1000, Train Count = 25594\n",
      "Episode 2398: Reward = 591.00, Steps = 5, Loss = 10.6466, Exploration Rate = 0.1000, Train Count = 25599\n",
      "Episode 2399: Reward = 600.00, Steps = 2, Loss = 11.6087, Exploration Rate = 0.1000, Train Count = 25601\n",
      "Episode 2400: Reward = 594.00, Steps = 4, Loss = 7.3484, Exploration Rate = 0.1000, Train Count = 25605\n",
      "Episode 2401: Reward = 597.00, Steps = 3, Loss = 10.7917, Exploration Rate = 0.1000, Train Count = 25608\n",
      "Episode 2402: Reward = 585.00, Steps = 7, Loss = 7.8911, Exploration Rate = 0.1000, Train Count = 25615\n",
      "Episode 2403: Reward = 591.00, Steps = 5, Loss = 7.6586, Exploration Rate = 0.1000, Train Count = 25620\n",
      "Episode 2404: Reward = 579.00, Steps = 9, Loss = 8.3715, Exploration Rate = 0.1000, Train Count = 25629\n",
      "Episode 2405: Reward = 597.00, Steps = 3, Loss = 5.9190, Exploration Rate = 0.1000, Train Count = 25632\n",
      "Episode 2406: Reward = 594.00, Steps = 4, Loss = 4.8660, Exploration Rate = 0.1000, Train Count = 25636\n",
      "Episode 2407: Reward = 594.00, Steps = 4, Loss = 9.6112, Exploration Rate = 0.1000, Train Count = 25640\n",
      "Episode 2408: Reward = 579.00, Steps = 9, Loss = 7.9767, Exploration Rate = 0.1000, Train Count = 25649\n",
      "Episode 2409: Reward = 594.00, Steps = 4, Loss = 6.7242, Exploration Rate = 0.1000, Train Count = 25653\n",
      "Episode 2410: Reward = 588.00, Steps = 6, Loss = 6.5867, Exploration Rate = 0.1000, Train Count = 25659\n",
      "Episode 2411: Reward = 591.00, Steps = 5, Loss = 6.0112, Exploration Rate = 0.1000, Train Count = 25664\n",
      "Episode 2412: Reward = 576.00, Steps = 10, Loss = 6.5050, Exploration Rate = 0.1000, Train Count = 25674\n",
      "Episode 2413: Reward = 597.00, Steps = 3, Loss = 4.2085, Exploration Rate = 0.1000, Train Count = 25677\n",
      "Episode 2414: Reward = 585.00, Steps = 7, Loss = 5.4563, Exploration Rate = 0.1000, Train Count = 25684\n",
      "Episode 2415: Reward = 588.00, Steps = 6, Loss = 9.2559, Exploration Rate = 0.1000, Train Count = 25690\n",
      "Episode 2416: Reward = 532.00, Steps = 9, Loss = 6.5709, Exploration Rate = 0.1000, Train Count = 25699\n",
      "Episode 2417: Reward = 591.00, Steps = 5, Loss = 10.0208, Exploration Rate = 0.1000, Train Count = 25704\n",
      "Episode 2418: Reward = 576.00, Steps = 10, Loss = 10.2237, Exploration Rate = 0.1000, Train Count = 25714\n",
      "Episode 2419: Reward = 588.00, Steps = 6, Loss = 11.7201, Exploration Rate = 0.1000, Train Count = 25720\n",
      "Episode 2420: Reward = 582.00, Steps = 8, Loss = 8.8828, Exploration Rate = 0.1000, Train Count = 25728\n",
      "Episode 2421: Reward = 594.00, Steps = 4, Loss = 6.0206, Exploration Rate = 0.1000, Train Count = 25732\n",
      "Episode 2422: Reward = 591.00, Steps = 5, Loss = 9.1874, Exploration Rate = 0.1000, Train Count = 25737\n",
      "Episode 2423: Reward = 582.00, Steps = 8, Loss = 5.9899, Exploration Rate = 0.1000, Train Count = 25745\n",
      "Episode 2424: Reward = 585.00, Steps = 7, Loss = 7.5152, Exploration Rate = 0.1000, Train Count = 25752\n",
      "Episode 2425: Reward = 597.00, Steps = 3, Loss = 5.6550, Exploration Rate = 0.1000, Train Count = 25755\n",
      "Episode 2426: Reward = 594.00, Steps = 4, Loss = 4.1951, Exploration Rate = 0.1000, Train Count = 25759\n",
      "Episode 2427: Reward = 588.00, Steps = 6, Loss = 4.2668, Exploration Rate = 0.1000, Train Count = 25765\n",
      "Episode 2428: Reward = 579.00, Steps = 9, Loss = 6.7424, Exploration Rate = 0.1000, Train Count = 25774\n",
      "Episode 2429: Reward = 597.00, Steps = 3, Loss = 4.9137, Exploration Rate = 0.1000, Train Count = 25777\n",
      "Episode 2430: Reward = 594.00, Steps = 4, Loss = 6.3636, Exploration Rate = 0.1000, Train Count = 25781\n",
      "Episode 2431: Reward = 585.00, Steps = 7, Loss = 4.1291, Exploration Rate = 0.1000, Train Count = 25788\n",
      "Episode 2432: Reward = 594.00, Steps = 4, Loss = 4.2244, Exploration Rate = 0.1000, Train Count = 25792\n",
      "Episode 2433: Reward = 544.00, Steps = 5, Loss = 4.7669, Exploration Rate = 0.1000, Train Count = 25797\n",
      "Episode 2434: Reward = 582.00, Steps = 8, Loss = 35.5137, Exploration Rate = 0.1000, Train Count = 25805\n",
      "Episode 2435: Reward = 597.00, Steps = 3, Loss = 46.9628, Exploration Rate = 0.1000, Train Count = 25808\n",
      "Episode 2436: Reward = 579.00, Steps = 9, Loss = 62.4021, Exploration Rate = 0.1000, Train Count = 25817\n",
      "Episode 2437: Reward = 585.00, Steps = 7, Loss = 42.0909, Exploration Rate = 0.1000, Train Count = 25824\n",
      "Episode 2438: Reward = 597.00, Steps = 3, Loss = 42.2527, Exploration Rate = 0.1000, Train Count = 25827\n",
      "Episode 2439: Reward = 576.00, Steps = 10, Loss = 26.2900, Exploration Rate = 0.1000, Train Count = 25837\n",
      "Episode 2440: Reward = 591.00, Steps = 5, Loss = 21.4454, Exploration Rate = 0.1000, Train Count = 25842\n",
      "Episode 2441: Reward = 529.00, Steps = 10, Loss = 20.9666, Exploration Rate = 0.1000, Train Count = 25852\n",
      "Episode 2442: Reward = 597.00, Steps = 3, Loss = 15.8836, Exploration Rate = 0.1000, Train Count = 25855\n",
      "Episode 2443: Reward = 579.00, Steps = 9, Loss = 15.7059, Exploration Rate = 0.1000, Train Count = 25864\n",
      "Episode 2444: Reward = 594.00, Steps = 4, Loss = 10.9637, Exploration Rate = 0.1000, Train Count = 25868\n",
      "Episode 2445: Reward = 588.00, Steps = 6, Loss = 12.0626, Exploration Rate = 0.1000, Train Count = 25874\n",
      "Episode 2446: Reward = 591.00, Steps = 5, Loss = 9.3555, Exploration Rate = 0.1000, Train Count = 25879\n",
      "Episode 2447: Reward = 579.00, Steps = 9, Loss = 7.6585, Exploration Rate = 0.1000, Train Count = 25888\n",
      "Episode 2448: Reward = 594.00, Steps = 4, Loss = 6.8153, Exploration Rate = 0.1000, Train Count = 25892\n",
      "Episode 2449: Reward = 597.00, Steps = 3, Loss = 7.1472, Exploration Rate = 0.1000, Train Count = 25895\n",
      "Episode 2450: Reward = 588.00, Steps = 6, Loss = 6.6147, Exploration Rate = 0.1000, Train Count = 25901\n",
      "Episode 2451: Reward = 582.00, Steps = 8, Loss = 12.9482, Exploration Rate = 0.1000, Train Count = 25909\n",
      "Episode 2452: Reward = 591.00, Steps = 5, Loss = 10.0771, Exploration Rate = 0.1000, Train Count = 25914\n",
      "Episode 2453: Reward = 544.00, Steps = 5, Loss = 15.4856, Exploration Rate = 0.1000, Train Count = 25919\n",
      "Episode 2454: Reward = 588.00, Steps = 6, Loss = 7.3322, Exploration Rate = 0.1000, Train Count = 25925\n",
      "Episode 2455: Reward = 591.00, Steps = 5, Loss = 12.2458, Exploration Rate = 0.1000, Train Count = 25930\n",
      "Episode 2456: Reward = 594.00, Steps = 4, Loss = 10.9022, Exploration Rate = 0.1000, Train Count = 25934\n",
      "Episode 2457: Reward = 585.00, Steps = 7, Loss = 15.8065, Exploration Rate = 0.1000, Train Count = 25941\n",
      "Episode 2458: Reward = 600.00, Steps = 2, Loss = 13.1724, Exploration Rate = 0.1000, Train Count = 25943\n",
      "Episode 2459: Reward = 585.00, Steps = 7, Loss = 8.7339, Exploration Rate = 0.1000, Train Count = 25950\n",
      "Episode 2460: Reward = 594.00, Steps = 4, Loss = 8.0016, Exploration Rate = 0.1000, Train Count = 25954\n",
      "Episode 2461: Reward = 582.00, Steps = 8, Loss = 9.1036, Exploration Rate = 0.1000, Train Count = 25962\n",
      "Episode 2462: Reward = 532.00, Steps = 9, Loss = 8.1202, Exploration Rate = 0.1000, Train Count = 25971\n",
      "Episode 2463: Reward = 591.00, Steps = 5, Loss = 8.6740, Exploration Rate = 0.1000, Train Count = 25976\n",
      "Episode 2464: Reward = 538.00, Steps = 7, Loss = 7.0696, Exploration Rate = 0.1000, Train Count = 25983\n",
      "Episode 2465: Reward = 576.00, Steps = 10, Loss = 6.2539, Exploration Rate = 0.1000, Train Count = 25993\n",
      "Episode 2466: Reward = 573.00, Steps = 11, Loss = 7.5983, Exploration Rate = 0.1000, Train Count = 26004\n",
      "Episode 2467: Reward = 576.00, Steps = 10, Loss = 5.6173, Exploration Rate = 0.1000, Train Count = 26014\n",
      "Episode 2468: Reward = 564.00, Steps = 14, Loss = 7.3594, Exploration Rate = 0.1000, Train Count = 26028\n",
      "Episode 2469: Reward = 591.00, Steps = 5, Loss = 9.1224, Exploration Rate = 0.1000, Train Count = 26033\n",
      "Episode 2470: Reward = 594.00, Steps = 4, Loss = 7.4334, Exploration Rate = 0.1000, Train Count = 26037\n",
      "Episode 2471: Reward = 588.00, Steps = 6, Loss = 6.2336, Exploration Rate = 0.1000, Train Count = 26043\n",
      "Episode 2472: Reward = 585.00, Steps = 7, Loss = 4.6508, Exploration Rate = 0.1000, Train Count = 26050\n",
      "Episode 2473: Reward = 570.00, Steps = 12, Loss = 9.8920, Exploration Rate = 0.1000, Train Count = 26062\n",
      "Episode 2474: Reward = 579.00, Steps = 9, Loss = 9.5833, Exploration Rate = 0.1000, Train Count = 26071\n",
      "Episode 2475: Reward = 535.00, Steps = 8, Loss = 13.2705, Exploration Rate = 0.1000, Train Count = 26079\n",
      "Episode 2476: Reward = 588.00, Steps = 6, Loss = 6.0032, Exploration Rate = 0.1000, Train Count = 26085\n",
      "Episode 2477: Reward = 594.00, Steps = 4, Loss = 9.4475, Exploration Rate = 0.1000, Train Count = 26089\n",
      "Episode 2478: Reward = 594.00, Steps = 4, Loss = 9.1491, Exploration Rate = 0.1000, Train Count = 26093\n",
      "Episode 2479: Reward = 582.00, Steps = 8, Loss = 6.9477, Exploration Rate = 0.1000, Train Count = 26101\n",
      "Episode 2480: Reward = 594.00, Steps = 4, Loss = 8.7309, Exploration Rate = 0.1000, Train Count = 26105\n",
      "Episode 2481: Reward = 585.00, Steps = 7, Loss = 8.9135, Exploration Rate = 0.1000, Train Count = 26112\n",
      "Episode 2482: Reward = 582.00, Steps = 8, Loss = 3.8262, Exploration Rate = 0.1000, Train Count = 26120\n",
      "Episode 2483: Reward = 538.00, Steps = 7, Loss = 8.9194, Exploration Rate = 0.1000, Train Count = 26127\n",
      "Episode 2484: Reward = 588.00, Steps = 6, Loss = 5.1832, Exploration Rate = 0.1000, Train Count = 26133\n",
      "Episode 2485: Reward = 588.00, Steps = 6, Loss = 6.7141, Exploration Rate = 0.1000, Train Count = 26139\n",
      "Episode 2486: Reward = 591.00, Steps = 5, Loss = 10.4535, Exploration Rate = 0.1000, Train Count = 26144\n",
      "Episode 2487: Reward = 591.00, Steps = 5, Loss = 11.9480, Exploration Rate = 0.1000, Train Count = 26149\n",
      "Episode 2488: Reward = 588.00, Steps = 6, Loss = 5.5146, Exploration Rate = 0.1000, Train Count = 26155\n",
      "Episode 2489: Reward = 576.00, Steps = 10, Loss = 11.0632, Exploration Rate = 0.1000, Train Count = 26165\n",
      "Episode 2490: Reward = 591.00, Steps = 5, Loss = 7.9561, Exploration Rate = 0.1000, Train Count = 26170\n",
      "Episode 2491: Reward = 591.00, Steps = 5, Loss = 7.7542, Exploration Rate = 0.1000, Train Count = 26175\n",
      "Episode 2492: Reward = 579.00, Steps = 9, Loss = 10.7363, Exploration Rate = 0.1000, Train Count = 26184\n",
      "Episode 2493: Reward = 594.00, Steps = 4, Loss = 5.1441, Exploration Rate = 0.1000, Train Count = 26188\n",
      "Episode 2494: Reward = 535.00, Steps = 8, Loss = 7.3088, Exploration Rate = 0.1000, Train Count = 26196\n",
      "Episode 2495: Reward = 579.00, Steps = 9, Loss = 10.8377, Exploration Rate = 0.1000, Train Count = 26205\n",
      "Episode 2496: Reward = 591.00, Steps = 5, Loss = 25.7382, Exploration Rate = 0.1000, Train Count = 26210\n",
      "Episode 2497: Reward = 585.00, Steps = 7, Loss = 26.4945, Exploration Rate = 0.1000, Train Count = 26217\n",
      "Episode 2498: Reward = 594.00, Steps = 4, Loss = 15.1661, Exploration Rate = 0.1000, Train Count = 26221\n",
      "Episode 2499: Reward = 597.00, Steps = 3, Loss = 13.5399, Exploration Rate = 0.1000, Train Count = 26224\n",
      "Episode 2500: Reward = 585.00, Steps = 7, Loss = 10.5229, Exploration Rate = 0.1000, Train Count = 26231\n",
      "Episode 2501: Reward = 591.00, Steps = 5, Loss = 10.1411, Exploration Rate = 0.1000, Train Count = 26236\n",
      "Episode 2502: Reward = 585.00, Steps = 7, Loss = 9.4225, Exploration Rate = 0.1000, Train Count = 26243\n",
      "Episode 2503: Reward = 576.00, Steps = 10, Loss = 6.7411, Exploration Rate = 0.1000, Train Count = 26253\n",
      "Episode 2504: Reward = 573.00, Steps = 11, Loss = 6.6893, Exploration Rate = 0.1000, Train Count = 26264\n",
      "Episode 2505: Reward = 588.00, Steps = 6, Loss = 5.0793, Exploration Rate = 0.1000, Train Count = 26270\n",
      "Episode 2506: Reward = 591.00, Steps = 5, Loss = 6.1307, Exploration Rate = 0.1000, Train Count = 26275\n",
      "Episode 2507: Reward = 597.00, Steps = 3, Loss = 6.4556, Exploration Rate = 0.1000, Train Count = 26278\n",
      "Episode 2508: Reward = 588.00, Steps = 6, Loss = 5.6095, Exploration Rate = 0.1000, Train Count = 26284\n",
      "Episode 2509: Reward = 541.00, Steps = 6, Loss = 20.5319, Exploration Rate = 0.1000, Train Count = 26290\n",
      "Episode 2510: Reward = 585.00, Steps = 7, Loss = 25.9983, Exploration Rate = 0.1000, Train Count = 26297\n",
      "Episode 2511: Reward = 591.00, Steps = 5, Loss = 44.9051, Exploration Rate = 0.1000, Train Count = 26302\n",
      "Episode 2512: Reward = 594.00, Steps = 4, Loss = 80.6979, Exploration Rate = 0.1000, Train Count = 26306\n",
      "Episode 2513: Reward = 573.00, Steps = 11, Loss = 57.2240, Exploration Rate = 0.1000, Train Count = 26317\n",
      "Episode 2514: Reward = 582.00, Steps = 8, Loss = 34.3385, Exploration Rate = 0.1000, Train Count = 26325\n",
      "Episode 2515: Reward = 588.00, Steps = 6, Loss = 36.5296, Exploration Rate = 0.1000, Train Count = 26331\n",
      "Episode 2516: Reward = 588.00, Steps = 6, Loss = 24.0468, Exploration Rate = 0.1000, Train Count = 26337\n",
      "Episode 2517: Reward = 594.00, Steps = 4, Loss = 23.4487, Exploration Rate = 0.1000, Train Count = 26341\n",
      "Episode 2518: Reward = 573.00, Steps = 11, Loss = 20.5794, Exploration Rate = 0.1000, Train Count = 26352\n",
      "Episode 2519: Reward = 573.00, Steps = 11, Loss = 21.3665, Exploration Rate = 0.1000, Train Count = 26363\n",
      "Episode 2520: Reward = 585.00, Steps = 7, Loss = 14.1494, Exploration Rate = 0.1000, Train Count = 26370\n",
      "Episode 2521: Reward = 588.00, Steps = 6, Loss = 13.8285, Exploration Rate = 0.1000, Train Count = 26376\n",
      "Episode 2522: Reward = 591.00, Steps = 5, Loss = 11.4581, Exploration Rate = 0.1000, Train Count = 26381\n",
      "Episode 2523: Reward = 591.00, Steps = 5, Loss = 13.1247, Exploration Rate = 0.1000, Train Count = 26386\n",
      "Episode 2524: Reward = 594.00, Steps = 4, Loss = 10.6172, Exploration Rate = 0.1000, Train Count = 26390\n",
      "Episode 2525: Reward = 582.00, Steps = 8, Loss = 9.0223, Exploration Rate = 0.1000, Train Count = 26398\n",
      "Episode 2526: Reward = 591.00, Steps = 5, Loss = 7.5175, Exploration Rate = 0.1000, Train Count = 26403\n",
      "Episode 2527: Reward = 591.00, Steps = 5, Loss = 5.5990, Exploration Rate = 0.1000, Train Count = 26408\n",
      "Episode 2528: Reward = 594.00, Steps = 4, Loss = 8.9524, Exploration Rate = 0.1000, Train Count = 26412\n",
      "Episode 2529: Reward = 594.00, Steps = 4, Loss = 8.8761, Exploration Rate = 0.1000, Train Count = 26416\n",
      "Episode 2530: Reward = 591.00, Steps = 5, Loss = 9.7529, Exploration Rate = 0.1000, Train Count = 26421\n",
      "Episode 2531: Reward = 591.00, Steps = 5, Loss = 13.1664, Exploration Rate = 0.1000, Train Count = 26426\n",
      "Episode 2532: Reward = 582.00, Steps = 8, Loss = 8.4488, Exploration Rate = 0.1000, Train Count = 26434\n",
      "Episode 2533: Reward = 594.00, Steps = 4, Loss = 12.0542, Exploration Rate = 0.1000, Train Count = 26438\n",
      "Episode 2534: Reward = 558.00, Steps = 16, Loss = 12.1187, Exploration Rate = 0.1000, Train Count = 26454\n",
      "Episode 2535: Reward = 585.00, Steps = 7, Loss = 15.2382, Exploration Rate = 0.1000, Train Count = 26461\n",
      "Episode 2536: Reward = 582.00, Steps = 8, Loss = 11.5171, Exploration Rate = 0.1000, Train Count = 26469\n",
      "Episode 2537: Reward = 588.00, Steps = 6, Loss = 9.8468, Exploration Rate = 0.1000, Train Count = 26475\n",
      "Episode 2538: Reward = 579.00, Steps = 9, Loss = 12.5531, Exploration Rate = 0.1000, Train Count = 26484\n",
      "Episode 2539: Reward = 594.00, Steps = 4, Loss = 6.4063, Exploration Rate = 0.1000, Train Count = 26488\n",
      "Episode 2540: Reward = 579.00, Steps = 9, Loss = 11.7733, Exploration Rate = 0.1000, Train Count = 26497\n",
      "Episode 2541: Reward = 594.00, Steps = 4, Loss = 11.1034, Exploration Rate = 0.1000, Train Count = 26501\n",
      "Episode 2542: Reward = 591.00, Steps = 5, Loss = 10.8354, Exploration Rate = 0.1000, Train Count = 26506\n",
      "Episode 2543: Reward = 591.00, Steps = 5, Loss = 9.8443, Exploration Rate = 0.1000, Train Count = 26511\n",
      "Episode 2544: Reward = 591.00, Steps = 5, Loss = 6.8861, Exploration Rate = 0.1000, Train Count = 26516\n",
      "Episode 2545: Reward = 576.00, Steps = 10, Loss = 8.2065, Exploration Rate = 0.1000, Train Count = 26526\n",
      "Episode 2546: Reward = 520.00, Steps = 13, Loss = 10.3604, Exploration Rate = 0.1000, Train Count = 26539\n",
      "Episode 2547: Reward = 540.00, Steps = 22, Loss = 13.3504, Exploration Rate = 0.1000, Train Count = 26561\n",
      "Episode 2548: Reward = 597.00, Steps = 3, Loss = 11.5409, Exploration Rate = 0.1000, Train Count = 26564\n",
      "Episode 2549: Reward = 582.00, Steps = 8, Loss = 7.2309, Exploration Rate = 0.1000, Train Count = 26572\n",
      "Episode 2550: Reward = 591.00, Steps = 5, Loss = 8.3795, Exploration Rate = 0.1000, Train Count = 26577\n",
      "Episode 2551: Reward = 552.00, Steps = 18, Loss = 13.2940, Exploration Rate = 0.1000, Train Count = 26595\n",
      "Episode 2552: Reward = 588.00, Steps = 6, Loss = 8.2338, Exploration Rate = 0.1000, Train Count = 26601\n",
      "Episode 2553: Reward = 564.00, Steps = 14, Loss = 8.8136, Exploration Rate = 0.1000, Train Count = 26615\n",
      "Episode 2554: Reward = 591.00, Steps = 5, Loss = 7.3468, Exploration Rate = 0.1000, Train Count = 26620\n",
      "Episode 2555: Reward = 597.00, Steps = 3, Loss = 7.6203, Exploration Rate = 0.1000, Train Count = 26623\n",
      "Episode 2556: Reward = 597.00, Steps = 3, Loss = 5.5124, Exploration Rate = 0.1000, Train Count = 26626\n",
      "Episode 2557: Reward = 582.00, Steps = 8, Loss = 4.4836, Exploration Rate = 0.1000, Train Count = 26634\n",
      "Episode 2558: Reward = 576.00, Steps = 10, Loss = 4.9945, Exploration Rate = 0.1000, Train Count = 26644\n",
      "Episode 2559: Reward = 600.00, Steps = 2, Loss = 7.7618, Exploration Rate = 0.1000, Train Count = 26646\n",
      "Episode 2560: Reward = 570.00, Steps = 12, Loss = 5.1634, Exploration Rate = 0.1000, Train Count = 26658\n",
      "Episode 2561: Reward = 579.00, Steps = 9, Loss = 7.2593, Exploration Rate = 0.1000, Train Count = 26667\n",
      "Episode 2562: Reward = 594.00, Steps = 4, Loss = 6.1418, Exploration Rate = 0.1000, Train Count = 26671\n",
      "Episode 2563: Reward = 576.00, Steps = 10, Loss = 7.8574, Exploration Rate = 0.1000, Train Count = 26681\n",
      "Episode 2564: Reward = 567.00, Steps = 13, Loss = 13.1668, Exploration Rate = 0.1000, Train Count = 26694\n",
      "Episode 2565: Reward = 594.00, Steps = 4, Loss = 11.6519, Exploration Rate = 0.1000, Train Count = 26698\n",
      "Episode 2566: Reward = 588.00, Steps = 6, Loss = 10.3330, Exploration Rate = 0.1000, Train Count = 26704\n",
      "Episode 2567: Reward = 597.00, Steps = 3, Loss = 9.0559, Exploration Rate = 0.1000, Train Count = 26707\n",
      "Episode 2568: Reward = 576.00, Steps = 10, Loss = 11.8780, Exploration Rate = 0.1000, Train Count = 26717\n",
      "Episode 2569: Reward = 594.00, Steps = 4, Loss = 6.1817, Exploration Rate = 0.1000, Train Count = 26721\n",
      "Episode 2570: Reward = 585.00, Steps = 7, Loss = 7.6237, Exploration Rate = 0.1000, Train Count = 26728\n",
      "Episode 2571: Reward = 585.00, Steps = 7, Loss = 6.3696, Exploration Rate = 0.1000, Train Count = 26735\n",
      "Episode 2572: Reward = 585.00, Steps = 7, Loss = 7.6518, Exploration Rate = 0.1000, Train Count = 26742\n",
      "Episode 2573: Reward = 597.00, Steps = 3, Loss = 4.6072, Exploration Rate = 0.1000, Train Count = 26745\n",
      "Episode 2574: Reward = 585.00, Steps = 7, Loss = 5.7753, Exploration Rate = 0.1000, Train Count = 26752\n",
      "Episode 2575: Reward = 591.00, Steps = 5, Loss = 5.9294, Exploration Rate = 0.1000, Train Count = 26757\n",
      "Episode 2576: Reward = 579.00, Steps = 9, Loss = 4.7499, Exploration Rate = 0.1000, Train Count = 26766\n",
      "Episode 2577: Reward = 591.00, Steps = 5, Loss = 4.6067, Exploration Rate = 0.1000, Train Count = 26771\n",
      "Episode 2578: Reward = 600.00, Steps = 2, Loss = 6.0570, Exploration Rate = 0.1000, Train Count = 26773\n",
      "Episode 2579: Reward = 588.00, Steps = 6, Loss = 6.5452, Exploration Rate = 0.1000, Train Count = 26779\n",
      "Episode 2580: Reward = 597.00, Steps = 3, Loss = 3.9396, Exploration Rate = 0.1000, Train Count = 26782\n",
      "Episode 2581: Reward = 591.00, Steps = 5, Loss = 4.7969, Exploration Rate = 0.1000, Train Count = 26787\n",
      "Episode 2582: Reward = 591.00, Steps = 5, Loss = 6.4811, Exploration Rate = 0.1000, Train Count = 26792\n",
      "Episode 2583: Reward = 585.00, Steps = 7, Loss = 5.9873, Exploration Rate = 0.1000, Train Count = 26799\n",
      "Episode 2584: Reward = 579.00, Steps = 9, Loss = 51.0546, Exploration Rate = 0.1000, Train Count = 26808\n",
      "Episode 2585: Reward = 597.00, Steps = 3, Loss = 41.3311, Exploration Rate = 0.1000, Train Count = 26811\n",
      "Episode 2586: Reward = 585.00, Steps = 7, Loss = 38.4326, Exploration Rate = 0.1000, Train Count = 26818\n",
      "Episode 2587: Reward = 582.00, Steps = 8, Loss = 25.2536, Exploration Rate = 0.1000, Train Count = 26826\n",
      "Episode 2588: Reward = 582.00, Steps = 8, Loss = 22.5976, Exploration Rate = 0.1000, Train Count = 26834\n",
      "Episode 2589: Reward = 591.00, Steps = 5, Loss = 17.2552, Exploration Rate = 0.1000, Train Count = 26839\n",
      "Episode 2590: Reward = 594.00, Steps = 4, Loss = 15.8152, Exploration Rate = 0.1000, Train Count = 26843\n",
      "Episode 2591: Reward = 591.00, Steps = 5, Loss = 16.6581, Exploration Rate = 0.1000, Train Count = 26848\n",
      "Episode 2592: Reward = 585.00, Steps = 7, Loss = 13.8804, Exploration Rate = 0.1000, Train Count = 26855\n",
      "Episode 2593: Reward = 535.00, Steps = 8, Loss = 12.2335, Exploration Rate = 0.1000, Train Count = 26863\n",
      "Episode 2594: Reward = 597.00, Steps = 3, Loss = 9.2945, Exploration Rate = 0.1000, Train Count = 26866\n",
      "Episode 2595: Reward = 582.00, Steps = 8, Loss = 10.7964, Exploration Rate = 0.1000, Train Count = 26874\n",
      "Episode 2596: Reward = 588.00, Steps = 6, Loss = 9.8167, Exploration Rate = 0.1000, Train Count = 26880\n",
      "Episode 2597: Reward = 594.00, Steps = 4, Loss = 6.4995, Exploration Rate = 0.1000, Train Count = 26884\n",
      "Episode 2598: Reward = 526.00, Steps = 11, Loss = 11.5717, Exploration Rate = 0.1000, Train Count = 26895\n",
      "Episode 2599: Reward = 585.00, Steps = 7, Loss = 10.4310, Exploration Rate = 0.1000, Train Count = 26902\n",
      "Episode 2600: Reward = 535.00, Steps = 8, Loss = 7.3028, Exploration Rate = 0.1000, Train Count = 26910\n",
      "Episode 2601: Reward = 591.00, Steps = 5, Loss = 8.9791, Exploration Rate = 0.1000, Train Count = 26915\n",
      "Episode 2602: Reward = 588.00, Steps = 6, Loss = 7.0372, Exploration Rate = 0.1000, Train Count = 26921\n",
      "Episode 2603: Reward = 564.00, Steps = 14, Loss = 7.1480, Exploration Rate = 0.1000, Train Count = 26935\n",
      "Episode 2604: Reward = 594.00, Steps = 4, Loss = 5.7697, Exploration Rate = 0.1000, Train Count = 26939\n",
      "Episode 2605: Reward = 529.00, Steps = 10, Loss = 7.3716, Exploration Rate = 0.1000, Train Count = 26949\n",
      "Episode 2606: Reward = 579.00, Steps = 9, Loss = 8.0290, Exploration Rate = 0.1000, Train Count = 26958\n",
      "Episode 2607: Reward = 567.00, Steps = 13, Loss = 16.0403, Exploration Rate = 0.1000, Train Count = 26971\n",
      "Episode 2608: Reward = 591.00, Steps = 5, Loss = 22.6610, Exploration Rate = 0.1000, Train Count = 26976\n",
      "Episode 2609: Reward = 588.00, Steps = 6, Loss = 15.7393, Exploration Rate = 0.1000, Train Count = 26982\n",
      "Episode 2610: Reward = 585.00, Steps = 7, Loss = 10.0674, Exploration Rate = 0.1000, Train Count = 26989\n",
      "Episode 2611: Reward = 591.00, Steps = 5, Loss = 6.3618, Exploration Rate = 0.1000, Train Count = 26994\n",
      "Episode 2612: Reward = 597.00, Steps = 3, Loss = 11.4274, Exploration Rate = 0.1000, Train Count = 26997\n",
      "Episode 2613: Reward = 588.00, Steps = 6, Loss = 11.8706, Exploration Rate = 0.1000, Train Count = 27003\n",
      "Episode 2614: Reward = 582.00, Steps = 8, Loss = 8.4458, Exploration Rate = 0.1000, Train Count = 27011\n",
      "Episode 2615: Reward = 594.00, Steps = 4, Loss = 8.1159, Exploration Rate = 0.1000, Train Count = 27015\n",
      "Episode 2616: Reward = 597.00, Steps = 3, Loss = 9.7528, Exploration Rate = 0.1000, Train Count = 27018\n",
      "Episode 2617: Reward = 588.00, Steps = 6, Loss = 10.0383, Exploration Rate = 0.1000, Train Count = 27024\n",
      "Episode 2618: Reward = 594.00, Steps = 4, Loss = 6.5823, Exploration Rate = 0.1000, Train Count = 27028\n",
      "Episode 2619: Reward = 591.00, Steps = 5, Loss = 5.5132, Exploration Rate = 0.1000, Train Count = 27033\n",
      "Episode 2620: Reward = 582.00, Steps = 8, Loss = 8.1924, Exploration Rate = 0.1000, Train Count = 27041\n",
      "Episode 2621: Reward = 588.00, Steps = 6, Loss = 4.8716, Exploration Rate = 0.1000, Train Count = 27047\n",
      "Episode 2622: Reward = 573.00, Steps = 11, Loss = 6.2840, Exploration Rate = 0.1000, Train Count = 27058\n",
      "Episode 2623: Reward = 585.00, Steps = 7, Loss = 6.2871, Exploration Rate = 0.1000, Train Count = 27065\n",
      "Episode 2624: Reward = 597.00, Steps = 3, Loss = 4.7211, Exploration Rate = 0.1000, Train Count = 27068\n",
      "Episode 2625: Reward = 597.00, Steps = 3, Loss = 8.0497, Exploration Rate = 0.1000, Train Count = 27071\n",
      "Episode 2626: Reward = 573.00, Steps = 11, Loss = 7.9103, Exploration Rate = 0.1000, Train Count = 27082\n",
      "Episode 2627: Reward = 597.00, Steps = 3, Loss = 4.5203, Exploration Rate = 0.1000, Train Count = 27085\n",
      "Episode 2628: Reward = 597.00, Steps = 3, Loss = 8.5152, Exploration Rate = 0.1000, Train Count = 27088\n",
      "Episode 2629: Reward = 597.00, Steps = 3, Loss = 10.1488, Exploration Rate = 0.1000, Train Count = 27091\n",
      "Episode 2630: Reward = 594.00, Steps = 4, Loss = 8.1170, Exploration Rate = 0.1000, Train Count = 27095\n",
      "Episode 2631: Reward = 597.00, Steps = 3, Loss = 4.4543, Exploration Rate = 0.1000, Train Count = 27098\n",
      "Episode 2632: Reward = 582.00, Steps = 8, Loss = 19.0827, Exploration Rate = 0.1000, Train Count = 27106\n",
      "Episode 2633: Reward = 585.00, Steps = 7, Loss = 9.8140, Exploration Rate = 0.1000, Train Count = 27113\n",
      "Episode 2634: Reward = 579.00, Steps = 9, Loss = 9.4794, Exploration Rate = 0.1000, Train Count = 27122\n",
      "Episode 2635: Reward = 594.00, Steps = 4, Loss = 6.6080, Exploration Rate = 0.1000, Train Count = 27126\n",
      "Episode 2636: Reward = 591.00, Steps = 5, Loss = 8.5147, Exploration Rate = 0.1000, Train Count = 27131\n",
      "Episode 2637: Reward = 591.00, Steps = 5, Loss = 4.9782, Exploration Rate = 0.1000, Train Count = 27136\n",
      "Episode 2638: Reward = 582.00, Steps = 8, Loss = 9.3979, Exploration Rate = 0.1000, Train Count = 27144\n",
      "Episode 2639: Reward = 588.00, Steps = 6, Loss = 6.3018, Exploration Rate = 0.1000, Train Count = 27150\n",
      "Episode 2640: Reward = 544.00, Steps = 5, Loss = 7.6811, Exploration Rate = 0.1000, Train Count = 27155\n",
      "Episode 2641: Reward = 588.00, Steps = 6, Loss = 4.7987, Exploration Rate = 0.1000, Train Count = 27161\n",
      "Episode 2642: Reward = 594.00, Steps = 4, Loss = 7.6776, Exploration Rate = 0.1000, Train Count = 27165\n",
      "Episode 2643: Reward = 591.00, Steps = 5, Loss = 6.2930, Exploration Rate = 0.1000, Train Count = 27170\n",
      "Episode 2644: Reward = 532.00, Steps = 9, Loss = 7.8454, Exploration Rate = 0.1000, Train Count = 27179\n",
      "Episode 2645: Reward = 585.00, Steps = 7, Loss = 9.6778, Exploration Rate = 0.1000, Train Count = 27186\n",
      "Episode 2646: Reward = 591.00, Steps = 5, Loss = 9.1668, Exploration Rate = 0.1000, Train Count = 27191\n",
      "Episode 2647: Reward = 579.00, Steps = 9, Loss = 6.4880, Exploration Rate = 0.1000, Train Count = 27200\n",
      "Episode 2648: Reward = 591.00, Steps = 5, Loss = 7.9471, Exploration Rate = 0.1000, Train Count = 27205\n",
      "Episode 2649: Reward = 494.00, Steps = 6, Loss = 7.4088, Exploration Rate = 0.1000, Train Count = 27211\n",
      "Episode 2650: Reward = 591.00, Steps = 5, Loss = 6.7373, Exploration Rate = 0.1000, Train Count = 27216\n",
      "Episode 2651: Reward = 585.00, Steps = 7, Loss = 8.2915, Exploration Rate = 0.1000, Train Count = 27223\n",
      "Episode 2652: Reward = 591.00, Steps = 5, Loss = 11.9144, Exploration Rate = 0.1000, Train Count = 27228\n",
      "Episode 2653: Reward = 594.00, Steps = 4, Loss = 12.3125, Exploration Rate = 0.1000, Train Count = 27232\n",
      "Episode 2654: Reward = 597.00, Steps = 3, Loss = 12.0575, Exploration Rate = 0.1000, Train Count = 27235\n",
      "Episode 2655: Reward = 588.00, Steps = 6, Loss = 6.8331, Exploration Rate = 0.1000, Train Count = 27241\n",
      "Episode 2656: Reward = 597.00, Steps = 3, Loss = 7.1621, Exploration Rate = 0.1000, Train Count = 27244\n",
      "Episode 2657: Reward = 588.00, Steps = 6, Loss = 6.4016, Exploration Rate = 0.1000, Train Count = 27250\n",
      "Episode 2658: Reward = 594.00, Steps = 4, Loss = 10.3465, Exploration Rate = 0.1000, Train Count = 27254\n",
      "Episode 2659: Reward = 523.00, Steps = 12, Loss = 11.0655, Exploration Rate = 0.1000, Train Count = 27266\n",
      "Episode 2660: Reward = 594.00, Steps = 4, Loss = 9.0953, Exploration Rate = 0.1000, Train Count = 27270\n",
      "Episode 2661: Reward = 594.00, Steps = 4, Loss = 10.1525, Exploration Rate = 0.1000, Train Count = 27274\n",
      "Episode 2662: Reward = 591.00, Steps = 5, Loss = 6.4873, Exploration Rate = 0.1000, Train Count = 27279\n",
      "Episode 2663: Reward = 591.00, Steps = 5, Loss = 6.0854, Exploration Rate = 0.1000, Train Count = 27284\n",
      "Episode 2664: Reward = 573.00, Steps = 11, Loss = 8.5687, Exploration Rate = 0.1000, Train Count = 27295\n",
      "Episode 2665: Reward = 588.00, Steps = 6, Loss = 20.8429, Exploration Rate = 0.1000, Train Count = 27301\n",
      "Episode 2666: Reward = 591.00, Steps = 5, Loss = 49.7932, Exploration Rate = 0.1000, Train Count = 27306\n",
      "Episode 2667: Reward = 576.00, Steps = 10, Loss = 40.8283, Exploration Rate = 0.1000, Train Count = 27316\n",
      "Episode 2668: Reward = 597.00, Steps = 3, Loss = 25.0236, Exploration Rate = 0.1000, Train Count = 27319\n",
      "Episode 2669: Reward = 597.00, Steps = 3, Loss = 26.1602, Exploration Rate = 0.1000, Train Count = 27322\n",
      "Episode 2670: Reward = 576.00, Steps = 10, Loss = 28.7950, Exploration Rate = 0.1000, Train Count = 27332\n",
      "Episode 2671: Reward = 588.00, Steps = 6, Loss = 15.1609, Exploration Rate = 0.1000, Train Count = 27338\n",
      "Episode 2672: Reward = 591.00, Steps = 5, Loss = 17.8254, Exploration Rate = 0.1000, Train Count = 27343\n",
      "Episode 2673: Reward = 591.00, Steps = 5, Loss = 13.1906, Exploration Rate = 0.1000, Train Count = 27348\n",
      "Episode 2674: Reward = 597.00, Steps = 3, Loss = 12.5480, Exploration Rate = 0.1000, Train Count = 27351\n",
      "Episode 2675: Reward = 582.00, Steps = 8, Loss = 13.5329, Exploration Rate = 0.1000, Train Count = 27359\n",
      "Episode 2676: Reward = 585.00, Steps = 7, Loss = 11.4270, Exploration Rate = 0.1000, Train Count = 27366\n",
      "Episode 2677: Reward = 597.00, Steps = 3, Loss = 13.1735, Exploration Rate = 0.1000, Train Count = 27369\n",
      "Episode 2678: Reward = 579.00, Steps = 9, Loss = 8.6860, Exploration Rate = 0.1000, Train Count = 27378\n",
      "Episode 2679: Reward = 600.00, Steps = 2, Loss = 9.8873, Exploration Rate = 0.1000, Train Count = 27380\n",
      "Episode 2680: Reward = 585.00, Steps = 7, Loss = 8.4960, Exploration Rate = 0.1000, Train Count = 27387\n",
      "Episode 2681: Reward = 591.00, Steps = 5, Loss = 7.1896, Exploration Rate = 0.1000, Train Count = 27392\n",
      "Episode 2682: Reward = 591.00, Steps = 5, Loss = 11.7282, Exploration Rate = 0.1000, Train Count = 27397\n",
      "Episode 2683: Reward = 582.00, Steps = 8, Loss = 11.3332, Exploration Rate = 0.1000, Train Count = 27405\n",
      "Episode 2684: Reward = 585.00, Steps = 7, Loss = 8.3009, Exploration Rate = 0.1000, Train Count = 27412\n",
      "Episode 2685: Reward = 528.00, Steps = 26, Loss = 8.3680, Exploration Rate = 0.1000, Train Count = 27438\n",
      "Episode 2686: Reward = 588.00, Steps = 6, Loss = 5.7474, Exploration Rate = 0.1000, Train Count = 27444\n",
      "Episode 2687: Reward = 329.00, Steps = 14, Loss = 12.6983, Exploration Rate = 0.1000, Train Count = 27458\n",
      "Episode 2688: Reward = 588.00, Steps = 6, Loss = 24.6731, Exploration Rate = 0.1000, Train Count = 27464\n",
      "Episode 2689: Reward = 529.00, Steps = 10, Loss = 25.5597, Exploration Rate = 0.1000, Train Count = 27474\n",
      "Episode 2690: Reward = 579.00, Steps = 9, Loss = 23.6480, Exploration Rate = 0.1000, Train Count = 27483\n",
      "Episode 2691: Reward = 591.00, Steps = 5, Loss = 10.5533, Exploration Rate = 0.1000, Train Count = 27488\n",
      "Episode 2692: Reward = 588.00, Steps = 6, Loss = 8.5816, Exploration Rate = 0.1000, Train Count = 27494\n",
      "Episode 2693: Reward = 594.00, Steps = 4, Loss = 9.2196, Exploration Rate = 0.1000, Train Count = 27498\n",
      "Episode 2694: Reward = 594.00, Steps = 4, Loss = 11.7317, Exploration Rate = 0.1000, Train Count = 27502\n",
      "Episode 2695: Reward = 585.00, Steps = 7, Loss = 7.3350, Exploration Rate = 0.1000, Train Count = 27509\n",
      "Episode 2696: Reward = 588.00, Steps = 6, Loss = 7.1721, Exploration Rate = 0.1000, Train Count = 27515\n",
      "Episode 2697: Reward = 576.00, Steps = 10, Loss = 8.7313, Exploration Rate = 0.1000, Train Count = 27525\n",
      "Episode 2698: Reward = 591.00, Steps = 5, Loss = 3.5574, Exploration Rate = 0.1000, Train Count = 27530\n",
      "Episode 2699: Reward = 588.00, Steps = 6, Loss = 6.9075, Exploration Rate = 0.1000, Train Count = 27536\n",
      "Episode 2700: Reward = 588.00, Steps = 6, Loss = 5.0384, Exploration Rate = 0.1000, Train Count = 27542\n",
      "Episode 2701: Reward = 585.00, Steps = 7, Loss = 5.1287, Exploration Rate = 0.1000, Train Count = 27549\n",
      "Episode 2702: Reward = 594.00, Steps = 4, Loss = 7.6971, Exploration Rate = 0.1000, Train Count = 27553\n",
      "Episode 2703: Reward = 597.00, Steps = 3, Loss = 6.0582, Exploration Rate = 0.1000, Train Count = 27556\n",
      "Episode 2704: Reward = 591.00, Steps = 5, Loss = 4.9871, Exploration Rate = 0.1000, Train Count = 27561\n",
      "Episode 2705: Reward = 523.00, Steps = 12, Loss = 7.2838, Exploration Rate = 0.1000, Train Count = 27573\n",
      "Episode 2706: Reward = 585.00, Steps = 7, Loss = 9.7527, Exploration Rate = 0.1000, Train Count = 27580\n",
      "Episode 2707: Reward = 579.00, Steps = 9, Loss = 8.1347, Exploration Rate = 0.1000, Train Count = 27589\n",
      "Episode 2708: Reward = 588.00, Steps = 6, Loss = 6.6792, Exploration Rate = 0.1000, Train Count = 27595\n",
      "Episode 2709: Reward = 588.00, Steps = 6, Loss = 8.2233, Exploration Rate = 0.1000, Train Count = 27601\n",
      "Episode 2710: Reward = 561.00, Steps = 15, Loss = 12.0214, Exploration Rate = 0.1000, Train Count = 27616\n",
      "Episode 2711: Reward = 558.00, Steps = 16, Loss = 11.5763, Exploration Rate = 0.1000, Train Count = 27632\n",
      "Episode 2712: Reward = 591.00, Steps = 5, Loss = 9.8371, Exploration Rate = 0.1000, Train Count = 27637\n",
      "Episode 2713: Reward = 591.00, Steps = 5, Loss = 8.4270, Exploration Rate = 0.1000, Train Count = 27642\n",
      "Episode 2714: Reward = 585.00, Steps = 7, Loss = 16.3345, Exploration Rate = 0.1000, Train Count = 27649\n",
      "Episode 2715: Reward = 579.00, Steps = 9, Loss = 14.9845, Exploration Rate = 0.1000, Train Count = 27658\n",
      "Episode 2716: Reward = 594.00, Steps = 4, Loss = 30.3352, Exploration Rate = 0.1000, Train Count = 27662\n",
      "Episode 2717: Reward = 594.00, Steps = 4, Loss = 13.0017, Exploration Rate = 0.1000, Train Count = 27666\n",
      "Episode 2718: Reward = 600.00, Steps = 2, Loss = 11.2565, Exploration Rate = 0.1000, Train Count = 27668\n",
      "Episode 2719: Reward = 597.00, Steps = 3, Loss = 7.9046, Exploration Rate = 0.1000, Train Count = 27671\n",
      "Episode 2720: Reward = 594.00, Steps = 4, Loss = 8.0747, Exploration Rate = 0.1000, Train Count = 27675\n",
      "Episode 2721: Reward = 594.00, Steps = 4, Loss = 11.6503, Exploration Rate = 0.1000, Train Count = 27679\n",
      "Episode 2722: Reward = 585.00, Steps = 7, Loss = 9.3813, Exploration Rate = 0.1000, Train Count = 27686\n",
      "Episode 2723: Reward = 579.00, Steps = 9, Loss = 7.8899, Exploration Rate = 0.1000, Train Count = 27695\n",
      "Episode 2724: Reward = 588.00, Steps = 6, Loss = 7.1408, Exploration Rate = 0.1000, Train Count = 27701\n",
      "Episode 2725: Reward = 597.00, Steps = 3, Loss = 5.2843, Exploration Rate = 0.1000, Train Count = 27704\n",
      "Episode 2726: Reward = 597.00, Steps = 3, Loss = 12.0286, Exploration Rate = 0.1000, Train Count = 27707\n",
      "Episode 2727: Reward = 597.00, Steps = 3, Loss = 4.8276, Exploration Rate = 0.1000, Train Count = 27710\n",
      "Episode 2728: Reward = 585.00, Steps = 7, Loss = 12.2670, Exploration Rate = 0.1000, Train Count = 27717\n",
      "Episode 2729: Reward = 588.00, Steps = 6, Loss = 21.6166, Exploration Rate = 0.1000, Train Count = 27723\n",
      "Episode 2730: Reward = 567.00, Steps = 13, Loss = 13.5688, Exploration Rate = 0.1000, Train Count = 27736\n",
      "Episode 2731: Reward = 579.00, Steps = 9, Loss = 10.9866, Exploration Rate = 0.1000, Train Count = 27745\n",
      "Episode 2732: Reward = 594.00, Steps = 4, Loss = 13.2912, Exploration Rate = 0.1000, Train Count = 27749\n",
      "Episode 2733: Reward = 535.00, Steps = 8, Loss = 12.3657, Exploration Rate = 0.1000, Train Count = 27757\n",
      "Episode 2734: Reward = 591.00, Steps = 5, Loss = 8.3134, Exploration Rate = 0.1000, Train Count = 27762\n",
      "Episode 2735: Reward = 588.00, Steps = 6, Loss = 10.1320, Exploration Rate = 0.1000, Train Count = 27768\n",
      "Episode 2736: Reward = 582.00, Steps = 8, Loss = 7.6087, Exploration Rate = 0.1000, Train Count = 27776\n",
      "Episode 2737: Reward = 579.00, Steps = 9, Loss = 8.1194, Exploration Rate = 0.1000, Train Count = 27785\n",
      "Episode 2738: Reward = 585.00, Steps = 7, Loss = 8.4726, Exploration Rate = 0.1000, Train Count = 27792\n",
      "Episode 2739: Reward = 591.00, Steps = 5, Loss = 7.9531, Exploration Rate = 0.1000, Train Count = 27797\n",
      "Episode 2740: Reward = 597.00, Steps = 3, Loss = 6.6090, Exploration Rate = 0.1000, Train Count = 27800\n",
      "Episode 2741: Reward = 594.00, Steps = 4, Loss = 64.4935, Exploration Rate = 0.1000, Train Count = 27804\n",
      "Episode 2742: Reward = 582.00, Steps = 8, Loss = 44.7302, Exploration Rate = 0.1000, Train Count = 27812\n",
      "Episode 2743: Reward = 594.00, Steps = 4, Loss = 35.4401, Exploration Rate = 0.1000, Train Count = 27816\n",
      "Episode 2744: Reward = 585.00, Steps = 7, Loss = 35.3372, Exploration Rate = 0.1000, Train Count = 27823\n",
      "Episode 2745: Reward = 591.00, Steps = 5, Loss = 31.0011, Exploration Rate = 0.1000, Train Count = 27828\n",
      "Episode 2746: Reward = 582.00, Steps = 8, Loss = 25.1495, Exploration Rate = 0.1000, Train Count = 27836\n",
      "Episode 2747: Reward = 597.00, Steps = 3, Loss = 19.9799, Exploration Rate = 0.1000, Train Count = 27839\n",
      "Episode 2748: Reward = 576.00, Steps = 10, Loss = 21.3589, Exploration Rate = 0.1000, Train Count = 27849\n",
      "Episode 2749: Reward = 588.00, Steps = 6, Loss = 17.1441, Exploration Rate = 0.1000, Train Count = 27855\n",
      "Episode 2750: Reward = 570.00, Steps = 12, Loss = 18.3241, Exploration Rate = 0.1000, Train Count = 27867\n",
      "Episode 2751: Reward = 588.00, Steps = 6, Loss = 15.0377, Exploration Rate = 0.1000, Train Count = 27873\n",
      "Episode 2752: Reward = 588.00, Steps = 6, Loss = 14.7143, Exploration Rate = 0.1000, Train Count = 27879\n",
      "Episode 2753: Reward = 594.00, Steps = 4, Loss = 10.0948, Exploration Rate = 0.1000, Train Count = 27883\n",
      "Episode 2754: Reward = 576.00, Steps = 10, Loss = 7.7153, Exploration Rate = 0.1000, Train Count = 27893\n",
      "Episode 2755: Reward = 591.00, Steps = 5, Loss = 15.3668, Exploration Rate = 0.1000, Train Count = 27898\n",
      "Episode 2756: Reward = 594.00, Steps = 4, Loss = 11.4719, Exploration Rate = 0.1000, Train Count = 27902\n",
      "Episode 2757: Reward = 597.00, Steps = 3, Loss = 20.6947, Exploration Rate = 0.1000, Train Count = 27905\n",
      "Episode 2758: Reward = 591.00, Steps = 5, Loss = 9.7679, Exploration Rate = 0.1000, Train Count = 27910\n",
      "Episode 2759: Reward = 591.00, Steps = 5, Loss = 6.5018, Exploration Rate = 0.1000, Train Count = 27915\n",
      "Episode 2760: Reward = 591.00, Steps = 5, Loss = 12.4563, Exploration Rate = 0.1000, Train Count = 27920\n",
      "Episode 2761: Reward = 576.00, Steps = 10, Loss = 10.3684, Exploration Rate = 0.1000, Train Count = 27930\n",
      "Episode 2762: Reward = 594.00, Steps = 4, Loss = 11.4832, Exploration Rate = 0.1000, Train Count = 27934\n",
      "Episode 2763: Reward = 594.00, Steps = 4, Loss = 10.5658, Exploration Rate = 0.1000, Train Count = 27938\n",
      "Episode 2764: Reward = 582.00, Steps = 8, Loss = 6.3616, Exploration Rate = 0.1000, Train Count = 27946\n",
      "Episode 2765: Reward = 591.00, Steps = 5, Loss = 5.5410, Exploration Rate = 0.1000, Train Count = 27951\n",
      "Episode 2766: Reward = 594.00, Steps = 4, Loss = 7.4422, Exploration Rate = 0.1000, Train Count = 27955\n",
      "Episode 2767: Reward = 597.00, Steps = 3, Loss = 5.7867, Exploration Rate = 0.1000, Train Count = 27958\n",
      "Episode 2768: Reward = 588.00, Steps = 6, Loss = 7.7044, Exploration Rate = 0.1000, Train Count = 27964\n",
      "Episode 2769: Reward = 591.00, Steps = 5, Loss = 4.3389, Exploration Rate = 0.1000, Train Count = 27969\n",
      "Episode 2770: Reward = 591.00, Steps = 5, Loss = 4.9508, Exploration Rate = 0.1000, Train Count = 27974\n",
      "Episode 2771: Reward = 576.00, Steps = 10, Loss = 5.5166, Exploration Rate = 0.1000, Train Count = 27984\n",
      "Episode 2772: Reward = 582.00, Steps = 8, Loss = 4.0434, Exploration Rate = 0.1000, Train Count = 27992\n",
      "Episode 2773: Reward = 591.00, Steps = 5, Loss = 4.1735, Exploration Rate = 0.1000, Train Count = 27997\n",
      "Episode 2774: Reward = 594.00, Steps = 4, Loss = 4.7053, Exploration Rate = 0.1000, Train Count = 28001\n",
      "Episode 2775: Reward = 585.00, Steps = 7, Loss = 3.3749, Exploration Rate = 0.1000, Train Count = 28008\n",
      "Episode 2776: Reward = 582.00, Steps = 8, Loss = 2.6402, Exploration Rate = 0.1000, Train Count = 28016\n",
      "Episode 2777: Reward = 594.00, Steps = 4, Loss = 2.6819, Exploration Rate = 0.1000, Train Count = 28020\n",
      "Episode 2778: Reward = 576.00, Steps = 10, Loss = 3.4533, Exploration Rate = 0.1000, Train Count = 28030\n",
      "Episode 2779: Reward = 585.00, Steps = 7, Loss = 3.8131, Exploration Rate = 0.1000, Train Count = 28037\n",
      "Episode 2780: Reward = 591.00, Steps = 5, Loss = 2.7685, Exploration Rate = 0.1000, Train Count = 28042\n",
      "Episode 2781: Reward = 544.00, Steps = 5, Loss = 9.8449, Exploration Rate = 0.1000, Train Count = 28047\n",
      "Episode 2782: Reward = 579.00, Steps = 9, Loss = 5.5874, Exploration Rate = 0.1000, Train Count = 28056\n",
      "Episode 2783: Reward = 597.00, Steps = 3, Loss = 3.6396, Exploration Rate = 0.1000, Train Count = 28059\n",
      "Episode 2784: Reward = 591.00, Steps = 5, Loss = 13.2235, Exploration Rate = 0.1000, Train Count = 28064\n",
      "Episode 2785: Reward = 591.00, Steps = 5, Loss = 8.0125, Exploration Rate = 0.1000, Train Count = 28069\n",
      "Episode 2786: Reward = 591.00, Steps = 5, Loss = 9.9538, Exploration Rate = 0.1000, Train Count = 28074\n",
      "Episode 2787: Reward = 582.00, Steps = 8, Loss = 13.8450, Exploration Rate = 0.1000, Train Count = 28082\n",
      "Episode 2788: Reward = 594.00, Steps = 4, Loss = 22.0841, Exploration Rate = 0.1000, Train Count = 28086\n",
      "Episode 2789: Reward = 591.00, Steps = 5, Loss = 10.8539, Exploration Rate = 0.1000, Train Count = 28091\n",
      "Episode 2790: Reward = 555.00, Steps = 17, Loss = 12.3097, Exploration Rate = 0.1000, Train Count = 28108\n",
      "Episode 2791: Reward = 591.00, Steps = 5, Loss = 8.4522, Exploration Rate = 0.1000, Train Count = 28113\n",
      "Episode 2792: Reward = 600.00, Steps = 2, Loss = 6.3550, Exploration Rate = 0.1000, Train Count = 28115\n",
      "Episode 2793: Reward = 538.00, Steps = 7, Loss = 5.3973, Exploration Rate = 0.1000, Train Count = 28122\n",
      "Episode 2794: Reward = 570.00, Steps = 12, Loss = 9.4956, Exploration Rate = 0.1000, Train Count = 28134\n",
      "Episode 2795: Reward = 591.00, Steps = 5, Loss = 7.4855, Exploration Rate = 0.1000, Train Count = 28139\n",
      "Episode 2796: Reward = 570.00, Steps = 12, Loss = 6.0319, Exploration Rate = 0.1000, Train Count = 28151\n",
      "Episode 2797: Reward = 591.00, Steps = 5, Loss = 9.7534, Exploration Rate = 0.1000, Train Count = 28156\n",
      "Episode 2798: Reward = 597.00, Steps = 3, Loss = 9.5642, Exploration Rate = 0.1000, Train Count = 28159\n",
      "Episode 2799: Reward = 594.00, Steps = 4, Loss = 4.6863, Exploration Rate = 0.1000, Train Count = 28163\n",
      "Episode 2800: Reward = 594.00, Steps = 4, Loss = 7.9175, Exploration Rate = 0.1000, Train Count = 28167\n",
      "Episode 2801: Reward = 588.00, Steps = 6, Loss = 6.0954, Exploration Rate = 0.1000, Train Count = 28173\n",
      "Episode 2802: Reward = 597.00, Steps = 3, Loss = 5.7064, Exploration Rate = 0.1000, Train Count = 28176\n",
      "Episode 2803: Reward = 597.00, Steps = 3, Loss = 7.2233, Exploration Rate = 0.1000, Train Count = 28179\n",
      "Episode 2804: Reward = 579.00, Steps = 9, Loss = 9.5516, Exploration Rate = 0.1000, Train Count = 28188\n",
      "Episode 2805: Reward = 597.00, Steps = 3, Loss = 3.4082, Exploration Rate = 0.1000, Train Count = 28191\n",
      "Episode 2806: Reward = 585.00, Steps = 7, Loss = 6.7113, Exploration Rate = 0.1000, Train Count = 28198\n",
      "Episode 2807: Reward = 588.00, Steps = 6, Loss = 5.5191, Exploration Rate = 0.1000, Train Count = 28204\n",
      "Episode 2808: Reward = 591.00, Steps = 5, Loss = 5.3272, Exploration Rate = 0.1000, Train Count = 28209\n",
      "Episode 2809: Reward = 591.00, Steps = 5, Loss = 7.5417, Exploration Rate = 0.1000, Train Count = 28214\n",
      "Episode 2810: Reward = 600.00, Steps = 2, Loss = 11.4339, Exploration Rate = 0.1000, Train Count = 28216\n",
      "Episode 2811: Reward = 597.00, Steps = 3, Loss = 4.9578, Exploration Rate = 0.1000, Train Count = 28219\n",
      "Episode 2812: Reward = 529.00, Steps = 10, Loss = 7.6034, Exploration Rate = 0.1000, Train Count = 28229\n",
      "Episode 2813: Reward = 588.00, Steps = 6, Loss = 4.3411, Exploration Rate = 0.1000, Train Count = 28235\n",
      "Episode 2814: Reward = 582.00, Steps = 8, Loss = 4.4843, Exploration Rate = 0.1000, Train Count = 28243\n",
      "Episode 2815: Reward = 541.00, Steps = 6, Loss = 5.1717, Exploration Rate = 0.1000, Train Count = 28249\n",
      "Episode 2816: Reward = 594.00, Steps = 4, Loss = 12.4210, Exploration Rate = 0.1000, Train Count = 28253\n",
      "Episode 2817: Reward = 585.00, Steps = 7, Loss = 5.0011, Exploration Rate = 0.1000, Train Count = 28260\n",
      "Episode 2818: Reward = 594.00, Steps = 4, Loss = 6.4613, Exploration Rate = 0.1000, Train Count = 28264\n",
      "Episode 2819: Reward = 594.00, Steps = 4, Loss = 6.0625, Exploration Rate = 0.1000, Train Count = 28268\n",
      "Episode 2820: Reward = 588.00, Steps = 6, Loss = 8.0352, Exploration Rate = 0.1000, Train Count = 28274\n",
      "Episode 2821: Reward = 585.00, Steps = 7, Loss = 4.4375, Exploration Rate = 0.1000, Train Count = 28281\n",
      "Episode 2822: Reward = 585.00, Steps = 7, Loss = 8.4821, Exploration Rate = 0.1000, Train Count = 28288\n",
      "Episode 2823: Reward = 588.00, Steps = 6, Loss = 8.5281, Exploration Rate = 0.1000, Train Count = 28294\n",
      "Episode 2824: Reward = 591.00, Steps = 5, Loss = 6.7096, Exploration Rate = 0.1000, Train Count = 28299\n",
      "Episode 2825: Reward = 585.00, Steps = 7, Loss = 48.4132, Exploration Rate = 0.1000, Train Count = 28306\n",
      "Episode 2826: Reward = 585.00, Steps = 7, Loss = 37.4246, Exploration Rate = 0.1000, Train Count = 28313\n",
      "Episode 2827: Reward = 538.00, Steps = 7, Loss = 31.1179, Exploration Rate = 0.1000, Train Count = 28320\n",
      "Episode 2828: Reward = 588.00, Steps = 6, Loss = 25.5585, Exploration Rate = 0.1000, Train Count = 28326\n",
      "Episode 2829: Reward = 594.00, Steps = 4, Loss = 24.4727, Exploration Rate = 0.1000, Train Count = 28330\n",
      "Episode 2830: Reward = 585.00, Steps = 7, Loss = 20.3401, Exploration Rate = 0.1000, Train Count = 28337\n",
      "Episode 2831: Reward = 594.00, Steps = 4, Loss = 15.4016, Exploration Rate = 0.1000, Train Count = 28341\n",
      "Episode 2832: Reward = 594.00, Steps = 4, Loss = 18.4100, Exploration Rate = 0.1000, Train Count = 28345\n",
      "Episode 2833: Reward = 591.00, Steps = 5, Loss = 12.8101, Exploration Rate = 0.1000, Train Count = 28350\n",
      "Episode 2834: Reward = 585.00, Steps = 7, Loss = 11.2657, Exploration Rate = 0.1000, Train Count = 28357\n",
      "Episode 2835: Reward = 591.00, Steps = 5, Loss = 16.7637, Exploration Rate = 0.1000, Train Count = 28362\n",
      "Episode 2836: Reward = 591.00, Steps = 5, Loss = 11.4890, Exploration Rate = 0.1000, Train Count = 28367\n",
      "Episode 2837: Reward = 591.00, Steps = 5, Loss = 13.7807, Exploration Rate = 0.1000, Train Count = 28372\n",
      "Episode 2838: Reward = 591.00, Steps = 5, Loss = 13.3842, Exploration Rate = 0.1000, Train Count = 28377\n",
      "Episode 2839: Reward = 585.00, Steps = 7, Loss = 11.2511, Exploration Rate = 0.1000, Train Count = 28384\n",
      "Episode 2840: Reward = 564.00, Steps = 14, Loss = 10.1880, Exploration Rate = 0.1000, Train Count = 28398\n",
      "Episode 2841: Reward = 588.00, Steps = 6, Loss = 6.0212, Exploration Rate = 0.1000, Train Count = 28404\n",
      "Episode 2842: Reward = 591.00, Steps = 5, Loss = 10.6476, Exploration Rate = 0.1000, Train Count = 28409\n",
      "Episode 2843: Reward = 591.00, Steps = 5, Loss = 9.3189, Exploration Rate = 0.1000, Train Count = 28414\n",
      "Episode 2844: Reward = 591.00, Steps = 5, Loss = 14.3261, Exploration Rate = 0.1000, Train Count = 28419\n",
      "Episode 2845: Reward = 585.00, Steps = 7, Loss = 9.0212, Exploration Rate = 0.1000, Train Count = 28426\n",
      "Episode 2846: Reward = 594.00, Steps = 4, Loss = 8.5768, Exploration Rate = 0.1000, Train Count = 28430\n",
      "Episode 2847: Reward = 585.00, Steps = 7, Loss = 20.6911, Exploration Rate = 0.1000, Train Count = 28437\n",
      "Episode 2848: Reward = 591.00, Steps = 5, Loss = 14.7870, Exploration Rate = 0.1000, Train Count = 28442\n",
      "Episode 2849: Reward = 597.00, Steps = 3, Loss = 18.6746, Exploration Rate = 0.1000, Train Count = 28445\n",
      "Episode 2850: Reward = 597.00, Steps = 3, Loss = 12.9563, Exploration Rate = 0.1000, Train Count = 28448\n",
      "Episode 2851: Reward = 538.00, Steps = 7, Loss = 11.0055, Exploration Rate = 0.1000, Train Count = 28455\n",
      "Episode 2852: Reward = 597.00, Steps = 3, Loss = 13.5938, Exploration Rate = 0.1000, Train Count = 28458\n",
      "Episode 2853: Reward = 579.00, Steps = 9, Loss = 8.1191, Exploration Rate = 0.1000, Train Count = 28467\n",
      "Episode 2854: Reward = 588.00, Steps = 6, Loss = 6.9486, Exploration Rate = 0.1000, Train Count = 28473\n",
      "Episode 2855: Reward = 591.00, Steps = 5, Loss = 11.5733, Exploration Rate = 0.1000, Train Count = 28478\n",
      "Episode 2856: Reward = 600.00, Steps = 2, Loss = 9.9676, Exploration Rate = 0.1000, Train Count = 28480\n",
      "Episode 2857: Reward = 594.00, Steps = 4, Loss = 6.7348, Exploration Rate = 0.1000, Train Count = 28484\n",
      "Episode 2858: Reward = 591.00, Steps = 5, Loss = 11.2755, Exploration Rate = 0.1000, Train Count = 28489\n",
      "Episode 2859: Reward = 591.00, Steps = 5, Loss = 10.1129, Exploration Rate = 0.1000, Train Count = 28494\n",
      "Episode 2860: Reward = 594.00, Steps = 4, Loss = 9.0928, Exploration Rate = 0.1000, Train Count = 28498\n",
      "Episode 2861: Reward = 582.00, Steps = 8, Loss = 11.7871, Exploration Rate = 0.1000, Train Count = 28506\n",
      "Episode 2862: Reward = 588.00, Steps = 6, Loss = 9.9309, Exploration Rate = 0.1000, Train Count = 28512\n",
      "Episode 2863: Reward = 600.00, Steps = 2, Loss = 11.2131, Exploration Rate = 0.1000, Train Count = 28514\n",
      "Episode 2864: Reward = 582.00, Steps = 8, Loss = 11.2497, Exploration Rate = 0.1000, Train Count = 28522\n",
      "Episode 2865: Reward = 591.00, Steps = 5, Loss = 10.9474, Exploration Rate = 0.1000, Train Count = 28527\n",
      "Episode 2866: Reward = 594.00, Steps = 4, Loss = 12.2476, Exploration Rate = 0.1000, Train Count = 28531\n",
      "Episode 2867: Reward = 582.00, Steps = 8, Loss = 8.4700, Exploration Rate = 0.1000, Train Count = 28539\n",
      "Episode 2868: Reward = 582.00, Steps = 8, Loss = 5.9466, Exploration Rate = 0.1000, Train Count = 28547\n",
      "Episode 2869: Reward = 585.00, Steps = 7, Loss = 8.0856, Exploration Rate = 0.1000, Train Count = 28554\n",
      "Episode 2870: Reward = 585.00, Steps = 7, Loss = 7.7724, Exploration Rate = 0.1000, Train Count = 28561\n",
      "Episode 2871: Reward = 594.00, Steps = 4, Loss = 7.1997, Exploration Rate = 0.1000, Train Count = 28565\n",
      "Episode 2872: Reward = 600.00, Steps = 2, Loss = 6.4709, Exploration Rate = 0.1000, Train Count = 28567\n",
      "Episode 2873: Reward = 585.00, Steps = 7, Loss = 10.1249, Exploration Rate = 0.1000, Train Count = 28574\n",
      "Episode 2874: Reward = 597.00, Steps = 3, Loss = 18.5716, Exploration Rate = 0.1000, Train Count = 28577\n",
      "Episode 2875: Reward = 579.00, Steps = 9, Loss = 22.1639, Exploration Rate = 0.1000, Train Count = 28586\n",
      "Episode 2876: Reward = 597.00, Steps = 3, Loss = 24.4946, Exploration Rate = 0.1000, Train Count = 28589\n",
      "Episode 2877: Reward = 594.00, Steps = 4, Loss = 18.3479, Exploration Rate = 0.1000, Train Count = 28593\n",
      "Episode 2878: Reward = 600.00, Steps = 2, Loss = 20.1796, Exploration Rate = 0.1000, Train Count = 28595\n",
      "Episode 2879: Reward = 597.00, Steps = 3, Loss = 10.7040, Exploration Rate = 0.1000, Train Count = 28598\n",
      "Episode 2880: Reward = 597.00, Steps = 3, Loss = 12.3062, Exploration Rate = 0.1000, Train Count = 28601\n",
      "Episode 2881: Reward = 588.00, Steps = 6, Loss = 11.8321, Exploration Rate = 0.1000, Train Count = 28607\n",
      "Episode 2882: Reward = 538.00, Steps = 7, Loss = 10.6419, Exploration Rate = 0.1000, Train Count = 28614\n",
      "Episode 2883: Reward = 597.00, Steps = 3, Loss = 7.1982, Exploration Rate = 0.1000, Train Count = 28617\n",
      "Episode 2884: Reward = 576.00, Steps = 10, Loss = 8.0398, Exploration Rate = 0.1000, Train Count = 28627\n",
      "Episode 2885: Reward = 579.00, Steps = 9, Loss = 13.4005, Exploration Rate = 0.1000, Train Count = 28636\n",
      "Episode 2886: Reward = 591.00, Steps = 5, Loss = 8.2737, Exploration Rate = 0.1000, Train Count = 28641\n",
      "Episode 2887: Reward = 588.00, Steps = 6, Loss = 10.0413, Exploration Rate = 0.1000, Train Count = 28647\n",
      "Episode 2888: Reward = 591.00, Steps = 5, Loss = 8.1818, Exploration Rate = 0.1000, Train Count = 28652\n",
      "Episode 2889: Reward = 594.00, Steps = 4, Loss = 7.7677, Exploration Rate = 0.1000, Train Count = 28656\n",
      "Episode 2890: Reward = 564.00, Steps = 14, Loss = 7.9008, Exploration Rate = 0.1000, Train Count = 28670\n",
      "Episode 2891: Reward = 588.00, Steps = 6, Loss = 5.7755, Exploration Rate = 0.1000, Train Count = 28676\n",
      "Episode 2892: Reward = 594.00, Steps = 4, Loss = 9.3757, Exploration Rate = 0.1000, Train Count = 28680\n",
      "Episode 2893: Reward = 588.00, Steps = 6, Loss = 6.4301, Exploration Rate = 0.1000, Train Count = 28686\n",
      "Episode 2894: Reward = 591.00, Steps = 5, Loss = 5.7148, Exploration Rate = 0.1000, Train Count = 28691\n",
      "Episode 2895: Reward = 588.00, Steps = 6, Loss = 7.0779, Exploration Rate = 0.1000, Train Count = 28697\n",
      "Episode 2896: Reward = 588.00, Steps = 6, Loss = 8.1533, Exploration Rate = 0.1000, Train Count = 28703\n",
      "Episode 2897: Reward = 585.00, Steps = 7, Loss = 10.3675, Exploration Rate = 0.1000, Train Count = 28710\n",
      "Episode 2898: Reward = 594.00, Steps = 4, Loss = 9.1198, Exploration Rate = 0.1000, Train Count = 28714\n",
      "Episode 2899: Reward = 588.00, Steps = 6, Loss = 11.3565, Exploration Rate = 0.1000, Train Count = 28720\n",
      "Episode 2900: Reward = 585.00, Steps = 7, Loss = 7.6846, Exploration Rate = 0.1000, Train Count = 28727\n",
      "Episode 2901: Reward = 591.00, Steps = 5, Loss = 6.8954, Exploration Rate = 0.1000, Train Count = 28732\n",
      "Episode 2902: Reward = 594.00, Steps = 4, Loss = 6.0820, Exploration Rate = 0.1000, Train Count = 28736\n",
      "Episode 2903: Reward = 591.00, Steps = 5, Loss = 6.0874, Exploration Rate = 0.1000, Train Count = 28741\n",
      "Episode 2904: Reward = 591.00, Steps = 5, Loss = 5.1028, Exploration Rate = 0.1000, Train Count = 28746\n",
      "Episode 2905: Reward = 594.00, Steps = 4, Loss = 4.1551, Exploration Rate = 0.1000, Train Count = 28750\n",
      "Episode 2906: Reward = 588.00, Steps = 6, Loss = 3.8811, Exploration Rate = 0.1000, Train Count = 28756\n",
      "Episode 2907: Reward = 600.00, Steps = 2, Loss = 5.4612, Exploration Rate = 0.1000, Train Count = 28758\n",
      "Episode 2908: Reward = 585.00, Steps = 7, Loss = 5.0752, Exploration Rate = 0.1000, Train Count = 28765\n",
      "Episode 2909: Reward = 579.00, Steps = 9, Loss = 4.5337, Exploration Rate = 0.1000, Train Count = 28774\n",
      "Episode 2910: Reward = 597.00, Steps = 3, Loss = 4.3079, Exploration Rate = 0.1000, Train Count = 28777\n",
      "Episode 2911: Reward = 597.00, Steps = 3, Loss = 2.2126, Exploration Rate = 0.1000, Train Count = 28780\n",
      "Episode 2912: Reward = 600.00, Steps = 2, Loss = 2.2480, Exploration Rate = 0.1000, Train Count = 28782\n",
      "Episode 2913: Reward = 585.00, Steps = 7, Loss = 2.5594, Exploration Rate = 0.1000, Train Count = 28789\n",
      "Episode 2914: Reward = 588.00, Steps = 6, Loss = 6.0879, Exploration Rate = 0.1000, Train Count = 28795\n",
      "Episode 2915: Reward = 600.00, Steps = 2, Loss = 4.0030, Exploration Rate = 0.1000, Train Count = 28797\n",
      "Episode 2916: Reward = 588.00, Steps = 6, Loss = 29.0479, Exploration Rate = 0.1000, Train Count = 28803\n",
      "Episode 2917: Reward = 597.00, Steps = 3, Loss = 43.6437, Exploration Rate = 0.1000, Train Count = 28806\n",
      "Episode 2918: Reward = 585.00, Steps = 7, Loss = 33.8811, Exploration Rate = 0.1000, Train Count = 28813\n",
      "Episode 2919: Reward = 573.00, Steps = 11, Loss = 24.7250, Exploration Rate = 0.1000, Train Count = 28824\n",
      "Episode 2920: Reward = 570.00, Steps = 12, Loss = 16.4531, Exploration Rate = 0.1000, Train Count = 28836\n",
      "Episode 2921: Reward = 597.00, Steps = 3, Loss = 12.6670, Exploration Rate = 0.1000, Train Count = 28839\n",
      "Episode 2922: Reward = 591.00, Steps = 5, Loss = 13.6934, Exploration Rate = 0.1000, Train Count = 28844\n",
      "Episode 2923: Reward = 597.00, Steps = 3, Loss = 12.0503, Exploration Rate = 0.1000, Train Count = 28847\n",
      "Episode 2924: Reward = 585.00, Steps = 7, Loss = 11.1317, Exploration Rate = 0.1000, Train Count = 28854\n",
      "Episode 2925: Reward = 591.00, Steps = 5, Loss = 9.3094, Exploration Rate = 0.1000, Train Count = 28859\n",
      "Episode 2926: Reward = 591.00, Steps = 5, Loss = 10.0548, Exploration Rate = 0.1000, Train Count = 28864\n",
      "Episode 2927: Reward = 579.00, Steps = 9, Loss = 6.8541, Exploration Rate = 0.1000, Train Count = 28873\n",
      "Episode 2928: Reward = 582.00, Steps = 8, Loss = 7.2025, Exploration Rate = 0.1000, Train Count = 28881\n",
      "Episode 2929: Reward = 588.00, Steps = 6, Loss = 4.5832, Exploration Rate = 0.1000, Train Count = 28887\n",
      "Episode 2930: Reward = 588.00, Steps = 6, Loss = 4.8814, Exploration Rate = 0.1000, Train Count = 28893\n",
      "Episode 2931: Reward = 582.00, Steps = 8, Loss = 6.7141, Exploration Rate = 0.1000, Train Count = 28901\n",
      "Episode 2932: Reward = 591.00, Steps = 5, Loss = 5.3593, Exploration Rate = 0.1000, Train Count = 28906\n",
      "Episode 2933: Reward = 585.00, Steps = 7, Loss = 7.2225, Exploration Rate = 0.1000, Train Count = 28913\n",
      "Episode 2934: Reward = 576.00, Steps = 10, Loss = 8.7004, Exploration Rate = 0.1000, Train Count = 28923\n",
      "Episode 2935: Reward = 526.00, Steps = 11, Loss = 8.9575, Exploration Rate = 0.1000, Train Count = 28934\n",
      "Episode 2936: Reward = 558.00, Steps = 16, Loss = 7.9261, Exploration Rate = 0.1000, Train Count = 28950\n",
      "Episode 2937: Reward = 591.00, Steps = 5, Loss = 6.5790, Exploration Rate = 0.1000, Train Count = 28955\n",
      "Episode 2938: Reward = 588.00, Steps = 6, Loss = 7.6659, Exploration Rate = 0.1000, Train Count = 28961\n",
      "Episode 2939: Reward = 594.00, Steps = 4, Loss = 5.3707, Exploration Rate = 0.1000, Train Count = 28965\n",
      "Episode 2940: Reward = 588.00, Steps = 6, Loss = 4.5987, Exploration Rate = 0.1000, Train Count = 28971\n",
      "Episode 2941: Reward = 594.00, Steps = 4, Loss = 8.0904, Exploration Rate = 0.1000, Train Count = 28975\n",
      "Episode 2942: Reward = 588.00, Steps = 6, Loss = 5.3058, Exploration Rate = 0.1000, Train Count = 28981\n",
      "Episode 2943: Reward = 585.00, Steps = 7, Loss = 5.5771, Exploration Rate = 0.1000, Train Count = 28988\n",
      "Episode 2944: Reward = 594.00, Steps = 4, Loss = 5.4073, Exploration Rate = 0.1000, Train Count = 28992\n",
      "Episode 2945: Reward = 591.00, Steps = 5, Loss = 5.7913, Exploration Rate = 0.1000, Train Count = 28997\n",
      "Episode 2946: Reward = 541.00, Steps = 6, Loss = 5.3452, Exploration Rate = 0.1000, Train Count = 29003\n",
      "Episode 2947: Reward = 579.00, Steps = 9, Loss = 14.6286, Exploration Rate = 0.1000, Train Count = 29012\n",
      "Episode 2948: Reward = 591.00, Steps = 5, Loss = 18.1983, Exploration Rate = 0.1000, Train Count = 29017\n",
      "Episode 2949: Reward = 594.00, Steps = 4, Loss = 13.6575, Exploration Rate = 0.1000, Train Count = 29021\n",
      "Episode 2950: Reward = 588.00, Steps = 6, Loss = 9.7104, Exploration Rate = 0.1000, Train Count = 29027\n",
      "Episode 2951: Reward = 573.00, Steps = 11, Loss = 11.9542, Exploration Rate = 0.1000, Train Count = 29038\n",
      "Episode 2952: Reward = 591.00, Steps = 5, Loss = 25.5664, Exploration Rate = 0.1000, Train Count = 29043\n",
      "Episode 2953: Reward = 594.00, Steps = 4, Loss = 11.0726, Exploration Rate = 0.1000, Train Count = 29047\n",
      "Episode 2954: Reward = 597.00, Steps = 3, Loss = 8.7185, Exploration Rate = 0.1000, Train Count = 29050\n",
      "Episode 2955: Reward = 597.00, Steps = 3, Loss = 6.5673, Exploration Rate = 0.1000, Train Count = 29053\n",
      "Episode 2956: Reward = 570.00, Steps = 12, Loss = 7.2991, Exploration Rate = 0.1000, Train Count = 29065\n",
      "Episode 2957: Reward = 585.00, Steps = 7, Loss = 5.9334, Exploration Rate = 0.1000, Train Count = 29072\n",
      "Episode 2958: Reward = 585.00, Steps = 7, Loss = 4.1040, Exploration Rate = 0.1000, Train Count = 29079\n",
      "Episode 2959: Reward = 591.00, Steps = 5, Loss = 4.2031, Exploration Rate = 0.1000, Train Count = 29084\n",
      "Episode 2960: Reward = 600.00, Steps = 2, Loss = 4.1855, Exploration Rate = 0.1000, Train Count = 29086\n",
      "Episode 2961: Reward = 529.00, Steps = 10, Loss = 5.1694, Exploration Rate = 0.1000, Train Count = 29096\n",
      "Episode 2962: Reward = 594.00, Steps = 4, Loss = 3.7557, Exploration Rate = 0.1000, Train Count = 29100\n",
      "Episode 2963: Reward = 594.00, Steps = 4, Loss = 4.1895, Exploration Rate = 0.1000, Train Count = 29104\n",
      "Episode 2964: Reward = 588.00, Steps = 6, Loss = 6.5903, Exploration Rate = 0.1000, Train Count = 29110\n",
      "Episode 2965: Reward = 594.00, Steps = 4, Loss = 4.1968, Exploration Rate = 0.1000, Train Count = 29114\n",
      "Episode 2966: Reward = 591.00, Steps = 5, Loss = 4.5958, Exploration Rate = 0.1000, Train Count = 29119\n",
      "Episode 2967: Reward = 582.00, Steps = 8, Loss = 4.0966, Exploration Rate = 0.1000, Train Count = 29127\n",
      "Episode 2968: Reward = 567.00, Steps = 13, Loss = 5.2641, Exploration Rate = 0.1000, Train Count = 29140\n",
      "Episode 2969: Reward = 585.00, Steps = 7, Loss = 4.4058, Exploration Rate = 0.1000, Train Count = 29147\n",
      "Episode 2970: Reward = 585.00, Steps = 7, Loss = 6.3046, Exploration Rate = 0.1000, Train Count = 29154\n",
      "Episode 2971: Reward = 585.00, Steps = 7, Loss = 8.5886, Exploration Rate = 0.1000, Train Count = 29161\n",
      "Episode 2972: Reward = 582.00, Steps = 8, Loss = 7.4730, Exploration Rate = 0.1000, Train Count = 29169\n",
      "Episode 2973: Reward = 576.00, Steps = 10, Loss = 7.6627, Exploration Rate = 0.1000, Train Count = 29179\n",
      "Episode 2974: Reward = 579.00, Steps = 9, Loss = 6.2664, Exploration Rate = 0.1000, Train Count = 29188\n",
      "Episode 2975: Reward = 582.00, Steps = 8, Loss = 4.8158, Exploration Rate = 0.1000, Train Count = 29196\n",
      "Episode 2976: Reward = 579.00, Steps = 9, Loss = 3.4142, Exploration Rate = 0.1000, Train Count = 29205\n",
      "Episode 2977: Reward = 591.00, Steps = 5, Loss = 3.0712, Exploration Rate = 0.1000, Train Count = 29210\n",
      "Episode 2978: Reward = 588.00, Steps = 6, Loss = 2.1665, Exploration Rate = 0.1000, Train Count = 29216\n",
      "Episode 2979: Reward = 591.00, Steps = 5, Loss = 3.2025, Exploration Rate = 0.1000, Train Count = 29221\n",
      "Episode 2980: Reward = 591.00, Steps = 5, Loss = 2.4995, Exploration Rate = 0.1000, Train Count = 29226\n",
      "Episode 2981: Reward = 576.00, Steps = 10, Loss = 1.9544, Exploration Rate = 0.1000, Train Count = 29236\n",
      "Episode 2982: Reward = 591.00, Steps = 5, Loss = 4.1162, Exploration Rate = 0.1000, Train Count = 29241\n",
      "Episode 2983: Reward = 597.00, Steps = 3, Loss = 2.6427, Exploration Rate = 0.1000, Train Count = 29244\n",
      "Episode 2984: Reward = 582.00, Steps = 8, Loss = 2.7540, Exploration Rate = 0.1000, Train Count = 29252\n",
      "Episode 2985: Reward = 597.00, Steps = 3, Loss = 2.9628, Exploration Rate = 0.1000, Train Count = 29255\n",
      "Episode 2986: Reward = 585.00, Steps = 7, Loss = 3.1705, Exploration Rate = 0.1000, Train Count = 29262\n",
      "Episode 2987: Reward = 585.00, Steps = 7, Loss = 3.0828, Exploration Rate = 0.1000, Train Count = 29269\n",
      "Episode 2988: Reward = 591.00, Steps = 5, Loss = 3.2976, Exploration Rate = 0.1000, Train Count = 29274\n",
      "Episode 2989: Reward = 582.00, Steps = 8, Loss = 8.2885, Exploration Rate = 0.1000, Train Count = 29282\n",
      "Episode 2990: Reward = 594.00, Steps = 4, Loss = 2.9301, Exploration Rate = 0.1000, Train Count = 29286\n",
      "Episode 2991: Reward = 585.00, Steps = 7, Loss = 16.6106, Exploration Rate = 0.1000, Train Count = 29293\n",
      "Episode 2992: Reward = 585.00, Steps = 7, Loss = 5.1900, Exploration Rate = 0.1000, Train Count = 29300\n",
      "Episode 2993: Reward = 576.00, Steps = 10, Loss = 36.7598, Exploration Rate = 0.1000, Train Count = 29310\n",
      "Episode 2994: Reward = 597.00, Steps = 3, Loss = 27.9469, Exploration Rate = 0.1000, Train Count = 29313\n",
      "Episode 2995: Reward = 585.00, Steps = 7, Loss = 23.1573, Exploration Rate = 0.1000, Train Count = 29320\n",
      "Episode 2996: Reward = 591.00, Steps = 5, Loss = 16.2846, Exploration Rate = 0.1000, Train Count = 29325\n",
      "Episode 2997: Reward = 567.00, Steps = 13, Loss = 18.3144, Exploration Rate = 0.1000, Train Count = 29338\n",
      "Episode 2998: Reward = 585.00, Steps = 7, Loss = 12.0176, Exploration Rate = 0.1000, Train Count = 29345\n",
      "Episode 2999: Reward = 594.00, Steps = 4, Loss = 44.5719, Exploration Rate = 0.1000, Train Count = 29349\n",
      "Episode 3000: Reward = 594.00, Steps = 4, Loss = 15.2037, Exploration Rate = 0.1000, Train Count = 29353\n",
      "Episode 3001: Reward = 597.00, Steps = 3, Loss = 16.1740, Exploration Rate = 0.1000, Train Count = 29356\n",
      "Episode 3002: Reward = 597.00, Steps = 3, Loss = 13.0594, Exploration Rate = 0.1000, Train Count = 29359\n",
      "Episode 3003: Reward = 582.00, Steps = 8, Loss = 11.6547, Exploration Rate = 0.1000, Train Count = 29367\n",
      "Episode 3004: Reward = 529.00, Steps = 10, Loss = 10.5405, Exploration Rate = 0.1000, Train Count = 29377\n",
      "Episode 3005: Reward = 588.00, Steps = 6, Loss = 10.1098, Exploration Rate = 0.1000, Train Count = 29383\n",
      "Episode 3006: Reward = 591.00, Steps = 5, Loss = 9.5559, Exploration Rate = 0.1000, Train Count = 29388\n",
      "Episode 3007: Reward = 591.00, Steps = 5, Loss = 6.7451, Exploration Rate = 0.1000, Train Count = 29393\n",
      "Episode 3008: Reward = 588.00, Steps = 6, Loss = 5.6923, Exploration Rate = 0.1000, Train Count = 29399\n",
      "Episode 3009: Reward = 600.00, Steps = 2, Loss = 3.3818, Exploration Rate = 0.1000, Train Count = 29401\n",
      "Episode 3010: Reward = 585.00, Steps = 7, Loss = 6.7403, Exploration Rate = 0.1000, Train Count = 29408\n",
      "Episode 3011: Reward = 582.00, Steps = 8, Loss = 6.4188, Exploration Rate = 0.1000, Train Count = 29416\n",
      "Episode 3012: Reward = 600.00, Steps = 2, Loss = 3.7309, Exploration Rate = 0.1000, Train Count = 29418\n",
      "Episode 3013: Reward = 588.00, Steps = 6, Loss = 7.3362, Exploration Rate = 0.1000, Train Count = 29424\n",
      "Episode 3014: Reward = 594.00, Steps = 4, Loss = 3.4395, Exploration Rate = 0.1000, Train Count = 29428\n",
      "Episode 3015: Reward = 588.00, Steps = 6, Loss = 5.1895, Exploration Rate = 0.1000, Train Count = 29434\n",
      "Episode 3016: Reward = 564.00, Steps = 14, Loss = 4.4158, Exploration Rate = 0.1000, Train Count = 29448\n",
      "Episode 3017: Reward = 594.00, Steps = 4, Loss = 5.8184, Exploration Rate = 0.1000, Train Count = 29452\n",
      "Episode 3018: Reward = 582.00, Steps = 8, Loss = 5.3305, Exploration Rate = 0.1000, Train Count = 29460\n",
      "Episode 3019: Reward = 594.00, Steps = 4, Loss = 3.8437, Exploration Rate = 0.1000, Train Count = 29464\n",
      "Episode 3020: Reward = 585.00, Steps = 7, Loss = 4.4482, Exploration Rate = 0.1000, Train Count = 29471\n",
      "Episode 3021: Reward = 585.00, Steps = 7, Loss = 4.7243, Exploration Rate = 0.1000, Train Count = 29478\n",
      "Episode 3022: Reward = 594.00, Steps = 4, Loss = 4.0205, Exploration Rate = 0.1000, Train Count = 29482\n",
      "Episode 3023: Reward = 585.00, Steps = 7, Loss = 4.1849, Exploration Rate = 0.1000, Train Count = 29489\n",
      "Episode 3024: Reward = 597.00, Steps = 3, Loss = 5.0406, Exploration Rate = 0.1000, Train Count = 29492\n",
      "Episode 3025: Reward = 582.00, Steps = 8, Loss = 4.2654, Exploration Rate = 0.1000, Train Count = 29500\n",
      "Episode 3026: Reward = 591.00, Steps = 5, Loss = 3.8313, Exploration Rate = 0.1000, Train Count = 29505\n",
      "Episode 3027: Reward = 597.00, Steps = 3, Loss = 5.2068, Exploration Rate = 0.1000, Train Count = 29508\n",
      "Episode 3028: Reward = 582.00, Steps = 8, Loss = 4.2927, Exploration Rate = 0.1000, Train Count = 29516\n",
      "Episode 3029: Reward = 591.00, Steps = 5, Loss = 4.3218, Exploration Rate = 0.1000, Train Count = 29521\n",
      "Episode 3030: Reward = 579.00, Steps = 9, Loss = 6.1013, Exploration Rate = 0.1000, Train Count = 29530\n",
      "Episode 3031: Reward = 541.00, Steps = 6, Loss = 5.9274, Exploration Rate = 0.1000, Train Count = 29536\n",
      "Episode 3032: Reward = 541.00, Steps = 6, Loss = 5.5067, Exploration Rate = 0.1000, Train Count = 29542\n",
      "Episode 3033: Reward = 582.00, Steps = 8, Loss = 6.2967, Exploration Rate = 0.1000, Train Count = 29550\n",
      "Episode 3034: Reward = 573.00, Steps = 11, Loss = 5.5398, Exploration Rate = 0.1000, Train Count = 29561\n",
      "Episode 3035: Reward = 567.00, Steps = 13, Loss = 5.9563, Exploration Rate = 0.1000, Train Count = 29574\n",
      "Episode 3036: Reward = 588.00, Steps = 6, Loss = 10.2033, Exploration Rate = 0.1000, Train Count = 29580\n",
      "Episode 3037: Reward = 591.00, Steps = 5, Loss = 7.1356, Exploration Rate = 0.1000, Train Count = 29585\n",
      "Episode 3038: Reward = 588.00, Steps = 6, Loss = 4.8216, Exploration Rate = 0.1000, Train Count = 29591\n",
      "Episode 3039: Reward = 582.00, Steps = 8, Loss = 3.5625, Exploration Rate = 0.1000, Train Count = 29599\n",
      "Episode 3040: Reward = 591.00, Steps = 5, Loss = 4.0090, Exploration Rate = 0.1000, Train Count = 29604\n",
      "Episode 3041: Reward = 591.00, Steps = 5, Loss = 9.1696, Exploration Rate = 0.1000, Train Count = 29609\n",
      "Episode 3042: Reward = 588.00, Steps = 6, Loss = 11.3489, Exploration Rate = 0.1000, Train Count = 29615\n",
      "Episode 3043: Reward = 594.00, Steps = 4, Loss = 5.5627, Exploration Rate = 0.1000, Train Count = 29619\n",
      "Episode 3044: Reward = 594.00, Steps = 4, Loss = 7.3324, Exploration Rate = 0.1000, Train Count = 29623\n",
      "Episode 3045: Reward = 588.00, Steps = 6, Loss = 5.8056, Exploration Rate = 0.1000, Train Count = 29629\n",
      "Episode 3046: Reward = 597.00, Steps = 3, Loss = 4.8356, Exploration Rate = 0.1000, Train Count = 29632\n",
      "Episode 3047: Reward = 579.00, Steps = 9, Loss = 7.2673, Exploration Rate = 0.1000, Train Count = 29641\n",
      "Episode 3048: Reward = 585.00, Steps = 7, Loss = 5.1916, Exploration Rate = 0.1000, Train Count = 29648\n",
      "Episode 3049: Reward = 588.00, Steps = 6, Loss = 4.1782, Exploration Rate = 0.1000, Train Count = 29654\n",
      "Episode 3050: Reward = 582.00, Steps = 8, Loss = 8.3947, Exploration Rate = 0.1000, Train Count = 29662\n",
      "Episode 3051: Reward = 582.00, Steps = 8, Loss = 7.0373, Exploration Rate = 0.1000, Train Count = 29670\n",
      "Episode 3052: Reward = 585.00, Steps = 7, Loss = 5.0329, Exploration Rate = 0.1000, Train Count = 29677\n",
      "Episode 3053: Reward = 594.00, Steps = 4, Loss = 6.5463, Exploration Rate = 0.1000, Train Count = 29681\n",
      "Episode 3054: Reward = 582.00, Steps = 8, Loss = 4.5314, Exploration Rate = 0.1000, Train Count = 29689\n",
      "Episode 3055: Reward = 588.00, Steps = 6, Loss = 3.5001, Exploration Rate = 0.1000, Train Count = 29695\n",
      "Episode 3056: Reward = 532.00, Steps = 9, Loss = 7.6582, Exploration Rate = 0.1000, Train Count = 29704\n",
      "Episode 3057: Reward = 588.00, Steps = 6, Loss = 9.2022, Exploration Rate = 0.1000, Train Count = 29710\n",
      "Episode 3058: Reward = 585.00, Steps = 7, Loss = 5.6544, Exploration Rate = 0.1000, Train Count = 29717\n",
      "Episode 3059: Reward = 597.00, Steps = 3, Loss = 2.9031, Exploration Rate = 0.1000, Train Count = 29720\n",
      "Episode 3060: Reward = 576.00, Steps = 10, Loss = 10.8504, Exploration Rate = 0.1000, Train Count = 29730\n",
      "Episode 3061: Reward = 532.00, Steps = 9, Loss = 8.4236, Exploration Rate = 0.1000, Train Count = 29739\n",
      "Episode 3062: Reward = 582.00, Steps = 8, Loss = 7.2583, Exploration Rate = 0.1000, Train Count = 29747\n",
      "Episode 3063: Reward = 585.00, Steps = 7, Loss = 3.4569, Exploration Rate = 0.1000, Train Count = 29754\n",
      "Episode 3064: Reward = 523.00, Steps = 12, Loss = 4.7625, Exploration Rate = 0.1000, Train Count = 29766\n",
      "Episode 3065: Reward = 591.00, Steps = 5, Loss = 7.1081, Exploration Rate = 0.1000, Train Count = 29771\n",
      "Episode 3066: Reward = 588.00, Steps = 6, Loss = 3.8526, Exploration Rate = 0.1000, Train Count = 29777\n",
      "Episode 3067: Reward = 588.00, Steps = 6, Loss = 4.6961, Exploration Rate = 0.1000, Train Count = 29783\n",
      "Episode 3068: Reward = 582.00, Steps = 8, Loss = 4.9381, Exploration Rate = 0.1000, Train Count = 29791\n",
      "Episode 3069: Reward = 585.00, Steps = 7, Loss = 7.7302, Exploration Rate = 0.1000, Train Count = 29798\n",
      "Episode 3070: Reward = 585.00, Steps = 7, Loss = 44.1462, Exploration Rate = 0.1000, Train Count = 29805\n",
      "Episode 3071: Reward = 588.00, Steps = 6, Loss = 43.9364, Exploration Rate = 0.1000, Train Count = 29811\n",
      "Episode 3072: Reward = 579.00, Steps = 9, Loss = 29.5122, Exploration Rate = 0.1000, Train Count = 29820\n",
      "Episode 3073: Reward = 591.00, Steps = 5, Loss = 22.9567, Exploration Rate = 0.1000, Train Count = 29825\n",
      "Episode 3074: Reward = 591.00, Steps = 5, Loss = 15.7347, Exploration Rate = 0.1000, Train Count = 29830\n",
      "Episode 3075: Reward = 588.00, Steps = 6, Loss = 15.7716, Exploration Rate = 0.1000, Train Count = 29836\n",
      "Episode 3076: Reward = 585.00, Steps = 7, Loss = 13.1489, Exploration Rate = 0.1000, Train Count = 29843\n",
      "Episode 3077: Reward = 585.00, Steps = 7, Loss = 9.6573, Exploration Rate = 0.1000, Train Count = 29850\n",
      "Episode 3078: Reward = 582.00, Steps = 8, Loss = 7.3673, Exploration Rate = 0.1000, Train Count = 29858\n",
      "Episode 3079: Reward = 585.00, Steps = 7, Loss = 6.2589, Exploration Rate = 0.1000, Train Count = 29865\n",
      "Episode 3080: Reward = 591.00, Steps = 5, Loss = 5.0023, Exploration Rate = 0.1000, Train Count = 29870\n",
      "Episode 3081: Reward = 591.00, Steps = 5, Loss = 4.8268, Exploration Rate = 0.1000, Train Count = 29875\n",
      "Episode 3082: Reward = 597.00, Steps = 3, Loss = 3.8298, Exploration Rate = 0.1000, Train Count = 29878\n",
      "Episode 3083: Reward = 585.00, Steps = 7, Loss = 4.6322, Exploration Rate = 0.1000, Train Count = 29885\n",
      "Episode 3084: Reward = 523.00, Steps = 12, Loss = 11.4843, Exploration Rate = 0.1000, Train Count = 29897\n",
      "Episode 3085: Reward = 594.00, Steps = 4, Loss = 5.8545, Exploration Rate = 0.1000, Train Count = 29901\n",
      "Episode 3086: Reward = 585.00, Steps = 7, Loss = 6.4869, Exploration Rate = 0.1000, Train Count = 29908\n",
      "Episode 3087: Reward = 591.00, Steps = 5, Loss = 5.0022, Exploration Rate = 0.1000, Train Count = 29913\n",
      "Episode 3088: Reward = 591.00, Steps = 5, Loss = 3.7069, Exploration Rate = 0.1000, Train Count = 29918\n",
      "Episode 3089: Reward = 570.00, Steps = 12, Loss = 6.0184, Exploration Rate = 0.1000, Train Count = 29930\n",
      "Episode 3090: Reward = 582.00, Steps = 8, Loss = 4.4115, Exploration Rate = 0.1000, Train Count = 29938\n",
      "Episode 3091: Reward = 588.00, Steps = 6, Loss = 3.2642, Exploration Rate = 0.1000, Train Count = 29944\n",
      "Episode 3092: Reward = 588.00, Steps = 6, Loss = 6.4012, Exploration Rate = 0.1000, Train Count = 29950\n",
      "Episode 3093: Reward = 591.00, Steps = 5, Loss = 6.8282, Exploration Rate = 0.1000, Train Count = 29955\n",
      "Episode 3094: Reward = 585.00, Steps = 7, Loss = 6.6738, Exploration Rate = 0.1000, Train Count = 29962\n",
      "Episode 3095: Reward = 570.00, Steps = 12, Loss = 8.1942, Exploration Rate = 0.1000, Train Count = 29974\n",
      "Episode 3096: Reward = 591.00, Steps = 5, Loss = 6.3599, Exploration Rate = 0.1000, Train Count = 29979\n",
      "Episode 3097: Reward = 588.00, Steps = 6, Loss = 5.2420, Exploration Rate = 0.1000, Train Count = 29985\n",
      "Episode 3098: Reward = 597.00, Steps = 3, Loss = 4.1640, Exploration Rate = 0.1000, Train Count = 29988\n",
      "Episode 3099: Reward = 597.00, Steps = 3, Loss = 4.1386, Exploration Rate = 0.1000, Train Count = 29991\n",
      "Episode 3100: Reward = 585.00, Steps = 7, Loss = 3.2330, Exploration Rate = 0.1000, Train Count = 29998\n",
      "Episode 3101: Reward = 582.00, Steps = 8, Loss = 3.7156, Exploration Rate = 0.1000, Train Count = 30006\n",
      "Episode 3102: Reward = 594.00, Steps = 4, Loss = 12.9805, Exploration Rate = 0.1000, Train Count = 30010\n",
      "Episode 3103: Reward = 597.00, Steps = 3, Loss = 3.5306, Exploration Rate = 0.1000, Train Count = 30013\n",
      "Episode 3104: Reward = 597.00, Steps = 3, Loss = 6.7687, Exploration Rate = 0.1000, Train Count = 30016\n",
      "Episode 3105: Reward = 588.00, Steps = 6, Loss = 2.2988, Exploration Rate = 0.1000, Train Count = 30022\n",
      "Episode 3106: Reward = 485.00, Steps = 9, Loss = 6.9541, Exploration Rate = 0.1000, Train Count = 30031\n",
      "Episode 3107: Reward = 594.00, Steps = 4, Loss = 9.7769, Exploration Rate = 0.1000, Train Count = 30035\n",
      "Episode 3108: Reward = 532.00, Steps = 9, Loss = 7.8672, Exploration Rate = 0.1000, Train Count = 30044\n",
      "Episode 3109: Reward = 594.00, Steps = 4, Loss = 6.0174, Exploration Rate = 0.1000, Train Count = 30048\n",
      "Episode 3110: Reward = 588.00, Steps = 6, Loss = 5.5121, Exploration Rate = 0.1000, Train Count = 30054\n",
      "Episode 3111: Reward = 585.00, Steps = 7, Loss = 6.8623, Exploration Rate = 0.1000, Train Count = 30061\n",
      "Episode 3112: Reward = 579.00, Steps = 9, Loss = 10.7752, Exploration Rate = 0.1000, Train Count = 30070\n",
      "Episode 3113: Reward = 594.00, Steps = 4, Loss = 9.2862, Exploration Rate = 0.1000, Train Count = 30074\n",
      "Episode 3114: Reward = 573.00, Steps = 11, Loss = 14.5516, Exploration Rate = 0.1000, Train Count = 30085\n",
      "Episode 3115: Reward = 567.00, Steps = 13, Loss = 10.2751, Exploration Rate = 0.1000, Train Count = 30098\n",
      "Episode 3116: Reward = 529.00, Steps = 10, Loss = 5.6836, Exploration Rate = 0.1000, Train Count = 30108\n",
      "Episode 3117: Reward = 582.00, Steps = 8, Loss = 13.9653, Exploration Rate = 0.1000, Train Count = 30116\n",
      "Episode 3118: Reward = 591.00, Steps = 5, Loss = 11.5911, Exploration Rate = 0.1000, Train Count = 30121\n",
      "Episode 3119: Reward = 594.00, Steps = 4, Loss = 10.0899, Exploration Rate = 0.1000, Train Count = 30125\n",
      "Episode 3120: Reward = 591.00, Steps = 5, Loss = 9.6798, Exploration Rate = 0.1000, Train Count = 30130\n",
      "Episode 3121: Reward = 594.00, Steps = 4, Loss = 9.1520, Exploration Rate = 0.1000, Train Count = 30134\n",
      "Episode 3122: Reward = 585.00, Steps = 7, Loss = 9.3085, Exploration Rate = 0.1000, Train Count = 30141\n",
      "Episode 3123: Reward = 594.00, Steps = 4, Loss = 5.1508, Exploration Rate = 0.1000, Train Count = 30145\n",
      "Episode 3124: Reward = 588.00, Steps = 6, Loss = 11.0011, Exploration Rate = 0.1000, Train Count = 30151\n",
      "Episode 3125: Reward = 594.00, Steps = 4, Loss = 8.4110, Exploration Rate = 0.1000, Train Count = 30155\n",
      "Episode 3126: Reward = 582.00, Steps = 8, Loss = 6.1125, Exploration Rate = 0.1000, Train Count = 30163\n",
      "Episode 3127: Reward = 588.00, Steps = 6, Loss = 10.4790, Exploration Rate = 0.1000, Train Count = 30169\n",
      "Episode 3128: Reward = 541.00, Steps = 6, Loss = 12.4422, Exploration Rate = 0.1000, Train Count = 30175\n",
      "Episode 3129: Reward = 532.00, Steps = 9, Loss = 8.4812, Exploration Rate = 0.1000, Train Count = 30184\n",
      "Episode 3130: Reward = 600.00, Steps = 2, Loss = 6.7722, Exploration Rate = 0.1000, Train Count = 30186\n",
      "Episode 3131: Reward = 594.00, Steps = 4, Loss = 7.3811, Exploration Rate = 0.1000, Train Count = 30190\n",
      "Episode 3132: Reward = 597.00, Steps = 3, Loss = 8.2898, Exploration Rate = 0.1000, Train Count = 30193\n",
      "Episode 3133: Reward = 588.00, Steps = 6, Loss = 8.4634, Exploration Rate = 0.1000, Train Count = 30199\n",
      "Episode 3134: Reward = 573.00, Steps = 11, Loss = 15.3549, Exploration Rate = 0.1000, Train Count = 30210\n",
      "Episode 3135: Reward = 591.00, Steps = 5, Loss = 10.4939, Exploration Rate = 0.1000, Train Count = 30215\n",
      "Episode 3136: Reward = 600.00, Steps = 2, Loss = 10.1951, Exploration Rate = 0.1000, Train Count = 30217\n",
      "Episode 3137: Reward = 591.00, Steps = 5, Loss = 7.4538, Exploration Rate = 0.1000, Train Count = 30222\n",
      "Episode 3138: Reward = 597.00, Steps = 3, Loss = 6.7128, Exploration Rate = 0.1000, Train Count = 30225\n",
      "Episode 3139: Reward = 585.00, Steps = 7, Loss = 6.7902, Exploration Rate = 0.1000, Train Count = 30232\n",
      "Episode 3140: Reward = 597.00, Steps = 3, Loss = 4.6659, Exploration Rate = 0.1000, Train Count = 30235\n",
      "Episode 3141: Reward = 525.00, Steps = 27, Loss = 6.7108, Exploration Rate = 0.1000, Train Count = 30262\n",
      "Episode 3142: Reward = 570.00, Steps = 12, Loss = 5.9053, Exploration Rate = 0.1000, Train Count = 30274\n",
      "Episode 3143: Reward = 529.00, Steps = 10, Loss = 7.3912, Exploration Rate = 0.1000, Train Count = 30284\n",
      "Episode 3144: Reward = 585.00, Steps = 7, Loss = 4.3911, Exploration Rate = 0.1000, Train Count = 30291\n",
      "Episode 3145: Reward = 591.00, Steps = 5, Loss = 7.1377, Exploration Rate = 0.1000, Train Count = 30296\n",
      "Episode 3146: Reward = 576.00, Steps = 10, Loss = 29.7751, Exploration Rate = 0.1000, Train Count = 30306\n",
      "Episode 3147: Reward = 579.00, Steps = 9, Loss = 31.0225, Exploration Rate = 0.1000, Train Count = 30315\n",
      "Episode 3148: Reward = 597.00, Steps = 3, Loss = 26.8263, Exploration Rate = 0.1000, Train Count = 30318\n",
      "Episode 3149: Reward = 508.00, Steps = 17, Loss = 20.9464, Exploration Rate = 0.1000, Train Count = 30335\n",
      "Episode 3150: Reward = 588.00, Steps = 6, Loss = 18.1384, Exploration Rate = 0.1000, Train Count = 30341\n",
      "Episode 3151: Reward = 485.00, Steps = 9, Loss = 17.8701, Exploration Rate = 0.1000, Train Count = 30350\n",
      "Episode 3152: Reward = 597.00, Steps = 3, Loss = 15.8111, Exploration Rate = 0.1000, Train Count = 30353\n",
      "Episode 3153: Reward = 585.00, Steps = 7, Loss = 13.3192, Exploration Rate = 0.1000, Train Count = 30360\n",
      "Episode 3154: Reward = 588.00, Steps = 6, Loss = 17.4691, Exploration Rate = 0.1000, Train Count = 30366\n",
      "Episode 3155: Reward = 594.00, Steps = 4, Loss = 15.9514, Exploration Rate = 0.1000, Train Count = 30370\n",
      "Episode 3156: Reward = 561.00, Steps = 15, Loss = 21.8916, Exploration Rate = 0.1000, Train Count = 30385\n",
      "Episode 3157: Reward = 585.00, Steps = 7, Loss = 18.6090, Exploration Rate = 0.1000, Train Count = 30392\n",
      "Episode 3158: Reward = 597.00, Steps = 3, Loss = 17.5375, Exploration Rate = 0.1000, Train Count = 30395\n",
      "Episode 3159: Reward = 579.00, Steps = 9, Loss = 25.3499, Exploration Rate = 0.1000, Train Count = 30404\n",
      "Episode 3160: Reward = 579.00, Steps = 9, Loss = 14.7339, Exploration Rate = 0.1000, Train Count = 30413\n",
      "Episode 3161: Reward = 585.00, Steps = 7, Loss = 14.4813, Exploration Rate = 0.1000, Train Count = 30420\n",
      "Episode 3162: Reward = 588.00, Steps = 6, Loss = 15.2572, Exploration Rate = 0.1000, Train Count = 30426\n",
      "Episode 3163: Reward = 585.00, Steps = 7, Loss = 11.8745, Exploration Rate = 0.1000, Train Count = 30433\n",
      "Episode 3164: Reward = 588.00, Steps = 6, Loss = 9.8930, Exploration Rate = 0.1000, Train Count = 30439\n",
      "Episode 3165: Reward = 597.00, Steps = 3, Loss = 13.9730, Exploration Rate = 0.1000, Train Count = 30442\n",
      "Episode 3166: Reward = 594.00, Steps = 4, Loss = 9.4647, Exploration Rate = 0.1000, Train Count = 30446\n",
      "Episode 3167: Reward = 579.00, Steps = 9, Loss = 7.1718, Exploration Rate = 0.1000, Train Count = 30455\n",
      "Episode 3168: Reward = 588.00, Steps = 6, Loss = 8.4176, Exploration Rate = 0.1000, Train Count = 30461\n",
      "Episode 3169: Reward = 591.00, Steps = 5, Loss = 6.5864, Exploration Rate = 0.1000, Train Count = 30466\n",
      "Episode 3170: Reward = 523.00, Steps = 12, Loss = 14.2800, Exploration Rate = 0.1000, Train Count = 30478\n",
      "Episode 3171: Reward = 585.00, Steps = 7, Loss = 12.1210, Exploration Rate = 0.1000, Train Count = 30485\n",
      "Episode 3172: Reward = 594.00, Steps = 4, Loss = 13.5877, Exploration Rate = 0.1000, Train Count = 30489\n",
      "Episode 3173: Reward = 591.00, Steps = 5, Loss = 13.0004, Exploration Rate = 0.1000, Train Count = 30494\n",
      "Episode 3174: Reward = 594.00, Steps = 4, Loss = 13.4034, Exploration Rate = 0.1000, Train Count = 30498\n",
      "Episode 3175: Reward = 585.00, Steps = 7, Loss = 10.3964, Exploration Rate = 0.1000, Train Count = 30505\n",
      "Episode 3176: Reward = 597.00, Steps = 3, Loss = 6.1384, Exploration Rate = 0.1000, Train Count = 30508\n",
      "Episode 3177: Reward = 585.00, Steps = 7, Loss = 7.5899, Exploration Rate = 0.1000, Train Count = 30515\n",
      "Episode 3178: Reward = 579.00, Steps = 9, Loss = 8.0215, Exploration Rate = 0.1000, Train Count = 30524\n",
      "Episode 3179: Reward = 585.00, Steps = 7, Loss = 7.9231, Exploration Rate = 0.1000, Train Count = 30531\n",
      "Episode 3180: Reward = 588.00, Steps = 6, Loss = 11.1365, Exploration Rate = 0.1000, Train Count = 30537\n",
      "Episode 3181: Reward = 585.00, Steps = 7, Loss = 8.7508, Exploration Rate = 0.1000, Train Count = 30544\n",
      "Episode 3182: Reward = 517.00, Steps = 14, Loss = 14.1889, Exploration Rate = 0.1000, Train Count = 30558\n",
      "Episode 3183: Reward = 597.00, Steps = 3, Loss = 11.2637, Exploration Rate = 0.1000, Train Count = 30561\n",
      "Episode 3184: Reward = 585.00, Steps = 7, Loss = 11.9983, Exploration Rate = 0.1000, Train Count = 30568\n",
      "Episode 3185: Reward = 567.00, Steps = 13, Loss = 15.4194, Exploration Rate = 0.1000, Train Count = 30581\n",
      "Episode 3186: Reward = 582.00, Steps = 8, Loss = 10.3559, Exploration Rate = 0.1000, Train Count = 30589\n",
      "Episode 3187: Reward = 576.00, Steps = 10, Loss = 12.0904, Exploration Rate = 0.1000, Train Count = 30599\n",
      "Episode 3188: Reward = 541.00, Steps = 6, Loss = 9.0526, Exploration Rate = 0.1000, Train Count = 30605\n",
      "Episode 3189: Reward = 594.00, Steps = 4, Loss = 21.8302, Exploration Rate = 0.1000, Train Count = 30609\n",
      "Episode 3190: Reward = 585.00, Steps = 7, Loss = 25.9705, Exploration Rate = 0.1000, Train Count = 30616\n",
      "Episode 3191: Reward = 579.00, Steps = 9, Loss = 17.8701, Exploration Rate = 0.1000, Train Count = 30625\n",
      "Episode 3192: Reward = 582.00, Steps = 8, Loss = 15.0350, Exploration Rate = 0.1000, Train Count = 30633\n",
      "Episode 3193: Reward = 594.00, Steps = 4, Loss = 12.5443, Exploration Rate = 0.1000, Train Count = 30637\n",
      "Episode 3194: Reward = 585.00, Steps = 7, Loss = 11.4391, Exploration Rate = 0.1000, Train Count = 30644\n",
      "Episode 3195: Reward = 582.00, Steps = 8, Loss = 12.9642, Exploration Rate = 0.1000, Train Count = 30652\n",
      "Episode 3196: Reward = 573.00, Steps = 11, Loss = 10.9396, Exploration Rate = 0.1000, Train Count = 30663\n",
      "Episode 3197: Reward = 594.00, Steps = 4, Loss = 9.3557, Exploration Rate = 0.1000, Train Count = 30667\n",
      "Episode 3198: Reward = 597.00, Steps = 3, Loss = 9.5253, Exploration Rate = 0.1000, Train Count = 30670\n",
      "Episode 3199: Reward = 585.00, Steps = 7, Loss = 10.0342, Exploration Rate = 0.1000, Train Count = 30677\n",
      "Episode 3200: Reward = 582.00, Steps = 8, Loss = 8.7331, Exploration Rate = 0.1000, Train Count = 30685\n",
      "Episode 3201: Reward = 564.00, Steps = 14, Loss = 12.1040, Exploration Rate = 0.1000, Train Count = 30699\n",
      "Episode 3202: Reward = 594.00, Steps = 4, Loss = 7.7878, Exploration Rate = 0.1000, Train Count = 30703\n",
      "Episode 3203: Reward = 579.00, Steps = 9, Loss = 9.2828, Exploration Rate = 0.1000, Train Count = 30712\n",
      "Episode 3204: Reward = 591.00, Steps = 5, Loss = 9.5634, Exploration Rate = 0.1000, Train Count = 30717\n",
      "Episode 3205: Reward = 588.00, Steps = 6, Loss = 5.0615, Exploration Rate = 0.1000, Train Count = 30723\n",
      "Episode 3206: Reward = 594.00, Steps = 4, Loss = 10.0268, Exploration Rate = 0.1000, Train Count = 30727\n",
      "Episode 3207: Reward = 588.00, Steps = 6, Loss = 8.0791, Exploration Rate = 0.1000, Train Count = 30733\n",
      "Episode 3208: Reward = 588.00, Steps = 6, Loss = 8.2670, Exploration Rate = 0.1000, Train Count = 30739\n",
      "Episode 3209: Reward = 538.00, Steps = 7, Loss = 8.7967, Exploration Rate = 0.1000, Train Count = 30746\n",
      "Episode 3210: Reward = 594.00, Steps = 4, Loss = 6.9440, Exploration Rate = 0.1000, Train Count = 30750\n",
      "Episode 3211: Reward = 594.00, Steps = 4, Loss = 16.0372, Exploration Rate = 0.1000, Train Count = 30754\n",
      "Episode 3212: Reward = 591.00, Steps = 5, Loss = 12.8263, Exploration Rate = 0.1000, Train Count = 30759\n",
      "Episode 3213: Reward = 591.00, Steps = 5, Loss = 10.7619, Exploration Rate = 0.1000, Train Count = 30764\n",
      "Episode 3214: Reward = 588.00, Steps = 6, Loss = 11.7677, Exploration Rate = 0.1000, Train Count = 30770\n",
      "Episode 3215: Reward = 594.00, Steps = 4, Loss = 7.7887, Exploration Rate = 0.1000, Train Count = 30774\n",
      "Episode 3216: Reward = 573.00, Steps = 11, Loss = 19.2628, Exploration Rate = 0.1000, Train Count = 30785\n",
      "Episode 3217: Reward = 582.00, Steps = 8, Loss = 14.1884, Exploration Rate = 0.1000, Train Count = 30793\n",
      "Episode 3218: Reward = 585.00, Steps = 7, Loss = 10.6456, Exploration Rate = 0.1000, Train Count = 30800\n",
      "Episode 3219: Reward = 588.00, Steps = 6, Loss = 77.5608, Exploration Rate = 0.1000, Train Count = 30806\n",
      "Episode 3220: Reward = 585.00, Steps = 7, Loss = 50.6203, Exploration Rate = 0.1000, Train Count = 30813\n",
      "Episode 3221: Reward = 579.00, Steps = 9, Loss = 33.6969, Exploration Rate = 0.1000, Train Count = 30822\n",
      "Episode 3222: Reward = 585.00, Steps = 7, Loss = 27.3549, Exploration Rate = 0.1000, Train Count = 30829\n",
      "Episode 3223: Reward = 591.00, Steps = 5, Loss = 22.8048, Exploration Rate = 0.1000, Train Count = 30834\n",
      "Episode 3224: Reward = 597.00, Steps = 3, Loss = 24.3286, Exploration Rate = 0.1000, Train Count = 30837\n",
      "Episode 3225: Reward = 591.00, Steps = 5, Loss = 21.5405, Exploration Rate = 0.1000, Train Count = 30842\n",
      "Episode 3226: Reward = 582.00, Steps = 8, Loss = 15.5357, Exploration Rate = 0.1000, Train Count = 30850\n",
      "Episode 3227: Reward = 579.00, Steps = 9, Loss = 13.1885, Exploration Rate = 0.1000, Train Count = 30859\n",
      "Episode 3228: Reward = 588.00, Steps = 6, Loss = 12.7640, Exploration Rate = 0.1000, Train Count = 30865\n",
      "Episode 3229: Reward = 582.00, Steps = 8, Loss = 8.2769, Exploration Rate = 0.1000, Train Count = 30873\n",
      "Episode 3230: Reward = 591.00, Steps = 5, Loss = 6.0480, Exploration Rate = 0.1000, Train Count = 30878\n",
      "Episode 3231: Reward = 588.00, Steps = 6, Loss = 7.5922, Exploration Rate = 0.1000, Train Count = 30884\n",
      "Episode 3232: Reward = 576.00, Steps = 10, Loss = 13.2269, Exploration Rate = 0.1000, Train Count = 30894\n",
      "Episode 3233: Reward = 597.00, Steps = 3, Loss = 9.0004, Exploration Rate = 0.1000, Train Count = 30897\n",
      "Episode 3234: Reward = 579.00, Steps = 9, Loss = 7.7972, Exploration Rate = 0.1000, Train Count = 30906\n",
      "Episode 3235: Reward = 582.00, Steps = 8, Loss = 5.7380, Exploration Rate = 0.1000, Train Count = 30914\n",
      "Episode 3236: Reward = 588.00, Steps = 6, Loss = 6.2739, Exploration Rate = 0.1000, Train Count = 30920\n",
      "Episode 3237: Reward = 582.00, Steps = 8, Loss = 7.3773, Exploration Rate = 0.1000, Train Count = 30928\n",
      "Episode 3238: Reward = 585.00, Steps = 7, Loss = 8.6764, Exploration Rate = 0.1000, Train Count = 30935\n",
      "Episode 3239: Reward = 594.00, Steps = 4, Loss = 6.2480, Exploration Rate = 0.1000, Train Count = 30939\n",
      "Episode 3240: Reward = 600.00, Steps = 2, Loss = 7.9050, Exploration Rate = 0.1000, Train Count = 30941\n",
      "Episode 3241: Reward = 588.00, Steps = 6, Loss = 6.9191, Exploration Rate = 0.1000, Train Count = 30947\n",
      "Episode 3242: Reward = 594.00, Steps = 4, Loss = 6.7011, Exploration Rate = 0.1000, Train Count = 30951\n",
      "Episode 3243: Reward = 582.00, Steps = 8, Loss = 4.6808, Exploration Rate = 0.1000, Train Count = 30959\n",
      "Episode 3244: Reward = 585.00, Steps = 7, Loss = 6.8096, Exploration Rate = 0.1000, Train Count = 30966\n",
      "Episode 3245: Reward = 594.00, Steps = 4, Loss = 5.2973, Exploration Rate = 0.1000, Train Count = 30970\n",
      "Episode 3246: Reward = 591.00, Steps = 5, Loss = 6.7401, Exploration Rate = 0.1000, Train Count = 30975\n",
      "Episode 3247: Reward = 594.00, Steps = 4, Loss = 7.8383, Exploration Rate = 0.1000, Train Count = 30979\n",
      "Episode 3248: Reward = 594.00, Steps = 4, Loss = 9.2541, Exploration Rate = 0.1000, Train Count = 30983\n",
      "Episode 3249: Reward = 597.00, Steps = 3, Loss = 4.9486, Exploration Rate = 0.1000, Train Count = 30986\n",
      "Episode 3250: Reward = 594.00, Steps = 4, Loss = 6.5251, Exploration Rate = 0.1000, Train Count = 30990\n",
      "Episode 3251: Reward = 532.00, Steps = 9, Loss = 9.5787, Exploration Rate = 0.1000, Train Count = 30999\n",
      "Episode 3252: Reward = 579.00, Steps = 9, Loss = 14.7023, Exploration Rate = 0.1000, Train Count = 31008\n",
      "Episode 3253: Reward = 576.00, Steps = 10, Loss = 11.5751, Exploration Rate = 0.1000, Train Count = 31018\n",
      "Episode 3254: Reward = 591.00, Steps = 5, Loss = 7.0621, Exploration Rate = 0.1000, Train Count = 31023\n",
      "Episode 3255: Reward = 576.00, Steps = 10, Loss = 8.3959, Exploration Rate = 0.1000, Train Count = 31033\n",
      "Episode 3256: Reward = 597.00, Steps = 3, Loss = 5.6054, Exploration Rate = 0.1000, Train Count = 31036\n",
      "Episode 3257: Reward = 597.00, Steps = 3, Loss = 8.4365, Exploration Rate = 0.1000, Train Count = 31039\n",
      "Episode 3258: Reward = 591.00, Steps = 5, Loss = 9.6966, Exploration Rate = 0.1000, Train Count = 31044\n",
      "Episode 3259: Reward = 591.00, Steps = 5, Loss = 8.0049, Exploration Rate = 0.1000, Train Count = 31049\n",
      "Episode 3260: Reward = 594.00, Steps = 4, Loss = 5.1994, Exploration Rate = 0.1000, Train Count = 31053\n",
      "Episode 3261: Reward = 585.00, Steps = 7, Loss = 7.6377, Exploration Rate = 0.1000, Train Count = 31060\n",
      "Episode 3262: Reward = 564.00, Steps = 14, Loss = 13.5870, Exploration Rate = 0.1000, Train Count = 31074\n",
      "Episode 3263: Reward = 597.00, Steps = 3, Loss = 7.2263, Exploration Rate = 0.1000, Train Count = 31077\n",
      "Episode 3264: Reward = 500.00, Steps = 4, Loss = 40.6988, Exploration Rate = 0.1000, Train Count = 31081\n",
      "Episode 3265: Reward = 588.00, Steps = 6, Loss = 34.3120, Exploration Rate = 0.1000, Train Count = 31087\n",
      "Episode 3266: Reward = 579.00, Steps = 9, Loss = 18.3885, Exploration Rate = 0.1000, Train Count = 31096\n",
      "Episode 3267: Reward = 576.00, Steps = 10, Loss = 11.5191, Exploration Rate = 0.1000, Train Count = 31106\n",
      "Episode 3268: Reward = 594.00, Steps = 4, Loss = 13.3263, Exploration Rate = 0.1000, Train Count = 31110\n",
      "Episode 3269: Reward = 594.00, Steps = 4, Loss = 8.4093, Exploration Rate = 0.1000, Train Count = 31114\n",
      "Episode 3270: Reward = 535.00, Steps = 8, Loss = 11.4930, Exploration Rate = 0.1000, Train Count = 31122\n",
      "Episode 3271: Reward = 535.00, Steps = 8, Loss = 8.7034, Exploration Rate = 0.1000, Train Count = 31130\n",
      "Episode 3272: Reward = 594.00, Steps = 4, Loss = 8.5189, Exploration Rate = 0.1000, Train Count = 31134\n",
      "Episode 3273: Reward = 600.00, Steps = 2, Loss = 22.1409, Exploration Rate = 0.1000, Train Count = 31136\n",
      "Episode 3274: Reward = 597.00, Steps = 3, Loss = 9.2641, Exploration Rate = 0.1000, Train Count = 31139\n",
      "Episode 3275: Reward = 585.00, Steps = 7, Loss = 10.9219, Exploration Rate = 0.1000, Train Count = 31146\n",
      "Episode 3276: Reward = 579.00, Steps = 9, Loss = 12.9653, Exploration Rate = 0.1000, Train Count = 31155\n",
      "Episode 3277: Reward = 588.00, Steps = 6, Loss = 12.0753, Exploration Rate = 0.1000, Train Count = 31161\n",
      "Episode 3278: Reward = 588.00, Steps = 6, Loss = 7.6677, Exploration Rate = 0.1000, Train Count = 31167\n",
      "Episode 3279: Reward = 588.00, Steps = 6, Loss = 11.0811, Exploration Rate = 0.1000, Train Count = 31173\n",
      "Episode 3280: Reward = 588.00, Steps = 6, Loss = 14.8083, Exploration Rate = 0.1000, Train Count = 31179\n",
      "Episode 3281: Reward = 600.00, Steps = 2, Loss = 13.1487, Exploration Rate = 0.1000, Train Count = 31181\n",
      "Episode 3282: Reward = 597.00, Steps = 3, Loss = 12.9409, Exploration Rate = 0.1000, Train Count = 31184\n",
      "Episode 3283: Reward = 591.00, Steps = 5, Loss = 5.6936, Exploration Rate = 0.1000, Train Count = 31189\n",
      "Episode 3284: Reward = 585.00, Steps = 7, Loss = 9.3825, Exploration Rate = 0.1000, Train Count = 31196\n",
      "Episode 3285: Reward = 594.00, Steps = 4, Loss = 6.0600, Exploration Rate = 0.1000, Train Count = 31200\n",
      "Episode 3286: Reward = 585.00, Steps = 7, Loss = 8.7071, Exploration Rate = 0.1000, Train Count = 31207\n",
      "Episode 3287: Reward = 591.00, Steps = 5, Loss = 8.0171, Exploration Rate = 0.1000, Train Count = 31212\n",
      "Episode 3288: Reward = 600.00, Steps = 2, Loss = 7.2542, Exploration Rate = 0.1000, Train Count = 31214\n",
      "Episode 3289: Reward = 585.00, Steps = 7, Loss = 5.6123, Exploration Rate = 0.1000, Train Count = 31221\n",
      "Episode 3290: Reward = 588.00, Steps = 6, Loss = 5.1040, Exploration Rate = 0.1000, Train Count = 31227\n",
      "Episode 3291: Reward = 585.00, Steps = 7, Loss = 6.5539, Exploration Rate = 0.1000, Train Count = 31234\n",
      "Episode 3292: Reward = 594.00, Steps = 4, Loss = 4.4074, Exploration Rate = 0.1000, Train Count = 31238\n",
      "Episode 3293: Reward = 588.00, Steps = 6, Loss = 6.3149, Exploration Rate = 0.1000, Train Count = 31244\n",
      "Episode 3294: Reward = 591.00, Steps = 5, Loss = 6.3359, Exploration Rate = 0.1000, Train Count = 31249\n",
      "Episode 3295: Reward = 591.00, Steps = 5, Loss = 3.6980, Exploration Rate = 0.1000, Train Count = 31254\n",
      "Episode 3296: Reward = 585.00, Steps = 7, Loss = 8.5344, Exploration Rate = 0.1000, Train Count = 31261\n",
      "Episode 3297: Reward = 594.00, Steps = 4, Loss = 8.4179, Exploration Rate = 0.1000, Train Count = 31265\n",
      "Episode 3298: Reward = 585.00, Steps = 7, Loss = 7.7188, Exploration Rate = 0.1000, Train Count = 31272\n",
      "Episode 3299: Reward = 597.00, Steps = 3, Loss = 7.0894, Exploration Rate = 0.1000, Train Count = 31275\n",
      "Episode 3300: Reward = 585.00, Steps = 7, Loss = 6.2528, Exploration Rate = 0.1000, Train Count = 31282\n",
      "Episode 3301: Reward = 582.00, Steps = 8, Loss = 6.8028, Exploration Rate = 0.1000, Train Count = 31290\n",
      "Episode 3302: Reward = 582.00, Steps = 8, Loss = 5.8854, Exploration Rate = 0.1000, Train Count = 31298\n",
      "Episode 3303: Reward = 594.00, Steps = 4, Loss = 30.1874, Exploration Rate = 0.1000, Train Count = 31302\n",
      "Episode 3304: Reward = 570.00, Steps = 12, Loss = 47.1753, Exploration Rate = 0.1000, Train Count = 31314\n",
      "Episode 3305: Reward = 591.00, Steps = 5, Loss = 30.3370, Exploration Rate = 0.1000, Train Count = 31319\n",
      "Episode 3306: Reward = 576.00, Steps = 10, Loss = 23.9835, Exploration Rate = 0.1000, Train Count = 31329\n",
      "Episode 3307: Reward = 594.00, Steps = 4, Loss = 19.4953, Exploration Rate = 0.1000, Train Count = 31333\n",
      "Episode 3308: Reward = 591.00, Steps = 5, Loss = 17.7147, Exploration Rate = 0.1000, Train Count = 31338\n",
      "Episode 3309: Reward = 597.00, Steps = 3, Loss = 14.1908, Exploration Rate = 0.1000, Train Count = 31341\n",
      "Episode 3310: Reward = 582.00, Steps = 8, Loss = 18.0511, Exploration Rate = 0.1000, Train Count = 31349\n",
      "Episode 3311: Reward = 588.00, Steps = 6, Loss = 8.7786, Exploration Rate = 0.1000, Train Count = 31355\n",
      "Episode 3312: Reward = 573.00, Steps = 11, Loss = 13.7971, Exploration Rate = 0.1000, Train Count = 31366\n",
      "Episode 3313: Reward = 585.00, Steps = 7, Loss = 11.1351, Exploration Rate = 0.1000, Train Count = 31373\n",
      "Episode 3314: Reward = 594.00, Steps = 4, Loss = 9.8489, Exploration Rate = 0.1000, Train Count = 31377\n",
      "Episode 3315: Reward = 597.00, Steps = 3, Loss = 6.7355, Exploration Rate = 0.1000, Train Count = 31380\n",
      "Episode 3316: Reward = 597.00, Steps = 3, Loss = 7.9494, Exploration Rate = 0.1000, Train Count = 31383\n",
      "Episode 3317: Reward = 588.00, Steps = 6, Loss = 10.4291, Exploration Rate = 0.1000, Train Count = 31389\n",
      "Episode 3318: Reward = 588.00, Steps = 6, Loss = 7.5172, Exploration Rate = 0.1000, Train Count = 31395\n",
      "Episode 3319: Reward = 591.00, Steps = 5, Loss = 8.8234, Exploration Rate = 0.1000, Train Count = 31400\n",
      "Episode 3320: Reward = 585.00, Steps = 7, Loss = 7.6058, Exploration Rate = 0.1000, Train Count = 31407\n",
      "Episode 3321: Reward = 597.00, Steps = 3, Loss = 6.3522, Exploration Rate = 0.1000, Train Count = 31410\n",
      "Episode 3322: Reward = 588.00, Steps = 6, Loss = 7.3609, Exploration Rate = 0.1000, Train Count = 31416\n",
      "Episode 3323: Reward = 585.00, Steps = 7, Loss = 8.1234, Exploration Rate = 0.1000, Train Count = 31423\n",
      "Episode 3324: Reward = 594.00, Steps = 4, Loss = 16.2865, Exploration Rate = 0.1000, Train Count = 31427\n",
      "Episode 3325: Reward = 591.00, Steps = 5, Loss = 8.5252, Exploration Rate = 0.1000, Train Count = 31432\n",
      "Episode 3326: Reward = 591.00, Steps = 5, Loss = 15.1537, Exploration Rate = 0.1000, Train Count = 31437\n",
      "Episode 3327: Reward = 579.00, Steps = 9, Loss = 10.2880, Exploration Rate = 0.1000, Train Count = 31446\n",
      "Episode 3328: Reward = 585.00, Steps = 7, Loss = 11.4458, Exploration Rate = 0.1000, Train Count = 31453\n",
      "Episode 3329: Reward = 597.00, Steps = 3, Loss = 7.0575, Exploration Rate = 0.1000, Train Count = 31456\n",
      "Episode 3330: Reward = 591.00, Steps = 5, Loss = 7.0329, Exploration Rate = 0.1000, Train Count = 31461\n",
      "Episode 3331: Reward = 597.00, Steps = 3, Loss = 8.0577, Exploration Rate = 0.1000, Train Count = 31464\n",
      "Episode 3332: Reward = 585.00, Steps = 7, Loss = 6.3126, Exploration Rate = 0.1000, Train Count = 31471\n",
      "Episode 3333: Reward = 582.00, Steps = 8, Loss = 6.7023, Exploration Rate = 0.1000, Train Count = 31479\n",
      "Episode 3334: Reward = 594.00, Steps = 4, Loss = 4.6320, Exploration Rate = 0.1000, Train Count = 31483\n",
      "Episode 3335: Reward = 547.00, Steps = 4, Loss = 3.7572, Exploration Rate = 0.1000, Train Count = 31487\n",
      "Episode 3336: Reward = 588.00, Steps = 6, Loss = 3.5193, Exploration Rate = 0.1000, Train Count = 31493\n",
      "Episode 3337: Reward = 582.00, Steps = 8, Loss = 4.3511, Exploration Rate = 0.1000, Train Count = 31501\n",
      "Episode 3338: Reward = 591.00, Steps = 5, Loss = 5.0590, Exploration Rate = 0.1000, Train Count = 31506\n",
      "Episode 3339: Reward = 582.00, Steps = 8, Loss = 4.2530, Exploration Rate = 0.1000, Train Count = 31514\n",
      "Episode 3340: Reward = 591.00, Steps = 5, Loss = 5.1972, Exploration Rate = 0.1000, Train Count = 31519\n",
      "Episode 3341: Reward = 588.00, Steps = 6, Loss = 4.2475, Exploration Rate = 0.1000, Train Count = 31525\n",
      "Episode 3342: Reward = 594.00, Steps = 4, Loss = 3.7762, Exploration Rate = 0.1000, Train Count = 31529\n",
      "Episode 3343: Reward = 591.00, Steps = 5, Loss = 4.5021, Exploration Rate = 0.1000, Train Count = 31534\n",
      "Episode 3344: Reward = 588.00, Steps = 6, Loss = 10.5805, Exploration Rate = 0.1000, Train Count = 31540\n",
      "Episode 3345: Reward = 597.00, Steps = 3, Loss = 10.3548, Exploration Rate = 0.1000, Train Count = 31543\n",
      "Episode 3346: Reward = 594.00, Steps = 4, Loss = 10.7620, Exploration Rate = 0.1000, Train Count = 31547\n",
      "Episode 3347: Reward = 588.00, Steps = 6, Loss = 9.4166, Exploration Rate = 0.1000, Train Count = 31553\n",
      "Episode 3348: Reward = 585.00, Steps = 7, Loss = 8.0797, Exploration Rate = 0.1000, Train Count = 31560\n",
      "Episode 3349: Reward = 591.00, Steps = 5, Loss = 8.7764, Exploration Rate = 0.1000, Train Count = 31565\n",
      "Episode 3350: Reward = 532.00, Steps = 9, Loss = 8.3138, Exploration Rate = 0.1000, Train Count = 31574\n",
      "Episode 3351: Reward = 588.00, Steps = 6, Loss = 7.4036, Exploration Rate = 0.1000, Train Count = 31580\n",
      "Episode 3352: Reward = 594.00, Steps = 4, Loss = 3.6597, Exploration Rate = 0.1000, Train Count = 31584\n",
      "Episode 3353: Reward = 582.00, Steps = 8, Loss = 6.7813, Exploration Rate = 0.1000, Train Count = 31592\n",
      "Episode 3354: Reward = 579.00, Steps = 9, Loss = 11.0544, Exploration Rate = 0.1000, Train Count = 31601\n",
      "Episode 3355: Reward = 591.00, Steps = 5, Loss = 6.1563, Exploration Rate = 0.1000, Train Count = 31606\n",
      "Episode 3356: Reward = 594.00, Steps = 4, Loss = 7.2157, Exploration Rate = 0.1000, Train Count = 31610\n",
      "Episode 3357: Reward = 588.00, Steps = 6, Loss = 12.1671, Exploration Rate = 0.1000, Train Count = 31616\n",
      "Episode 3358: Reward = 588.00, Steps = 6, Loss = 10.0238, Exploration Rate = 0.1000, Train Count = 31622\n",
      "Episode 3359: Reward = 597.00, Steps = 3, Loss = 8.7953, Exploration Rate = 0.1000, Train Count = 31625\n",
      "Episode 3360: Reward = 594.00, Steps = 4, Loss = 9.4648, Exploration Rate = 0.1000, Train Count = 31629\n",
      "Episode 3361: Reward = 585.00, Steps = 7, Loss = 6.2549, Exploration Rate = 0.1000, Train Count = 31636\n",
      "Episode 3362: Reward = 591.00, Steps = 5, Loss = 5.8535, Exploration Rate = 0.1000, Train Count = 31641\n",
      "Episode 3363: Reward = 591.00, Steps = 5, Loss = 6.5077, Exploration Rate = 0.1000, Train Count = 31646\n",
      "Episode 3364: Reward = 538.00, Steps = 7, Loss = 6.8901, Exploration Rate = 0.1000, Train Count = 31653\n",
      "Episode 3365: Reward = 594.00, Steps = 4, Loss = 8.5912, Exploration Rate = 0.1000, Train Count = 31657\n",
      "Episode 3366: Reward = 591.00, Steps = 5, Loss = 6.4676, Exploration Rate = 0.1000, Train Count = 31662\n",
      "Episode 3367: Reward = 588.00, Steps = 6, Loss = 8.8828, Exploration Rate = 0.1000, Train Count = 31668\n",
      "Episode 3368: Reward = 591.00, Steps = 5, Loss = 7.0725, Exploration Rate = 0.1000, Train Count = 31673\n",
      "Episode 3369: Reward = 597.00, Steps = 3, Loss = 5.0672, Exploration Rate = 0.1000, Train Count = 31676\n",
      "Episode 3370: Reward = 600.00, Steps = 2, Loss = 10.8955, Exploration Rate = 0.1000, Train Count = 31678\n",
      "Episode 3371: Reward = 576.00, Steps = 10, Loss = 7.3529, Exploration Rate = 0.1000, Train Count = 31688\n",
      "Episode 3372: Reward = 591.00, Steps = 5, Loss = 6.1567, Exploration Rate = 0.1000, Train Count = 31693\n",
      "Episode 3373: Reward = 591.00, Steps = 5, Loss = 5.6185, Exploration Rate = 0.1000, Train Count = 31698\n",
      "Episode 3374: Reward = 591.00, Steps = 5, Loss = 5.0747, Exploration Rate = 0.1000, Train Count = 31703\n",
      "Episode 3375: Reward = 576.00, Steps = 10, Loss = 6.3430, Exploration Rate = 0.1000, Train Count = 31713\n",
      "Episode 3376: Reward = 579.00, Steps = 9, Loss = 9.8274, Exploration Rate = 0.1000, Train Count = 31722\n",
      "Episode 3377: Reward = 582.00, Steps = 8, Loss = 7.8449, Exploration Rate = 0.1000, Train Count = 31730\n",
      "Episode 3378: Reward = 591.00, Steps = 5, Loss = 8.9628, Exploration Rate = 0.1000, Train Count = 31735\n",
      "Episode 3379: Reward = 594.00, Steps = 4, Loss = 7.9872, Exploration Rate = 0.1000, Train Count = 31739\n",
      "Episode 3380: Reward = 597.00, Steps = 3, Loss = 6.1507, Exploration Rate = 0.1000, Train Count = 31742\n",
      "Episode 3381: Reward = 594.00, Steps = 4, Loss = 10.2013, Exploration Rate = 0.1000, Train Count = 31746\n",
      "Episode 3382: Reward = 582.00, Steps = 8, Loss = 6.7283, Exploration Rate = 0.1000, Train Count = 31754\n",
      "Episode 3383: Reward = 591.00, Steps = 5, Loss = 4.4215, Exploration Rate = 0.1000, Train Count = 31759\n",
      "Episode 3384: Reward = 541.00, Steps = 6, Loss = 6.6643, Exploration Rate = 0.1000, Train Count = 31765\n",
      "Episode 3385: Reward = 591.00, Steps = 5, Loss = 4.4888, Exploration Rate = 0.1000, Train Count = 31770\n",
      "Episode 3386: Reward = 591.00, Steps = 5, Loss = 7.1600, Exploration Rate = 0.1000, Train Count = 31775\n",
      "Episode 3387: Reward = 579.00, Steps = 9, Loss = 14.9912, Exploration Rate = 0.1000, Train Count = 31784\n",
      "Episode 3388: Reward = 579.00, Steps = 9, Loss = 9.3364, Exploration Rate = 0.1000, Train Count = 31793\n",
      "Episode 3389: Reward = 591.00, Steps = 5, Loss = 8.9763, Exploration Rate = 0.1000, Train Count = 31798\n",
      "Episode 3390: Reward = 538.00, Steps = 7, Loss = 36.8182, Exploration Rate = 0.1000, Train Count = 31805\n",
      "Episode 3391: Reward = 591.00, Steps = 5, Loss = 52.1583, Exploration Rate = 0.1000, Train Count = 31810\n",
      "Episode 3392: Reward = 582.00, Steps = 8, Loss = 30.3484, Exploration Rate = 0.1000, Train Count = 31818\n",
      "Episode 3393: Reward = 526.00, Steps = 11, Loss = 31.5683, Exploration Rate = 0.1000, Train Count = 31829\n",
      "Episode 3394: Reward = 594.00, Steps = 4, Loss = 28.8091, Exploration Rate = 0.1000, Train Count = 31833\n",
      "Episode 3395: Reward = 594.00, Steps = 4, Loss = 20.0295, Exploration Rate = 0.1000, Train Count = 31837\n",
      "Episode 3396: Reward = 588.00, Steps = 6, Loss = 21.6587, Exploration Rate = 0.1000, Train Count = 31843\n",
      "Episode 3397: Reward = 540.00, Steps = 22, Loss = 21.1031, Exploration Rate = 0.1000, Train Count = 31865\n",
      "Episode 3398: Reward = 585.00, Steps = 7, Loss = 19.1768, Exploration Rate = 0.1000, Train Count = 31872\n",
      "Episode 3399: Reward = 529.00, Steps = 10, Loss = 11.2720, Exploration Rate = 0.1000, Train Count = 31882\n",
      "Episode 3400: Reward = 594.00, Steps = 4, Loss = 18.4091, Exploration Rate = 0.1000, Train Count = 31886\n",
      "Episode 3401: Reward = 594.00, Steps = 4, Loss = 7.0478, Exploration Rate = 0.1000, Train Count = 31890\n",
      "Episode 3402: Reward = 585.00, Steps = 7, Loss = 11.7093, Exploration Rate = 0.1000, Train Count = 31897\n",
      "Episode 3403: Reward = 591.00, Steps = 5, Loss = 7.2219, Exploration Rate = 0.1000, Train Count = 31902\n",
      "Episode 3404: Reward = 585.00, Steps = 7, Loss = 7.9181, Exploration Rate = 0.1000, Train Count = 31909\n",
      "Episode 3405: Reward = 588.00, Steps = 6, Loss = 12.0283, Exploration Rate = 0.1000, Train Count = 31915\n",
      "Episode 3406: Reward = 591.00, Steps = 5, Loss = 9.2955, Exploration Rate = 0.1000, Train Count = 31920\n",
      "Episode 3407: Reward = 585.00, Steps = 7, Loss = 6.9309, Exploration Rate = 0.1000, Train Count = 31927\n",
      "Episode 3408: Reward = 591.00, Steps = 5, Loss = 9.2564, Exploration Rate = 0.1000, Train Count = 31932\n",
      "Episode 3409: Reward = 588.00, Steps = 6, Loss = 9.4960, Exploration Rate = 0.1000, Train Count = 31938\n",
      "Episode 3410: Reward = 567.00, Steps = 13, Loss = 10.3204, Exploration Rate = 0.1000, Train Count = 31951\n",
      "Episode 3411: Reward = 582.00, Steps = 8, Loss = 7.6648, Exploration Rate = 0.1000, Train Count = 31959\n",
      "Episode 3412: Reward = 576.00, Steps = 10, Loss = 12.7829, Exploration Rate = 0.1000, Train Count = 31969\n",
      "Episode 3413: Reward = 582.00, Steps = 8, Loss = 7.9336, Exploration Rate = 0.1000, Train Count = 31977\n",
      "Episode 3414: Reward = 523.00, Steps = 12, Loss = 7.6305, Exploration Rate = 0.1000, Train Count = 31989\n",
      "Episode 3415: Reward = 594.00, Steps = 4, Loss = 6.3353, Exploration Rate = 0.1000, Train Count = 31993\n",
      "Episode 3416: Reward = 567.00, Steps = 13, Loss = 4.4947, Exploration Rate = 0.1000, Train Count = 32006\n",
      "Episode 3417: Reward = 529.00, Steps = 10, Loss = 6.0925, Exploration Rate = 0.1000, Train Count = 32016\n",
      "Episode 3418: Reward = 582.00, Steps = 8, Loss = 9.4787, Exploration Rate = 0.1000, Train Count = 32024\n",
      "Episode 3419: Reward = 591.00, Steps = 5, Loss = 5.8940, Exploration Rate = 0.1000, Train Count = 32029\n",
      "Episode 3420: Reward = 591.00, Steps = 5, Loss = 4.9279, Exploration Rate = 0.1000, Train Count = 32034\n",
      "Episode 3421: Reward = 591.00, Steps = 5, Loss = 4.8970, Exploration Rate = 0.1000, Train Count = 32039\n",
      "Episode 3422: Reward = 591.00, Steps = 5, Loss = 6.2722, Exploration Rate = 0.1000, Train Count = 32044\n",
      "Episode 3423: Reward = 576.00, Steps = 10, Loss = 7.0821, Exploration Rate = 0.1000, Train Count = 32054\n",
      "Episode 3424: Reward = 541.00, Steps = 6, Loss = 6.4543, Exploration Rate = 0.1000, Train Count = 32060\n",
      "Episode 3425: Reward = 496.00, Steps = 21, Loss = 8.5839, Exploration Rate = 0.1000, Train Count = 32081\n",
      "Episode 3426: Reward = 585.00, Steps = 7, Loss = 4.5343, Exploration Rate = 0.1000, Train Count = 32088\n",
      "Episode 3427: Reward = 552.00, Steps = 18, Loss = 12.9369, Exploration Rate = 0.1000, Train Count = 32106\n",
      "Episode 3428: Reward = 591.00, Steps = 5, Loss = 6.9846, Exploration Rate = 0.1000, Train Count = 32111\n",
      "Episode 3429: Reward = 591.00, Steps = 5, Loss = 5.4655, Exploration Rate = 0.1000, Train Count = 32116\n",
      "Episode 3430: Reward = 591.00, Steps = 5, Loss = 5.0752, Exploration Rate = 0.1000, Train Count = 32121\n",
      "Episode 3431: Reward = 594.00, Steps = 4, Loss = 7.0765, Exploration Rate = 0.1000, Train Count = 32125\n",
      "Episode 3432: Reward = 591.00, Steps = 5, Loss = 3.2548, Exploration Rate = 0.1000, Train Count = 32130\n",
      "Episode 3433: Reward = 585.00, Steps = 7, Loss = 3.2841, Exploration Rate = 0.1000, Train Count = 32137\n",
      "Episode 3434: Reward = 344.00, Steps = 9, Loss = 25.7106, Exploration Rate = 0.1000, Train Count = 32146\n",
      "Episode 3435: Reward = 573.00, Steps = 11, Loss = 13.0067, Exploration Rate = 0.1000, Train Count = 32157\n",
      "Episode 3436: Reward = 576.00, Steps = 10, Loss = 10.1476, Exploration Rate = 0.1000, Train Count = 32167\n",
      "Episode 3437: Reward = 541.00, Steps = 6, Loss = 10.2684, Exploration Rate = 0.1000, Train Count = 32173\n",
      "Episode 3438: Reward = 579.00, Steps = 9, Loss = 5.8636, Exploration Rate = 0.1000, Train Count = 32182\n",
      "Episode 3439: Reward = 588.00, Steps = 6, Loss = 9.1684, Exploration Rate = 0.1000, Train Count = 32188\n",
      "Episode 3440: Reward = 597.00, Steps = 3, Loss = 8.6937, Exploration Rate = 0.1000, Train Count = 32191\n",
      "Episode 3441: Reward = 582.00, Steps = 8, Loss = 6.9615, Exploration Rate = 0.1000, Train Count = 32199\n",
      "Episode 3442: Reward = 591.00, Steps = 5, Loss = 12.7081, Exploration Rate = 0.1000, Train Count = 32204\n",
      "Episode 3443: Reward = 597.00, Steps = 3, Loss = 8.7023, Exploration Rate = 0.1000, Train Count = 32207\n",
      "Episode 3444: Reward = 591.00, Steps = 5, Loss = 7.7577, Exploration Rate = 0.1000, Train Count = 32212\n",
      "Episode 3445: Reward = 585.00, Steps = 7, Loss = 8.5936, Exploration Rate = 0.1000, Train Count = 32219\n",
      "Episode 3446: Reward = 588.00, Steps = 6, Loss = 3.6607, Exploration Rate = 0.1000, Train Count = 32225\n",
      "Episode 3447: Reward = 570.00, Steps = 12, Loss = 7.2356, Exploration Rate = 0.1000, Train Count = 32237\n",
      "Episode 3448: Reward = 585.00, Steps = 7, Loss = 10.8282, Exploration Rate = 0.1000, Train Count = 32244\n",
      "Episode 3449: Reward = 588.00, Steps = 6, Loss = 6.6506, Exploration Rate = 0.1000, Train Count = 32250\n",
      "Episode 3450: Reward = 588.00, Steps = 6, Loss = 5.4274, Exploration Rate = 0.1000, Train Count = 32256\n",
      "Episode 3451: Reward = 585.00, Steps = 7, Loss = 4.4029, Exploration Rate = 0.1000, Train Count = 32263\n",
      "Episode 3452: Reward = 597.00, Steps = 3, Loss = 5.3288, Exploration Rate = 0.1000, Train Count = 32266\n",
      "Episode 3453: Reward = 576.00, Steps = 10, Loss = 4.6479, Exploration Rate = 0.1000, Train Count = 32276\n",
      "Episode 3454: Reward = 591.00, Steps = 5, Loss = 3.4103, Exploration Rate = 0.1000, Train Count = 32281\n",
      "Episode 3455: Reward = 579.00, Steps = 9, Loss = 3.3136, Exploration Rate = 0.1000, Train Count = 32290\n",
      "Episode 3456: Reward = 588.00, Steps = 6, Loss = 4.4231, Exploration Rate = 0.1000, Train Count = 32296\n",
      "Episode 3457: Reward = 582.00, Steps = 8, Loss = 24.4070, Exploration Rate = 0.1000, Train Count = 32304\n",
      "Episode 3458: Reward = 582.00, Steps = 8, Loss = 34.2785, Exploration Rate = 0.1000, Train Count = 32312\n",
      "Episode 3459: Reward = 588.00, Steps = 6, Loss = 27.0747, Exploration Rate = 0.1000, Train Count = 32318\n",
      "Episode 3460: Reward = 582.00, Steps = 8, Loss = 21.0892, Exploration Rate = 0.1000, Train Count = 32326\n",
      "Episode 3461: Reward = 597.00, Steps = 3, Loss = 18.4984, Exploration Rate = 0.1000, Train Count = 32329\n",
      "Episode 3462: Reward = 594.00, Steps = 4, Loss = 13.3228, Exploration Rate = 0.1000, Train Count = 32333\n",
      "Episode 3463: Reward = 591.00, Steps = 5, Loss = 13.8285, Exploration Rate = 0.1000, Train Count = 32338\n",
      "Episode 3464: Reward = 579.00, Steps = 9, Loss = 10.2366, Exploration Rate = 0.1000, Train Count = 32347\n",
      "Episode 3465: Reward = 591.00, Steps = 5, Loss = 9.0111, Exploration Rate = 0.1000, Train Count = 32352\n",
      "Episode 3466: Reward = 597.00, Steps = 3, Loss = 6.8753, Exploration Rate = 0.1000, Train Count = 32355\n",
      "Episode 3467: Reward = 591.00, Steps = 5, Loss = 8.2233, Exploration Rate = 0.1000, Train Count = 32360\n",
      "Episode 3468: Reward = 594.00, Steps = 4, Loss = 7.5863, Exploration Rate = 0.1000, Train Count = 32364\n",
      "Episode 3469: Reward = 591.00, Steps = 5, Loss = 9.9880, Exploration Rate = 0.1000, Train Count = 32369\n",
      "Episode 3470: Reward = 585.00, Steps = 7, Loss = 5.8212, Exploration Rate = 0.1000, Train Count = 32376\n",
      "Episode 3471: Reward = 597.00, Steps = 3, Loss = 4.6528, Exploration Rate = 0.1000, Train Count = 32379\n",
      "Episode 3472: Reward = 597.00, Steps = 3, Loss = 4.7941, Exploration Rate = 0.1000, Train Count = 32382\n",
      "Episode 3473: Reward = 576.00, Steps = 10, Loss = 10.0887, Exploration Rate = 0.1000, Train Count = 32392\n",
      "Episode 3474: Reward = 582.00, Steps = 8, Loss = 8.4574, Exploration Rate = 0.1000, Train Count = 32400\n",
      "Episode 3475: Reward = 541.00, Steps = 6, Loss = 7.6088, Exploration Rate = 0.1000, Train Count = 32406\n",
      "Episode 3476: Reward = 570.00, Steps = 12, Loss = 7.9619, Exploration Rate = 0.1000, Train Count = 32418\n",
      "Episode 3477: Reward = 579.00, Steps = 9, Loss = 4.5604, Exploration Rate = 0.1000, Train Count = 32427\n",
      "Episode 3478: Reward = 597.00, Steps = 3, Loss = 2.5892, Exploration Rate = 0.1000, Train Count = 32430\n",
      "Episode 3479: Reward = 600.00, Steps = 2, Loss = 5.7811, Exploration Rate = 0.1000, Train Count = 32432\n",
      "Episode 3480: Reward = 591.00, Steps = 5, Loss = 6.1670, Exploration Rate = 0.1000, Train Count = 32437\n",
      "Episode 3481: Reward = 591.00, Steps = 5, Loss = 3.4592, Exploration Rate = 0.1000, Train Count = 32442\n",
      "Episode 3482: Reward = 576.00, Steps = 10, Loss = 7.0073, Exploration Rate = 0.1000, Train Count = 32452\n",
      "Episode 3483: Reward = 594.00, Steps = 4, Loss = 3.9900, Exploration Rate = 0.1000, Train Count = 32456\n",
      "Episode 3484: Reward = 585.00, Steps = 7, Loss = 3.6781, Exploration Rate = 0.1000, Train Count = 32463\n",
      "Episode 3485: Reward = 538.00, Steps = 7, Loss = 2.4711, Exploration Rate = 0.1000, Train Count = 32470\n",
      "Episode 3486: Reward = 585.00, Steps = 7, Loss = 5.3813, Exploration Rate = 0.1000, Train Count = 32477\n",
      "Episode 3487: Reward = 588.00, Steps = 6, Loss = 6.5025, Exploration Rate = 0.1000, Train Count = 32483\n",
      "Episode 3488: Reward = 585.00, Steps = 7, Loss = 4.4193, Exploration Rate = 0.1000, Train Count = 32490\n",
      "Episode 3489: Reward = 588.00, Steps = 6, Loss = 4.4610, Exploration Rate = 0.1000, Train Count = 32496\n",
      "Episode 3490: Reward = 597.00, Steps = 3, Loss = 5.4703, Exploration Rate = 0.1000, Train Count = 32499\n",
      "Episode 3491: Reward = 541.00, Steps = 6, Loss = 5.3230, Exploration Rate = 0.1000, Train Count = 32505\n",
      "Episode 3492: Reward = 594.00, Steps = 4, Loss = 11.0312, Exploration Rate = 0.1000, Train Count = 32509\n",
      "Episode 3493: Reward = 585.00, Steps = 7, Loss = 5.5369, Exploration Rate = 0.1000, Train Count = 32516\n",
      "Episode 3494: Reward = 591.00, Steps = 5, Loss = 4.9762, Exploration Rate = 0.1000, Train Count = 32521\n",
      "Episode 3495: Reward = 585.00, Steps = 7, Loss = 6.8039, Exploration Rate = 0.1000, Train Count = 32528\n",
      "Episode 3496: Reward = 597.00, Steps = 3, Loss = 2.9370, Exploration Rate = 0.1000, Train Count = 32531\n",
      "Episode 3497: Reward = 600.00, Steps = 2, Loss = 7.8006, Exploration Rate = 0.1000, Train Count = 32533\n",
      "Episode 3498: Reward = 591.00, Steps = 5, Loss = 5.2931, Exploration Rate = 0.1000, Train Count = 32538\n",
      "Episode 3499: Reward = 588.00, Steps = 6, Loss = 4.3748, Exploration Rate = 0.1000, Train Count = 32544\n",
      "Episode 3500: Reward = 588.00, Steps = 6, Loss = 5.6381, Exploration Rate = 0.1000, Train Count = 32550\n",
      "Episode 3501: Reward = 591.00, Steps = 5, Loss = 5.6015, Exploration Rate = 0.1000, Train Count = 32555\n",
      "Episode 3502: Reward = 485.00, Steps = 9, Loss = 11.8064, Exploration Rate = 0.1000, Train Count = 32564\n",
      "Episode 3503: Reward = 594.00, Steps = 4, Loss = 13.7839, Exploration Rate = 0.1000, Train Count = 32568\n",
      "Episode 3504: Reward = 594.00, Steps = 4, Loss = 12.0996, Exploration Rate = 0.1000, Train Count = 32572\n",
      "Episode 3505: Reward = 585.00, Steps = 7, Loss = 6.8589, Exploration Rate = 0.1000, Train Count = 32579\n",
      "Episode 3506: Reward = 591.00, Steps = 5, Loss = 5.0559, Exploration Rate = 0.1000, Train Count = 32584\n",
      "Episode 3507: Reward = 597.00, Steps = 3, Loss = 8.4540, Exploration Rate = 0.1000, Train Count = 32587\n",
      "Episode 3508: Reward = 582.00, Steps = 8, Loss = 9.2416, Exploration Rate = 0.1000, Train Count = 32595\n",
      "Episode 3509: Reward = 597.00, Steps = 3, Loss = 12.7285, Exploration Rate = 0.1000, Train Count = 32598\n",
      "Episode 3510: Reward = 567.00, Steps = 13, Loss = 8.8044, Exploration Rate = 0.1000, Train Count = 32611\n",
      "Episode 3511: Reward = 579.00, Steps = 9, Loss = 11.3652, Exploration Rate = 0.1000, Train Count = 32620\n",
      "Episode 3512: Reward = 591.00, Steps = 5, Loss = 9.1567, Exploration Rate = 0.1000, Train Count = 32625\n",
      "Episode 3513: Reward = 588.00, Steps = 6, Loss = 4.9453, Exploration Rate = 0.1000, Train Count = 32631\n",
      "Episode 3514: Reward = 588.00, Steps = 6, Loss = 5.4581, Exploration Rate = 0.1000, Train Count = 32637\n",
      "Episode 3515: Reward = 585.00, Steps = 7, Loss = 5.1730, Exploration Rate = 0.1000, Train Count = 32644\n",
      "Episode 3516: Reward = 576.00, Steps = 10, Loss = 5.9204, Exploration Rate = 0.1000, Train Count = 32654\n",
      "Episode 3517: Reward = 588.00, Steps = 6, Loss = 5.8514, Exploration Rate = 0.1000, Train Count = 32660\n",
      "Episode 3518: Reward = 582.00, Steps = 8, Loss = 6.6617, Exploration Rate = 0.1000, Train Count = 32668\n",
      "Episode 3519: Reward = 570.00, Steps = 12, Loss = 6.3549, Exploration Rate = 0.1000, Train Count = 32680\n",
      "Episode 3520: Reward = 591.00, Steps = 5, Loss = 4.4217, Exploration Rate = 0.1000, Train Count = 32685\n",
      "Episode 3521: Reward = 585.00, Steps = 7, Loss = 3.6714, Exploration Rate = 0.1000, Train Count = 32692\n",
      "Episode 3522: Reward = 597.00, Steps = 3, Loss = 4.5502, Exploration Rate = 0.1000, Train Count = 32695\n",
      "Episode 3523: Reward = 588.00, Steps = 6, Loss = 16.9479, Exploration Rate = 0.1000, Train Count = 32701\n",
      "Episode 3524: Reward = 585.00, Steps = 7, Loss = 7.6897, Exploration Rate = 0.1000, Train Count = 32708\n",
      "Episode 3525: Reward = 588.00, Steps = 6, Loss = 11.2935, Exploration Rate = 0.1000, Train Count = 32714\n",
      "Episode 3526: Reward = 576.00, Steps = 10, Loss = 8.2046, Exploration Rate = 0.1000, Train Count = 32724\n",
      "Episode 3527: Reward = 538.00, Steps = 7, Loss = 7.6720, Exploration Rate = 0.1000, Train Count = 32731\n",
      "Episode 3528: Reward = 588.00, Steps = 6, Loss = 7.7710, Exploration Rate = 0.1000, Train Count = 32737\n",
      "Episode 3529: Reward = 597.00, Steps = 3, Loss = 13.2268, Exploration Rate = 0.1000, Train Count = 32740\n",
      "Episode 3530: Reward = 591.00, Steps = 5, Loss = 14.0693, Exploration Rate = 0.1000, Train Count = 32745\n",
      "Episode 3531: Reward = 541.00, Steps = 6, Loss = 11.9845, Exploration Rate = 0.1000, Train Count = 32751\n",
      "Episode 3532: Reward = 588.00, Steps = 6, Loss = 13.5012, Exploration Rate = 0.1000, Train Count = 32757\n",
      "Episode 3533: Reward = 591.00, Steps = 5, Loss = 11.5556, Exploration Rate = 0.1000, Train Count = 32762\n",
      "Episode 3534: Reward = 597.00, Steps = 3, Loss = 15.9739, Exploration Rate = 0.1000, Train Count = 32765\n",
      "Episode 3535: Reward = 588.00, Steps = 6, Loss = 9.2414, Exploration Rate = 0.1000, Train Count = 32771\n",
      "Episode 3536: Reward = 594.00, Steps = 4, Loss = 11.1941, Exploration Rate = 0.1000, Train Count = 32775\n",
      "Episode 3537: Reward = 582.00, Steps = 8, Loss = 7.9959, Exploration Rate = 0.1000, Train Count = 32783\n",
      "Episode 3538: Reward = 582.00, Steps = 8, Loss = 10.0462, Exploration Rate = 0.1000, Train Count = 32791\n",
      "Episode 3539: Reward = 594.00, Steps = 4, Loss = 12.8465, Exploration Rate = 0.1000, Train Count = 32795\n",
      "Episode 3540: Reward = 591.00, Steps = 5, Loss = 6.3362, Exploration Rate = 0.1000, Train Count = 32800\n",
      "Episode 3541: Reward = 588.00, Steps = 6, Loss = 33.0048, Exploration Rate = 0.1000, Train Count = 32806\n",
      "Episode 3542: Reward = 541.00, Steps = 6, Loss = 33.8297, Exploration Rate = 0.1000, Train Count = 32812\n",
      "Episode 3543: Reward = 582.00, Steps = 8, Loss = 24.7271, Exploration Rate = 0.1000, Train Count = 32820\n",
      "Episode 3544: Reward = 582.00, Steps = 8, Loss = 21.0022, Exploration Rate = 0.1000, Train Count = 32828\n",
      "Episode 3545: Reward = 573.00, Steps = 11, Loss = 18.5574, Exploration Rate = 0.1000, Train Count = 32839\n",
      "Episode 3546: Reward = 579.00, Steps = 9, Loss = 14.9679, Exploration Rate = 0.1000, Train Count = 32848\n",
      "Episode 3547: Reward = 600.00, Steps = 2, Loss = 12.3606, Exploration Rate = 0.1000, Train Count = 32850\n",
      "Episode 3548: Reward = 532.00, Steps = 9, Loss = 10.6154, Exploration Rate = 0.1000, Train Count = 32859\n",
      "Episode 3549: Reward = 597.00, Steps = 3, Loss = 15.5767, Exploration Rate = 0.1000, Train Count = 32862\n",
      "Episode 3550: Reward = 585.00, Steps = 7, Loss = 8.3297, Exploration Rate = 0.1000, Train Count = 32869\n",
      "Episode 3551: Reward = 579.00, Steps = 9, Loss = 9.3268, Exploration Rate = 0.1000, Train Count = 32878\n",
      "Episode 3552: Reward = 585.00, Steps = 7, Loss = 11.0629, Exploration Rate = 0.1000, Train Count = 32885\n",
      "Episode 3553: Reward = 591.00, Steps = 5, Loss = 9.8134, Exploration Rate = 0.1000, Train Count = 32890\n",
      "Episode 3554: Reward = 538.00, Steps = 7, Loss = 16.6546, Exploration Rate = 0.1000, Train Count = 32897\n",
      "Episode 3555: Reward = 597.00, Steps = 3, Loss = 9.5996, Exploration Rate = 0.1000, Train Count = 32900\n",
      "Episode 3556: Reward = 597.00, Steps = 3, Loss = 16.6951, Exploration Rate = 0.1000, Train Count = 32903\n",
      "Episode 3557: Reward = 600.00, Steps = 2, Loss = 9.7502, Exploration Rate = 0.1000, Train Count = 32905\n",
      "Episode 3558: Reward = 600.00, Steps = 2, Loss = 10.0148, Exploration Rate = 0.1000, Train Count = 32907\n",
      "Episode 3559: Reward = 591.00, Steps = 5, Loss = 12.1838, Exploration Rate = 0.1000, Train Count = 32912\n",
      "Episode 3560: Reward = 594.00, Steps = 4, Loss = 17.4021, Exploration Rate = 0.1000, Train Count = 32916\n",
      "Episode 3561: Reward = 594.00, Steps = 4, Loss = 11.8156, Exploration Rate = 0.1000, Train Count = 32920\n",
      "Episode 3562: Reward = 597.00, Steps = 3, Loss = 7.8781, Exploration Rate = 0.1000, Train Count = 32923\n",
      "Episode 3563: Reward = 588.00, Steps = 6, Loss = 10.0225, Exploration Rate = 0.1000, Train Count = 32929\n",
      "Episode 3564: Reward = 597.00, Steps = 3, Loss = 8.4211, Exploration Rate = 0.1000, Train Count = 32932\n",
      "Episode 3565: Reward = 591.00, Steps = 5, Loss = 7.8526, Exploration Rate = 0.1000, Train Count = 32937\n",
      "Episode 3566: Reward = 582.00, Steps = 8, Loss = 12.8998, Exploration Rate = 0.1000, Train Count = 32945\n",
      "Episode 3567: Reward = 588.00, Steps = 6, Loss = 11.3756, Exploration Rate = 0.1000, Train Count = 32951\n",
      "Episode 3568: Reward = 591.00, Steps = 5, Loss = 9.1231, Exploration Rate = 0.1000, Train Count = 32956\n",
      "Episode 3569: Reward = 588.00, Steps = 6, Loss = 11.9363, Exploration Rate = 0.1000, Train Count = 32962\n",
      "Episode 3570: Reward = 585.00, Steps = 7, Loss = 11.2713, Exploration Rate = 0.1000, Train Count = 32969\n",
      "Episode 3571: Reward = 588.00, Steps = 6, Loss = 11.4104, Exploration Rate = 0.1000, Train Count = 32975\n",
      "Episode 3572: Reward = 585.00, Steps = 7, Loss = 10.8549, Exploration Rate = 0.1000, Train Count = 32982\n",
      "Episode 3573: Reward = 579.00, Steps = 9, Loss = 11.3493, Exploration Rate = 0.1000, Train Count = 32991\n",
      "Episode 3574: Reward = 588.00, Steps = 6, Loss = 9.6685, Exploration Rate = 0.1000, Train Count = 32997\n",
      "Episode 3575: Reward = 591.00, Steps = 5, Loss = 9.5755, Exploration Rate = 0.1000, Train Count = 33002\n",
      "Episode 3576: Reward = 588.00, Steps = 6, Loss = 8.8391, Exploration Rate = 0.1000, Train Count = 33008\n",
      "Episode 3577: Reward = 594.00, Steps = 4, Loss = 11.5324, Exploration Rate = 0.1000, Train Count = 33012\n",
      "Episode 3578: Reward = 597.00, Steps = 3, Loss = 9.1497, Exploration Rate = 0.1000, Train Count = 33015\n",
      "Episode 3579: Reward = 591.00, Steps = 5, Loss = 7.3760, Exploration Rate = 0.1000, Train Count = 33020\n",
      "Episode 3580: Reward = 588.00, Steps = 6, Loss = 4.7765, Exploration Rate = 0.1000, Train Count = 33026\n",
      "Episode 3581: Reward = 585.00, Steps = 7, Loss = 10.3643, Exploration Rate = 0.1000, Train Count = 33033\n",
      "Episode 3582: Reward = 591.00, Steps = 5, Loss = 7.8027, Exploration Rate = 0.1000, Train Count = 33038\n",
      "Episode 3583: Reward = 591.00, Steps = 5, Loss = 12.5516, Exploration Rate = 0.1000, Train Count = 33043\n",
      "Episode 3584: Reward = 594.00, Steps = 4, Loss = 8.6918, Exploration Rate = 0.1000, Train Count = 33047\n",
      "Episode 3585: Reward = 582.00, Steps = 8, Loss = 10.3774, Exploration Rate = 0.1000, Train Count = 33055\n",
      "Episode 3586: Reward = 591.00, Steps = 5, Loss = 6.8063, Exploration Rate = 0.1000, Train Count = 33060\n",
      "Episode 3587: Reward = 591.00, Steps = 5, Loss = 7.8475, Exploration Rate = 0.1000, Train Count = 33065\n",
      "Episode 3588: Reward = 591.00, Steps = 5, Loss = 4.7678, Exploration Rate = 0.1000, Train Count = 33070\n",
      "Episode 3589: Reward = 582.00, Steps = 8, Loss = 6.3770, Exploration Rate = 0.1000, Train Count = 33078\n",
      "Episode 3590: Reward = 585.00, Steps = 7, Loss = 10.3409, Exploration Rate = 0.1000, Train Count = 33085\n",
      "Episode 3591: Reward = 538.00, Steps = 7, Loss = 10.5246, Exploration Rate = 0.1000, Train Count = 33092\n",
      "Episode 3592: Reward = 591.00, Steps = 5, Loss = 10.9093, Exploration Rate = 0.1000, Train Count = 33097\n",
      "Episode 3593: Reward = 588.00, Steps = 6, Loss = 7.0843, Exploration Rate = 0.1000, Train Count = 33103\n",
      "Episode 3594: Reward = 579.00, Steps = 9, Loss = 9.5501, Exploration Rate = 0.1000, Train Count = 33112\n",
      "Episode 3595: Reward = 576.00, Steps = 10, Loss = 8.1559, Exploration Rate = 0.1000, Train Count = 33122\n",
      "Episode 3596: Reward = 588.00, Steps = 6, Loss = 9.9441, Exploration Rate = 0.1000, Train Count = 33128\n",
      "Episode 3597: Reward = 585.00, Steps = 7, Loss = 8.2583, Exploration Rate = 0.1000, Train Count = 33135\n",
      "Episode 3598: Reward = 573.00, Steps = 11, Loss = 7.9156, Exploration Rate = 0.1000, Train Count = 33146\n",
      "Episode 3599: Reward = 594.00, Steps = 4, Loss = 12.0615, Exploration Rate = 0.1000, Train Count = 33150\n",
      "Episode 3600: Reward = 544.00, Steps = 5, Loss = 10.3358, Exploration Rate = 0.1000, Train Count = 33155\n",
      "Episode 3601: Reward = 597.00, Steps = 3, Loss = 11.4997, Exploration Rate = 0.1000, Train Count = 33158\n",
      "Episode 3602: Reward = 549.00, Steps = 19, Loss = 17.1687, Exploration Rate = 0.1000, Train Count = 33177\n",
      "Episode 3603: Reward = 582.00, Steps = 8, Loss = 14.7698, Exploration Rate = 0.1000, Train Count = 33185\n",
      "Episode 3604: Reward = 591.00, Steps = 5, Loss = 8.9757, Exploration Rate = 0.1000, Train Count = 33190\n",
      "Episode 3605: Reward = 544.00, Steps = 5, Loss = 13.0557, Exploration Rate = 0.1000, Train Count = 33195\n",
      "Episode 3606: Reward = 579.00, Steps = 9, Loss = 15.2651, Exploration Rate = 0.1000, Train Count = 33204\n",
      "Episode 3607: Reward = 579.00, Steps = 9, Loss = 13.1999, Exploration Rate = 0.1000, Train Count = 33213\n",
      "Episode 3608: Reward = 597.00, Steps = 3, Loss = 7.1485, Exploration Rate = 0.1000, Train Count = 33216\n",
      "Episode 3609: Reward = 591.00, Steps = 5, Loss = 10.9479, Exploration Rate = 0.1000, Train Count = 33221\n",
      "Episode 3610: Reward = 597.00, Steps = 3, Loss = 10.4655, Exploration Rate = 0.1000, Train Count = 33224\n",
      "Episode 3611: Reward = 585.00, Steps = 7, Loss = 10.5792, Exploration Rate = 0.1000, Train Count = 33231\n",
      "Episode 3612: Reward = 588.00, Steps = 6, Loss = 8.7766, Exploration Rate = 0.1000, Train Count = 33237\n",
      "Episode 3613: Reward = 597.00, Steps = 3, Loss = 6.7871, Exploration Rate = 0.1000, Train Count = 33240\n",
      "Episode 3614: Reward = 591.00, Steps = 5, Loss = 8.7304, Exploration Rate = 0.1000, Train Count = 33245\n",
      "Episode 3615: Reward = 600.00, Steps = 2, Loss = 17.3811, Exploration Rate = 0.1000, Train Count = 33247\n",
      "Episode 3616: Reward = 591.00, Steps = 5, Loss = 10.6283, Exploration Rate = 0.1000, Train Count = 33252\n",
      "Episode 3617: Reward = 576.00, Steps = 10, Loss = 7.8102, Exploration Rate = 0.1000, Train Count = 33262\n",
      "Episode 3618: Reward = 588.00, Steps = 6, Loss = 12.2634, Exploration Rate = 0.1000, Train Count = 33268\n",
      "Episode 3619: Reward = 597.00, Steps = 3, Loss = 15.7469, Exploration Rate = 0.1000, Train Count = 33271\n",
      "Episode 3620: Reward = 594.00, Steps = 4, Loss = 10.9304, Exploration Rate = 0.1000, Train Count = 33275\n",
      "Episode 3621: Reward = 594.00, Steps = 4, Loss = 15.2908, Exploration Rate = 0.1000, Train Count = 33279\n",
      "Episode 3622: Reward = 591.00, Steps = 5, Loss = 6.4491, Exploration Rate = 0.1000, Train Count = 33284\n",
      "Episode 3623: Reward = 597.00, Steps = 3, Loss = 13.2127, Exploration Rate = 0.1000, Train Count = 33287\n",
      "Episode 3624: Reward = 538.00, Steps = 7, Loss = 9.9939, Exploration Rate = 0.1000, Train Count = 33294\n",
      "Episode 3625: Reward = 597.00, Steps = 3, Loss = 14.2844, Exploration Rate = 0.1000, Train Count = 33297\n",
      "Episode 3626: Reward = 588.00, Steps = 6, Loss = 28.9639, Exploration Rate = 0.1000, Train Count = 33303\n",
      "Episode 3627: Reward = 597.00, Steps = 3, Loss = 35.6624, Exploration Rate = 0.1000, Train Count = 33306\n",
      "Episode 3628: Reward = 594.00, Steps = 4, Loss = 28.4520, Exploration Rate = 0.1000, Train Count = 33310\n",
      "Episode 3629: Reward = 585.00, Steps = 7, Loss = 33.6760, Exploration Rate = 0.1000, Train Count = 33317\n",
      "Episode 3630: Reward = 597.00, Steps = 3, Loss = 26.9376, Exploration Rate = 0.1000, Train Count = 33320\n",
      "Episode 3631: Reward = 588.00, Steps = 6, Loss = 24.1517, Exploration Rate = 0.1000, Train Count = 33326\n",
      "Episode 3632: Reward = 588.00, Steps = 6, Loss = 19.0463, Exploration Rate = 0.1000, Train Count = 33332\n",
      "Episode 3633: Reward = 591.00, Steps = 5, Loss = 20.7758, Exploration Rate = 0.1000, Train Count = 33337\n",
      "Episode 3634: Reward = 594.00, Steps = 4, Loss = 18.7124, Exploration Rate = 0.1000, Train Count = 33341\n",
      "Episode 3635: Reward = 585.00, Steps = 7, Loss = 14.7942, Exploration Rate = 0.1000, Train Count = 33348\n",
      "Episode 3636: Reward = 588.00, Steps = 6, Loss = 14.6533, Exploration Rate = 0.1000, Train Count = 33354\n",
      "Episode 3637: Reward = 594.00, Steps = 4, Loss = 12.1234, Exploration Rate = 0.1000, Train Count = 33358\n",
      "Episode 3638: Reward = 597.00, Steps = 3, Loss = 15.3549, Exploration Rate = 0.1000, Train Count = 33361\n",
      "Episode 3639: Reward = 588.00, Steps = 6, Loss = 13.4415, Exploration Rate = 0.1000, Train Count = 33367\n",
      "Episode 3640: Reward = 582.00, Steps = 8, Loss = 10.1362, Exploration Rate = 0.1000, Train Count = 33375\n",
      "Episode 3641: Reward = 594.00, Steps = 4, Loss = 15.2545, Exploration Rate = 0.1000, Train Count = 33379\n",
      "Episode 3642: Reward = 573.00, Steps = 11, Loss = 10.3823, Exploration Rate = 0.1000, Train Count = 33390\n",
      "Episode 3643: Reward = 588.00, Steps = 6, Loss = 13.2499, Exploration Rate = 0.1000, Train Count = 33396\n",
      "Episode 3644: Reward = 582.00, Steps = 8, Loss = 11.1509, Exploration Rate = 0.1000, Train Count = 33404\n",
      "Episode 3645: Reward = 591.00, Steps = 5, Loss = 6.9530, Exploration Rate = 0.1000, Train Count = 33409\n",
      "Episode 3646: Reward = 597.00, Steps = 3, Loss = 11.6055, Exploration Rate = 0.1000, Train Count = 33412\n",
      "Episode 3647: Reward = 594.00, Steps = 4, Loss = 8.1340, Exploration Rate = 0.1000, Train Count = 33416\n",
      "Episode 3648: Reward = 588.00, Steps = 6, Loss = 9.9392, Exploration Rate = 0.1000, Train Count = 33422\n",
      "Episode 3649: Reward = 588.00, Steps = 6, Loss = 14.6685, Exploration Rate = 0.1000, Train Count = 33428\n",
      "Episode 3650: Reward = 585.00, Steps = 7, Loss = 17.6104, Exploration Rate = 0.1000, Train Count = 33435\n",
      "Episode 3651: Reward = 588.00, Steps = 6, Loss = 15.8355, Exploration Rate = 0.1000, Train Count = 33441\n",
      "Episode 3652: Reward = 585.00, Steps = 7, Loss = 15.1532, Exploration Rate = 0.1000, Train Count = 33448\n",
      "Episode 3653: Reward = 600.00, Steps = 2, Loss = 9.4870, Exploration Rate = 0.1000, Train Count = 33450\n",
      "Episode 3654: Reward = 491.00, Steps = 7, Loss = 10.6654, Exploration Rate = 0.1000, Train Count = 33457\n",
      "Episode 3655: Reward = 579.00, Steps = 9, Loss = 15.7780, Exploration Rate = 0.1000, Train Count = 33466\n",
      "Episode 3656: Reward = 544.00, Steps = 5, Loss = 16.1123, Exploration Rate = 0.1000, Train Count = 33471\n",
      "Episode 3657: Reward = 585.00, Steps = 7, Loss = 12.9373, Exploration Rate = 0.1000, Train Count = 33478\n",
      "Episode 3658: Reward = 591.00, Steps = 5, Loss = 10.7531, Exploration Rate = 0.1000, Train Count = 33483\n",
      "Episode 3659: Reward = 591.00, Steps = 5, Loss = 10.3436, Exploration Rate = 0.1000, Train Count = 33488\n",
      "Episode 3660: Reward = 582.00, Steps = 8, Loss = 12.1345, Exploration Rate = 0.1000, Train Count = 33496\n",
      "Episode 3661: Reward = 597.00, Steps = 3, Loss = 11.2609, Exploration Rate = 0.1000, Train Count = 33499\n",
      "Episode 3662: Reward = 591.00, Steps = 5, Loss = 8.5055, Exploration Rate = 0.1000, Train Count = 33504\n",
      "Episode 3663: Reward = 591.00, Steps = 5, Loss = 10.9122, Exploration Rate = 0.1000, Train Count = 33509\n",
      "Episode 3664: Reward = 594.00, Steps = 4, Loss = 7.3542, Exploration Rate = 0.1000, Train Count = 33513\n",
      "Episode 3665: Reward = 600.00, Steps = 2, Loss = 14.3976, Exploration Rate = 0.1000, Train Count = 33515\n",
      "Episode 3666: Reward = 588.00, Steps = 6, Loss = 6.9122, Exploration Rate = 0.1000, Train Count = 33521\n",
      "Episode 3667: Reward = 582.00, Steps = 8, Loss = 13.8206, Exploration Rate = 0.1000, Train Count = 33529\n",
      "Episode 3668: Reward = 588.00, Steps = 6, Loss = 11.5016, Exploration Rate = 0.1000, Train Count = 33535\n",
      "Episode 3669: Reward = 576.00, Steps = 10, Loss = 9.0874, Exploration Rate = 0.1000, Train Count = 33545\n",
      "Episode 3670: Reward = 600.00, Steps = 2, Loss = 10.7937, Exploration Rate = 0.1000, Train Count = 33547\n",
      "Episode 3671: Reward = 597.00, Steps = 3, Loss = 9.0831, Exploration Rate = 0.1000, Train Count = 33550\n",
      "Episode 3672: Reward = 594.00, Steps = 4, Loss = 12.6213, Exploration Rate = 0.1000, Train Count = 33554\n",
      "Episode 3673: Reward = 526.00, Steps = 11, Loss = 14.7844, Exploration Rate = 0.1000, Train Count = 33565\n",
      "Episode 3674: Reward = 573.00, Steps = 11, Loss = 13.7175, Exploration Rate = 0.1000, Train Count = 33576\n",
      "Episode 3675: Reward = 585.00, Steps = 7, Loss = 23.0524, Exploration Rate = 0.1000, Train Count = 33583\n",
      "Episode 3676: Reward = 582.00, Steps = 8, Loss = 16.7558, Exploration Rate = 0.1000, Train Count = 33591\n",
      "Episode 3677: Reward = 544.00, Steps = 5, Loss = 18.5360, Exploration Rate = 0.1000, Train Count = 33596\n",
      "Episode 3678: Reward = 591.00, Steps = 5, Loss = 17.6151, Exploration Rate = 0.1000, Train Count = 33601\n",
      "Episode 3679: Reward = 585.00, Steps = 7, Loss = 14.7099, Exploration Rate = 0.1000, Train Count = 33608\n",
      "Episode 3680: Reward = 579.00, Steps = 9, Loss = 23.6864, Exploration Rate = 0.1000, Train Count = 33617\n",
      "Episode 3681: Reward = 535.00, Steps = 8, Loss = 19.6547, Exploration Rate = 0.1000, Train Count = 33625\n",
      "Episode 3682: Reward = 585.00, Steps = 7, Loss = 14.4262, Exploration Rate = 0.1000, Train Count = 33632\n",
      "Episode 3683: Reward = 588.00, Steps = 6, Loss = 14.9839, Exploration Rate = 0.1000, Train Count = 33638\n",
      "Episode 3684: Reward = 597.00, Steps = 3, Loss = 12.3230, Exploration Rate = 0.1000, Train Count = 33641\n",
      "Episode 3685: Reward = 597.00, Steps = 3, Loss = 20.2806, Exploration Rate = 0.1000, Train Count = 33644\n",
      "Episode 3686: Reward = 591.00, Steps = 5, Loss = 12.5317, Exploration Rate = 0.1000, Train Count = 33649\n",
      "Episode 3687: Reward = 594.00, Steps = 4, Loss = 10.9391, Exploration Rate = 0.1000, Train Count = 33653\n",
      "Episode 3688: Reward = 526.00, Steps = 11, Loss = 17.8753, Exploration Rate = 0.1000, Train Count = 33664\n",
      "Episode 3689: Reward = 582.00, Steps = 8, Loss = 14.0026, Exploration Rate = 0.1000, Train Count = 33672\n",
      "Episode 3690: Reward = 541.00, Steps = 6, Loss = 15.2834, Exploration Rate = 0.1000, Train Count = 33678\n",
      "Episode 3691: Reward = 591.00, Steps = 5, Loss = 20.3440, Exploration Rate = 0.1000, Train Count = 33683\n",
      "Episode 3692: Reward = 576.00, Steps = 10, Loss = 18.9327, Exploration Rate = 0.1000, Train Count = 33693\n",
      "Episode 3693: Reward = 531.00, Steps = 25, Loss = 18.9614, Exploration Rate = 0.1000, Train Count = 33718\n",
      "Episode 3694: Reward = 594.00, Steps = 4, Loss = 15.8106, Exploration Rate = 0.1000, Train Count = 33722\n",
      "Episode 3695: Reward = 594.00, Steps = 4, Loss = 22.3020, Exploration Rate = 0.1000, Train Count = 33726\n",
      "Episode 3696: Reward = 591.00, Steps = 5, Loss = 17.3334, Exploration Rate = 0.1000, Train Count = 33731\n",
      "Episode 3697: Reward = 591.00, Steps = 5, Loss = 17.2961, Exploration Rate = 0.1000, Train Count = 33736\n",
      "Episode 3698: Reward = 585.00, Steps = 7, Loss = 12.7731, Exploration Rate = 0.1000, Train Count = 33743\n",
      "Episode 3699: Reward = 585.00, Steps = 7, Loss = 14.7579, Exploration Rate = 0.1000, Train Count = 33750\n",
      "Episode 3700: Reward = 585.00, Steps = 7, Loss = 14.6265, Exploration Rate = 0.1000, Train Count = 33757\n",
      "Episode 3701: Reward = 591.00, Steps = 5, Loss = 12.1385, Exploration Rate = 0.1000, Train Count = 33762\n",
      "Episode 3702: Reward = 585.00, Steps = 7, Loss = 13.5147, Exploration Rate = 0.1000, Train Count = 33769\n",
      "Episode 3703: Reward = 588.00, Steps = 6, Loss = 12.2052, Exploration Rate = 0.1000, Train Count = 33775\n",
      "Episode 3704: Reward = 600.00, Steps = 2, Loss = 16.6312, Exploration Rate = 0.1000, Train Count = 33777\n",
      "Episode 3705: Reward = 588.00, Steps = 6, Loss = 15.6102, Exploration Rate = 0.1000, Train Count = 33783\n",
      "Episode 3706: Reward = 541.00, Steps = 6, Loss = 20.0229, Exploration Rate = 0.1000, Train Count = 33789\n",
      "Episode 3707: Reward = 600.00, Steps = 2, Loss = 13.5155, Exploration Rate = 0.1000, Train Count = 33791\n",
      "Episode 3708: Reward = 585.00, Steps = 7, Loss = 20.1451, Exploration Rate = 0.1000, Train Count = 33798\n",
      "Episode 3709: Reward = 585.00, Steps = 7, Loss = 45.6080, Exploration Rate = 0.1000, Train Count = 33805\n",
      "Episode 3710: Reward = 591.00, Steps = 5, Loss = 40.2164, Exploration Rate = 0.1000, Train Count = 33810\n",
      "Episode 3711: Reward = 582.00, Steps = 8, Loss = 35.1156, Exploration Rate = 0.1000, Train Count = 33818\n",
      "Episode 3712: Reward = 529.00, Steps = 10, Loss = 28.3098, Exploration Rate = 0.1000, Train Count = 33828\n",
      "Episode 3713: Reward = 594.00, Steps = 4, Loss = 21.4795, Exploration Rate = 0.1000, Train Count = 33832\n",
      "Episode 3714: Reward = 585.00, Steps = 7, Loss = 22.1949, Exploration Rate = 0.1000, Train Count = 33839\n",
      "Episode 3715: Reward = 588.00, Steps = 6, Loss = 21.3845, Exploration Rate = 0.1000, Train Count = 33845\n",
      "Episode 3716: Reward = 573.00, Steps = 11, Loss = 24.7292, Exploration Rate = 0.1000, Train Count = 33856\n",
      "Episode 3717: Reward = 544.00, Steps = 5, Loss = 24.2320, Exploration Rate = 0.1000, Train Count = 33861\n",
      "Episode 3718: Reward = 555.00, Steps = 17, Loss = 24.6638, Exploration Rate = 0.1000, Train Count = 33878\n",
      "Episode 3719: Reward = 540.00, Steps = 22, Loss = 21.6311, Exploration Rate = 0.1000, Train Count = 33900\n",
      "Episode 3720: Reward = 585.00, Steps = 7, Loss = 15.3827, Exploration Rate = 0.1000, Train Count = 33907\n",
      "Episode 3721: Reward = 585.00, Steps = 7, Loss = 17.6860, Exploration Rate = 0.1000, Train Count = 33914\n",
      "Episode 3722: Reward = 591.00, Steps = 5, Loss = 16.9508, Exploration Rate = 0.1000, Train Count = 33919\n",
      "Episode 3723: Reward = 588.00, Steps = 6, Loss = 17.9446, Exploration Rate = 0.1000, Train Count = 33925\n",
      "Episode 3724: Reward = 582.00, Steps = 8, Loss = 25.6580, Exploration Rate = 0.1000, Train Count = 33933\n",
      "Episode 3725: Reward = 597.00, Steps = 3, Loss = 19.5573, Exploration Rate = 0.1000, Train Count = 33936\n",
      "Episode 3726: Reward = 597.00, Steps = 3, Loss = 22.1323, Exploration Rate = 0.1000, Train Count = 33939\n",
      "Episode 3727: Reward = 482.00, Steps = 10, Loss = 22.7071, Exploration Rate = 0.1000, Train Count = 33949\n",
      "Episode 3728: Reward = 579.00, Steps = 9, Loss = 21.9036, Exploration Rate = 0.1000, Train Count = 33958\n",
      "Episode 3729: Reward = 585.00, Steps = 7, Loss = 16.3652, Exploration Rate = 0.1000, Train Count = 33965\n",
      "Episode 3730: Reward = 591.00, Steps = 5, Loss = 16.8644, Exploration Rate = 0.1000, Train Count = 33970\n",
      "Episode 3731: Reward = 585.00, Steps = 7, Loss = 17.7981, Exploration Rate = 0.1000, Train Count = 33977\n",
      "Episode 3732: Reward = 588.00, Steps = 6, Loss = 16.8203, Exploration Rate = 0.1000, Train Count = 33983\n",
      "Episode 3733: Reward = 588.00, Steps = 6, Loss = 15.4174, Exploration Rate = 0.1000, Train Count = 33989\n",
      "Episode 3734: Reward = 585.00, Steps = 7, Loss = 13.2434, Exploration Rate = 0.1000, Train Count = 33996\n",
      "Episode 3735: Reward = 588.00, Steps = 6, Loss = 18.2697, Exploration Rate = 0.1000, Train Count = 34002\n",
      "Episode 3736: Reward = 582.00, Steps = 8, Loss = 16.6839, Exploration Rate = 0.1000, Train Count = 34010\n",
      "Episode 3737: Reward = 582.00, Steps = 8, Loss = 15.7963, Exploration Rate = 0.1000, Train Count = 34018\n",
      "Episode 3738: Reward = 579.00, Steps = 9, Loss = 13.2490, Exploration Rate = 0.1000, Train Count = 34027\n",
      "Episode 3739: Reward = 597.00, Steps = 3, Loss = 15.9094, Exploration Rate = 0.1000, Train Count = 34030\n",
      "Episode 3740: Reward = 579.00, Steps = 9, Loss = 11.2369, Exploration Rate = 0.1000, Train Count = 34039\n",
      "Episode 3741: Reward = 591.00, Steps = 5, Loss = 15.6330, Exploration Rate = 0.1000, Train Count = 34044\n",
      "Episode 3742: Reward = 594.00, Steps = 4, Loss = 9.2334, Exploration Rate = 0.1000, Train Count = 34048\n",
      "Episode 3743: Reward = 597.00, Steps = 3, Loss = 12.7304, Exploration Rate = 0.1000, Train Count = 34051\n",
      "Episode 3744: Reward = 600.00, Steps = 2, Loss = 10.5754, Exploration Rate = 0.1000, Train Count = 34053\n",
      "Episode 3745: Reward = 600.00, Steps = 2, Loss = 19.1425, Exploration Rate = 0.1000, Train Count = 34055\n",
      "Episode 3746: Reward = 585.00, Steps = 7, Loss = 14.6039, Exploration Rate = 0.1000, Train Count = 34062\n",
      "Episode 3747: Reward = 591.00, Steps = 5, Loss = 18.3287, Exploration Rate = 0.1000, Train Count = 34067\n",
      "Episode 3748: Reward = 582.00, Steps = 8, Loss = 16.0903, Exploration Rate = 0.1000, Train Count = 34075\n",
      "Episode 3749: Reward = 588.00, Steps = 6, Loss = 21.2253, Exploration Rate = 0.1000, Train Count = 34081\n",
      "Episode 3750: Reward = 600.00, Steps = 2, Loss = 17.8564, Exploration Rate = 0.1000, Train Count = 34083\n",
      "Episode 3751: Reward = 594.00, Steps = 4, Loss = 16.4350, Exploration Rate = 0.1000, Train Count = 34087\n",
      "Episode 3752: Reward = 588.00, Steps = 6, Loss = 14.8243, Exploration Rate = 0.1000, Train Count = 34093\n",
      "Episode 3753: Reward = 594.00, Steps = 4, Loss = 14.9002, Exploration Rate = 0.1000, Train Count = 34097\n",
      "Episode 3754: Reward = 594.00, Steps = 4, Loss = 24.6002, Exploration Rate = 0.1000, Train Count = 34101\n",
      "Episode 3755: Reward = 585.00, Steps = 7, Loss = 17.8819, Exploration Rate = 0.1000, Train Count = 34108\n",
      "Episode 3756: Reward = 579.00, Steps = 9, Loss = 17.9411, Exploration Rate = 0.1000, Train Count = 34117\n",
      "Episode 3757: Reward = 594.00, Steps = 4, Loss = 16.0569, Exploration Rate = 0.1000, Train Count = 34121\n",
      "Episode 3758: Reward = 591.00, Steps = 5, Loss = 20.3049, Exploration Rate = 0.1000, Train Count = 34126\n",
      "Episode 3759: Reward = 591.00, Steps = 5, Loss = 16.1554, Exploration Rate = 0.1000, Train Count = 34131\n",
      "Episode 3760: Reward = 597.00, Steps = 3, Loss = 22.4834, Exploration Rate = 0.1000, Train Count = 34134\n",
      "Episode 3761: Reward = 597.00, Steps = 3, Loss = 15.7552, Exploration Rate = 0.1000, Train Count = 34137\n",
      "Episode 3762: Reward = 597.00, Steps = 3, Loss = 15.7945, Exploration Rate = 0.1000, Train Count = 34140\n",
      "Episode 3763: Reward = 591.00, Steps = 5, Loss = 14.4662, Exploration Rate = 0.1000, Train Count = 34145\n",
      "Episode 3764: Reward = 591.00, Steps = 5, Loss = 11.0118, Exploration Rate = 0.1000, Train Count = 34150\n",
      "Episode 3765: Reward = 594.00, Steps = 4, Loss = 19.4630, Exploration Rate = 0.1000, Train Count = 34154\n",
      "Episode 3766: Reward = 585.00, Steps = 7, Loss = 12.3165, Exploration Rate = 0.1000, Train Count = 34161\n",
      "Episode 3767: Reward = 597.00, Steps = 3, Loss = 11.2826, Exploration Rate = 0.1000, Train Count = 34164\n",
      "Episode 3768: Reward = 582.00, Steps = 8, Loss = 11.0270, Exploration Rate = 0.1000, Train Count = 34172\n",
      "Episode 3769: Reward = 582.00, Steps = 8, Loss = 15.5614, Exploration Rate = 0.1000, Train Count = 34180\n",
      "Episode 3770: Reward = 582.00, Steps = 8, Loss = 10.6290, Exploration Rate = 0.1000, Train Count = 34188\n",
      "Episode 3771: Reward = 600.00, Steps = 2, Loss = 5.5245, Exploration Rate = 0.1000, Train Count = 34190\n",
      "Episode 3772: Reward = 591.00, Steps = 5, Loss = 9.9180, Exploration Rate = 0.1000, Train Count = 34195\n",
      "Episode 3773: Reward = 579.00, Steps = 9, Loss = 11.8115, Exploration Rate = 0.1000, Train Count = 34204\n",
      "Episode 3774: Reward = 591.00, Steps = 5, Loss = 6.3462, Exploration Rate = 0.1000, Train Count = 34209\n",
      "Episode 3775: Reward = 591.00, Steps = 5, Loss = 12.6137, Exploration Rate = 0.1000, Train Count = 34214\n",
      "Episode 3776: Reward = 597.00, Steps = 3, Loss = 13.5245, Exploration Rate = 0.1000, Train Count = 34217\n",
      "Episode 3777: Reward = 585.00, Steps = 7, Loss = 11.7439, Exploration Rate = 0.1000, Train Count = 34224\n",
      "Episode 3778: Reward = 594.00, Steps = 4, Loss = 10.3582, Exploration Rate = 0.1000, Train Count = 34228\n",
      "Episode 3779: Reward = 591.00, Steps = 5, Loss = 13.6661, Exploration Rate = 0.1000, Train Count = 34233\n",
      "Episode 3780: Reward = 594.00, Steps = 4, Loss = 10.6859, Exploration Rate = 0.1000, Train Count = 34237\n",
      "Episode 3781: Reward = 591.00, Steps = 5, Loss = 13.0857, Exploration Rate = 0.1000, Train Count = 34242\n",
      "Episode 3782: Reward = 591.00, Steps = 5, Loss = 8.7470, Exploration Rate = 0.1000, Train Count = 34247\n",
      "Episode 3783: Reward = 561.00, Steps = 15, Loss = 13.1214, Exploration Rate = 0.1000, Train Count = 34262\n",
      "Episode 3784: Reward = 585.00, Steps = 7, Loss = 11.8559, Exploration Rate = 0.1000, Train Count = 34269\n",
      "Episode 3785: Reward = 588.00, Steps = 6, Loss = 11.3956, Exploration Rate = 0.1000, Train Count = 34275\n",
      "Episode 3786: Reward = 594.00, Steps = 4, Loss = 7.7960, Exploration Rate = 0.1000, Train Count = 34279\n",
      "Episode 3787: Reward = 594.00, Steps = 4, Loss = 7.7649, Exploration Rate = 0.1000, Train Count = 34283\n",
      "Episode 3788: Reward = 588.00, Steps = 6, Loss = 12.5541, Exploration Rate = 0.1000, Train Count = 34289\n",
      "Episode 3789: Reward = 591.00, Steps = 5, Loss = 11.7896, Exploration Rate = 0.1000, Train Count = 34294\n",
      "Episode 3790: Reward = 594.00, Steps = 4, Loss = 16.5697, Exploration Rate = 0.1000, Train Count = 34298\n",
      "Episode 3791: Reward = 591.00, Steps = 5, Loss = 38.8184, Exploration Rate = 0.1000, Train Count = 34303\n",
      "Episode 3792: Reward = 588.00, Steps = 6, Loss = 47.0394, Exploration Rate = 0.1000, Train Count = 34309\n",
      "Episode 3793: Reward = 600.00, Steps = 2, Loss = 37.3732, Exploration Rate = 0.1000, Train Count = 34311\n",
      "Episode 3794: Reward = 532.00, Steps = 9, Loss = 32.8986, Exploration Rate = 0.1000, Train Count = 34320\n",
      "Episode 3795: Reward = 585.00, Steps = 7, Loss = 27.4121, Exploration Rate = 0.1000, Train Count = 34327\n",
      "Episode 3796: Reward = 588.00, Steps = 6, Loss = 22.0778, Exploration Rate = 0.1000, Train Count = 34333\n",
      "Episode 3797: Reward = 591.00, Steps = 5, Loss = 22.0582, Exploration Rate = 0.1000, Train Count = 34338\n",
      "Episode 3798: Reward = 585.00, Steps = 7, Loss = 18.1703, Exploration Rate = 0.1000, Train Count = 34345\n",
      "Episode 3799: Reward = 588.00, Steps = 6, Loss = 14.4638, Exploration Rate = 0.1000, Train Count = 34351\n",
      "Episode 3800: Reward = 579.00, Steps = 9, Loss = 14.8116, Exploration Rate = 0.1000, Train Count = 34360\n",
      "Episode 3801: Reward = 582.00, Steps = 8, Loss = 15.1702, Exploration Rate = 0.1000, Train Count = 34368\n",
      "Episode 3802: Reward = 597.00, Steps = 3, Loss = 9.3924, Exploration Rate = 0.1000, Train Count = 34371\n",
      "Episode 3803: Reward = 594.00, Steps = 4, Loss = 12.8820, Exploration Rate = 0.1000, Train Count = 34375\n",
      "Episode 3804: Reward = 591.00, Steps = 5, Loss = 14.4432, Exploration Rate = 0.1000, Train Count = 34380\n",
      "Episode 3805: Reward = 591.00, Steps = 5, Loss = 16.1025, Exploration Rate = 0.1000, Train Count = 34385\n",
      "Episode 3806: Reward = 582.00, Steps = 8, Loss = 13.7674, Exploration Rate = 0.1000, Train Count = 34393\n",
      "Episode 3807: Reward = 538.00, Steps = 7, Loss = 14.7476, Exploration Rate = 0.1000, Train Count = 34400\n",
      "Episode 3808: Reward = 588.00, Steps = 6, Loss = 13.7259, Exploration Rate = 0.1000, Train Count = 34406\n",
      "Episode 3809: Reward = 597.00, Steps = 3, Loss = 14.5737, Exploration Rate = 0.1000, Train Count = 34409\n",
      "Episode 3810: Reward = 597.00, Steps = 3, Loss = 13.7393, Exploration Rate = 0.1000, Train Count = 34412\n",
      "Episode 3811: Reward = 573.00, Steps = 11, Loss = 21.1696, Exploration Rate = 0.1000, Train Count = 34423\n",
      "Episode 3812: Reward = 570.00, Steps = 12, Loss = 17.9909, Exploration Rate = 0.1000, Train Count = 34435\n",
      "Episode 3813: Reward = 591.00, Steps = 5, Loss = 17.0722, Exploration Rate = 0.1000, Train Count = 34440\n",
      "Episode 3814: Reward = 597.00, Steps = 3, Loss = 11.5144, Exploration Rate = 0.1000, Train Count = 34443\n",
      "Episode 3815: Reward = 576.00, Steps = 10, Loss = 14.2551, Exploration Rate = 0.1000, Train Count = 34453\n",
      "Episode 3816: Reward = 544.00, Steps = 5, Loss = 9.9975, Exploration Rate = 0.1000, Train Count = 34458\n",
      "Episode 3817: Reward = 597.00, Steps = 3, Loss = 12.1856, Exploration Rate = 0.1000, Train Count = 34461\n",
      "Episode 3818: Reward = 600.00, Steps = 2, Loss = 9.1915, Exploration Rate = 0.1000, Train Count = 34463\n",
      "Episode 3819: Reward = 591.00, Steps = 5, Loss = 11.7114, Exploration Rate = 0.1000, Train Count = 34468\n",
      "Episode 3820: Reward = 588.00, Steps = 6, Loss = 14.8325, Exploration Rate = 0.1000, Train Count = 34474\n",
      "Episode 3821: Reward = 597.00, Steps = 3, Loss = 11.9117, Exploration Rate = 0.1000, Train Count = 34477\n",
      "Episode 3822: Reward = 588.00, Steps = 6, Loss = 10.2642, Exploration Rate = 0.1000, Train Count = 34483\n",
      "Episode 3823: Reward = 591.00, Steps = 5, Loss = 9.5188, Exploration Rate = 0.1000, Train Count = 34488\n",
      "Episode 3824: Reward = 585.00, Steps = 7, Loss = 9.3741, Exploration Rate = 0.1000, Train Count = 34495\n",
      "Episode 3825: Reward = 588.00, Steps = 6, Loss = 10.5525, Exploration Rate = 0.1000, Train Count = 34501\n",
      "Episode 3826: Reward = 579.00, Steps = 9, Loss = 8.4552, Exploration Rate = 0.1000, Train Count = 34510\n",
      "Episode 3827: Reward = 588.00, Steps = 6, Loss = 8.5104, Exploration Rate = 0.1000, Train Count = 34516\n",
      "Episode 3828: Reward = 591.00, Steps = 5, Loss = 7.1356, Exploration Rate = 0.1000, Train Count = 34521\n",
      "Episode 3829: Reward = 597.00, Steps = 3, Loss = 12.6449, Exploration Rate = 0.1000, Train Count = 34524\n",
      "Episode 3830: Reward = 585.00, Steps = 7, Loss = 7.3735, Exploration Rate = 0.1000, Train Count = 34531\n",
      "Episode 3831: Reward = 588.00, Steps = 6, Loss = 14.4478, Exploration Rate = 0.1000, Train Count = 34537\n",
      "Episode 3832: Reward = 591.00, Steps = 5, Loss = 12.0694, Exploration Rate = 0.1000, Train Count = 34542\n",
      "Episode 3833: Reward = 591.00, Steps = 5, Loss = 11.7014, Exploration Rate = 0.1000, Train Count = 34547\n",
      "Episode 3834: Reward = 585.00, Steps = 7, Loss = 12.2362, Exploration Rate = 0.1000, Train Count = 34554\n",
      "Episode 3835: Reward = 597.00, Steps = 3, Loss = 8.0570, Exploration Rate = 0.1000, Train Count = 34557\n",
      "Episode 3836: Reward = 585.00, Steps = 7, Loss = 5.5419, Exploration Rate = 0.1000, Train Count = 34564\n",
      "Episode 3837: Reward = 588.00, Steps = 6, Loss = 8.9959, Exploration Rate = 0.1000, Train Count = 34570\n",
      "Episode 3838: Reward = 591.00, Steps = 5, Loss = 11.7599, Exploration Rate = 0.1000, Train Count = 34575\n",
      "Episode 3839: Reward = 564.00, Steps = 14, Loss = 11.7369, Exploration Rate = 0.1000, Train Count = 34589\n",
      "Episode 3840: Reward = 594.00, Steps = 4, Loss = 9.5111, Exploration Rate = 0.1000, Train Count = 34593\n",
      "Episode 3841: Reward = 588.00, Steps = 6, Loss = 7.3037, Exploration Rate = 0.1000, Train Count = 34599\n",
      "Episode 3842: Reward = 600.00, Steps = 2, Loss = 18.2568, Exploration Rate = 0.1000, Train Count = 34601\n",
      "Episode 3843: Reward = 588.00, Steps = 6, Loss = 15.5587, Exploration Rate = 0.1000, Train Count = 34607\n",
      "Episode 3844: Reward = 594.00, Steps = 4, Loss = 11.6013, Exploration Rate = 0.1000, Train Count = 34611\n",
      "Episode 3845: Reward = 597.00, Steps = 3, Loss = 9.4699, Exploration Rate = 0.1000, Train Count = 34614\n",
      "Episode 3846: Reward = 594.00, Steps = 4, Loss = 11.6326, Exploration Rate = 0.1000, Train Count = 34618\n",
      "Episode 3847: Reward = 579.00, Steps = 9, Loss = 7.2188, Exploration Rate = 0.1000, Train Count = 34627\n",
      "Episode 3848: Reward = 585.00, Steps = 7, Loss = 7.0620, Exploration Rate = 0.1000, Train Count = 34634\n",
      "Episode 3849: Reward = 588.00, Steps = 6, Loss = 10.4223, Exploration Rate = 0.1000, Train Count = 34640\n",
      "Episode 3850: Reward = 588.00, Steps = 6, Loss = 13.0312, Exploration Rate = 0.1000, Train Count = 34646\n",
      "Episode 3851: Reward = 579.00, Steps = 9, Loss = 9.5219, Exploration Rate = 0.1000, Train Count = 34655\n",
      "Episode 3852: Reward = 597.00, Steps = 3, Loss = 14.4357, Exploration Rate = 0.1000, Train Count = 34658\n",
      "Episode 3853: Reward = 591.00, Steps = 5, Loss = 9.0249, Exploration Rate = 0.1000, Train Count = 34663\n",
      "Episode 3854: Reward = 597.00, Steps = 3, Loss = 8.8933, Exploration Rate = 0.1000, Train Count = 34666\n",
      "Episode 3855: Reward = 588.00, Steps = 6, Loss = 9.2592, Exploration Rate = 0.1000, Train Count = 34672\n",
      "Episode 3856: Reward = 532.00, Steps = 9, Loss = 5.8542, Exploration Rate = 0.1000, Train Count = 34681\n",
      "Episode 3857: Reward = 591.00, Steps = 5, Loss = 3.1540, Exploration Rate = 0.1000, Train Count = 34686\n",
      "Episode 3858: Reward = 544.00, Steps = 5, Loss = 4.8909, Exploration Rate = 0.1000, Train Count = 34691\n",
      "Episode 3859: Reward = 579.00, Steps = 9, Loss = 6.2679, Exploration Rate = 0.1000, Train Count = 34700\n",
      "Episode 3860: Reward = 594.00, Steps = 4, Loss = 4.5021, Exploration Rate = 0.1000, Train Count = 34704\n",
      "Episode 3861: Reward = 591.00, Steps = 5, Loss = 9.1224, Exploration Rate = 0.1000, Train Count = 34709\n",
      "Episode 3862: Reward = 582.00, Steps = 8, Loss = 5.5418, Exploration Rate = 0.1000, Train Count = 34717\n",
      "Episode 3863: Reward = 585.00, Steps = 7, Loss = 5.5067, Exploration Rate = 0.1000, Train Count = 34724\n",
      "Episode 3864: Reward = 588.00, Steps = 6, Loss = 4.9604, Exploration Rate = 0.1000, Train Count = 34730\n",
      "Episode 3865: Reward = 582.00, Steps = 8, Loss = 3.2379, Exploration Rate = 0.1000, Train Count = 34738\n",
      "Episode 3866: Reward = 591.00, Steps = 5, Loss = 4.6175, Exploration Rate = 0.1000, Train Count = 34743\n",
      "Episode 3867: Reward = 591.00, Steps = 5, Loss = 3.9090, Exploration Rate = 0.1000, Train Count = 34748\n",
      "Episode 3868: Reward = 588.00, Steps = 6, Loss = 3.7520, Exploration Rate = 0.1000, Train Count = 34754\n",
      "Episode 3869: Reward = 541.00, Steps = 6, Loss = 3.6975, Exploration Rate = 0.1000, Train Count = 34760\n",
      "Episode 3870: Reward = 588.00, Steps = 6, Loss = 8.3246, Exploration Rate = 0.1000, Train Count = 34766\n",
      "Episode 3871: Reward = 579.00, Steps = 9, Loss = 8.0238, Exploration Rate = 0.1000, Train Count = 34775\n",
      "Episode 3872: Reward = 597.00, Steps = 3, Loss = 6.1918, Exploration Rate = 0.1000, Train Count = 34778\n",
      "Episode 3873: Reward = 585.00, Steps = 7, Loss = 7.1649, Exploration Rate = 0.1000, Train Count = 34785\n",
      "Episode 3874: Reward = 582.00, Steps = 8, Loss = 7.6909, Exploration Rate = 0.1000, Train Count = 34793\n",
      "Episode 3875: Reward = 594.00, Steps = 4, Loss = 10.4547, Exploration Rate = 0.1000, Train Count = 34797\n",
      "Episode 3876: Reward = 585.00, Steps = 7, Loss = 23.8892, Exploration Rate = 0.1000, Train Count = 34804\n",
      "Episode 3877: Reward = 591.00, Steps = 5, Loss = 30.6765, Exploration Rate = 0.1000, Train Count = 34809\n",
      "Episode 3878: Reward = 585.00, Steps = 7, Loss = 23.4852, Exploration Rate = 0.1000, Train Count = 34816\n",
      "Episode 3879: Reward = 582.00, Steps = 8, Loss = 22.5508, Exploration Rate = 0.1000, Train Count = 34824\n",
      "Episode 3880: Reward = 591.00, Steps = 5, Loss = 18.6972, Exploration Rate = 0.1000, Train Count = 34829\n",
      "Episode 3881: Reward = 588.00, Steps = 6, Loss = 16.3665, Exploration Rate = 0.1000, Train Count = 34835\n",
      "Episode 3882: Reward = 585.00, Steps = 7, Loss = 12.1739, Exploration Rate = 0.1000, Train Count = 34842\n",
      "Episode 3883: Reward = 597.00, Steps = 3, Loss = 9.3219, Exploration Rate = 0.1000, Train Count = 34845\n",
      "Episode 3884: Reward = 588.00, Steps = 6, Loss = 10.9382, Exploration Rate = 0.1000, Train Count = 34851\n",
      "Episode 3885: Reward = 597.00, Steps = 3, Loss = 8.9058, Exploration Rate = 0.1000, Train Count = 34854\n",
      "Episode 3886: Reward = 597.00, Steps = 3, Loss = 5.8701, Exploration Rate = 0.1000, Train Count = 34857\n",
      "Episode 3887: Reward = 585.00, Steps = 7, Loss = 7.9389, Exploration Rate = 0.1000, Train Count = 34864\n",
      "Episode 3888: Reward = 585.00, Steps = 7, Loss = 5.0829, Exploration Rate = 0.1000, Train Count = 34871\n",
      "Episode 3889: Reward = 588.00, Steps = 6, Loss = 6.7283, Exploration Rate = 0.1000, Train Count = 34877\n",
      "Episode 3890: Reward = 597.00, Steps = 3, Loss = 6.6378, Exploration Rate = 0.1000, Train Count = 34880\n",
      "Episode 3891: Reward = 591.00, Steps = 5, Loss = 6.7378, Exploration Rate = 0.1000, Train Count = 34885\n",
      "Episode 3892: Reward = 579.00, Steps = 9, Loss = 5.8189, Exploration Rate = 0.1000, Train Count = 34894\n",
      "Episode 3893: Reward = 588.00, Steps = 6, Loss = 10.7153, Exploration Rate = 0.1000, Train Count = 34900\n",
      "Episode 3894: Reward = 594.00, Steps = 4, Loss = 7.6018, Exploration Rate = 0.1000, Train Count = 34904\n",
      "Episode 3895: Reward = 594.00, Steps = 4, Loss = 4.0743, Exploration Rate = 0.1000, Train Count = 34908\n",
      "Episode 3896: Reward = 549.00, Steps = 19, Loss = 10.4081, Exploration Rate = 0.1000, Train Count = 34927\n",
      "Episode 3897: Reward = 582.00, Steps = 8, Loss = 7.5347, Exploration Rate = 0.1000, Train Count = 34935\n",
      "Episode 3898: Reward = 585.00, Steps = 7, Loss = 5.3392, Exploration Rate = 0.1000, Train Count = 34942\n",
      "Episode 3899: Reward = 585.00, Steps = 7, Loss = 6.3008, Exploration Rate = 0.1000, Train Count = 34949\n",
      "Episode 3900: Reward = 597.00, Steps = 3, Loss = 2.8149, Exploration Rate = 0.1000, Train Count = 34952\n",
      "Episode 3901: Reward = 582.00, Steps = 8, Loss = 8.5729, Exploration Rate = 0.1000, Train Count = 34960\n",
      "Episode 3902: Reward = 591.00, Steps = 5, Loss = 5.7369, Exploration Rate = 0.1000, Train Count = 34965\n",
      "Episode 3903: Reward = 582.00, Steps = 8, Loss = 7.3299, Exploration Rate = 0.1000, Train Count = 34973\n",
      "Episode 3904: Reward = 532.00, Steps = 9, Loss = 8.3264, Exploration Rate = 0.1000, Train Count = 34982\n",
      "Episode 3905: Reward = 588.00, Steps = 6, Loss = 5.3138, Exploration Rate = 0.1000, Train Count = 34988\n",
      "Episode 3906: Reward = 594.00, Steps = 4, Loss = 3.3164, Exploration Rate = 0.1000, Train Count = 34992\n",
      "Episode 3907: Reward = 588.00, Steps = 6, Loss = 10.5815, Exploration Rate = 0.1000, Train Count = 34998\n",
      "Episode 3908: Reward = 591.00, Steps = 5, Loss = 11.8962, Exploration Rate = 0.1000, Train Count = 35003\n",
      "Episode 3909: Reward = 582.00, Steps = 8, Loss = 7.1050, Exploration Rate = 0.1000, Train Count = 35011\n",
      "Episode 3910: Reward = 552.00, Steps = 18, Loss = 13.8440, Exploration Rate = 0.1000, Train Count = 35029\n",
      "Episode 3911: Reward = 538.00, Steps = 7, Loss = 8.3369, Exploration Rate = 0.1000, Train Count = 35036\n",
      "Episode 3912: Reward = 585.00, Steps = 7, Loss = 10.2034, Exploration Rate = 0.1000, Train Count = 35043\n",
      "Episode 3913: Reward = 594.00, Steps = 4, Loss = 5.3305, Exploration Rate = 0.1000, Train Count = 35047\n",
      "Episode 3914: Reward = 588.00, Steps = 6, Loss = 17.2516, Exploration Rate = 0.1000, Train Count = 35053\n",
      "Episode 3915: Reward = 591.00, Steps = 5, Loss = 11.1502, Exploration Rate = 0.1000, Train Count = 35058\n",
      "Episode 3916: Reward = 591.00, Steps = 5, Loss = 11.1034, Exploration Rate = 0.1000, Train Count = 35063\n",
      "Episode 3917: Reward = 585.00, Steps = 7, Loss = 11.3303, Exploration Rate = 0.1000, Train Count = 35070\n",
      "Episode 3918: Reward = 588.00, Steps = 6, Loss = 9.8713, Exploration Rate = 0.1000, Train Count = 35076\n",
      "Episode 3919: Reward = 600.00, Steps = 2, Loss = 6.6071, Exploration Rate = 0.1000, Train Count = 35078\n",
      "Episode 3920: Reward = 588.00, Steps = 6, Loss = 6.3557, Exploration Rate = 0.1000, Train Count = 35084\n",
      "Episode 3921: Reward = 594.00, Steps = 4, Loss = 7.9430, Exploration Rate = 0.1000, Train Count = 35088\n",
      "Episode 3922: Reward = 585.00, Steps = 7, Loss = 8.8101, Exploration Rate = 0.1000, Train Count = 35095\n",
      "Episode 3923: Reward = 579.00, Steps = 9, Loss = 8.1827, Exploration Rate = 0.1000, Train Count = 35104\n",
      "Episode 3924: Reward = 591.00, Steps = 5, Loss = 5.8963, Exploration Rate = 0.1000, Train Count = 35109\n",
      "Episode 3925: Reward = 591.00, Steps = 5, Loss = 4.8770, Exploration Rate = 0.1000, Train Count = 35114\n",
      "Episode 3926: Reward = 579.00, Steps = 9, Loss = 8.0061, Exploration Rate = 0.1000, Train Count = 35123\n",
      "Episode 3927: Reward = 594.00, Steps = 4, Loss = 9.7901, Exploration Rate = 0.1000, Train Count = 35127\n",
      "Episode 3928: Reward = 600.00, Steps = 2, Loss = 10.8904, Exploration Rate = 0.1000, Train Count = 35129\n",
      "Episode 3929: Reward = 573.00, Steps = 11, Loss = 8.3282, Exploration Rate = 0.1000, Train Count = 35140\n",
      "Episode 3930: Reward = 582.00, Steps = 8, Loss = 5.6467, Exploration Rate = 0.1000, Train Count = 35148\n",
      "Episode 3931: Reward = 588.00, Steps = 6, Loss = 7.0153, Exploration Rate = 0.1000, Train Count = 35154\n",
      "Episode 3932: Reward = 585.00, Steps = 7, Loss = 6.9685, Exploration Rate = 0.1000, Train Count = 35161\n",
      "Episode 3933: Reward = 585.00, Steps = 7, Loss = 19.0132, Exploration Rate = 0.1000, Train Count = 35168\n",
      "Episode 3934: Reward = 582.00, Steps = 8, Loss = 11.7658, Exploration Rate = 0.1000, Train Count = 35176\n",
      "Episode 3935: Reward = 588.00, Steps = 6, Loss = 8.8278, Exploration Rate = 0.1000, Train Count = 35182\n",
      "Episode 3936: Reward = 573.00, Steps = 11, Loss = 8.3559, Exploration Rate = 0.1000, Train Count = 35193\n",
      "Episode 3937: Reward = 585.00, Steps = 7, Loss = 8.7400, Exploration Rate = 0.1000, Train Count = 35200\n",
      "Episode 3938: Reward = 588.00, Steps = 6, Loss = 8.5004, Exploration Rate = 0.1000, Train Count = 35206\n",
      "Episode 3939: Reward = 594.00, Steps = 4, Loss = 7.2723, Exploration Rate = 0.1000, Train Count = 35210\n",
      "Episode 3940: Reward = 591.00, Steps = 5, Loss = 5.9076, Exploration Rate = 0.1000, Train Count = 35215\n",
      "Episode 3941: Reward = 588.00, Steps = 6, Loss = 5.3311, Exploration Rate = 0.1000, Train Count = 35221\n",
      "Episode 3942: Reward = 591.00, Steps = 5, Loss = 6.3687, Exploration Rate = 0.1000, Train Count = 35226\n",
      "Episode 3943: Reward = 594.00, Steps = 4, Loss = 5.1930, Exploration Rate = 0.1000, Train Count = 35230\n",
      "Episode 3944: Reward = 594.00, Steps = 4, Loss = 7.5980, Exploration Rate = 0.1000, Train Count = 35234\n",
      "Episode 3945: Reward = 597.00, Steps = 3, Loss = 6.8921, Exploration Rate = 0.1000, Train Count = 35237\n",
      "Episode 3946: Reward = 582.00, Steps = 8, Loss = 8.2304, Exploration Rate = 0.1000, Train Count = 35245\n",
      "Episode 3947: Reward = 591.00, Steps = 5, Loss = 15.4617, Exploration Rate = 0.1000, Train Count = 35250\n",
      "Episode 3948: Reward = 579.00, Steps = 9, Loss = 10.0287, Exploration Rate = 0.1000, Train Count = 35259\n",
      "Episode 3949: Reward = 597.00, Steps = 3, Loss = 11.6845, Exploration Rate = 0.1000, Train Count = 35262\n",
      "Episode 3950: Reward = 585.00, Steps = 7, Loss = 6.5593, Exploration Rate = 0.1000, Train Count = 35269\n",
      "Episode 3951: Reward = 594.00, Steps = 4, Loss = 17.1915, Exploration Rate = 0.1000, Train Count = 35273\n",
      "Episode 3952: Reward = 594.00, Steps = 4, Loss = 7.8692, Exploration Rate = 0.1000, Train Count = 35277\n",
      "Episode 3953: Reward = 588.00, Steps = 6, Loss = 11.8805, Exploration Rate = 0.1000, Train Count = 35283\n",
      "Episode 3954: Reward = 597.00, Steps = 3, Loss = 10.8410, Exploration Rate = 0.1000, Train Count = 35286\n",
      "Episode 3955: Reward = 585.00, Steps = 7, Loss = 10.7748, Exploration Rate = 0.1000, Train Count = 35293\n",
      "Episode 3956: Reward = 588.00, Steps = 6, Loss = 9.2517, Exploration Rate = 0.1000, Train Count = 35299\n",
      "Episode 3957: Reward = 591.00, Steps = 5, Loss = 32.0971, Exploration Rate = 0.1000, Train Count = 35304\n",
      "Episode 3958: Reward = 588.00, Steps = 6, Loss = 29.7114, Exploration Rate = 0.1000, Train Count = 35310\n",
      "Episode 3959: Reward = 579.00, Steps = 9, Loss = 25.7239, Exploration Rate = 0.1000, Train Count = 35319\n",
      "Episode 3960: Reward = 594.00, Steps = 4, Loss = 21.7075, Exploration Rate = 0.1000, Train Count = 35323\n",
      "Episode 3961: Reward = 594.00, Steps = 4, Loss = 14.3975, Exploration Rate = 0.1000, Train Count = 35327\n",
      "Episode 3962: Reward = 594.00, Steps = 4, Loss = 15.7417, Exploration Rate = 0.1000, Train Count = 35331\n",
      "Episode 3963: Reward = 597.00, Steps = 3, Loss = 16.6364, Exploration Rate = 0.1000, Train Count = 35334\n",
      "Episode 3964: Reward = 573.00, Steps = 11, Loss = 12.5613, Exploration Rate = 0.1000, Train Count = 35345\n",
      "Episode 3965: Reward = 585.00, Steps = 7, Loss = 11.6295, Exploration Rate = 0.1000, Train Count = 35352\n",
      "Episode 3966: Reward = 591.00, Steps = 5, Loss = 10.5543, Exploration Rate = 0.1000, Train Count = 35357\n",
      "Episode 3967: Reward = 600.00, Steps = 2, Loss = 8.7716, Exploration Rate = 0.1000, Train Count = 35359\n",
      "Episode 3968: Reward = 582.00, Steps = 8, Loss = 11.1258, Exploration Rate = 0.1000, Train Count = 35367\n",
      "Episode 3969: Reward = 491.00, Steps = 7, Loss = 17.2680, Exploration Rate = 0.1000, Train Count = 35374\n",
      "Episode 3970: Reward = 588.00, Steps = 6, Loss = 12.6270, Exploration Rate = 0.1000, Train Count = 35380\n",
      "Episode 3971: Reward = 532.00, Steps = 9, Loss = 14.2744, Exploration Rate = 0.1000, Train Count = 35389\n",
      "Episode 3972: Reward = 588.00, Steps = 6, Loss = 19.5657, Exploration Rate = 0.1000, Train Count = 35395\n",
      "Episode 3973: Reward = 591.00, Steps = 5, Loss = 13.8341, Exploration Rate = 0.1000, Train Count = 35400\n",
      "Episode 3974: Reward = 588.00, Steps = 6, Loss = 9.4887, Exploration Rate = 0.1000, Train Count = 35406\n",
      "Episode 3975: Reward = 576.00, Steps = 10, Loss = 14.0688, Exploration Rate = 0.1000, Train Count = 35416\n",
      "Episode 3976: Reward = 582.00, Steps = 8, Loss = 13.6513, Exploration Rate = 0.1000, Train Count = 35424\n",
      "Episode 3977: Reward = 591.00, Steps = 5, Loss = 14.5435, Exploration Rate = 0.1000, Train Count = 35429\n",
      "Episode 3978: Reward = 594.00, Steps = 4, Loss = 15.3958, Exploration Rate = 0.1000, Train Count = 35433\n",
      "Episode 3979: Reward = 588.00, Steps = 6, Loss = 13.5850, Exploration Rate = 0.1000, Train Count = 35439\n",
      "Episode 3980: Reward = 591.00, Steps = 5, Loss = 11.8945, Exploration Rate = 0.1000, Train Count = 35444\n",
      "Episode 3981: Reward = 591.00, Steps = 5, Loss = 13.0045, Exploration Rate = 0.1000, Train Count = 35449\n",
      "Episode 3982: Reward = 588.00, Steps = 6, Loss = 11.4641, Exploration Rate = 0.1000, Train Count = 35455\n",
      "Episode 3983: Reward = 600.00, Steps = 2, Loss = 7.3927, Exploration Rate = 0.1000, Train Count = 35457\n",
      "Episode 3984: Reward = 582.00, Steps = 8, Loss = 9.9841, Exploration Rate = 0.1000, Train Count = 35465\n",
      "Episode 3985: Reward = 582.00, Steps = 8, Loss = 14.0347, Exploration Rate = 0.1000, Train Count = 35473\n",
      "Episode 3986: Reward = 591.00, Steps = 5, Loss = 11.9152, Exploration Rate = 0.1000, Train Count = 35478\n",
      "Episode 3987: Reward = 600.00, Steps = 2, Loss = 10.9580, Exploration Rate = 0.1000, Train Count = 35480\n",
      "Episode 3988: Reward = 541.00, Steps = 6, Loss = 8.9202, Exploration Rate = 0.1000, Train Count = 35486\n",
      "Episode 3989: Reward = 600.00, Steps = 2, Loss = 7.0131, Exploration Rate = 0.1000, Train Count = 35488\n",
      "Episode 3990: Reward = 591.00, Steps = 5, Loss = 11.6391, Exploration Rate = 0.1000, Train Count = 35493\n",
      "Episode 3991: Reward = 597.00, Steps = 3, Loss = 10.0092, Exploration Rate = 0.1000, Train Count = 35496\n",
      "Episode 3992: Reward = 597.00, Steps = 3, Loss = 9.6150, Exploration Rate = 0.1000, Train Count = 35499\n",
      "Episode 3993: Reward = 591.00, Steps = 5, Loss = 9.0376, Exploration Rate = 0.1000, Train Count = 35504\n",
      "Episode 3994: Reward = 576.00, Steps = 10, Loss = 10.3552, Exploration Rate = 0.1000, Train Count = 35514\n",
      "Episode 3995: Reward = 585.00, Steps = 7, Loss = 10.1669, Exploration Rate = 0.1000, Train Count = 35521\n",
      "Episode 3996: Reward = 588.00, Steps = 6, Loss = 9.2805, Exploration Rate = 0.1000, Train Count = 35527\n",
      "Episode 3997: Reward = 544.00, Steps = 5, Loss = 11.0848, Exploration Rate = 0.1000, Train Count = 35532\n",
      "Episode 3998: Reward = 597.00, Steps = 3, Loss = 5.4017, Exploration Rate = 0.1000, Train Count = 35535\n",
      "Episode 3999: Reward = 594.00, Steps = 4, Loss = 12.1647, Exploration Rate = 0.1000, Train Count = 35539\n",
      "Episode 4000: Reward = 541.00, Steps = 6, Loss = 9.5657, Exploration Rate = 0.1000, Train Count = 35545\n",
      "Episode 4001: Reward = 538.00, Steps = 7, Loss = 11.3523, Exploration Rate = 0.1000, Train Count = 35552\n",
      "Episode 4002: Reward = 594.00, Steps = 4, Loss = 16.3430, Exploration Rate = 0.1000, Train Count = 35556\n",
      "Episode 4003: Reward = 597.00, Steps = 3, Loss = 11.2628, Exploration Rate = 0.1000, Train Count = 35559\n",
      "Episode 4004: Reward = 591.00, Steps = 5, Loss = 14.8089, Exploration Rate = 0.1000, Train Count = 35564\n",
      "Episode 4005: Reward = 594.00, Steps = 4, Loss = 15.6179, Exploration Rate = 0.1000, Train Count = 35568\n",
      "Episode 4006: Reward = 591.00, Steps = 5, Loss = 15.0341, Exploration Rate = 0.1000, Train Count = 35573\n",
      "Episode 4007: Reward = 585.00, Steps = 7, Loss = 10.4485, Exploration Rate = 0.1000, Train Count = 35580\n",
      "Episode 4008: Reward = 585.00, Steps = 7, Loss = 11.7631, Exploration Rate = 0.1000, Train Count = 35587\n",
      "Episode 4009: Reward = 570.00, Steps = 12, Loss = 13.4619, Exploration Rate = 0.1000, Train Count = 35599\n",
      "Episode 4010: Reward = 561.00, Steps = 15, Loss = 15.0671, Exploration Rate = 0.1000, Train Count = 35614\n",
      "Episode 4011: Reward = 591.00, Steps = 5, Loss = 12.2432, Exploration Rate = 0.1000, Train Count = 35619\n",
      "Episode 4012: Reward = 585.00, Steps = 7, Loss = 15.8201, Exploration Rate = 0.1000, Train Count = 35626\n",
      "Episode 4013: Reward = 535.00, Steps = 8, Loss = 27.3804, Exploration Rate = 0.1000, Train Count = 35634\n",
      "Episode 4014: Reward = 588.00, Steps = 6, Loss = 21.3843, Exploration Rate = 0.1000, Train Count = 35640\n",
      "Episode 4015: Reward = 594.00, Steps = 4, Loss = 11.3202, Exploration Rate = 0.1000, Train Count = 35644\n",
      "Episode 4016: Reward = 594.00, Steps = 4, Loss = 14.9557, Exploration Rate = 0.1000, Train Count = 35648\n",
      "Episode 4017: Reward = 585.00, Steps = 7, Loss = 12.3228, Exploration Rate = 0.1000, Train Count = 35655\n",
      "Episode 4018: Reward = 600.00, Steps = 2, Loss = 12.7936, Exploration Rate = 0.1000, Train Count = 35657\n",
      "Episode 4019: Reward = 600.00, Steps = 2, Loss = 14.2163, Exploration Rate = 0.1000, Train Count = 35659\n",
      "Episode 4020: Reward = 588.00, Steps = 6, Loss = 13.9031, Exploration Rate = 0.1000, Train Count = 35665\n",
      "Episode 4021: Reward = 594.00, Steps = 4, Loss = 11.9592, Exploration Rate = 0.1000, Train Count = 35669\n",
      "Episode 4022: Reward = 588.00, Steps = 6, Loss = 11.5226, Exploration Rate = 0.1000, Train Count = 35675\n",
      "Episode 4023: Reward = 591.00, Steps = 5, Loss = 9.6193, Exploration Rate = 0.1000, Train Count = 35680\n",
      "Episode 4024: Reward = 585.00, Steps = 7, Loss = 17.9439, Exploration Rate = 0.1000, Train Count = 35687\n",
      "Episode 4025: Reward = 591.00, Steps = 5, Loss = 9.6249, Exploration Rate = 0.1000, Train Count = 35692\n",
      "Episode 4026: Reward = 532.00, Steps = 9, Loss = 22.4491, Exploration Rate = 0.1000, Train Count = 35701\n",
      "Episode 4027: Reward = 582.00, Steps = 8, Loss = 15.9493, Exploration Rate = 0.1000, Train Count = 35709\n",
      "Episode 4028: Reward = 597.00, Steps = 3, Loss = 10.5507, Exploration Rate = 0.1000, Train Count = 35712\n",
      "Episode 4029: Reward = 588.00, Steps = 6, Loss = 15.1282, Exploration Rate = 0.1000, Train Count = 35718\n",
      "Episode 4030: Reward = 597.00, Steps = 3, Loss = 16.1892, Exploration Rate = 0.1000, Train Count = 35721\n",
      "Episode 4031: Reward = 582.00, Steps = 8, Loss = 13.6415, Exploration Rate = 0.1000, Train Count = 35729\n",
      "Episode 4032: Reward = 541.00, Steps = 6, Loss = 11.0671, Exploration Rate = 0.1000, Train Count = 35735\n",
      "Episode 4033: Reward = 579.00, Steps = 9, Loss = 12.5191, Exploration Rate = 0.1000, Train Count = 35744\n",
      "Episode 4034: Reward = 594.00, Steps = 4, Loss = 13.6959, Exploration Rate = 0.1000, Train Count = 35748\n",
      "Episode 4035: Reward = 600.00, Steps = 2, Loss = 12.2426, Exploration Rate = 0.1000, Train Count = 35750\n",
      "Episode 4036: Reward = 597.00, Steps = 3, Loss = 17.5892, Exploration Rate = 0.1000, Train Count = 35753\n",
      "Episode 4037: Reward = 597.00, Steps = 3, Loss = 13.0527, Exploration Rate = 0.1000, Train Count = 35756\n",
      "Episode 4038: Reward = 579.00, Steps = 9, Loss = 6.5946, Exploration Rate = 0.1000, Train Count = 35765\n",
      "Episode 4039: Reward = 594.00, Steps = 4, Loss = 13.2681, Exploration Rate = 0.1000, Train Count = 35769\n",
      "Episode 4040: Reward = 591.00, Steps = 5, Loss = 12.4741, Exploration Rate = 0.1000, Train Count = 35774\n",
      "Episode 4041: Reward = 591.00, Steps = 5, Loss = 9.2157, Exploration Rate = 0.1000, Train Count = 35779\n",
      "Episode 4042: Reward = 594.00, Steps = 4, Loss = 16.4891, Exploration Rate = 0.1000, Train Count = 35783\n",
      "Episode 4043: Reward = 594.00, Steps = 4, Loss = 8.1511, Exploration Rate = 0.1000, Train Count = 35787\n",
      "Episode 4044: Reward = 591.00, Steps = 5, Loss = 15.5086, Exploration Rate = 0.1000, Train Count = 35792\n",
      "Episode 4045: Reward = 588.00, Steps = 6, Loss = 8.8725, Exploration Rate = 0.1000, Train Count = 35798\n",
      "Episode 4046: Reward = 570.00, Steps = 12, Loss = 45.8165, Exploration Rate = 0.1000, Train Count = 35810\n",
      "Episode 4047: Reward = 591.00, Steps = 5, Loss = 45.1167, Exploration Rate = 0.1000, Train Count = 35815\n",
      "Episode 4048: Reward = 591.00, Steps = 5, Loss = 37.0218, Exploration Rate = 0.1000, Train Count = 35820\n",
      "Episode 4049: Reward = 600.00, Steps = 2, Loss = 34.6021, Exploration Rate = 0.1000, Train Count = 35822\n",
      "Episode 4050: Reward = 555.00, Steps = 17, Loss = 38.4441, Exploration Rate = 0.1000, Train Count = 35839\n",
      "Episode 4051: Reward = 541.00, Steps = 6, Loss = 22.6050, Exploration Rate = 0.1000, Train Count = 35845\n",
      "Episode 4052: Reward = 588.00, Steps = 6, Loss = 21.1601, Exploration Rate = 0.1000, Train Count = 35851\n",
      "Episode 4053: Reward = 588.00, Steps = 6, Loss = 15.2707, Exploration Rate = 0.1000, Train Count = 35857\n",
      "Episode 4054: Reward = 591.00, Steps = 5, Loss = 19.9670, Exploration Rate = 0.1000, Train Count = 35862\n",
      "Episode 4055: Reward = 588.00, Steps = 6, Loss = 17.0146, Exploration Rate = 0.1000, Train Count = 35868\n",
      "Episode 4056: Reward = 582.00, Steps = 8, Loss = 15.3658, Exploration Rate = 0.1000, Train Count = 35876\n",
      "Episode 4057: Reward = 594.00, Steps = 4, Loss = 11.8506, Exploration Rate = 0.1000, Train Count = 35880\n",
      "Episode 4058: Reward = 520.00, Steps = 13, Loss = 13.4524, Exploration Rate = 0.1000, Train Count = 35893\n",
      "Episode 4059: Reward = 594.00, Steps = 4, Loss = 12.4300, Exploration Rate = 0.1000, Train Count = 35897\n",
      "Episode 4060: Reward = 585.00, Steps = 7, Loss = 13.5580, Exploration Rate = 0.1000, Train Count = 35904\n",
      "Episode 4061: Reward = 591.00, Steps = 5, Loss = 13.0125, Exploration Rate = 0.1000, Train Count = 35909\n",
      "Episode 4062: Reward = 573.00, Steps = 11, Loss = 10.1000, Exploration Rate = 0.1000, Train Count = 35920\n",
      "Episode 4063: Reward = 591.00, Steps = 5, Loss = 10.6589, Exploration Rate = 0.1000, Train Count = 35925\n",
      "Episode 4064: Reward = 594.00, Steps = 4, Loss = 11.6728, Exploration Rate = 0.1000, Train Count = 35929\n",
      "Episode 4065: Reward = 582.00, Steps = 8, Loss = 11.4929, Exploration Rate = 0.1000, Train Count = 35937\n",
      "Episode 4066: Reward = 597.00, Steps = 3, Loss = 13.5260, Exploration Rate = 0.1000, Train Count = 35940\n",
      "Episode 4067: Reward = 591.00, Steps = 5, Loss = 9.3204, Exploration Rate = 0.1000, Train Count = 35945\n",
      "Episode 4068: Reward = 591.00, Steps = 5, Loss = 6.4062, Exploration Rate = 0.1000, Train Count = 35950\n",
      "Episode 4069: Reward = 585.00, Steps = 7, Loss = 9.7790, Exploration Rate = 0.1000, Train Count = 35957\n",
      "Episode 4070: Reward = 591.00, Steps = 5, Loss = 13.9524, Exploration Rate = 0.1000, Train Count = 35962\n",
      "Episode 4071: Reward = 585.00, Steps = 7, Loss = 9.0849, Exploration Rate = 0.1000, Train Count = 35969\n",
      "Episode 4072: Reward = 588.00, Steps = 6, Loss = 9.9648, Exploration Rate = 0.1000, Train Count = 35975\n",
      "Episode 4073: Reward = 585.00, Steps = 7, Loss = 9.9212, Exploration Rate = 0.1000, Train Count = 35982\n",
      "Episode 4074: Reward = 537.00, Steps = 23, Loss = 10.7877, Exploration Rate = 0.1000, Train Count = 36005\n",
      "Episode 4075: Reward = 579.00, Steps = 9, Loss = 13.5486, Exploration Rate = 0.1000, Train Count = 36014\n",
      "Episode 4076: Reward = 588.00, Steps = 6, Loss = 10.3953, Exploration Rate = 0.1000, Train Count = 36020\n",
      "Episode 4077: Reward = 588.00, Steps = 6, Loss = 9.2380, Exploration Rate = 0.1000, Train Count = 36026\n",
      "Episode 4078: Reward = 588.00, Steps = 6, Loss = 8.2319, Exploration Rate = 0.1000, Train Count = 36032\n",
      "Episode 4079: Reward = 576.00, Steps = 10, Loss = 10.0460, Exploration Rate = 0.1000, Train Count = 36042\n",
      "Episode 4080: Reward = 579.00, Steps = 9, Loss = 8.6555, Exploration Rate = 0.1000, Train Count = 36051\n",
      "Episode 4081: Reward = 597.00, Steps = 3, Loss = 5.9886, Exploration Rate = 0.1000, Train Count = 36054\n",
      "Episode 4082: Reward = 588.00, Steps = 6, Loss = 3.6079, Exploration Rate = 0.1000, Train Count = 36060\n",
      "Episode 4083: Reward = 594.00, Steps = 4, Loss = 11.2968, Exploration Rate = 0.1000, Train Count = 36064\n",
      "Episode 4084: Reward = 579.00, Steps = 9, Loss = 7.7850, Exploration Rate = 0.1000, Train Count = 36073\n",
      "Episode 4085: Reward = 585.00, Steps = 7, Loss = 9.5139, Exploration Rate = 0.1000, Train Count = 36080\n",
      "Episode 4086: Reward = 591.00, Steps = 5, Loss = 11.1728, Exploration Rate = 0.1000, Train Count = 36085\n",
      "Episode 4087: Reward = 476.00, Steps = 12, Loss = 8.5219, Exploration Rate = 0.1000, Train Count = 36097\n",
      "Episode 4088: Reward = 576.00, Steps = 10, Loss = 7.3141, Exploration Rate = 0.1000, Train Count = 36107\n",
      "Episode 4089: Reward = 597.00, Steps = 3, Loss = 3.8107, Exploration Rate = 0.1000, Train Count = 36110\n",
      "Episode 4090: Reward = 585.00, Steps = 7, Loss = 8.6454, Exploration Rate = 0.1000, Train Count = 36117\n",
      "Episode 4091: Reward = 585.00, Steps = 7, Loss = 7.1924, Exploration Rate = 0.1000, Train Count = 36124\n",
      "Episode 4092: Reward = 588.00, Steps = 6, Loss = 6.5678, Exploration Rate = 0.1000, Train Count = 36130\n",
      "Episode 4093: Reward = 582.00, Steps = 8, Loss = 8.0436, Exploration Rate = 0.1000, Train Count = 36138\n",
      "Episode 4094: Reward = 588.00, Steps = 6, Loss = 7.9846, Exploration Rate = 0.1000, Train Count = 36144\n",
      "Episode 4095: Reward = 591.00, Steps = 5, Loss = 12.1840, Exploration Rate = 0.1000, Train Count = 36149\n",
      "Episode 4096: Reward = 588.00, Steps = 6, Loss = 10.6458, Exploration Rate = 0.1000, Train Count = 36155\n",
      "Episode 4097: Reward = 591.00, Steps = 5, Loss = 8.8834, Exploration Rate = 0.1000, Train Count = 36160\n",
      "Episode 4098: Reward = 591.00, Steps = 5, Loss = 9.7208, Exploration Rate = 0.1000, Train Count = 36165\n",
      "Episode 4099: Reward = 591.00, Steps = 5, Loss = 9.0950, Exploration Rate = 0.1000, Train Count = 36170\n",
      "Episode 4100: Reward = 588.00, Steps = 6, Loss = 8.7819, Exploration Rate = 0.1000, Train Count = 36176\n",
      "Episode 4101: Reward = 585.00, Steps = 7, Loss = 8.0402, Exploration Rate = 0.1000, Train Count = 36183\n",
      "Episode 4102: Reward = 579.00, Steps = 9, Loss = 5.4525, Exploration Rate = 0.1000, Train Count = 36192\n",
      "Episode 4103: Reward = 585.00, Steps = 7, Loss = 6.5368, Exploration Rate = 0.1000, Train Count = 36199\n",
      "Episode 4104: Reward = 597.00, Steps = 3, Loss = 3.5015, Exploration Rate = 0.1000, Train Count = 36202\n",
      "Episode 4105: Reward = 588.00, Steps = 6, Loss = 8.7207, Exploration Rate = 0.1000, Train Count = 36208\n",
      "Episode 4106: Reward = 585.00, Steps = 7, Loss = 7.7691, Exploration Rate = 0.1000, Train Count = 36215\n",
      "Episode 4107: Reward = 585.00, Steps = 7, Loss = 7.2100, Exploration Rate = 0.1000, Train Count = 36222\n",
      "Episode 4108: Reward = 591.00, Steps = 5, Loss = 6.5820, Exploration Rate = 0.1000, Train Count = 36227\n",
      "Episode 4109: Reward = 585.00, Steps = 7, Loss = 7.8104, Exploration Rate = 0.1000, Train Count = 36234\n",
      "Episode 4110: Reward = 588.00, Steps = 6, Loss = 8.1828, Exploration Rate = 0.1000, Train Count = 36240\n",
      "Episode 4111: Reward = 588.00, Steps = 6, Loss = 7.3663, Exploration Rate = 0.1000, Train Count = 36246\n",
      "Episode 4112: Reward = 588.00, Steps = 6, Loss = 8.2092, Exploration Rate = 0.1000, Train Count = 36252\n",
      "Episode 4113: Reward = 538.00, Steps = 7, Loss = 6.3911, Exploration Rate = 0.1000, Train Count = 36259\n",
      "Episode 4114: Reward = 582.00, Steps = 8, Loss = 9.7289, Exploration Rate = 0.1000, Train Count = 36267\n",
      "Episode 4115: Reward = 576.00, Steps = 10, Loss = 9.0744, Exploration Rate = 0.1000, Train Count = 36277\n",
      "Episode 4116: Reward = 591.00, Steps = 5, Loss = 8.0020, Exploration Rate = 0.1000, Train Count = 36282\n",
      "Episode 4117: Reward = 582.00, Steps = 8, Loss = 9.1391, Exploration Rate = 0.1000, Train Count = 36290\n",
      "Episode 4118: Reward = 576.00, Steps = 10, Loss = 7.9316, Exploration Rate = 0.1000, Train Count = 36300\n",
      "Episode 4119: Reward = 597.00, Steps = 3, Loss = 52.1505, Exploration Rate = 0.1000, Train Count = 36303\n",
      "Episode 4120: Reward = 576.00, Steps = 10, Loss = 40.1740, Exploration Rate = 0.1000, Train Count = 36313\n",
      "Episode 4121: Reward = 585.00, Steps = 7, Loss = 30.3370, Exploration Rate = 0.1000, Train Count = 36320\n",
      "Episode 4122: Reward = 579.00, Steps = 9, Loss = 18.5084, Exploration Rate = 0.1000, Train Count = 36329\n",
      "Episode 4123: Reward = 591.00, Steps = 5, Loss = 18.9197, Exploration Rate = 0.1000, Train Count = 36334\n",
      "Episode 4124: Reward = 591.00, Steps = 5, Loss = 17.3626, Exploration Rate = 0.1000, Train Count = 36339\n",
      "Episode 4125: Reward = 588.00, Steps = 6, Loss = 14.9596, Exploration Rate = 0.1000, Train Count = 36345\n",
      "Episode 4126: Reward = 573.00, Steps = 11, Loss = 13.0422, Exploration Rate = 0.1000, Train Count = 36356\n",
      "Episode 4127: Reward = 591.00, Steps = 5, Loss = 10.2234, Exploration Rate = 0.1000, Train Count = 36361\n",
      "Episode 4128: Reward = 591.00, Steps = 5, Loss = 12.0395, Exploration Rate = 0.1000, Train Count = 36366\n",
      "Episode 4129: Reward = 588.00, Steps = 6, Loss = 13.1147, Exploration Rate = 0.1000, Train Count = 36372\n",
      "Episode 4130: Reward = 588.00, Steps = 6, Loss = 9.7822, Exploration Rate = 0.1000, Train Count = 36378\n",
      "Episode 4131: Reward = 594.00, Steps = 4, Loss = 9.5428, Exploration Rate = 0.1000, Train Count = 36382\n",
      "Episode 4132: Reward = 594.00, Steps = 4, Loss = 7.1694, Exploration Rate = 0.1000, Train Count = 36386\n",
      "Episode 4133: Reward = 591.00, Steps = 5, Loss = 6.1824, Exploration Rate = 0.1000, Train Count = 36391\n",
      "Episode 4134: Reward = 591.00, Steps = 5, Loss = 6.2445, Exploration Rate = 0.1000, Train Count = 36396\n",
      "Episode 4135: Reward = 588.00, Steps = 6, Loss = 3.7565, Exploration Rate = 0.1000, Train Count = 36402\n",
      "Episode 4136: Reward = 594.00, Steps = 4, Loss = 6.7912, Exploration Rate = 0.1000, Train Count = 36406\n",
      "Episode 4137: Reward = 585.00, Steps = 7, Loss = 3.8265, Exploration Rate = 0.1000, Train Count = 36413\n",
      "Episode 4138: Reward = 591.00, Steps = 5, Loss = 3.7402, Exploration Rate = 0.1000, Train Count = 36418\n",
      "Episode 4139: Reward = 594.00, Steps = 4, Loss = 4.0701, Exploration Rate = 0.1000, Train Count = 36422\n",
      "Episode 4140: Reward = 591.00, Steps = 5, Loss = 2.9813, Exploration Rate = 0.1000, Train Count = 36427\n",
      "Episode 4141: Reward = 588.00, Steps = 6, Loss = 7.2429, Exploration Rate = 0.1000, Train Count = 36433\n",
      "Episode 4142: Reward = 573.00, Steps = 11, Loss = 5.4751, Exploration Rate = 0.1000, Train Count = 36444\n",
      "Episode 4143: Reward = 591.00, Steps = 5, Loss = 3.5356, Exploration Rate = 0.1000, Train Count = 36449\n",
      "Episode 4144: Reward = 594.00, Steps = 4, Loss = 2.8427, Exploration Rate = 0.1000, Train Count = 36453\n",
      "Episode 4145: Reward = 576.00, Steps = 10, Loss = 4.1121, Exploration Rate = 0.1000, Train Count = 36463\n",
      "Episode 4146: Reward = 585.00, Steps = 7, Loss = 4.6055, Exploration Rate = 0.1000, Train Count = 36470\n",
      "Episode 4147: Reward = 585.00, Steps = 7, Loss = 2.6128, Exploration Rate = 0.1000, Train Count = 36477\n",
      "Episode 4148: Reward = 591.00, Steps = 5, Loss = 3.1572, Exploration Rate = 0.1000, Train Count = 36482\n",
      "Episode 4149: Reward = 591.00, Steps = 5, Loss = 7.7231, Exploration Rate = 0.1000, Train Count = 36487\n",
      "Episode 4150: Reward = 585.00, Steps = 7, Loss = 8.3612, Exploration Rate = 0.1000, Train Count = 36494\n",
      "Episode 4151: Reward = 541.00, Steps = 6, Loss = 13.9230, Exploration Rate = 0.1000, Train Count = 36500\n",
      "Episode 4152: Reward = 591.00, Steps = 5, Loss = 13.7775, Exploration Rate = 0.1000, Train Count = 36505\n",
      "Episode 4153: Reward = 588.00, Steps = 6, Loss = 7.6954, Exploration Rate = 0.1000, Train Count = 36511\n",
      "Episode 4154: Reward = 585.00, Steps = 7, Loss = 5.8441, Exploration Rate = 0.1000, Train Count = 36518\n",
      "Episode 4155: Reward = 591.00, Steps = 5, Loss = 5.1149, Exploration Rate = 0.1000, Train Count = 36523\n",
      "Episode 4156: Reward = 573.00, Steps = 11, Loss = 4.1498, Exploration Rate = 0.1000, Train Count = 36534\n",
      "Episode 4157: Reward = 585.00, Steps = 7, Loss = 6.8003, Exploration Rate = 0.1000, Train Count = 36541\n",
      "Episode 4158: Reward = 532.00, Steps = 9, Loss = 5.0342, Exploration Rate = 0.1000, Train Count = 36550\n",
      "Episode 4159: Reward = 585.00, Steps = 7, Loss = 4.2552, Exploration Rate = 0.1000, Train Count = 36557\n",
      "Episode 4160: Reward = 597.00, Steps = 3, Loss = 6.4395, Exploration Rate = 0.1000, Train Count = 36560\n",
      "Episode 4161: Reward = 582.00, Steps = 8, Loss = 7.3139, Exploration Rate = 0.1000, Train Count = 36568\n",
      "Episode 4162: Reward = 585.00, Steps = 7, Loss = 5.5785, Exploration Rate = 0.1000, Train Count = 36575\n",
      "Episode 4163: Reward = 588.00, Steps = 6, Loss = 5.4913, Exploration Rate = 0.1000, Train Count = 36581\n",
      "Episode 4164: Reward = 582.00, Steps = 8, Loss = 3.5985, Exploration Rate = 0.1000, Train Count = 36589\n",
      "Episode 4165: Reward = 588.00, Steps = 6, Loss = 2.8961, Exploration Rate = 0.1000, Train Count = 36595\n",
      "Episode 4166: Reward = 594.00, Steps = 4, Loss = 2.3664, Exploration Rate = 0.1000, Train Count = 36599\n",
      "Episode 4167: Reward = 535.00, Steps = 8, Loss = 3.9191, Exploration Rate = 0.1000, Train Count = 36607\n",
      "Episode 4168: Reward = 579.00, Steps = 9, Loss = 4.5041, Exploration Rate = 0.1000, Train Count = 36616\n",
      "Episode 4169: Reward = 532.00, Steps = 9, Loss = 7.0658, Exploration Rate = 0.1000, Train Count = 36625\n",
      "Episode 4170: Reward = 588.00, Steps = 6, Loss = 8.2922, Exploration Rate = 0.1000, Train Count = 36631\n",
      "Episode 4171: Reward = 585.00, Steps = 7, Loss = 3.7589, Exploration Rate = 0.1000, Train Count = 36638\n",
      "Episode 4172: Reward = 579.00, Steps = 9, Loss = 6.3239, Exploration Rate = 0.1000, Train Count = 36647\n",
      "Episode 4173: Reward = 576.00, Steps = 10, Loss = 3.4502, Exploration Rate = 0.1000, Train Count = 36657\n",
      "Episode 4174: Reward = 594.00, Steps = 4, Loss = 3.8414, Exploration Rate = 0.1000, Train Count = 36661\n",
      "Episode 4175: Reward = 594.00, Steps = 4, Loss = 2.5709, Exploration Rate = 0.1000, Train Count = 36665\n",
      "Episode 4176: Reward = 597.00, Steps = 3, Loss = 2.5050, Exploration Rate = 0.1000, Train Count = 36668\n",
      "Episode 4177: Reward = 579.00, Steps = 9, Loss = 2.2127, Exploration Rate = 0.1000, Train Count = 36677\n",
      "Episode 4178: Reward = 588.00, Steps = 6, Loss = 2.0012, Exploration Rate = 0.1000, Train Count = 36683\n",
      "Episode 4179: Reward = 588.00, Steps = 6, Loss = 1.7116, Exploration Rate = 0.1000, Train Count = 36689\n",
      "Episode 4180: Reward = 585.00, Steps = 7, Loss = 2.3022, Exploration Rate = 0.1000, Train Count = 36696\n",
      "Episode 4181: Reward = 591.00, Steps = 5, Loss = 1.5222, Exploration Rate = 0.1000, Train Count = 36701\n",
      "Episode 4182: Reward = 591.00, Steps = 5, Loss = 3.2131, Exploration Rate = 0.1000, Train Count = 36706\n",
      "Episode 4183: Reward = 585.00, Steps = 7, Loss = 2.1056, Exploration Rate = 0.1000, Train Count = 36713\n",
      "Episode 4184: Reward = 585.00, Steps = 7, Loss = 1.9125, Exploration Rate = 0.1000, Train Count = 36720\n",
      "Episode 4185: Reward = 585.00, Steps = 7, Loss = 2.4223, Exploration Rate = 0.1000, Train Count = 36727\n",
      "Episode 4186: Reward = 588.00, Steps = 6, Loss = 1.8038, Exploration Rate = 0.1000, Train Count = 36733\n",
      "Episode 4187: Reward = 585.00, Steps = 7, Loss = 1.8738, Exploration Rate = 0.1000, Train Count = 36740\n",
      "Episode 4188: Reward = 582.00, Steps = 8, Loss = 2.8901, Exploration Rate = 0.1000, Train Count = 36748\n",
      "Episode 4189: Reward = 600.00, Steps = 2, Loss = 10.1308, Exploration Rate = 0.1000, Train Count = 36750\n",
      "Episode 4190: Reward = 588.00, Steps = 6, Loss = 9.0917, Exploration Rate = 0.1000, Train Count = 36756\n",
      "Episode 4191: Reward = 579.00, Steps = 9, Loss = 6.9898, Exploration Rate = 0.1000, Train Count = 36765\n",
      "Episode 4192: Reward = 591.00, Steps = 5, Loss = 4.3776, Exploration Rate = 0.1000, Train Count = 36770\n",
      "Episode 4193: Reward = 579.00, Steps = 9, Loss = 4.0031, Exploration Rate = 0.1000, Train Count = 36779\n",
      "Episode 4194: Reward = 544.00, Steps = 5, Loss = 3.7947, Exploration Rate = 0.1000, Train Count = 36784\n",
      "Episode 4195: Reward = 585.00, Steps = 7, Loss = 8.2848, Exploration Rate = 0.1000, Train Count = 36791\n",
      "Episode 4196: Reward = 588.00, Steps = 6, Loss = 4.3217, Exploration Rate = 0.1000, Train Count = 36797\n",
      "Episode 4197: Reward = 585.00, Steps = 7, Loss = 18.8224, Exploration Rate = 0.1000, Train Count = 36804\n",
      "Episode 4198: Reward = 585.00, Steps = 7, Loss = 28.9977, Exploration Rate = 0.1000, Train Count = 36811\n",
      "Episode 4199: Reward = 582.00, Steps = 8, Loss = 20.4639, Exploration Rate = 0.1000, Train Count = 36819\n",
      "Episode 4200: Reward = 597.00, Steps = 3, Loss = 15.2650, Exploration Rate = 0.1000, Train Count = 36822\n",
      "Episode 4201: Reward = 591.00, Steps = 5, Loss = 13.9428, Exploration Rate = 0.1000, Train Count = 36827\n",
      "Episode 4202: Reward = 594.00, Steps = 4, Loss = 10.7390, Exploration Rate = 0.1000, Train Count = 36831\n",
      "Episode 4203: Reward = 591.00, Steps = 5, Loss = 10.4627, Exploration Rate = 0.1000, Train Count = 36836\n",
      "Episode 4204: Reward = 597.00, Steps = 3, Loss = 7.7670, Exploration Rate = 0.1000, Train Count = 36839\n",
      "Episode 4205: Reward = 585.00, Steps = 7, Loss = 8.4085, Exploration Rate = 0.1000, Train Count = 36846\n",
      "Episode 4206: Reward = 594.00, Steps = 4, Loss = 5.7651, Exploration Rate = 0.1000, Train Count = 36850\n",
      "Episode 4207: Reward = 582.00, Steps = 8, Loss = 5.6484, Exploration Rate = 0.1000, Train Count = 36858\n",
      "Episode 4208: Reward = 597.00, Steps = 3, Loss = 4.7235, Exploration Rate = 0.1000, Train Count = 36861\n",
      "Episode 4209: Reward = 591.00, Steps = 5, Loss = 5.6552, Exploration Rate = 0.1000, Train Count = 36866\n",
      "Episode 4210: Reward = 585.00, Steps = 7, Loss = 5.5989, Exploration Rate = 0.1000, Train Count = 36873\n",
      "Episode 4211: Reward = 579.00, Steps = 9, Loss = 5.0049, Exploration Rate = 0.1000, Train Count = 36882\n",
      "Episode 4212: Reward = 538.00, Steps = 7, Loss = 4.2817, Exploration Rate = 0.1000, Train Count = 36889\n",
      "Episode 4213: Reward = 570.00, Steps = 12, Loss = 5.7324, Exploration Rate = 0.1000, Train Count = 36901\n",
      "Episode 4214: Reward = 585.00, Steps = 7, Loss = 4.2678, Exploration Rate = 0.1000, Train Count = 36908\n",
      "Episode 4215: Reward = 582.00, Steps = 8, Loss = 3.0952, Exploration Rate = 0.1000, Train Count = 36916\n",
      "Episode 4216: Reward = 588.00, Steps = 6, Loss = 3.4711, Exploration Rate = 0.1000, Train Count = 36922\n",
      "Episode 4217: Reward = 582.00, Steps = 8, Loss = 3.6507, Exploration Rate = 0.1000, Train Count = 36930\n",
      "Episode 4218: Reward = 591.00, Steps = 5, Loss = 3.0531, Exploration Rate = 0.1000, Train Count = 36935\n",
      "Episode 4219: Reward = 585.00, Steps = 7, Loss = 2.7877, Exploration Rate = 0.1000, Train Count = 36942\n",
      "Episode 4220: Reward = 576.00, Steps = 10, Loss = 2.5583, Exploration Rate = 0.1000, Train Count = 36952\n",
      "Episode 4221: Reward = 597.00, Steps = 3, Loss = 2.7544, Exploration Rate = 0.1000, Train Count = 36955\n",
      "Episode 4222: Reward = 594.00, Steps = 4, Loss = 2.5633, Exploration Rate = 0.1000, Train Count = 36959\n",
      "Episode 4223: Reward = 588.00, Steps = 6, Loss = 1.5440, Exploration Rate = 0.1000, Train Count = 36965\n",
      "Episode 4224: Reward = 594.00, Steps = 4, Loss = 1.2846, Exploration Rate = 0.1000, Train Count = 36969\n",
      "Episode 4225: Reward = 588.00, Steps = 6, Loss = 2.6153, Exploration Rate = 0.1000, Train Count = 36975\n",
      "Episode 4226: Reward = 591.00, Steps = 5, Loss = 4.0117, Exploration Rate = 0.1000, Train Count = 36980\n",
      "Episode 4227: Reward = 597.00, Steps = 3, Loss = 3.3891, Exploration Rate = 0.1000, Train Count = 36983\n",
      "Episode 4228: Reward = 588.00, Steps = 6, Loss = 3.0081, Exploration Rate = 0.1000, Train Count = 36989\n",
      "Episode 4229: Reward = 597.00, Steps = 3, Loss = 2.4215, Exploration Rate = 0.1000, Train Count = 36992\n",
      "Episode 4230: Reward = 600.00, Steps = 2, Loss = 1.4398, Exploration Rate = 0.1000, Train Count = 36994\n",
      "Episode 4231: Reward = 594.00, Steps = 4, Loss = 3.4208, Exploration Rate = 0.1000, Train Count = 36998\n",
      "Episode 4232: Reward = 597.00, Steps = 3, Loss = 1.8547, Exploration Rate = 0.1000, Train Count = 37001\n",
      "Episode 4233: Reward = 591.00, Steps = 5, Loss = 2.0472, Exploration Rate = 0.1000, Train Count = 37006\n",
      "Episode 4234: Reward = 541.00, Steps = 6, Loss = 2.3543, Exploration Rate = 0.1000, Train Count = 37012\n",
      "Episode 4235: Reward = 591.00, Steps = 5, Loss = 2.0727, Exploration Rate = 0.1000, Train Count = 37017\n",
      "Episode 4236: Reward = 591.00, Steps = 5, Loss = 9.8519, Exploration Rate = 0.1000, Train Count = 37022\n",
      "Episode 4237: Reward = 591.00, Steps = 5, Loss = 7.3527, Exploration Rate = 0.1000, Train Count = 37027\n",
      "Episode 4238: Reward = 597.00, Steps = 3, Loss = 3.5439, Exploration Rate = 0.1000, Train Count = 37030\n",
      "Episode 4239: Reward = 582.00, Steps = 8, Loss = 4.7020, Exploration Rate = 0.1000, Train Count = 37038\n",
      "Episode 4240: Reward = 597.00, Steps = 3, Loss = 2.1428, Exploration Rate = 0.1000, Train Count = 37041\n",
      "Episode 4241: Reward = 591.00, Steps = 5, Loss = 2.6045, Exploration Rate = 0.1000, Train Count = 37046\n",
      "Episode 4242: Reward = 585.00, Steps = 7, Loss = 7.4801, Exploration Rate = 0.1000, Train Count = 37053\n",
      "Episode 4243: Reward = 585.00, Steps = 7, Loss = 19.2405, Exploration Rate = 0.1000, Train Count = 37060\n",
      "Episode 4244: Reward = 582.00, Steps = 8, Loss = 10.5905, Exploration Rate = 0.1000, Train Count = 37068\n",
      "Episode 4245: Reward = 597.00, Steps = 3, Loss = 3.4602, Exploration Rate = 0.1000, Train Count = 37071\n",
      "Episode 4246: Reward = 576.00, Steps = 10, Loss = 12.1196, Exploration Rate = 0.1000, Train Count = 37081\n",
      "Episode 4247: Reward = 588.00, Steps = 6, Loss = 5.1706, Exploration Rate = 0.1000, Train Count = 37087\n",
      "Episode 4248: Reward = 594.00, Steps = 4, Loss = 2.8866, Exploration Rate = 0.1000, Train Count = 37091\n",
      "Episode 4249: Reward = 600.00, Steps = 2, Loss = 9.4315, Exploration Rate = 0.1000, Train Count = 37093\n",
      "Episode 4250: Reward = 594.00, Steps = 4, Loss = 6.1865, Exploration Rate = 0.1000, Train Count = 37097\n",
      "Episode 4251: Reward = 591.00, Steps = 5, Loss = 8.2278, Exploration Rate = 0.1000, Train Count = 37102\n",
      "Episode 4252: Reward = 594.00, Steps = 4, Loss = 10.4519, Exploration Rate = 0.1000, Train Count = 37106\n",
      "Episode 4253: Reward = 588.00, Steps = 6, Loss = 9.6836, Exploration Rate = 0.1000, Train Count = 37112\n",
      "Episode 4254: Reward = 591.00, Steps = 5, Loss = 4.8434, Exploration Rate = 0.1000, Train Count = 37117\n",
      "Episode 4255: Reward = 588.00, Steps = 6, Loss = 4.9489, Exploration Rate = 0.1000, Train Count = 37123\n",
      "Episode 4256: Reward = 535.00, Steps = 8, Loss = 12.4254, Exploration Rate = 0.1000, Train Count = 37131\n",
      "Episode 4257: Reward = 588.00, Steps = 6, Loss = 5.6622, Exploration Rate = 0.1000, Train Count = 37137\n",
      "Episode 4258: Reward = 594.00, Steps = 4, Loss = 11.8520, Exploration Rate = 0.1000, Train Count = 37141\n",
      "Episode 4259: Reward = 597.00, Steps = 3, Loss = 13.0519, Exploration Rate = 0.1000, Train Count = 37144\n",
      "Episode 4260: Reward = 594.00, Steps = 4, Loss = 6.6755, Exploration Rate = 0.1000, Train Count = 37148\n",
      "Episode 4261: Reward = 585.00, Steps = 7, Loss = 4.7967, Exploration Rate = 0.1000, Train Count = 37155\n",
      "Episode 4262: Reward = 594.00, Steps = 4, Loss = 6.3121, Exploration Rate = 0.1000, Train Count = 37159\n",
      "Episode 4263: Reward = 591.00, Steps = 5, Loss = 4.5302, Exploration Rate = 0.1000, Train Count = 37164\n",
      "Episode 4264: Reward = 588.00, Steps = 6, Loss = 3.3447, Exploration Rate = 0.1000, Train Count = 37170\n",
      "Episode 4265: Reward = 585.00, Steps = 7, Loss = 4.0599, Exploration Rate = 0.1000, Train Count = 37177\n",
      "Episode 4266: Reward = 582.00, Steps = 8, Loss = 5.6053, Exploration Rate = 0.1000, Train Count = 37185\n",
      "Episode 4267: Reward = 591.00, Steps = 5, Loss = 3.6337, Exploration Rate = 0.1000, Train Count = 37190\n",
      "Episode 4268: Reward = 594.00, Steps = 4, Loss = 3.5177, Exploration Rate = 0.1000, Train Count = 37194\n",
      "Episode 4269: Reward = 591.00, Steps = 5, Loss = 2.5955, Exploration Rate = 0.1000, Train Count = 37199\n",
      "Episode 4270: Reward = 600.00, Steps = 2, Loss = 3.9785, Exploration Rate = 0.1000, Train Count = 37201\n",
      "Episode 4271: Reward = 597.00, Steps = 3, Loss = 3.6059, Exploration Rate = 0.1000, Train Count = 37204\n",
      "Episode 4272: Reward = 597.00, Steps = 3, Loss = 1.8927, Exploration Rate = 0.1000, Train Count = 37207\n",
      "Episode 4273: Reward = 585.00, Steps = 7, Loss = 4.1159, Exploration Rate = 0.1000, Train Count = 37214\n",
      "Episode 4274: Reward = 585.00, Steps = 7, Loss = 6.8380, Exploration Rate = 0.1000, Train Count = 37221\n",
      "Episode 4275: Reward = 582.00, Steps = 8, Loss = 5.3983, Exploration Rate = 0.1000, Train Count = 37229\n",
      "Episode 4276: Reward = 585.00, Steps = 7, Loss = 3.0803, Exploration Rate = 0.1000, Train Count = 37236\n",
      "Episode 4277: Reward = 582.00, Steps = 8, Loss = 2.3081, Exploration Rate = 0.1000, Train Count = 37244\n",
      "Episode 4278: Reward = 585.00, Steps = 7, Loss = 1.7806, Exploration Rate = 0.1000, Train Count = 37251\n",
      "Episode 4279: Reward = 591.00, Steps = 5, Loss = 3.1778, Exploration Rate = 0.1000, Train Count = 37256\n",
      "Episode 4280: Reward = 588.00, Steps = 6, Loss = 2.6666, Exploration Rate = 0.1000, Train Count = 37262\n",
      "Episode 4281: Reward = 591.00, Steps = 5, Loss = 4.6251, Exploration Rate = 0.1000, Train Count = 37267\n",
      "Episode 4282: Reward = 534.00, Steps = 24, Loss = 5.8999, Exploration Rate = 0.1000, Train Count = 37291\n",
      "Episode 4283: Reward = 591.00, Steps = 5, Loss = 3.6492, Exploration Rate = 0.1000, Train Count = 37296\n",
      "Episode 4284: Reward = 582.00, Steps = 8, Loss = 15.7896, Exploration Rate = 0.1000, Train Count = 37304\n",
      "Episode 4285: Reward = 591.00, Steps = 5, Loss = 20.3038, Exploration Rate = 0.1000, Train Count = 37309\n",
      "Episode 4286: Reward = 594.00, Steps = 4, Loss = 21.1970, Exploration Rate = 0.1000, Train Count = 37313\n",
      "Episode 4287: Reward = 579.00, Steps = 9, Loss = 14.1976, Exploration Rate = 0.1000, Train Count = 37322\n",
      "Episode 4288: Reward = 591.00, Steps = 5, Loss = 14.4200, Exploration Rate = 0.1000, Train Count = 37327\n",
      "Episode 4289: Reward = 588.00, Steps = 6, Loss = 12.8816, Exploration Rate = 0.1000, Train Count = 37333\n",
      "Episode 4290: Reward = 579.00, Steps = 9, Loss = 12.5266, Exploration Rate = 0.1000, Train Count = 37342\n",
      "Episode 4291: Reward = 591.00, Steps = 5, Loss = 14.8310, Exploration Rate = 0.1000, Train Count = 37347\n",
      "Episode 4292: Reward = 591.00, Steps = 5, Loss = 11.2379, Exploration Rate = 0.1000, Train Count = 37352\n",
      "Episode 4293: Reward = 597.00, Steps = 3, Loss = 8.8847, Exploration Rate = 0.1000, Train Count = 37355\n",
      "Episode 4294: Reward = 591.00, Steps = 5, Loss = 7.9389, Exploration Rate = 0.1000, Train Count = 37360\n",
      "Episode 4295: Reward = 579.00, Steps = 9, Loss = 5.2082, Exploration Rate = 0.1000, Train Count = 37369\n",
      "Episode 4296: Reward = 597.00, Steps = 3, Loss = 3.5644, Exploration Rate = 0.1000, Train Count = 37372\n",
      "Episode 4297: Reward = 588.00, Steps = 6, Loss = 6.1454, Exploration Rate = 0.1000, Train Count = 37378\n",
      "Episode 4298: Reward = 558.00, Steps = 16, Loss = 5.2910, Exploration Rate = 0.1000, Train Count = 37394\n",
      "Episode 4299: Reward = 591.00, Steps = 5, Loss = 7.7946, Exploration Rate = 0.1000, Train Count = 37399\n",
      "Episode 4300: Reward = 591.00, Steps = 5, Loss = 6.1820, Exploration Rate = 0.1000, Train Count = 37404\n",
      "Episode 4301: Reward = 594.00, Steps = 4, Loss = 5.9922, Exploration Rate = 0.1000, Train Count = 37408\n",
      "Episode 4302: Reward = 582.00, Steps = 8, Loss = 6.0210, Exploration Rate = 0.1000, Train Count = 37416\n",
      "Episode 4303: Reward = 585.00, Steps = 7, Loss = 5.1518, Exploration Rate = 0.1000, Train Count = 37423\n",
      "Episode 4304: Reward = 588.00, Steps = 6, Loss = 5.7126, Exploration Rate = 0.1000, Train Count = 37429\n",
      "Episode 4305: Reward = 582.00, Steps = 8, Loss = 4.2718, Exploration Rate = 0.1000, Train Count = 37437\n",
      "Episode 4306: Reward = 582.00, Steps = 8, Loss = 3.4192, Exploration Rate = 0.1000, Train Count = 37445\n",
      "Episode 4307: Reward = 585.00, Steps = 7, Loss = 4.9736, Exploration Rate = 0.1000, Train Count = 37452\n",
      "Episode 4308: Reward = 594.00, Steps = 4, Loss = 3.3294, Exploration Rate = 0.1000, Train Count = 37456\n",
      "Episode 4309: Reward = 594.00, Steps = 4, Loss = 3.2632, Exploration Rate = 0.1000, Train Count = 37460\n",
      "Episode 4310: Reward = 591.00, Steps = 5, Loss = 3.1712, Exploration Rate = 0.1000, Train Count = 37465\n",
      "Episode 4311: Reward = 600.00, Steps = 2, Loss = 3.0855, Exploration Rate = 0.1000, Train Count = 37467\n",
      "Episode 4312: Reward = 582.00, Steps = 8, Loss = 2.6998, Exploration Rate = 0.1000, Train Count = 37475\n",
      "Episode 4313: Reward = 588.00, Steps = 6, Loss = 7.1722, Exploration Rate = 0.1000, Train Count = 37481\n",
      "Episode 4314: Reward = 597.00, Steps = 3, Loss = 4.5880, Exploration Rate = 0.1000, Train Count = 37484\n",
      "Episode 4315: Reward = 582.00, Steps = 8, Loss = 4.1615, Exploration Rate = 0.1000, Train Count = 37492\n",
      "Episode 4316: Reward = 588.00, Steps = 6, Loss = 3.6956, Exploration Rate = 0.1000, Train Count = 37498\n",
      "Episode 4317: Reward = 588.00, Steps = 6, Loss = 3.5125, Exploration Rate = 0.1000, Train Count = 37504\n",
      "Episode 4318: Reward = 591.00, Steps = 5, Loss = 3.1466, Exploration Rate = 0.1000, Train Count = 37509\n",
      "Episode 4319: Reward = 600.00, Steps = 2, Loss = 3.1894, Exploration Rate = 0.1000, Train Count = 37511\n",
      "Episode 4320: Reward = 591.00, Steps = 5, Loss = 2.7066, Exploration Rate = 0.1000, Train Count = 37516\n",
      "Episode 4321: Reward = 597.00, Steps = 3, Loss = 2.1164, Exploration Rate = 0.1000, Train Count = 37519\n",
      "Episode 4322: Reward = 435.00, Steps = 10, Loss = 3.3359, Exploration Rate = 0.1000, Train Count = 37529\n",
      "Episode 4323: Reward = 585.00, Steps = 7, Loss = 2.7176, Exploration Rate = 0.1000, Train Count = 37536\n",
      "Episode 4324: Reward = 576.00, Steps = 10, Loss = 5.0499, Exploration Rate = 0.1000, Train Count = 37546\n",
      "Episode 4325: Reward = 588.00, Steps = 6, Loss = 2.8666, Exploration Rate = 0.1000, Train Count = 37552\n",
      "Episode 4326: Reward = 588.00, Steps = 6, Loss = 2.7156, Exploration Rate = 0.1000, Train Count = 37558\n",
      "Episode 4327: Reward = 591.00, Steps = 5, Loss = 2.8256, Exploration Rate = 0.1000, Train Count = 37563\n",
      "Episode 4328: Reward = 579.00, Steps = 9, Loss = 4.0216, Exploration Rate = 0.1000, Train Count = 37572\n",
      "Episode 4329: Reward = 594.00, Steps = 4, Loss = 3.1508, Exploration Rate = 0.1000, Train Count = 37576\n",
      "Episode 4330: Reward = 591.00, Steps = 5, Loss = 4.2958, Exploration Rate = 0.1000, Train Count = 37581\n",
      "Episode 4331: Reward = 588.00, Steps = 6, Loss = 4.1969, Exploration Rate = 0.1000, Train Count = 37587\n",
      "Episode 4332: Reward = 588.00, Steps = 6, Loss = 3.4827, Exploration Rate = 0.1000, Train Count = 37593\n",
      "Episode 4333: Reward = 582.00, Steps = 8, Loss = 2.3803, Exploration Rate = 0.1000, Train Count = 37601\n",
      "Episode 4334: Reward = 591.00, Steps = 5, Loss = 1.9727, Exploration Rate = 0.1000, Train Count = 37606\n",
      "Episode 4335: Reward = 591.00, Steps = 5, Loss = 2.3253, Exploration Rate = 0.1000, Train Count = 37611\n",
      "Episode 4336: Reward = 579.00, Steps = 9, Loss = 1.4011, Exploration Rate = 0.1000, Train Count = 37620\n",
      "Episode 4337: Reward = 579.00, Steps = 9, Loss = 2.8743, Exploration Rate = 0.1000, Train Count = 37629\n",
      "Episode 4338: Reward = 597.00, Steps = 3, Loss = 4.0656, Exploration Rate = 0.1000, Train Count = 37632\n",
      "Episode 4339: Reward = 594.00, Steps = 4, Loss = 5.5801, Exploration Rate = 0.1000, Train Count = 37636\n",
      "Episode 4340: Reward = 585.00, Steps = 7, Loss = 3.4938, Exploration Rate = 0.1000, Train Count = 37643\n",
      "Episode 4341: Reward = 597.00, Steps = 3, Loss = 2.8564, Exploration Rate = 0.1000, Train Count = 37646\n",
      "Episode 4342: Reward = 547.00, Steps = 4, Loss = 2.2060, Exploration Rate = 0.1000, Train Count = 37650\n",
      "Episode 4343: Reward = 588.00, Steps = 6, Loss = 3.8764, Exploration Rate = 0.1000, Train Count = 37656\n",
      "Episode 4344: Reward = 585.00, Steps = 7, Loss = 8.4807, Exploration Rate = 0.1000, Train Count = 37663\n",
      "Episode 4345: Reward = 582.00, Steps = 8, Loss = 6.9669, Exploration Rate = 0.1000, Train Count = 37671\n",
      "Episode 4346: Reward = 585.00, Steps = 7, Loss = 3.9560, Exploration Rate = 0.1000, Train Count = 37678\n",
      "Episode 4347: Reward = 547.00, Steps = 4, Loss = 2.7471, Exploration Rate = 0.1000, Train Count = 37682\n",
      "Episode 4348: Reward = 579.00, Steps = 9, Loss = 5.5031, Exploration Rate = 0.1000, Train Count = 37691\n",
      "Episode 4349: Reward = 591.00, Steps = 5, Loss = 6.7350, Exploration Rate = 0.1000, Train Count = 37696\n",
      "Episode 4350: Reward = 582.00, Steps = 8, Loss = 6.5361, Exploration Rate = 0.1000, Train Count = 37704\n",
      "Episode 4351: Reward = 591.00, Steps = 5, Loss = 7.4739, Exploration Rate = 0.1000, Train Count = 37709\n",
      "Episode 4352: Reward = 594.00, Steps = 4, Loss = 4.0814, Exploration Rate = 0.1000, Train Count = 37713\n",
      "Episode 4353: Reward = 585.00, Steps = 7, Loss = 4.8235, Exploration Rate = 0.1000, Train Count = 37720\n",
      "Episode 4354: Reward = 588.00, Steps = 6, Loss = 5.3520, Exploration Rate = 0.1000, Train Count = 37726\n",
      "Episode 4355: Reward = 588.00, Steps = 6, Loss = 3.3962, Exploration Rate = 0.1000, Train Count = 37732\n",
      "Episode 4356: Reward = 597.00, Steps = 3, Loss = 2.0121, Exploration Rate = 0.1000, Train Count = 37735\n",
      "Episode 4357: Reward = 591.00, Steps = 5, Loss = 5.0319, Exploration Rate = 0.1000, Train Count = 37740\n",
      "Episode 4358: Reward = 594.00, Steps = 4, Loss = 5.0836, Exploration Rate = 0.1000, Train Count = 37744\n",
      "Episode 4359: Reward = 585.00, Steps = 7, Loss = 5.3010, Exploration Rate = 0.1000, Train Count = 37751\n",
      "Episode 4360: Reward = 582.00, Steps = 8, Loss = 7.5766, Exploration Rate = 0.1000, Train Count = 37759\n",
      "Episode 4361: Reward = 579.00, Steps = 9, Loss = 8.2437, Exploration Rate = 0.1000, Train Count = 37768\n",
      "Episode 4362: Reward = 591.00, Steps = 5, Loss = 6.2951, Exploration Rate = 0.1000, Train Count = 37773\n",
      "Episode 4363: Reward = 591.00, Steps = 5, Loss = 4.7134, Exploration Rate = 0.1000, Train Count = 37778\n",
      "Episode 4364: Reward = 594.00, Steps = 4, Loss = 3.6744, Exploration Rate = 0.1000, Train Count = 37782\n",
      "Episode 4365: Reward = 582.00, Steps = 8, Loss = 5.8696, Exploration Rate = 0.1000, Train Count = 37790\n",
      "Episode 4366: Reward = 591.00, Steps = 5, Loss = 7.7977, Exploration Rate = 0.1000, Train Count = 37795\n",
      "Episode 4367: Reward = 591.00, Steps = 5, Loss = 4.9523, Exploration Rate = 0.1000, Train Count = 37800\n",
      "Episode 4368: Reward = 600.00, Steps = 2, Loss = 27.8910, Exploration Rate = 0.1000, Train Count = 37802\n",
      "Episode 4369: Reward = 594.00, Steps = 4, Loss = 29.3378, Exploration Rate = 0.1000, Train Count = 37806\n",
      "Episode 4370: Reward = 588.00, Steps = 6, Loss = 24.6900, Exploration Rate = 0.1000, Train Count = 37812\n",
      "Episode 4371: Reward = 591.00, Steps = 5, Loss = 29.5157, Exploration Rate = 0.1000, Train Count = 37817\n",
      "Episode 4372: Reward = 538.00, Steps = 7, Loss = 20.0508, Exploration Rate = 0.1000, Train Count = 37824\n",
      "Episode 4373: Reward = 591.00, Steps = 5, Loss = 22.8395, Exploration Rate = 0.1000, Train Count = 37829\n",
      "Episode 4374: Reward = 600.00, Steps = 2, Loss = 18.8311, Exploration Rate = 0.1000, Train Count = 37831\n",
      "Episode 4375: Reward = 591.00, Steps = 5, Loss = 14.8333, Exploration Rate = 0.1000, Train Count = 37836\n",
      "Episode 4376: Reward = 588.00, Steps = 6, Loss = 13.4889, Exploration Rate = 0.1000, Train Count = 37842\n",
      "Episode 4377: Reward = 591.00, Steps = 5, Loss = 10.0665, Exploration Rate = 0.1000, Train Count = 37847\n",
      "Episode 4378: Reward = 597.00, Steps = 3, Loss = 11.0241, Exploration Rate = 0.1000, Train Count = 37850\n",
      "Episode 4379: Reward = 594.00, Steps = 4, Loss = 11.6711, Exploration Rate = 0.1000, Train Count = 37854\n",
      "Episode 4380: Reward = 591.00, Steps = 5, Loss = 12.2981, Exploration Rate = 0.1000, Train Count = 37859\n",
      "Episode 4381: Reward = 585.00, Steps = 7, Loss = 19.3322, Exploration Rate = 0.1000, Train Count = 37866\n",
      "Episode 4382: Reward = 585.00, Steps = 7, Loss = 14.0616, Exploration Rate = 0.1000, Train Count = 37873\n",
      "Episode 4383: Reward = 579.00, Steps = 9, Loss = 9.7396, Exploration Rate = 0.1000, Train Count = 37882\n",
      "Episode 4384: Reward = 594.00, Steps = 4, Loss = 13.3812, Exploration Rate = 0.1000, Train Count = 37886\n",
      "Episode 4385: Reward = 585.00, Steps = 7, Loss = 9.1758, Exploration Rate = 0.1000, Train Count = 37893\n",
      "Episode 4386: Reward = 576.00, Steps = 10, Loss = 9.4197, Exploration Rate = 0.1000, Train Count = 37903\n",
      "Episode 4387: Reward = 588.00, Steps = 6, Loss = 5.6823, Exploration Rate = 0.1000, Train Count = 37909\n",
      "Episode 4388: Reward = 597.00, Steps = 3, Loss = 4.9805, Exploration Rate = 0.1000, Train Count = 37912\n",
      "Episode 4389: Reward = 597.00, Steps = 3, Loss = 7.5703, Exploration Rate = 0.1000, Train Count = 37915\n",
      "Episode 4390: Reward = 591.00, Steps = 5, Loss = 6.7554, Exploration Rate = 0.1000, Train Count = 37920\n",
      "Episode 4391: Reward = 591.00, Steps = 5, Loss = 5.7305, Exploration Rate = 0.1000, Train Count = 37925\n",
      "Episode 4392: Reward = 588.00, Steps = 6, Loss = 3.9962, Exploration Rate = 0.1000, Train Count = 37931\n",
      "Episode 4393: Reward = 591.00, Steps = 5, Loss = 6.1969, Exploration Rate = 0.1000, Train Count = 37936\n",
      "Episode 4394: Reward = 591.00, Steps = 5, Loss = 7.0965, Exploration Rate = 0.1000, Train Count = 37941\n",
      "Episode 4395: Reward = 582.00, Steps = 8, Loss = 8.8811, Exploration Rate = 0.1000, Train Count = 37949\n",
      "Episode 4396: Reward = 594.00, Steps = 4, Loss = 7.8847, Exploration Rate = 0.1000, Train Count = 37953\n",
      "Episode 4397: Reward = 594.00, Steps = 4, Loss = 4.9159, Exploration Rate = 0.1000, Train Count = 37957\n",
      "Episode 4398: Reward = 594.00, Steps = 4, Loss = 5.9564, Exploration Rate = 0.1000, Train Count = 37961\n",
      "Episode 4399: Reward = 597.00, Steps = 3, Loss = 3.5719, Exploration Rate = 0.1000, Train Count = 37964\n",
      "Episode 4400: Reward = 588.00, Steps = 6, Loss = 5.3097, Exploration Rate = 0.1000, Train Count = 37970\n",
      "Episode 4401: Reward = 585.00, Steps = 7, Loss = 4.3247, Exploration Rate = 0.1000, Train Count = 37977\n",
      "Episode 4402: Reward = 588.00, Steps = 6, Loss = 5.0731, Exploration Rate = 0.1000, Train Count = 37983\n",
      "Episode 4403: Reward = 594.00, Steps = 4, Loss = 4.7700, Exploration Rate = 0.1000, Train Count = 37987\n",
      "Episode 4404: Reward = 588.00, Steps = 6, Loss = 5.7579, Exploration Rate = 0.1000, Train Count = 37993\n",
      "Episode 4405: Reward = 594.00, Steps = 4, Loss = 8.6338, Exploration Rate = 0.1000, Train Count = 37997\n",
      "Episode 4406: Reward = 579.00, Steps = 9, Loss = 13.6161, Exploration Rate = 0.1000, Train Count = 38006\n",
      "Episode 4407: Reward = 594.00, Steps = 4, Loss = 10.8287, Exploration Rate = 0.1000, Train Count = 38010\n",
      "Episode 4408: Reward = 588.00, Steps = 6, Loss = 5.6915, Exploration Rate = 0.1000, Train Count = 38016\n",
      "Episode 4409: Reward = 594.00, Steps = 4, Loss = 8.5205, Exploration Rate = 0.1000, Train Count = 38020\n",
      "Episode 4410: Reward = 597.00, Steps = 3, Loss = 5.2183, Exploration Rate = 0.1000, Train Count = 38023\n",
      "Episode 4411: Reward = 585.00, Steps = 7, Loss = 5.1856, Exploration Rate = 0.1000, Train Count = 38030\n",
      "Episode 4412: Reward = 579.00, Steps = 9, Loss = 6.8321, Exploration Rate = 0.1000, Train Count = 38039\n",
      "Episode 4413: Reward = 585.00, Steps = 7, Loss = 6.3936, Exploration Rate = 0.1000, Train Count = 38046\n",
      "Episode 4414: Reward = 597.00, Steps = 3, Loss = 3.8847, Exploration Rate = 0.1000, Train Count = 38049\n",
      "Episode 4415: Reward = 597.00, Steps = 3, Loss = 4.6212, Exploration Rate = 0.1000, Train Count = 38052\n",
      "Episode 4416: Reward = 585.00, Steps = 7, Loss = 6.2569, Exploration Rate = 0.1000, Train Count = 38059\n",
      "Episode 4417: Reward = 591.00, Steps = 5, Loss = 4.9002, Exploration Rate = 0.1000, Train Count = 38064\n",
      "Episode 4418: Reward = 591.00, Steps = 5, Loss = 3.9130, Exploration Rate = 0.1000, Train Count = 38069\n",
      "Episode 4419: Reward = 523.00, Steps = 12, Loss = 8.4686, Exploration Rate = 0.1000, Train Count = 38081\n",
      "Episode 4420: Reward = 585.00, Steps = 7, Loss = 10.8586, Exploration Rate = 0.1000, Train Count = 38088\n",
      "Episode 4421: Reward = 585.00, Steps = 7, Loss = 11.3539, Exploration Rate = 0.1000, Train Count = 38095\n",
      "Episode 4422: Reward = 594.00, Steps = 4, Loss = 9.3329, Exploration Rate = 0.1000, Train Count = 38099\n",
      "Episode 4423: Reward = 576.00, Steps = 10, Loss = 8.1116, Exploration Rate = 0.1000, Train Count = 38109\n",
      "Episode 4424: Reward = 588.00, Steps = 6, Loss = 4.5491, Exploration Rate = 0.1000, Train Count = 38115\n",
      "Episode 4425: Reward = 535.00, Steps = 8, Loss = 5.6299, Exploration Rate = 0.1000, Train Count = 38123\n",
      "Episode 4426: Reward = 579.00, Steps = 9, Loss = 6.3759, Exploration Rate = 0.1000, Train Count = 38132\n",
      "Episode 4427: Reward = 597.00, Steps = 3, Loss = 3.8215, Exploration Rate = 0.1000, Train Count = 38135\n",
      "Episode 4428: Reward = 585.00, Steps = 7, Loss = 6.2230, Exploration Rate = 0.1000, Train Count = 38142\n",
      "Episode 4429: Reward = 585.00, Steps = 7, Loss = 3.9375, Exploration Rate = 0.1000, Train Count = 38149\n",
      "Episode 4430: Reward = 591.00, Steps = 5, Loss = 6.7947, Exploration Rate = 0.1000, Train Count = 38154\n",
      "Episode 4431: Reward = 588.00, Steps = 6, Loss = 5.7206, Exploration Rate = 0.1000, Train Count = 38160\n",
      "Episode 4432: Reward = 588.00, Steps = 6, Loss = 7.8792, Exploration Rate = 0.1000, Train Count = 38166\n",
      "Episode 4433: Reward = 579.00, Steps = 9, Loss = 6.4151, Exploration Rate = 0.1000, Train Count = 38175\n",
      "Episode 4434: Reward = 582.00, Steps = 8, Loss = 3.6015, Exploration Rate = 0.1000, Train Count = 38183\n",
      "Episode 4435: Reward = 576.00, Steps = 10, Loss = 5.6270, Exploration Rate = 0.1000, Train Count = 38193\n",
      "Episode 4436: Reward = 585.00, Steps = 7, Loss = 6.7997, Exploration Rate = 0.1000, Train Count = 38200\n",
      "Episode 4437: Reward = 594.00, Steps = 4, Loss = 4.8147, Exploration Rate = 0.1000, Train Count = 38204\n",
      "Episode 4438: Reward = 594.00, Steps = 4, Loss = 7.7013, Exploration Rate = 0.1000, Train Count = 38208\n",
      "Episode 4439: Reward = 591.00, Steps = 5, Loss = 5.0830, Exploration Rate = 0.1000, Train Count = 38213\n",
      "Episode 4440: Reward = 591.00, Steps = 5, Loss = 4.5984, Exploration Rate = 0.1000, Train Count = 38218\n",
      "Episode 4441: Reward = 585.00, Steps = 7, Loss = 3.5913, Exploration Rate = 0.1000, Train Count = 38225\n",
      "Episode 4442: Reward = 535.00, Steps = 8, Loss = 6.1676, Exploration Rate = 0.1000, Train Count = 38233\n",
      "Episode 4443: Reward = 594.00, Steps = 4, Loss = 3.8018, Exploration Rate = 0.1000, Train Count = 38237\n",
      "Episode 4444: Reward = 597.00, Steps = 3, Loss = 3.4028, Exploration Rate = 0.1000, Train Count = 38240\n",
      "Episode 4445: Reward = 591.00, Steps = 5, Loss = 4.7555, Exploration Rate = 0.1000, Train Count = 38245\n",
      "Episode 4446: Reward = 579.00, Steps = 9, Loss = 5.5396, Exploration Rate = 0.1000, Train Count = 38254\n",
      "Episode 4447: Reward = 600.00, Steps = 2, Loss = 4.6465, Exploration Rate = 0.1000, Train Count = 38256\n",
      "Episode 4448: Reward = 591.00, Steps = 5, Loss = 4.1144, Exploration Rate = 0.1000, Train Count = 38261\n",
      "Episode 4449: Reward = 558.00, Steps = 16, Loss = 5.2079, Exploration Rate = 0.1000, Train Count = 38277\n",
      "Episode 4450: Reward = 588.00, Steps = 6, Loss = 6.6103, Exploration Rate = 0.1000, Train Count = 38283\n",
      "Episode 4451: Reward = 582.00, Steps = 8, Loss = 3.7133, Exploration Rate = 0.1000, Train Count = 38291\n",
      "Episode 4452: Reward = 538.00, Steps = 7, Loss = 5.9597, Exploration Rate = 0.1000, Train Count = 38298\n",
      "Episode 4453: Reward = 594.00, Steps = 4, Loss = 24.4461, Exploration Rate = 0.1000, Train Count = 38302\n",
      "Episode 4454: Reward = 591.00, Steps = 5, Loss = 35.7288, Exploration Rate = 0.1000, Train Count = 38307\n",
      "Episode 4455: Reward = 532.00, Steps = 9, Loss = 33.0710, Exploration Rate = 0.1000, Train Count = 38316\n",
      "Episode 4456: Reward = 597.00, Steps = 3, Loss = 31.0765, Exploration Rate = 0.1000, Train Count = 38319\n",
      "Episode 4457: Reward = 597.00, Steps = 3, Loss = 23.2364, Exploration Rate = 0.1000, Train Count = 38322\n",
      "Episode 4458: Reward = 538.00, Steps = 7, Loss = 19.1790, Exploration Rate = 0.1000, Train Count = 38329\n",
      "Episode 4459: Reward = 441.00, Steps = 8, Loss = 32.5433, Exploration Rate = 0.1000, Train Count = 38337\n",
      "Episode 4460: Reward = 597.00, Steps = 3, Loss = 24.1229, Exploration Rate = 0.1000, Train Count = 38340\n",
      "Episode 4461: Reward = 594.00, Steps = 4, Loss = 21.5172, Exploration Rate = 0.1000, Train Count = 38344\n",
      "Episode 4462: Reward = 591.00, Steps = 5, Loss = 22.7667, Exploration Rate = 0.1000, Train Count = 38349\n",
      "Episode 4463: Reward = 591.00, Steps = 5, Loss = 22.9922, Exploration Rate = 0.1000, Train Count = 38354\n",
      "Episode 4464: Reward = 526.00, Steps = 11, Loss = 13.7752, Exploration Rate = 0.1000, Train Count = 38365\n",
      "Episode 4465: Reward = 597.00, Steps = 3, Loss = 17.3346, Exploration Rate = 0.1000, Train Count = 38368\n",
      "Episode 4466: Reward = 585.00, Steps = 7, Loss = 11.3111, Exploration Rate = 0.1000, Train Count = 38375\n",
      "Episode 4467: Reward = 541.00, Steps = 6, Loss = 11.5705, Exploration Rate = 0.1000, Train Count = 38381\n",
      "Episode 4468: Reward = 588.00, Steps = 6, Loss = 9.5702, Exploration Rate = 0.1000, Train Count = 38387\n",
      "Episode 4469: Reward = 597.00, Steps = 3, Loss = 7.5430, Exploration Rate = 0.1000, Train Count = 38390\n",
      "Episode 4470: Reward = 594.00, Steps = 4, Loss = 9.6713, Exploration Rate = 0.1000, Train Count = 38394\n",
      "Episode 4471: Reward = 573.00, Steps = 11, Loss = 8.2672, Exploration Rate = 0.1000, Train Count = 38405\n",
      "Episode 4472: Reward = 588.00, Steps = 6, Loss = 9.5956, Exploration Rate = 0.1000, Train Count = 38411\n",
      "Episode 4473: Reward = 582.00, Steps = 8, Loss = 10.0242, Exploration Rate = 0.1000, Train Count = 38419\n",
      "Episode 4474: Reward = 597.00, Steps = 3, Loss = 6.7185, Exploration Rate = 0.1000, Train Count = 38422\n",
      "Episode 4475: Reward = 585.00, Steps = 7, Loss = 7.4607, Exploration Rate = 0.1000, Train Count = 38429\n",
      "Episode 4476: Reward = 597.00, Steps = 3, Loss = 5.7187, Exploration Rate = 0.1000, Train Count = 38432\n",
      "Episode 4477: Reward = 547.00, Steps = 4, Loss = 9.4976, Exploration Rate = 0.1000, Train Count = 38436\n",
      "Episode 4478: Reward = 585.00, Steps = 7, Loss = 7.1870, Exploration Rate = 0.1000, Train Count = 38443\n",
      "Episode 4479: Reward = 523.00, Steps = 12, Loss = 5.7102, Exploration Rate = 0.1000, Train Count = 38455\n",
      "Episode 4480: Reward = 588.00, Steps = 6, Loss = 9.3688, Exploration Rate = 0.1000, Train Count = 38461\n",
      "Episode 4481: Reward = 564.00, Steps = 14, Loss = 9.0944, Exploration Rate = 0.1000, Train Count = 38475\n",
      "Episode 4482: Reward = 582.00, Steps = 8, Loss = 8.4877, Exploration Rate = 0.1000, Train Count = 38483\n",
      "Episode 4483: Reward = 585.00, Steps = 7, Loss = 6.6813, Exploration Rate = 0.1000, Train Count = 38490\n",
      "Episode 4484: Reward = 582.00, Steps = 8, Loss = 5.0509, Exploration Rate = 0.1000, Train Count = 38498\n",
      "Episode 4485: Reward = 588.00, Steps = 6, Loss = 5.1696, Exploration Rate = 0.1000, Train Count = 38504\n",
      "Episode 4486: Reward = 594.00, Steps = 4, Loss = 8.9432, Exploration Rate = 0.1000, Train Count = 38508\n",
      "Episode 4487: Reward = 576.00, Steps = 10, Loss = 6.0229, Exploration Rate = 0.1000, Train Count = 38518\n",
      "Episode 4488: Reward = 588.00, Steps = 6, Loss = 6.1768, Exploration Rate = 0.1000, Train Count = 38524\n",
      "Episode 4489: Reward = 585.00, Steps = 7, Loss = 5.9092, Exploration Rate = 0.1000, Train Count = 38531\n",
      "Episode 4490: Reward = 588.00, Steps = 6, Loss = 5.7854, Exploration Rate = 0.1000, Train Count = 38537\n",
      "Episode 4491: Reward = 588.00, Steps = 6, Loss = 7.7714, Exploration Rate = 0.1000, Train Count = 38543\n",
      "Episode 4492: Reward = 585.00, Steps = 7, Loss = 6.8480, Exploration Rate = 0.1000, Train Count = 38550\n",
      "Episode 4493: Reward = 588.00, Steps = 6, Loss = 6.0588, Exploration Rate = 0.1000, Train Count = 38556\n",
      "Episode 4494: Reward = 585.00, Steps = 7, Loss = 5.2285, Exploration Rate = 0.1000, Train Count = 38563\n",
      "Episode 4495: Reward = 538.00, Steps = 7, Loss = 6.6176, Exploration Rate = 0.1000, Train Count = 38570\n",
      "Episode 4496: Reward = 538.00, Steps = 7, Loss = 6.0302, Exploration Rate = 0.1000, Train Count = 38577\n",
      "Episode 4497: Reward = 597.00, Steps = 3, Loss = 3.0251, Exploration Rate = 0.1000, Train Count = 38580\n",
      "Episode 4498: Reward = 594.00, Steps = 4, Loss = 10.9862, Exploration Rate = 0.1000, Train Count = 38584\n",
      "Episode 4499: Reward = 582.00, Steps = 8, Loss = 9.0936, Exploration Rate = 0.1000, Train Count = 38592\n",
      "Episode 4500: Reward = 585.00, Steps = 7, Loss = 6.9564, Exploration Rate = 0.1000, Train Count = 38599\n",
      "Episode 4501: Reward = 597.00, Steps = 3, Loss = 10.6467, Exploration Rate = 0.1000, Train Count = 38602\n",
      "Episode 4502: Reward = 588.00, Steps = 6, Loss = 6.5974, Exploration Rate = 0.1000, Train Count = 38608\n",
      "Episode 4503: Reward = 594.00, Steps = 4, Loss = 10.5189, Exploration Rate = 0.1000, Train Count = 38612\n",
      "Episode 4504: Reward = 591.00, Steps = 5, Loss = 4.9061, Exploration Rate = 0.1000, Train Count = 38617\n",
      "Episode 4505: Reward = 591.00, Steps = 5, Loss = 6.9482, Exploration Rate = 0.1000, Train Count = 38622\n",
      "Episode 4506: Reward = 588.00, Steps = 6, Loss = 3.7609, Exploration Rate = 0.1000, Train Count = 38628\n",
      "Episode 4507: Reward = 597.00, Steps = 3, Loss = 2.3775, Exploration Rate = 0.1000, Train Count = 38631\n",
      "Episode 4508: Reward = 588.00, Steps = 6, Loss = 4.3204, Exploration Rate = 0.1000, Train Count = 38637\n",
      "Episode 4509: Reward = 597.00, Steps = 3, Loss = 3.3105, Exploration Rate = 0.1000, Train Count = 38640\n",
      "Episode 4510: Reward = 591.00, Steps = 5, Loss = 2.5806, Exploration Rate = 0.1000, Train Count = 38645\n",
      "Episode 4511: Reward = 591.00, Steps = 5, Loss = 3.3418, Exploration Rate = 0.1000, Train Count = 38650\n",
      "Episode 4512: Reward = 591.00, Steps = 5, Loss = 3.9534, Exploration Rate = 0.1000, Train Count = 38655\n",
      "Episode 4513: Reward = 591.00, Steps = 5, Loss = 2.8119, Exploration Rate = 0.1000, Train Count = 38660\n",
      "Episode 4514: Reward = 591.00, Steps = 5, Loss = 1.6879, Exploration Rate = 0.1000, Train Count = 38665\n",
      "Episode 4515: Reward = 576.00, Steps = 10, Loss = 4.4024, Exploration Rate = 0.1000, Train Count = 38675\n",
      "Episode 4516: Reward = 591.00, Steps = 5, Loss = 3.8683, Exploration Rate = 0.1000, Train Count = 38680\n",
      "Episode 4517: Reward = 597.00, Steps = 3, Loss = 5.6678, Exploration Rate = 0.1000, Train Count = 38683\n",
      "Episode 4518: Reward = 597.00, Steps = 3, Loss = 3.3721, Exploration Rate = 0.1000, Train Count = 38686\n",
      "Episode 4519: Reward = 597.00, Steps = 3, Loss = 3.7220, Exploration Rate = 0.1000, Train Count = 38689\n",
      "Episode 4520: Reward = 594.00, Steps = 4, Loss = 4.3229, Exploration Rate = 0.1000, Train Count = 38693\n",
      "Episode 4521: Reward = 591.00, Steps = 5, Loss = 3.9431, Exploration Rate = 0.1000, Train Count = 38698\n",
      "Episode 4522: Reward = 585.00, Steps = 7, Loss = 6.2037, Exploration Rate = 0.1000, Train Count = 38705\n",
      "Episode 4523: Reward = 576.00, Steps = 10, Loss = 4.1310, Exploration Rate = 0.1000, Train Count = 38715\n",
      "Episode 4524: Reward = 597.00, Steps = 3, Loss = 3.5424, Exploration Rate = 0.1000, Train Count = 38718\n",
      "Episode 4525: Reward = 591.00, Steps = 5, Loss = 3.8169, Exploration Rate = 0.1000, Train Count = 38723\n",
      "Episode 4526: Reward = 594.00, Steps = 4, Loss = 4.8733, Exploration Rate = 0.1000, Train Count = 38727\n",
      "Episode 4527: Reward = 585.00, Steps = 7, Loss = 4.9675, Exploration Rate = 0.1000, Train Count = 38734\n",
      "Episode 4528: Reward = 597.00, Steps = 3, Loss = 4.5696, Exploration Rate = 0.1000, Train Count = 38737\n",
      "Episode 4529: Reward = 591.00, Steps = 5, Loss = 6.2919, Exploration Rate = 0.1000, Train Count = 38742\n",
      "Episode 4530: Reward = 591.00, Steps = 5, Loss = 7.5085, Exploration Rate = 0.1000, Train Count = 38747\n",
      "Episode 4531: Reward = 591.00, Steps = 5, Loss = 5.0330, Exploration Rate = 0.1000, Train Count = 38752\n",
      "Episode 4532: Reward = 535.00, Steps = 8, Loss = 7.0228, Exploration Rate = 0.1000, Train Count = 38760\n",
      "Episode 4533: Reward = 582.00, Steps = 8, Loss = 5.8833, Exploration Rate = 0.1000, Train Count = 38768\n",
      "Episode 4534: Reward = 594.00, Steps = 4, Loss = 6.6645, Exploration Rate = 0.1000, Train Count = 38772\n",
      "Episode 4535: Reward = 591.00, Steps = 5, Loss = 6.0405, Exploration Rate = 0.1000, Train Count = 38777\n",
      "Episode 4536: Reward = 594.00, Steps = 4, Loss = 7.2537, Exploration Rate = 0.1000, Train Count = 38781\n",
      "Episode 4537: Reward = 564.00, Steps = 14, Loss = 8.5510, Exploration Rate = 0.1000, Train Count = 38795\n",
      "Episode 4538: Reward = 594.00, Steps = 4, Loss = 3.3888, Exploration Rate = 0.1000, Train Count = 38799\n",
      "Episode 4539: Reward = 591.00, Steps = 5, Loss = 34.9490, Exploration Rate = 0.1000, Train Count = 38804\n",
      "Episode 4540: Reward = 579.00, Steps = 9, Loss = 36.4321, Exploration Rate = 0.1000, Train Count = 38813\n",
      "Episode 4541: Reward = 470.00, Steps = 14, Loss = 29.1300, Exploration Rate = 0.1000, Train Count = 38827\n",
      "Episode 4542: Reward = 588.00, Steps = 6, Loss = 26.7953, Exploration Rate = 0.1000, Train Count = 38833\n",
      "Episode 4543: Reward = 564.00, Steps = 14, Loss = 19.8309, Exploration Rate = 0.1000, Train Count = 38847\n",
      "Episode 4544: Reward = 535.00, Steps = 8, Loss = 18.3129, Exploration Rate = 0.1000, Train Count = 38855\n",
      "Episode 4545: Reward = 591.00, Steps = 5, Loss = 10.2071, Exploration Rate = 0.1000, Train Count = 38860\n",
      "Episode 4546: Reward = 591.00, Steps = 5, Loss = 9.6534, Exploration Rate = 0.1000, Train Count = 38865\n",
      "Episode 4547: Reward = 579.00, Steps = 9, Loss = 7.2183, Exploration Rate = 0.1000, Train Count = 38874\n",
      "Episode 4548: Reward = 585.00, Steps = 7, Loss = 7.3151, Exploration Rate = 0.1000, Train Count = 38881\n",
      "Episode 4549: Reward = 594.00, Steps = 4, Loss = 8.8073, Exploration Rate = 0.1000, Train Count = 38885\n",
      "Episode 4550: Reward = 591.00, Steps = 5, Loss = 5.4386, Exploration Rate = 0.1000, Train Count = 38890\n",
      "Episode 4551: Reward = 594.00, Steps = 4, Loss = 4.8216, Exploration Rate = 0.1000, Train Count = 38894\n",
      "Episode 4552: Reward = 591.00, Steps = 5, Loss = 7.8484, Exploration Rate = 0.1000, Train Count = 38899\n",
      "Episode 4553: Reward = 597.00, Steps = 3, Loss = 7.0339, Exploration Rate = 0.1000, Train Count = 38902\n",
      "Episode 4554: Reward = 591.00, Steps = 5, Loss = 5.5395, Exploration Rate = 0.1000, Train Count = 38907\n",
      "Episode 4555: Reward = 591.00, Steps = 5, Loss = 6.1047, Exploration Rate = 0.1000, Train Count = 38912\n",
      "Episode 4556: Reward = 585.00, Steps = 7, Loss = 8.5053, Exploration Rate = 0.1000, Train Count = 38919\n",
      "Episode 4557: Reward = 582.00, Steps = 8, Loss = 8.9045, Exploration Rate = 0.1000, Train Count = 38927\n",
      "Episode 4558: Reward = 585.00, Steps = 7, Loss = 5.8163, Exploration Rate = 0.1000, Train Count = 38934\n",
      "Episode 4559: Reward = 600.00, Steps = 2, Loss = 3.6164, Exploration Rate = 0.1000, Train Count = 38936\n",
      "Episode 4560: Reward = 591.00, Steps = 5, Loss = 3.8178, Exploration Rate = 0.1000, Train Count = 38941\n",
      "Episode 4561: Reward = 579.00, Steps = 9, Loss = 8.3929, Exploration Rate = 0.1000, Train Count = 38950\n",
      "Episode 4562: Reward = 585.00, Steps = 7, Loss = 8.3245, Exploration Rate = 0.1000, Train Count = 38957\n",
      "Episode 4563: Reward = 582.00, Steps = 8, Loss = 5.4019, Exploration Rate = 0.1000, Train Count = 38965\n",
      "Episode 4564: Reward = 585.00, Steps = 7, Loss = 5.2260, Exploration Rate = 0.1000, Train Count = 38972\n",
      "Episode 4565: Reward = 588.00, Steps = 6, Loss = 6.0053, Exploration Rate = 0.1000, Train Count = 38978\n",
      "Episode 4566: Reward = 591.00, Steps = 5, Loss = 4.6189, Exploration Rate = 0.1000, Train Count = 38983\n",
      "Episode 4567: Reward = 585.00, Steps = 7, Loss = 4.1481, Exploration Rate = 0.1000, Train Count = 38990\n",
      "Episode 4568: Reward = 588.00, Steps = 6, Loss = 4.6216, Exploration Rate = 0.1000, Train Count = 38996\n",
      "Episode 4569: Reward = 594.00, Steps = 4, Loss = 3.0610, Exploration Rate = 0.1000, Train Count = 39000\n",
      "Episode 4570: Reward = 582.00, Steps = 8, Loss = 4.4582, Exploration Rate = 0.1000, Train Count = 39008\n",
      "Episode 4571: Reward = 579.00, Steps = 9, Loss = 3.8675, Exploration Rate = 0.1000, Train Count = 39017\n",
      "Episode 4572: Reward = 591.00, Steps = 5, Loss = 4.7950, Exploration Rate = 0.1000, Train Count = 39022\n",
      "Episode 4573: Reward = 597.00, Steps = 3, Loss = 2.5162, Exploration Rate = 0.1000, Train Count = 39025\n",
      "Episode 4574: Reward = 585.00, Steps = 7, Loss = 4.1377, Exploration Rate = 0.1000, Train Count = 39032\n",
      "Episode 4575: Reward = 597.00, Steps = 3, Loss = 3.4899, Exploration Rate = 0.1000, Train Count = 39035\n",
      "Episode 4576: Reward = 588.00, Steps = 6, Loss = 6.2283, Exploration Rate = 0.1000, Train Count = 39041\n",
      "Episode 4577: Reward = 585.00, Steps = 7, Loss = 5.1566, Exploration Rate = 0.1000, Train Count = 39048\n",
      "Episode 4578: Reward = 600.00, Steps = 2, Loss = 4.8412, Exploration Rate = 0.1000, Train Count = 39050\n",
      "Episode 4579: Reward = 579.00, Steps = 9, Loss = 12.1611, Exploration Rate = 0.1000, Train Count = 39059\n",
      "Episode 4580: Reward = 576.00, Steps = 10, Loss = 6.1447, Exploration Rate = 0.1000, Train Count = 39069\n",
      "Episode 4581: Reward = 537.00, Steps = 23, Loss = 5.8336, Exploration Rate = 0.1000, Train Count = 39092\n",
      "Episode 4582: Reward = 529.00, Steps = 10, Loss = 6.6681, Exploration Rate = 0.1000, Train Count = 39102\n",
      "Episode 4583: Reward = 597.00, Steps = 3, Loss = 8.7384, Exploration Rate = 0.1000, Train Count = 39105\n",
      "Episode 4584: Reward = 591.00, Steps = 5, Loss = 8.4902, Exploration Rate = 0.1000, Train Count = 39110\n",
      "Episode 4585: Reward = 591.00, Steps = 5, Loss = 5.5941, Exploration Rate = 0.1000, Train Count = 39115\n",
      "Episode 4586: Reward = 585.00, Steps = 7, Loss = 4.5215, Exploration Rate = 0.1000, Train Count = 39122\n",
      "Episode 4587: Reward = 591.00, Steps = 5, Loss = 3.3036, Exploration Rate = 0.1000, Train Count = 39127\n",
      "Episode 4588: Reward = 541.00, Steps = 6, Loss = 2.4631, Exploration Rate = 0.1000, Train Count = 39133\n",
      "Episode 4589: Reward = 558.00, Steps = 16, Loss = 7.1230, Exploration Rate = 0.1000, Train Count = 39149\n",
      "Episode 4590: Reward = 591.00, Steps = 5, Loss = 3.0587, Exploration Rate = 0.1000, Train Count = 39154\n",
      "Episode 4591: Reward = 588.00, Steps = 6, Loss = 4.4425, Exploration Rate = 0.1000, Train Count = 39160\n",
      "Episode 4592: Reward = 579.00, Steps = 9, Loss = 5.8931, Exploration Rate = 0.1000, Train Count = 39169\n",
      "Episode 4593: Reward = 585.00, Steps = 7, Loss = 4.1590, Exploration Rate = 0.1000, Train Count = 39176\n",
      "Episode 4594: Reward = 594.00, Steps = 4, Loss = 2.3154, Exploration Rate = 0.1000, Train Count = 39180\n",
      "Episode 4595: Reward = 594.00, Steps = 4, Loss = 8.6537, Exploration Rate = 0.1000, Train Count = 39184\n",
      "Episode 4596: Reward = 588.00, Steps = 6, Loss = 4.7416, Exploration Rate = 0.1000, Train Count = 39190\n",
      "Episode 4597: Reward = 591.00, Steps = 5, Loss = 4.1862, Exploration Rate = 0.1000, Train Count = 39195\n",
      "Episode 4598: Reward = 579.00, Steps = 9, Loss = 4.7169, Exploration Rate = 0.1000, Train Count = 39204\n",
      "Episode 4599: Reward = 600.00, Steps = 2, Loss = 5.5565, Exploration Rate = 0.1000, Train Count = 39206\n",
      "Episode 4600: Reward = 591.00, Steps = 5, Loss = 5.0717, Exploration Rate = 0.1000, Train Count = 39211\n",
      "Episode 4601: Reward = 600.00, Steps = 2, Loss = 5.5480, Exploration Rate = 0.1000, Train Count = 39213\n",
      "Episode 4602: Reward = 576.00, Steps = 10, Loss = 4.4258, Exploration Rate = 0.1000, Train Count = 39223\n",
      "Episode 4603: Reward = 591.00, Steps = 5, Loss = 3.3670, Exploration Rate = 0.1000, Train Count = 39228\n",
      "Episode 4604: Reward = 591.00, Steps = 5, Loss = 2.2011, Exploration Rate = 0.1000, Train Count = 39233\n",
      "Episode 4605: Reward = 591.00, Steps = 5, Loss = 2.0149, Exploration Rate = 0.1000, Train Count = 39238\n",
      "Episode 4606: Reward = 597.00, Steps = 3, Loss = 4.7603, Exploration Rate = 0.1000, Train Count = 39241\n",
      "Episode 4607: Reward = 526.00, Steps = 11, Loss = 2.3824, Exploration Rate = 0.1000, Train Count = 39252\n",
      "Episode 4608: Reward = 585.00, Steps = 7, Loss = 4.1390, Exploration Rate = 0.1000, Train Count = 39259\n",
      "Episode 4609: Reward = 597.00, Steps = 3, Loss = 4.1312, Exploration Rate = 0.1000, Train Count = 39262\n",
      "Episode 4610: Reward = 591.00, Steps = 5, Loss = 2.6536, Exploration Rate = 0.1000, Train Count = 39267\n",
      "Episode 4611: Reward = 570.00, Steps = 12, Loss = 4.6925, Exploration Rate = 0.1000, Train Count = 39279\n",
      "Episode 4612: Reward = 591.00, Steps = 5, Loss = 9.5563, Exploration Rate = 0.1000, Train Count = 39284\n",
      "Episode 4613: Reward = 588.00, Steps = 6, Loss = 6.9133, Exploration Rate = 0.1000, Train Count = 39290\n",
      "Episode 4614: Reward = 585.00, Steps = 7, Loss = 7.3418, Exploration Rate = 0.1000, Train Count = 39297\n",
      "Episode 4615: Reward = 600.00, Steps = 2, Loss = 8.0290, Exploration Rate = 0.1000, Train Count = 39299\n",
      "Episode 4616: Reward = 591.00, Steps = 5, Loss = 32.2939, Exploration Rate = 0.1000, Train Count = 39304\n",
      "Episode 4617: Reward = 541.00, Steps = 6, Loss = 34.5589, Exploration Rate = 0.1000, Train Count = 39310\n",
      "Episode 4618: Reward = 585.00, Steps = 7, Loss = 24.5286, Exploration Rate = 0.1000, Train Count = 39317\n",
      "Episode 4619: Reward = 594.00, Steps = 4, Loss = 18.9405, Exploration Rate = 0.1000, Train Count = 39321\n",
      "Episode 4620: Reward = 588.00, Steps = 6, Loss = 13.6234, Exploration Rate = 0.1000, Train Count = 39327\n",
      "Episode 4621: Reward = 588.00, Steps = 6, Loss = 11.8778, Exploration Rate = 0.1000, Train Count = 39333\n",
      "Episode 4622: Reward = 579.00, Steps = 9, Loss = 9.3449, Exploration Rate = 0.1000, Train Count = 39342\n",
      "Episode 4623: Reward = 585.00, Steps = 7, Loss = 8.0996, Exploration Rate = 0.1000, Train Count = 39349\n",
      "Episode 4624: Reward = 582.00, Steps = 8, Loss = 6.5652, Exploration Rate = 0.1000, Train Count = 39357\n",
      "Episode 4625: Reward = 523.00, Steps = 12, Loss = 6.0149, Exploration Rate = 0.1000, Train Count = 39369\n",
      "Episode 4626: Reward = 582.00, Steps = 8, Loss = 5.8195, Exploration Rate = 0.1000, Train Count = 39377\n",
      "Episode 4627: Reward = 541.00, Steps = 6, Loss = 4.9849, Exploration Rate = 0.1000, Train Count = 39383\n",
      "Episode 4628: Reward = 579.00, Steps = 9, Loss = 5.9416, Exploration Rate = 0.1000, Train Count = 39392\n",
      "Episode 4629: Reward = 591.00, Steps = 5, Loss = 4.8595, Exploration Rate = 0.1000, Train Count = 39397\n",
      "Episode 4630: Reward = 579.00, Steps = 9, Loss = 3.8104, Exploration Rate = 0.1000, Train Count = 39406\n",
      "Episode 4631: Reward = 591.00, Steps = 5, Loss = 3.4114, Exploration Rate = 0.1000, Train Count = 39411\n",
      "Episode 4632: Reward = 576.00, Steps = 10, Loss = 4.4919, Exploration Rate = 0.1000, Train Count = 39421\n",
      "Episode 4633: Reward = 591.00, Steps = 5, Loss = 2.9066, Exploration Rate = 0.1000, Train Count = 39426\n",
      "Episode 4634: Reward = 591.00, Steps = 5, Loss = 2.0047, Exploration Rate = 0.1000, Train Count = 39431\n",
      "Episode 4635: Reward = 585.00, Steps = 7, Loss = 4.5625, Exploration Rate = 0.1000, Train Count = 39438\n",
      "Episode 4636: Reward = 582.00, Steps = 8, Loss = 3.4185, Exploration Rate = 0.1000, Train Count = 39446\n",
      "Episode 4637: Reward = 591.00, Steps = 5, Loss = 2.6920, Exploration Rate = 0.1000, Train Count = 39451\n",
      "Episode 4638: Reward = 585.00, Steps = 7, Loss = 7.0629, Exploration Rate = 0.1000, Train Count = 39458\n",
      "Episode 4639: Reward = 591.00, Steps = 5, Loss = 8.3554, Exploration Rate = 0.1000, Train Count = 39463\n",
      "Episode 4640: Reward = 594.00, Steps = 4, Loss = 5.5133, Exploration Rate = 0.1000, Train Count = 39467\n",
      "Episode 4641: Reward = 582.00, Steps = 8, Loss = 3.1557, Exploration Rate = 0.1000, Train Count = 39475\n",
      "Episode 4642: Reward = 591.00, Steps = 5, Loss = 2.8695, Exploration Rate = 0.1000, Train Count = 39480\n",
      "Episode 4643: Reward = 594.00, Steps = 4, Loss = 2.6757, Exploration Rate = 0.1000, Train Count = 39484\n",
      "Episode 4644: Reward = 600.00, Steps = 2, Loss = 2.7684, Exploration Rate = 0.1000, Train Count = 39486\n",
      "Episode 4645: Reward = 591.00, Steps = 5, Loss = 2.1972, Exploration Rate = 0.1000, Train Count = 39491\n",
      "Episode 4646: Reward = 588.00, Steps = 6, Loss = 2.3956, Exploration Rate = 0.1000, Train Count = 39497\n",
      "Episode 4647: Reward = 582.00, Steps = 8, Loss = 2.3733, Exploration Rate = 0.1000, Train Count = 39505\n",
      "Episode 4648: Reward = 588.00, Steps = 6, Loss = 2.3453, Exploration Rate = 0.1000, Train Count = 39511\n",
      "Episode 4649: Reward = 482.00, Steps = 10, Loss = 3.0605, Exploration Rate = 0.1000, Train Count = 39521\n",
      "Episode 4650: Reward = 591.00, Steps = 5, Loss = 4.0012, Exploration Rate = 0.1000, Train Count = 39526\n",
      "Episode 4651: Reward = 591.00, Steps = 5, Loss = 4.2152, Exploration Rate = 0.1000, Train Count = 39531\n",
      "Episode 4652: Reward = 585.00, Steps = 7, Loss = 4.4505, Exploration Rate = 0.1000, Train Count = 39538\n",
      "Episode 4653: Reward = 591.00, Steps = 5, Loss = 3.1529, Exploration Rate = 0.1000, Train Count = 39543\n",
      "Episode 4654: Reward = 591.00, Steps = 5, Loss = 2.2460, Exploration Rate = 0.1000, Train Count = 39548\n",
      "Episode 4655: Reward = 591.00, Steps = 5, Loss = 3.0283, Exploration Rate = 0.1000, Train Count = 39553\n",
      "Episode 4656: Reward = 600.00, Steps = 2, Loss = 3.9820, Exploration Rate = 0.1000, Train Count = 39555\n",
      "Episode 4657: Reward = 597.00, Steps = 3, Loss = 4.1929, Exploration Rate = 0.1000, Train Count = 39558\n",
      "Episode 4658: Reward = 582.00, Steps = 8, Loss = 5.3896, Exploration Rate = 0.1000, Train Count = 39566\n",
      "Episode 4659: Reward = 582.00, Steps = 8, Loss = 3.3037, Exploration Rate = 0.1000, Train Count = 39574\n",
      "Episode 4660: Reward = 576.00, Steps = 10, Loss = 3.6995, Exploration Rate = 0.1000, Train Count = 39584\n",
      "Episode 4661: Reward = 573.00, Steps = 11, Loss = 8.6222, Exploration Rate = 0.1000, Train Count = 39595\n",
      "Episode 4662: Reward = 588.00, Steps = 6, Loss = 6.4195, Exploration Rate = 0.1000, Train Count = 39601\n",
      "Episode 4663: Reward = 535.00, Steps = 8, Loss = 11.3261, Exploration Rate = 0.1000, Train Count = 39609\n",
      "Episode 4664: Reward = 582.00, Steps = 8, Loss = 5.5624, Exploration Rate = 0.1000, Train Count = 39617\n",
      "Episode 4665: Reward = 588.00, Steps = 6, Loss = 4.0260, Exploration Rate = 0.1000, Train Count = 39623\n",
      "Episode 4666: Reward = 582.00, Steps = 8, Loss = 11.9622, Exploration Rate = 0.1000, Train Count = 39631\n",
      "Episode 4667: Reward = 588.00, Steps = 6, Loss = 9.1480, Exploration Rate = 0.1000, Train Count = 39637\n",
      "Episode 4668: Reward = 585.00, Steps = 7, Loss = 7.7192, Exploration Rate = 0.1000, Train Count = 39644\n",
      "Episode 4669: Reward = 585.00, Steps = 7, Loss = 5.7609, Exploration Rate = 0.1000, Train Count = 39651\n",
      "Episode 4670: Reward = 597.00, Steps = 3, Loss = 3.7574, Exploration Rate = 0.1000, Train Count = 39654\n",
      "Episode 4671: Reward = 582.00, Steps = 8, Loss = 5.7534, Exploration Rate = 0.1000, Train Count = 39662\n",
      "Episode 4672: Reward = 594.00, Steps = 4, Loss = 4.2950, Exploration Rate = 0.1000, Train Count = 39666\n",
      "Episode 4673: Reward = 585.00, Steps = 7, Loss = 3.8001, Exploration Rate = 0.1000, Train Count = 39673\n",
      "Episode 4674: Reward = 594.00, Steps = 4, Loss = 5.6649, Exploration Rate = 0.1000, Train Count = 39677\n",
      "Episode 4675: Reward = 591.00, Steps = 5, Loss = 7.0078, Exploration Rate = 0.1000, Train Count = 39682\n",
      "Episode 4676: Reward = 597.00, Steps = 3, Loss = 5.2276, Exploration Rate = 0.1000, Train Count = 39685\n",
      "Episode 4677: Reward = 585.00, Steps = 7, Loss = 4.6557, Exploration Rate = 0.1000, Train Count = 39692\n",
      "Episode 4678: Reward = 585.00, Steps = 7, Loss = 3.6666, Exploration Rate = 0.1000, Train Count = 39699\n",
      "Episode 4679: Reward = 567.00, Steps = 13, Loss = 2.4887, Exploration Rate = 0.1000, Train Count = 39712\n",
      "Episode 4680: Reward = 582.00, Steps = 8, Loss = 1.9885, Exploration Rate = 0.1000, Train Count = 39720\n",
      "Episode 4681: Reward = 594.00, Steps = 4, Loss = 2.7862, Exploration Rate = 0.1000, Train Count = 39724\n",
      "Episode 4682: Reward = 594.00, Steps = 4, Loss = 2.2564, Exploration Rate = 0.1000, Train Count = 39728\n",
      "Episode 4683: Reward = 591.00, Steps = 5, Loss = 2.0363, Exploration Rate = 0.1000, Train Count = 39733\n",
      "Episode 4684: Reward = 591.00, Steps = 5, Loss = 2.7642, Exploration Rate = 0.1000, Train Count = 39738\n",
      "Episode 4685: Reward = 585.00, Steps = 7, Loss = 1.9999, Exploration Rate = 0.1000, Train Count = 39745\n",
      "Episode 4686: Reward = 588.00, Steps = 6, Loss = 1.5845, Exploration Rate = 0.1000, Train Count = 39751\n",
      "Episode 4687: Reward = 594.00, Steps = 4, Loss = 2.5640, Exploration Rate = 0.1000, Train Count = 39755\n",
      "Episode 4688: Reward = 585.00, Steps = 7, Loss = 4.4357, Exploration Rate = 0.1000, Train Count = 39762\n",
      "Episode 4689: Reward = 597.00, Steps = 3, Loss = 1.9294, Exploration Rate = 0.1000, Train Count = 39765\n",
      "Episode 4690: Reward = 573.00, Steps = 11, Loss = 2.1607, Exploration Rate = 0.1000, Train Count = 39776\n",
      "Episode 4691: Reward = 582.00, Steps = 8, Loss = 2.9826, Exploration Rate = 0.1000, Train Count = 39784\n",
      "Episode 4692: Reward = 591.00, Steps = 5, Loss = 1.2882, Exploration Rate = 0.1000, Train Count = 39789\n",
      "Episode 4693: Reward = 588.00, Steps = 6, Loss = 1.6652, Exploration Rate = 0.1000, Train Count = 39795\n",
      "Episode 4694: Reward = 573.00, Steps = 11, Loss = 23.0376, Exploration Rate = 0.1000, Train Count = 39806\n",
      "Episode 4695: Reward = 594.00, Steps = 4, Loss = 29.7366, Exploration Rate = 0.1000, Train Count = 39810\n",
      "Episode 4696: Reward = 588.00, Steps = 6, Loss = 23.4749, Exploration Rate = 0.1000, Train Count = 39816\n",
      "Episode 4697: Reward = 597.00, Steps = 3, Loss = 17.4746, Exploration Rate = 0.1000, Train Count = 39819\n",
      "Episode 4698: Reward = 591.00, Steps = 5, Loss = 15.8976, Exploration Rate = 0.1000, Train Count = 39824\n",
      "Episode 4699: Reward = 597.00, Steps = 3, Loss = 11.4988, Exploration Rate = 0.1000, Train Count = 39827\n",
      "Episode 4700: Reward = 594.00, Steps = 4, Loss = 10.8624, Exploration Rate = 0.1000, Train Count = 39831\n",
      "Episode 4701: Reward = 591.00, Steps = 5, Loss = 11.4118, Exploration Rate = 0.1000, Train Count = 39836\n",
      "Episode 4702: Reward = 594.00, Steps = 4, Loss = 8.9043, Exploration Rate = 0.1000, Train Count = 39840\n",
      "Episode 4703: Reward = 591.00, Steps = 5, Loss = 6.9354, Exploration Rate = 0.1000, Train Count = 39845\n",
      "Episode 4704: Reward = 591.00, Steps = 5, Loss = 9.5572, Exploration Rate = 0.1000, Train Count = 39850\n",
      "Episode 4705: Reward = 591.00, Steps = 5, Loss = 5.6471, Exploration Rate = 0.1000, Train Count = 39855\n",
      "Episode 4706: Reward = 582.00, Steps = 8, Loss = 8.0756, Exploration Rate = 0.1000, Train Count = 39863\n",
      "Episode 4707: Reward = 594.00, Steps = 4, Loss = 10.0450, Exploration Rate = 0.1000, Train Count = 39867\n",
      "Episode 4708: Reward = 585.00, Steps = 7, Loss = 5.7548, Exploration Rate = 0.1000, Train Count = 39874\n",
      "Episode 4709: Reward = 585.00, Steps = 7, Loss = 4.4661, Exploration Rate = 0.1000, Train Count = 39881\n",
      "Episode 4710: Reward = 588.00, Steps = 6, Loss = 3.5263, Exploration Rate = 0.1000, Train Count = 39887\n",
      "Episode 4711: Reward = 529.00, Steps = 10, Loss = 4.4403, Exploration Rate = 0.1000, Train Count = 39897\n",
      "Episode 4712: Reward = 582.00, Steps = 8, Loss = 14.8135, Exploration Rate = 0.1000, Train Count = 39905\n",
      "Episode 4713: Reward = 582.00, Steps = 8, Loss = 12.6954, Exploration Rate = 0.1000, Train Count = 39913\n",
      "Episode 4714: Reward = 585.00, Steps = 7, Loss = 11.9996, Exploration Rate = 0.1000, Train Count = 39920\n",
      "Episode 4715: Reward = 582.00, Steps = 8, Loss = 8.5946, Exploration Rate = 0.1000, Train Count = 39928\n",
      "Episode 4716: Reward = 591.00, Steps = 5, Loss = 8.7836, Exploration Rate = 0.1000, Train Count = 39933\n",
      "Episode 4717: Reward = 594.00, Steps = 4, Loss = 5.6841, Exploration Rate = 0.1000, Train Count = 39937\n",
      "Episode 4718: Reward = 576.00, Steps = 10, Loss = 5.2274, Exploration Rate = 0.1000, Train Count = 39947\n",
      "Episode 4719: Reward = 594.00, Steps = 4, Loss = 4.1394, Exploration Rate = 0.1000, Train Count = 39951\n",
      "Episode 4720: Reward = 597.00, Steps = 3, Loss = 4.4023, Exploration Rate = 0.1000, Train Count = 39954\n",
      "Episode 4721: Reward = 588.00, Steps = 6, Loss = 3.4473, Exploration Rate = 0.1000, Train Count = 39960\n",
      "Episode 4722: Reward = 582.00, Steps = 8, Loss = 3.9777, Exploration Rate = 0.1000, Train Count = 39968\n",
      "Episode 4723: Reward = 591.00, Steps = 5, Loss = 4.3934, Exploration Rate = 0.1000, Train Count = 39973\n",
      "Episode 4724: Reward = 582.00, Steps = 8, Loss = 3.5325, Exploration Rate = 0.1000, Train Count = 39981\n",
      "Episode 4725: Reward = 594.00, Steps = 4, Loss = 5.7794, Exploration Rate = 0.1000, Train Count = 39985\n",
      "Episode 4726: Reward = 588.00, Steps = 6, Loss = 2.5362, Exploration Rate = 0.1000, Train Count = 39991\n",
      "Episode 4727: Reward = 597.00, Steps = 3, Loss = 2.4360, Exploration Rate = 0.1000, Train Count = 39994\n",
      "Episode 4728: Reward = 591.00, Steps = 5, Loss = 2.1083, Exploration Rate = 0.1000, Train Count = 39999\n",
      "Episode 4729: Reward = 591.00, Steps = 5, Loss = 8.3396, Exploration Rate = 0.1000, Train Count = 40004\n",
      "Episode 4730: Reward = 591.00, Steps = 5, Loss = 5.0437, Exploration Rate = 0.1000, Train Count = 40009\n",
      "Episode 4731: Reward = 570.00, Steps = 12, Loss = 9.5763, Exploration Rate = 0.1000, Train Count = 40021\n",
      "Episode 4732: Reward = 588.00, Steps = 6, Loss = 5.7181, Exploration Rate = 0.1000, Train Count = 40027\n",
      "Episode 4733: Reward = 576.00, Steps = 10, Loss = 5.1455, Exploration Rate = 0.1000, Train Count = 40037\n",
      "Episode 4734: Reward = 576.00, Steps = 10, Loss = 3.0414, Exploration Rate = 0.1000, Train Count = 40047\n",
      "Episode 4735: Reward = 594.00, Steps = 4, Loss = 3.6452, Exploration Rate = 0.1000, Train Count = 40051\n",
      "Episode 4736: Reward = 591.00, Steps = 5, Loss = 2.3502, Exploration Rate = 0.1000, Train Count = 40056\n",
      "Episode 4737: Reward = 591.00, Steps = 5, Loss = 4.5204, Exploration Rate = 0.1000, Train Count = 40061\n",
      "Episode 4738: Reward = 573.00, Steps = 11, Loss = 4.9177, Exploration Rate = 0.1000, Train Count = 40072\n",
      "Episode 4739: Reward = 588.00, Steps = 6, Loss = 5.4793, Exploration Rate = 0.1000, Train Count = 40078\n",
      "Episode 4740: Reward = 597.00, Steps = 3, Loss = 4.1991, Exploration Rate = 0.1000, Train Count = 40081\n",
      "Episode 4741: Reward = 585.00, Steps = 7, Loss = 6.4975, Exploration Rate = 0.1000, Train Count = 40088\n",
      "Episode 4742: Reward = 588.00, Steps = 6, Loss = 9.6797, Exploration Rate = 0.1000, Train Count = 40094\n",
      "Episode 4743: Reward = 600.00, Steps = 2, Loss = 3.6204, Exploration Rate = 0.1000, Train Count = 40096\n",
      "Episode 4744: Reward = 591.00, Steps = 5, Loss = 12.3979, Exploration Rate = 0.1000, Train Count = 40101\n",
      "Episode 4745: Reward = 591.00, Steps = 5, Loss = 5.8731, Exploration Rate = 0.1000, Train Count = 40106\n",
      "Episode 4746: Reward = 594.00, Steps = 4, Loss = 4.5641, Exploration Rate = 0.1000, Train Count = 40110\n",
      "Episode 4747: Reward = 591.00, Steps = 5, Loss = 6.0068, Exploration Rate = 0.1000, Train Count = 40115\n",
      "Episode 4748: Reward = 597.00, Steps = 3, Loss = 5.2674, Exploration Rate = 0.1000, Train Count = 40118\n",
      "Episode 4749: Reward = 591.00, Steps = 5, Loss = 4.0500, Exploration Rate = 0.1000, Train Count = 40123\n",
      "Episode 4750: Reward = 529.00, Steps = 10, Loss = 3.5448, Exploration Rate = 0.1000, Train Count = 40133\n",
      "Episode 4751: Reward = 532.00, Steps = 9, Loss = 6.8698, Exploration Rate = 0.1000, Train Count = 40142\n",
      "Episode 4752: Reward = 591.00, Steps = 5, Loss = 4.2964, Exploration Rate = 0.1000, Train Count = 40147\n",
      "Episode 4753: Reward = 585.00, Steps = 7, Loss = 3.7094, Exploration Rate = 0.1000, Train Count = 40154\n",
      "Episode 4754: Reward = 588.00, Steps = 6, Loss = 3.8034, Exploration Rate = 0.1000, Train Count = 40160\n",
      "Episode 4755: Reward = 582.00, Steps = 8, Loss = 3.3675, Exploration Rate = 0.1000, Train Count = 40168\n",
      "Episode 4756: Reward = 591.00, Steps = 5, Loss = 2.2355, Exploration Rate = 0.1000, Train Count = 40173\n",
      "Episode 4757: Reward = 588.00, Steps = 6, Loss = 2.6306, Exploration Rate = 0.1000, Train Count = 40179\n",
      "Episode 4758: Reward = 538.00, Steps = 7, Loss = 3.3904, Exploration Rate = 0.1000, Train Count = 40186\n",
      "Episode 4759: Reward = 561.00, Steps = 15, Loss = 4.6888, Exploration Rate = 0.1000, Train Count = 40201\n",
      "Episode 4760: Reward = 594.00, Steps = 4, Loss = 3.4786, Exploration Rate = 0.1000, Train Count = 40205\n",
      "Episode 4761: Reward = 541.00, Steps = 6, Loss = 3.1181, Exploration Rate = 0.1000, Train Count = 40211\n",
      "Episode 4762: Reward = 594.00, Steps = 4, Loss = 1.8762, Exploration Rate = 0.1000, Train Count = 40215\n",
      "Episode 4763: Reward = 588.00, Steps = 6, Loss = 3.0793, Exploration Rate = 0.1000, Train Count = 40221\n",
      "Episode 4764: Reward = 576.00, Steps = 10, Loss = 3.5292, Exploration Rate = 0.1000, Train Count = 40231\n",
      "Episode 4765: Reward = 597.00, Steps = 3, Loss = 1.4427, Exploration Rate = 0.1000, Train Count = 40234\n",
      "Episode 4766: Reward = 588.00, Steps = 6, Loss = 2.2763, Exploration Rate = 0.1000, Train Count = 40240\n",
      "Episode 4767: Reward = 585.00, Steps = 7, Loss = 2.9533, Exploration Rate = 0.1000, Train Count = 40247\n",
      "Episode 4768: Reward = 588.00, Steps = 6, Loss = 1.9061, Exploration Rate = 0.1000, Train Count = 40253\n",
      "Episode 4769: Reward = 597.00, Steps = 3, Loss = 1.5745, Exploration Rate = 0.1000, Train Count = 40256\n",
      "Episode 4770: Reward = 591.00, Steps = 5, Loss = 3.3675, Exploration Rate = 0.1000, Train Count = 40261\n",
      "Episode 4771: Reward = 594.00, Steps = 4, Loss = 2.8129, Exploration Rate = 0.1000, Train Count = 40265\n",
      "Episode 4772: Reward = 594.00, Steps = 4, Loss = 1.5251, Exploration Rate = 0.1000, Train Count = 40269\n",
      "Episode 4773: Reward = 582.00, Steps = 8, Loss = 1.9357, Exploration Rate = 0.1000, Train Count = 40277\n",
      "Episode 4774: Reward = 544.00, Steps = 5, Loss = 2.6491, Exploration Rate = 0.1000, Train Count = 40282\n",
      "Episode 4775: Reward = 588.00, Steps = 6, Loss = 3.8373, Exploration Rate = 0.1000, Train Count = 40288\n",
      "Episode 4776: Reward = 591.00, Steps = 5, Loss = 6.4765, Exploration Rate = 0.1000, Train Count = 40293\n",
      "Episode 4777: Reward = 591.00, Steps = 5, Loss = 8.9141, Exploration Rate = 0.1000, Train Count = 40298\n",
      "Episode 4778: Reward = 600.00, Steps = 2, Loss = 4.2184, Exploration Rate = 0.1000, Train Count = 40300\n",
      "Episode 4779: Reward = 591.00, Steps = 5, Loss = 29.1455, Exploration Rate = 0.1000, Train Count = 40305\n",
      "Episode 4780: Reward = 541.00, Steps = 6, Loss = 30.5711, Exploration Rate = 0.1000, Train Count = 40311\n",
      "Episode 4781: Reward = 588.00, Steps = 6, Loss = 22.3310, Exploration Rate = 0.1000, Train Count = 40317\n",
      "Episode 4782: Reward = 588.00, Steps = 6, Loss = 24.7573, Exploration Rate = 0.1000, Train Count = 40323\n",
      "Episode 4783: Reward = 594.00, Steps = 4, Loss = 17.7890, Exploration Rate = 0.1000, Train Count = 40327\n",
      "Episode 4784: Reward = 591.00, Steps = 5, Loss = 10.7094, Exploration Rate = 0.1000, Train Count = 40332\n",
      "Episode 4785: Reward = 535.00, Steps = 8, Loss = 14.1394, Exploration Rate = 0.1000, Train Count = 40340\n",
      "Episode 4786: Reward = 582.00, Steps = 8, Loss = 12.5532, Exploration Rate = 0.1000, Train Count = 40348\n",
      "Episode 4787: Reward = 594.00, Steps = 4, Loss = 17.5778, Exploration Rate = 0.1000, Train Count = 40352\n",
      "Episode 4788: Reward = 591.00, Steps = 5, Loss = 10.1924, Exploration Rate = 0.1000, Train Count = 40357\n",
      "Episode 4789: Reward = 588.00, Steps = 6, Loss = 10.9687, Exploration Rate = 0.1000, Train Count = 40363\n",
      "Episode 4790: Reward = 594.00, Steps = 4, Loss = 8.9691, Exploration Rate = 0.1000, Train Count = 40367\n",
      "Episode 4791: Reward = 594.00, Steps = 4, Loss = 10.5569, Exploration Rate = 0.1000, Train Count = 40371\n",
      "Episode 4792: Reward = 591.00, Steps = 5, Loss = 9.1215, Exploration Rate = 0.1000, Train Count = 40376\n",
      "Episode 4793: Reward = 579.00, Steps = 9, Loss = 8.9698, Exploration Rate = 0.1000, Train Count = 40385\n",
      "Episode 4794: Reward = 582.00, Steps = 8, Loss = 7.0867, Exploration Rate = 0.1000, Train Count = 40393\n",
      "Episode 4795: Reward = 585.00, Steps = 7, Loss = 7.3708, Exploration Rate = 0.1000, Train Count = 40400\n",
      "Episode 4796: Reward = 582.00, Steps = 8, Loss = 7.0576, Exploration Rate = 0.1000, Train Count = 40408\n",
      "Episode 4797: Reward = 585.00, Steps = 7, Loss = 5.9035, Exploration Rate = 0.1000, Train Count = 40415\n",
      "Episode 4798: Reward = 588.00, Steps = 6, Loss = 7.9002, Exploration Rate = 0.1000, Train Count = 40421\n",
      "Episode 4799: Reward = 588.00, Steps = 6, Loss = 9.8968, Exploration Rate = 0.1000, Train Count = 40427\n",
      "Episode 4800: Reward = 538.00, Steps = 7, Loss = 12.2119, Exploration Rate = 0.1000, Train Count = 40434\n",
      "Episode 4801: Reward = 585.00, Steps = 7, Loss = 15.0393, Exploration Rate = 0.1000, Train Count = 40441\n",
      "Episode 4802: Reward = 576.00, Steps = 10, Loss = 13.0487, Exploration Rate = 0.1000, Train Count = 40451\n",
      "Episode 4803: Reward = 588.00, Steps = 6, Loss = 8.4697, Exploration Rate = 0.1000, Train Count = 40457\n",
      "Episode 4804: Reward = 594.00, Steps = 4, Loss = 7.7301, Exploration Rate = 0.1000, Train Count = 40461\n",
      "Episode 4805: Reward = 588.00, Steps = 6, Loss = 9.0555, Exploration Rate = 0.1000, Train Count = 40467\n",
      "Episode 4806: Reward = 582.00, Steps = 8, Loss = 9.1759, Exploration Rate = 0.1000, Train Count = 40475\n",
      "Episode 4807: Reward = 591.00, Steps = 5, Loss = 13.0767, Exploration Rate = 0.1000, Train Count = 40480\n",
      "Episode 4808: Reward = 582.00, Steps = 8, Loss = 9.2116, Exploration Rate = 0.1000, Train Count = 40488\n",
      "Episode 4809: Reward = 541.00, Steps = 6, Loss = 8.5128, Exploration Rate = 0.1000, Train Count = 40494\n",
      "Episode 4810: Reward = 579.00, Steps = 9, Loss = 9.5744, Exploration Rate = 0.1000, Train Count = 40503\n",
      "Episode 4811: Reward = 591.00, Steps = 5, Loss = 8.1785, Exploration Rate = 0.1000, Train Count = 40508\n",
      "Episode 4812: Reward = 591.00, Steps = 5, Loss = 8.0482, Exploration Rate = 0.1000, Train Count = 40513\n",
      "Episode 4813: Reward = 582.00, Steps = 8, Loss = 10.3398, Exploration Rate = 0.1000, Train Count = 40521\n",
      "Episode 4814: Reward = 591.00, Steps = 5, Loss = 6.4833, Exploration Rate = 0.1000, Train Count = 40526\n",
      "Episode 4815: Reward = 588.00, Steps = 6, Loss = 5.8348, Exploration Rate = 0.1000, Train Count = 40532\n",
      "Episode 4816: Reward = 585.00, Steps = 7, Loss = 6.7180, Exploration Rate = 0.1000, Train Count = 40539\n",
      "Episode 4817: Reward = 588.00, Steps = 6, Loss = 9.2448, Exploration Rate = 0.1000, Train Count = 40545\n",
      "Episode 4818: Reward = 588.00, Steps = 6, Loss = 6.8140, Exploration Rate = 0.1000, Train Count = 40551\n",
      "Episode 4819: Reward = 588.00, Steps = 6, Loss = 8.5726, Exploration Rate = 0.1000, Train Count = 40557\n",
      "Episode 4820: Reward = 594.00, Steps = 4, Loss = 2.3425, Exploration Rate = 0.1000, Train Count = 40561\n",
      "Episode 4821: Reward = 591.00, Steps = 5, Loss = 6.5557, Exploration Rate = 0.1000, Train Count = 40566\n",
      "Episode 4822: Reward = 597.00, Steps = 3, Loss = 9.8917, Exploration Rate = 0.1000, Train Count = 40569\n",
      "Episode 4823: Reward = 582.00, Steps = 8, Loss = 7.9890, Exploration Rate = 0.1000, Train Count = 40577\n",
      "Episode 4824: Reward = 597.00, Steps = 3, Loss = 9.5635, Exploration Rate = 0.1000, Train Count = 40580\n",
      "Episode 4825: Reward = 576.00, Steps = 10, Loss = 8.6138, Exploration Rate = 0.1000, Train Count = 40590\n",
      "Episode 4826: Reward = 582.00, Steps = 8, Loss = 8.3605, Exploration Rate = 0.1000, Train Count = 40598\n",
      "Episode 4827: Reward = 591.00, Steps = 5, Loss = 9.1900, Exploration Rate = 0.1000, Train Count = 40603\n",
      "Episode 4828: Reward = 594.00, Steps = 4, Loss = 9.9176, Exploration Rate = 0.1000, Train Count = 40607\n",
      "Episode 4829: Reward = 591.00, Steps = 5, Loss = 11.2619, Exploration Rate = 0.1000, Train Count = 40612\n",
      "Episode 4830: Reward = 591.00, Steps = 5, Loss = 9.4446, Exploration Rate = 0.1000, Train Count = 40617\n",
      "Episode 4831: Reward = 597.00, Steps = 3, Loss = 7.5099, Exploration Rate = 0.1000, Train Count = 40620\n",
      "Episode 4832: Reward = 588.00, Steps = 6, Loss = 5.6851, Exploration Rate = 0.1000, Train Count = 40626\n",
      "Episode 4833: Reward = 585.00, Steps = 7, Loss = 7.9937, Exploration Rate = 0.1000, Train Count = 40633\n",
      "Episode 4834: Reward = 591.00, Steps = 5, Loss = 10.8434, Exploration Rate = 0.1000, Train Count = 40638\n",
      "Episode 4835: Reward = 585.00, Steps = 7, Loss = 5.6718, Exploration Rate = 0.1000, Train Count = 40645\n",
      "Episode 4836: Reward = 597.00, Steps = 3, Loss = 7.3726, Exploration Rate = 0.1000, Train Count = 40648\n",
      "Episode 4837: Reward = 582.00, Steps = 8, Loss = 7.3561, Exploration Rate = 0.1000, Train Count = 40656\n",
      "Episode 4838: Reward = 594.00, Steps = 4, Loss = 8.4051, Exploration Rate = 0.1000, Train Count = 40660\n",
      "Episode 4839: Reward = 591.00, Steps = 5, Loss = 8.0756, Exploration Rate = 0.1000, Train Count = 40665\n",
      "Episode 4840: Reward = 585.00, Steps = 7, Loss = 9.3942, Exploration Rate = 0.1000, Train Count = 40672\n",
      "Episode 4841: Reward = 535.00, Steps = 8, Loss = 9.7745, Exploration Rate = 0.1000, Train Count = 40680\n",
      "Episode 4842: Reward = 591.00, Steps = 5, Loss = 8.2024, Exploration Rate = 0.1000, Train Count = 40685\n",
      "Episode 4843: Reward = 597.00, Steps = 3, Loss = 5.7977, Exploration Rate = 0.1000, Train Count = 40688\n",
      "Episode 4844: Reward = 585.00, Steps = 7, Loss = 8.6587, Exploration Rate = 0.1000, Train Count = 40695\n",
      "Episode 4845: Reward = 594.00, Steps = 4, Loss = 7.0813, Exploration Rate = 0.1000, Train Count = 40699\n",
      "Episode 4846: Reward = 547.00, Steps = 4, Loss = 6.8672, Exploration Rate = 0.1000, Train Count = 40703\n",
      "Episode 4847: Reward = 594.00, Steps = 4, Loss = 8.3101, Exploration Rate = 0.1000, Train Count = 40707\n",
      "Episode 4848: Reward = 591.00, Steps = 5, Loss = 8.2560, Exploration Rate = 0.1000, Train Count = 40712\n",
      "Episode 4849: Reward = 579.00, Steps = 9, Loss = 18.3933, Exploration Rate = 0.1000, Train Count = 40721\n",
      "Episode 4850: Reward = 591.00, Steps = 5, Loss = 18.7460, Exploration Rate = 0.1000, Train Count = 40726\n",
      "Episode 4851: Reward = 588.00, Steps = 6, Loss = 16.2228, Exploration Rate = 0.1000, Train Count = 40732\n",
      "Episode 4852: Reward = 594.00, Steps = 4, Loss = 22.7560, Exploration Rate = 0.1000, Train Count = 40736\n",
      "Episode 4853: Reward = 591.00, Steps = 5, Loss = 18.2735, Exploration Rate = 0.1000, Train Count = 40741\n",
      "Episode 4854: Reward = 582.00, Steps = 8, Loss = 19.8463, Exploration Rate = 0.1000, Train Count = 40749\n",
      "Episode 4855: Reward = 594.00, Steps = 4, Loss = 13.2516, Exploration Rate = 0.1000, Train Count = 40753\n",
      "Episode 4856: Reward = 591.00, Steps = 5, Loss = 11.2139, Exploration Rate = 0.1000, Train Count = 40758\n",
      "Episode 4857: Reward = 597.00, Steps = 3, Loss = 13.0194, Exploration Rate = 0.1000, Train Count = 40761\n",
      "Episode 4858: Reward = 514.00, Steps = 15, Loss = 12.3419, Exploration Rate = 0.1000, Train Count = 40776\n",
      "Episode 4859: Reward = 597.00, Steps = 3, Loss = 13.3353, Exploration Rate = 0.1000, Train Count = 40779\n",
      "Episode 4860: Reward = 591.00, Steps = 5, Loss = 13.6701, Exploration Rate = 0.1000, Train Count = 40784\n",
      "Episode 4861: Reward = 591.00, Steps = 5, Loss = 10.9031, Exploration Rate = 0.1000, Train Count = 40789\n",
      "Episode 4862: Reward = 585.00, Steps = 7, Loss = 14.1306, Exploration Rate = 0.1000, Train Count = 40796\n",
      "Episode 4863: Reward = 591.00, Steps = 5, Loss = 13.3329, Exploration Rate = 0.1000, Train Count = 40801\n",
      "Episode 4864: Reward = 591.00, Steps = 5, Loss = 35.7817, Exploration Rate = 0.1000, Train Count = 40806\n",
      "Episode 4865: Reward = 594.00, Steps = 4, Loss = 27.5401, Exploration Rate = 0.1000, Train Count = 40810\n",
      "Episode 4866: Reward = 600.00, Steps = 2, Loss = 22.4906, Exploration Rate = 0.1000, Train Count = 40812\n",
      "Episode 4867: Reward = 585.00, Steps = 7, Loss = 25.3872, Exploration Rate = 0.1000, Train Count = 40819\n",
      "Episode 4868: Reward = 591.00, Steps = 5, Loss = 22.2253, Exploration Rate = 0.1000, Train Count = 40824\n",
      "Episode 4869: Reward = 579.00, Steps = 9, Loss = 20.0255, Exploration Rate = 0.1000, Train Count = 40833\n",
      "Episode 4870: Reward = 597.00, Steps = 3, Loss = 16.7671, Exploration Rate = 0.1000, Train Count = 40836\n",
      "Episode 4871: Reward = 594.00, Steps = 4, Loss = 17.9274, Exploration Rate = 0.1000, Train Count = 40840\n",
      "Episode 4872: Reward = 597.00, Steps = 3, Loss = 23.6029, Exploration Rate = 0.1000, Train Count = 40843\n",
      "Episode 4873: Reward = 585.00, Steps = 7, Loss = 14.7224, Exploration Rate = 0.1000, Train Count = 40850\n",
      "Episode 4874: Reward = 582.00, Steps = 8, Loss = 12.3900, Exploration Rate = 0.1000, Train Count = 40858\n",
      "Episode 4875: Reward = 597.00, Steps = 3, Loss = 7.9989, Exploration Rate = 0.1000, Train Count = 40861\n",
      "Episode 4876: Reward = 591.00, Steps = 5, Loss = 9.5270, Exploration Rate = 0.1000, Train Count = 40866\n",
      "Episode 4877: Reward = 579.00, Steps = 9, Loss = 13.5144, Exploration Rate = 0.1000, Train Count = 40875\n",
      "Episode 4878: Reward = 591.00, Steps = 5, Loss = 10.1358, Exploration Rate = 0.1000, Train Count = 40880\n",
      "Episode 4879: Reward = 591.00, Steps = 5, Loss = 13.9492, Exploration Rate = 0.1000, Train Count = 40885\n",
      "Episode 4880: Reward = 591.00, Steps = 5, Loss = 10.0126, Exploration Rate = 0.1000, Train Count = 40890\n",
      "Episode 4881: Reward = 579.00, Steps = 9, Loss = 18.8553, Exploration Rate = 0.1000, Train Count = 40899\n",
      "Episode 4882: Reward = 588.00, Steps = 6, Loss = 13.9466, Exploration Rate = 0.1000, Train Count = 40905\n",
      "Episode 4883: Reward = 597.00, Steps = 3, Loss = 14.3264, Exploration Rate = 0.1000, Train Count = 40908\n",
      "Episode 4884: Reward = 591.00, Steps = 5, Loss = 15.0611, Exploration Rate = 0.1000, Train Count = 40913\n",
      "Episode 4885: Reward = 591.00, Steps = 5, Loss = 13.1463, Exploration Rate = 0.1000, Train Count = 40918\n",
      "Episode 4886: Reward = 576.00, Steps = 10, Loss = 12.5643, Exploration Rate = 0.1000, Train Count = 40928\n",
      "Episode 4887: Reward = 597.00, Steps = 3, Loss = 8.7066, Exploration Rate = 0.1000, Train Count = 40931\n",
      "Episode 4888: Reward = 588.00, Steps = 6, Loss = 9.6500, Exploration Rate = 0.1000, Train Count = 40937\n",
      "Episode 4889: Reward = 582.00, Steps = 8, Loss = 13.0032, Exploration Rate = 0.1000, Train Count = 40945\n",
      "Episode 4890: Reward = 600.00, Steps = 2, Loss = 11.5491, Exploration Rate = 0.1000, Train Count = 40947\n",
      "Episode 4891: Reward = 543.00, Steps = 21, Loss = 14.7971, Exploration Rate = 0.1000, Train Count = 40968\n",
      "Episode 4892: Reward = 582.00, Steps = 8, Loss = 14.3545, Exploration Rate = 0.1000, Train Count = 40976\n",
      "Episode 4893: Reward = 526.00, Steps = 11, Loss = 13.9560, Exploration Rate = 0.1000, Train Count = 40987\n",
      "Episode 4894: Reward = 594.00, Steps = 4, Loss = 24.1294, Exploration Rate = 0.1000, Train Count = 40991\n",
      "Episode 4895: Reward = 585.00, Steps = 7, Loss = 14.4649, Exploration Rate = 0.1000, Train Count = 40998\n",
      "Episode 4896: Reward = 585.00, Steps = 7, Loss = 12.8066, Exploration Rate = 0.1000, Train Count = 41005\n",
      "Episode 4897: Reward = 573.00, Steps = 11, Loss = 13.0508, Exploration Rate = 0.1000, Train Count = 41016\n",
      "Episode 4898: Reward = 585.00, Steps = 7, Loss = 16.2244, Exploration Rate = 0.1000, Train Count = 41023\n",
      "Episode 4899: Reward = 591.00, Steps = 5, Loss = 13.1336, Exploration Rate = 0.1000, Train Count = 41028\n",
      "Episode 4900: Reward = 600.00, Steps = 2, Loss = 6.8725, Exploration Rate = 0.1000, Train Count = 41030\n",
      "Episode 4901: Reward = 597.00, Steps = 3, Loss = 6.8850, Exploration Rate = 0.1000, Train Count = 41033\n",
      "Episode 4902: Reward = 585.00, Steps = 7, Loss = 11.9460, Exploration Rate = 0.1000, Train Count = 41040\n",
      "Episode 4903: Reward = 594.00, Steps = 4, Loss = 9.9932, Exploration Rate = 0.1000, Train Count = 41044\n",
      "Episode 4904: Reward = 597.00, Steps = 3, Loss = 17.8576, Exploration Rate = 0.1000, Train Count = 41047\n",
      "Episode 4905: Reward = 588.00, Steps = 6, Loss = 12.3339, Exploration Rate = 0.1000, Train Count = 41053\n",
      "Episode 4906: Reward = 597.00, Steps = 3, Loss = 13.9954, Exploration Rate = 0.1000, Train Count = 41056\n",
      "Episode 4907: Reward = 588.00, Steps = 6, Loss = 16.4416, Exploration Rate = 0.1000, Train Count = 41062\n",
      "Episode 4908: Reward = 597.00, Steps = 3, Loss = 11.2919, Exploration Rate = 0.1000, Train Count = 41065\n",
      "Episode 4909: Reward = 591.00, Steps = 5, Loss = 11.6491, Exploration Rate = 0.1000, Train Count = 41070\n",
      "Episode 4910: Reward = 535.00, Steps = 8, Loss = 11.9078, Exploration Rate = 0.1000, Train Count = 41078\n",
      "Episode 4911: Reward = 541.00, Steps = 6, Loss = 11.9299, Exploration Rate = 0.1000, Train Count = 41084\n",
      "Episode 4912: Reward = 591.00, Steps = 5, Loss = 10.9188, Exploration Rate = 0.1000, Train Count = 41089\n",
      "Episode 4913: Reward = 591.00, Steps = 5, Loss = 9.9330, Exploration Rate = 0.1000, Train Count = 41094\n",
      "Episode 4914: Reward = 594.00, Steps = 4, Loss = 10.9450, Exploration Rate = 0.1000, Train Count = 41098\n",
      "Episode 4915: Reward = 585.00, Steps = 7, Loss = 11.2505, Exploration Rate = 0.1000, Train Count = 41105\n",
      "Episode 4916: Reward = 594.00, Steps = 4, Loss = 21.3845, Exploration Rate = 0.1000, Train Count = 41109\n",
      "Episode 4917: Reward = 591.00, Steps = 5, Loss = 9.8653, Exploration Rate = 0.1000, Train Count = 41114\n",
      "Episode 4918: Reward = 591.00, Steps = 5, Loss = 11.2184, Exploration Rate = 0.1000, Train Count = 41119\n",
      "Episode 4919: Reward = 597.00, Steps = 3, Loss = 12.0874, Exploration Rate = 0.1000, Train Count = 41122\n",
      "Episode 4920: Reward = 591.00, Steps = 5, Loss = 14.1514, Exploration Rate = 0.1000, Train Count = 41127\n",
      "Episode 4921: Reward = 588.00, Steps = 6, Loss = 8.9935, Exploration Rate = 0.1000, Train Count = 41133\n",
      "Episode 4922: Reward = 597.00, Steps = 3, Loss = 11.6477, Exploration Rate = 0.1000, Train Count = 41136\n",
      "Episode 4923: Reward = 588.00, Steps = 6, Loss = 10.8409, Exploration Rate = 0.1000, Train Count = 41142\n",
      "Episode 4924: Reward = 600.00, Steps = 2, Loss = 9.7562, Exploration Rate = 0.1000, Train Count = 41144\n",
      "Episode 4925: Reward = 588.00, Steps = 6, Loss = 11.1675, Exploration Rate = 0.1000, Train Count = 41150\n",
      "Episode 4926: Reward = 582.00, Steps = 8, Loss = 10.8672, Exploration Rate = 0.1000, Train Count = 41158\n",
      "Episode 4927: Reward = 591.00, Steps = 5, Loss = 7.3948, Exploration Rate = 0.1000, Train Count = 41163\n",
      "Episode 4928: Reward = 585.00, Steps = 7, Loss = 9.0186, Exploration Rate = 0.1000, Train Count = 41170\n",
      "Episode 4929: Reward = 591.00, Steps = 5, Loss = 12.1607, Exploration Rate = 0.1000, Train Count = 41175\n",
      "Episode 4930: Reward = 588.00, Steps = 6, Loss = 12.1382, Exploration Rate = 0.1000, Train Count = 41181\n",
      "Episode 4931: Reward = 588.00, Steps = 6, Loss = 11.4617, Exploration Rate = 0.1000, Train Count = 41187\n",
      "Episode 4932: Reward = 597.00, Steps = 3, Loss = 18.5812, Exploration Rate = 0.1000, Train Count = 41190\n",
      "Episode 4933: Reward = 594.00, Steps = 4, Loss = 15.1275, Exploration Rate = 0.1000, Train Count = 41194\n",
      "Episode 4934: Reward = 594.00, Steps = 4, Loss = 8.6024, Exploration Rate = 0.1000, Train Count = 41198\n",
      "Episode 4935: Reward = 594.00, Steps = 4, Loss = 14.1916, Exploration Rate = 0.1000, Train Count = 41202\n",
      "Episode 4936: Reward = 591.00, Steps = 5, Loss = 8.5518, Exploration Rate = 0.1000, Train Count = 41207\n",
      "Episode 4937: Reward = 576.00, Steps = 10, Loss = 12.6980, Exploration Rate = 0.1000, Train Count = 41217\n",
      "Episode 4938: Reward = 582.00, Steps = 8, Loss = 10.1035, Exploration Rate = 0.1000, Train Count = 41225\n",
      "Episode 4939: Reward = 594.00, Steps = 4, Loss = 14.7423, Exploration Rate = 0.1000, Train Count = 41229\n",
      "Episode 4940: Reward = 597.00, Steps = 3, Loss = 6.8018, Exploration Rate = 0.1000, Train Count = 41232\n",
      "Episode 4941: Reward = 582.00, Steps = 8, Loss = 11.4828, Exploration Rate = 0.1000, Train Count = 41240\n",
      "Episode 4942: Reward = 588.00, Steps = 6, Loss = 7.1057, Exploration Rate = 0.1000, Train Count = 41246\n",
      "Episode 4943: Reward = 591.00, Steps = 5, Loss = 3.9393, Exploration Rate = 0.1000, Train Count = 41251\n",
      "Episode 4944: Reward = 585.00, Steps = 7, Loss = 11.0769, Exploration Rate = 0.1000, Train Count = 41258\n",
      "Episode 4945: Reward = 591.00, Steps = 5, Loss = 6.3423, Exploration Rate = 0.1000, Train Count = 41263\n",
      "Episode 4946: Reward = 532.00, Steps = 9, Loss = 13.8877, Exploration Rate = 0.1000, Train Count = 41272\n",
      "Episode 4947: Reward = 585.00, Steps = 7, Loss = 13.3816, Exploration Rate = 0.1000, Train Count = 41279\n",
      "Episode 4948: Reward = 597.00, Steps = 3, Loss = 7.5956, Exploration Rate = 0.1000, Train Count = 41282\n",
      "Episode 4949: Reward = 594.00, Steps = 4, Loss = 6.9790, Exploration Rate = 0.1000, Train Count = 41286\n",
      "Episode 4950: Reward = 579.00, Steps = 9, Loss = 7.7835, Exploration Rate = 0.1000, Train Count = 41295\n",
      "Episode 4951: Reward = 585.00, Steps = 7, Loss = 15.7464, Exploration Rate = 0.1000, Train Count = 41302\n",
      "Episode 4952: Reward = 585.00, Steps = 7, Loss = 32.5416, Exploration Rate = 0.1000, Train Count = 41309\n",
      "Episode 4953: Reward = 591.00, Steps = 5, Loss = 31.6443, Exploration Rate = 0.1000, Train Count = 41314\n",
      "Episode 4954: Reward = 585.00, Steps = 7, Loss = 31.2299, Exploration Rate = 0.1000, Train Count = 41321\n",
      "Episode 4955: Reward = 591.00, Steps = 5, Loss = 26.1802, Exploration Rate = 0.1000, Train Count = 41326\n",
      "Episode 4956: Reward = 541.00, Steps = 6, Loss = 24.2129, Exploration Rate = 0.1000, Train Count = 41332\n",
      "Episode 4957: Reward = 570.00, Steps = 12, Loss = 21.9011, Exploration Rate = 0.1000, Train Count = 41344\n",
      "Episode 4958: Reward = 594.00, Steps = 4, Loss = 19.8426, Exploration Rate = 0.1000, Train Count = 41348\n",
      "Episode 4959: Reward = 547.00, Steps = 4, Loss = 24.3364, Exploration Rate = 0.1000, Train Count = 41352\n",
      "Episode 4960: Reward = 591.00, Steps = 5, Loss = 23.3077, Exploration Rate = 0.1000, Train Count = 41357\n",
      "Episode 4961: Reward = 585.00, Steps = 7, Loss = 19.2305, Exploration Rate = 0.1000, Train Count = 41364\n",
      "Episode 4962: Reward = 585.00, Steps = 7, Loss = 14.7476, Exploration Rate = 0.1000, Train Count = 41371\n",
      "Episode 4963: Reward = 591.00, Steps = 5, Loss = 16.8766, Exploration Rate = 0.1000, Train Count = 41376\n",
      "Episode 4964: Reward = 535.00, Steps = 8, Loss = 23.4174, Exploration Rate = 0.1000, Train Count = 41384\n",
      "Episode 4965: Reward = 564.00, Steps = 14, Loss = 17.1977, Exploration Rate = 0.1000, Train Count = 41398\n",
      "Episode 4966: Reward = 591.00, Steps = 5, Loss = 9.0466, Exploration Rate = 0.1000, Train Count = 41403\n",
      "Episode 4967: Reward = 591.00, Steps = 5, Loss = 12.0434, Exploration Rate = 0.1000, Train Count = 41408\n",
      "Episode 4968: Reward = 597.00, Steps = 3, Loss = 10.1502, Exploration Rate = 0.1000, Train Count = 41411\n",
      "Episode 4969: Reward = 585.00, Steps = 7, Loss = 13.2636, Exploration Rate = 0.1000, Train Count = 41418\n",
      "Episode 4970: Reward = 585.00, Steps = 7, Loss = 16.1308, Exploration Rate = 0.1000, Train Count = 41425\n",
      "Episode 4971: Reward = 579.00, Steps = 9, Loss = 17.2341, Exploration Rate = 0.1000, Train Count = 41434\n",
      "Episode 4972: Reward = 588.00, Steps = 6, Loss = 9.6078, Exploration Rate = 0.1000, Train Count = 41440\n",
      "Episode 4973: Reward = 591.00, Steps = 5, Loss = 9.2837, Exploration Rate = 0.1000, Train Count = 41445\n",
      "Episode 4974: Reward = 594.00, Steps = 4, Loss = 9.4428, Exploration Rate = 0.1000, Train Count = 41449\n",
      "Episode 4975: Reward = 588.00, Steps = 6, Loss = 10.9681, Exploration Rate = 0.1000, Train Count = 41455\n",
      "Episode 4976: Reward = 585.00, Steps = 7, Loss = 10.9025, Exploration Rate = 0.1000, Train Count = 41462\n",
      "Episode 4977: Reward = 538.00, Steps = 7, Loss = 7.6744, Exploration Rate = 0.1000, Train Count = 41469\n",
      "Episode 4978: Reward = 597.00, Steps = 3, Loss = 7.4347, Exploration Rate = 0.1000, Train Count = 41472\n",
      "Episode 4979: Reward = 579.00, Steps = 9, Loss = 10.8979, Exploration Rate = 0.1000, Train Count = 41481\n",
      "Episode 4980: Reward = 564.00, Steps = 14, Loss = 16.6899, Exploration Rate = 0.1000, Train Count = 41495\n",
      "Episode 4981: Reward = 585.00, Steps = 7, Loss = 17.1363, Exploration Rate = 0.1000, Train Count = 41502\n",
      "Episode 4982: Reward = 591.00, Steps = 5, Loss = 14.6075, Exploration Rate = 0.1000, Train Count = 41507\n",
      "Episode 4983: Reward = 591.00, Steps = 5, Loss = 13.9578, Exploration Rate = 0.1000, Train Count = 41512\n",
      "Episode 4984: Reward = 594.00, Steps = 4, Loss = 11.0613, Exploration Rate = 0.1000, Train Count = 41516\n",
      "Episode 4985: Reward = 594.00, Steps = 4, Loss = 10.1953, Exploration Rate = 0.1000, Train Count = 41520\n",
      "Episode 4986: Reward = 597.00, Steps = 3, Loss = 6.2448, Exploration Rate = 0.1000, Train Count = 41523\n",
      "Episode 4987: Reward = 585.00, Steps = 7, Loss = 7.1241, Exploration Rate = 0.1000, Train Count = 41530\n",
      "Episode 4988: Reward = 585.00, Steps = 7, Loss = 7.0506, Exploration Rate = 0.1000, Train Count = 41537\n",
      "Episode 4989: Reward = 597.00, Steps = 3, Loss = 14.6879, Exploration Rate = 0.1000, Train Count = 41540\n",
      "Episode 4990: Reward = 588.00, Steps = 6, Loss = 8.7284, Exploration Rate = 0.1000, Train Count = 41546\n",
      "Episode 4991: Reward = 538.00, Steps = 7, Loss = 6.2289, Exploration Rate = 0.1000, Train Count = 41553\n",
      "Episode 4992: Reward = 594.00, Steps = 4, Loss = 6.1114, Exploration Rate = 0.1000, Train Count = 41557\n",
      "Episode 4993: Reward = 591.00, Steps = 5, Loss = 7.1349, Exploration Rate = 0.1000, Train Count = 41562\n",
      "Episode 4994: Reward = 579.00, Steps = 9, Loss = 12.0133, Exploration Rate = 0.1000, Train Count = 41571\n",
      "Episode 4995: Reward = 597.00, Steps = 3, Loss = 6.7531, Exploration Rate = 0.1000, Train Count = 41574\n",
      "Episode 4996: Reward = 594.00, Steps = 4, Loss = 7.8066, Exploration Rate = 0.1000, Train Count = 41578\n",
      "Episode 4997: Reward = 588.00, Steps = 6, Loss = 6.6204, Exploration Rate = 0.1000, Train Count = 41584\n",
      "Episode 4998: Reward = 588.00, Steps = 6, Loss = 12.0017, Exploration Rate = 0.1000, Train Count = 41590\n",
      "Episode 4999: Reward = 597.00, Steps = 3, Loss = 8.4744, Exploration Rate = 0.1000, Train Count = 41593\n",
      "Episode 5000: Reward = 582.00, Steps = 8, Loss = 11.1336, Exploration Rate = 0.1000, Train Count = 41601\n",
      "Episode 5001: Reward = 582.00, Steps = 8, Loss = 9.5752, Exploration Rate = 0.1000, Train Count = 41609\n",
      "Episode 5002: Reward = 579.00, Steps = 9, Loss = 7.4543, Exploration Rate = 0.1000, Train Count = 41618\n",
      "Episode 5003: Reward = 591.00, Steps = 5, Loss = 13.5411, Exploration Rate = 0.1000, Train Count = 41623\n",
      "Episode 5004: Reward = 582.00, Steps = 8, Loss = 8.0988, Exploration Rate = 0.1000, Train Count = 41631\n",
      "Episode 5005: Reward = 585.00, Steps = 7, Loss = 9.3178, Exploration Rate = 0.1000, Train Count = 41638\n",
      "Episode 5006: Reward = 535.00, Steps = 8, Loss = 8.8689, Exploration Rate = 0.1000, Train Count = 41646\n",
      "Episode 5007: Reward = 588.00, Steps = 6, Loss = 16.1411, Exploration Rate = 0.1000, Train Count = 41652\n",
      "Episode 5008: Reward = 600.00, Steps = 2, Loss = 14.5046, Exploration Rate = 0.1000, Train Count = 41654\n",
      "Episode 5009: Reward = 594.00, Steps = 4, Loss = 11.0849, Exploration Rate = 0.1000, Train Count = 41658\n",
      "Episode 5010: Reward = 582.00, Steps = 8, Loss = 9.8483, Exploration Rate = 0.1000, Train Count = 41666\n",
      "Episode 5011: Reward = 585.00, Steps = 7, Loss = 10.8913, Exploration Rate = 0.1000, Train Count = 41673\n",
      "Episode 5012: Reward = 576.00, Steps = 10, Loss = 8.1933, Exploration Rate = 0.1000, Train Count = 41683\n",
      "Episode 5013: Reward = 597.00, Steps = 3, Loss = 4.5295, Exploration Rate = 0.1000, Train Count = 41686\n",
      "Episode 5014: Reward = 544.00, Steps = 5, Loss = 6.8884, Exploration Rate = 0.1000, Train Count = 41691\n",
      "Episode 5015: Reward = 591.00, Steps = 5, Loss = 9.3907, Exploration Rate = 0.1000, Train Count = 41696\n",
      "Episode 5016: Reward = 585.00, Steps = 7, Loss = 15.5301, Exploration Rate = 0.1000, Train Count = 41703\n",
      "Episode 5017: Reward = 579.00, Steps = 9, Loss = 13.0243, Exploration Rate = 0.1000, Train Count = 41712\n",
      "Episode 5018: Reward = 585.00, Steps = 7, Loss = 11.4243, Exploration Rate = 0.1000, Train Count = 41719\n",
      "Episode 5019: Reward = 573.00, Steps = 11, Loss = 21.2692, Exploration Rate = 0.1000, Train Count = 41730\n",
      "Episode 5020: Reward = 582.00, Steps = 8, Loss = 14.8570, Exploration Rate = 0.1000, Train Count = 41738\n",
      "Episode 5021: Reward = 597.00, Steps = 3, Loss = 8.7611, Exploration Rate = 0.1000, Train Count = 41741\n",
      "Episode 5022: Reward = 579.00, Steps = 9, Loss = 10.2508, Exploration Rate = 0.1000, Train Count = 41750\n",
      "Episode 5023: Reward = 591.00, Steps = 5, Loss = 8.2016, Exploration Rate = 0.1000, Train Count = 41755\n",
      "Episode 5024: Reward = 585.00, Steps = 7, Loss = 5.7728, Exploration Rate = 0.1000, Train Count = 41762\n",
      "Episode 5025: Reward = 535.00, Steps = 8, Loss = 13.3253, Exploration Rate = 0.1000, Train Count = 41770\n",
      "Episode 5026: Reward = 594.00, Steps = 4, Loss = 9.3826, Exploration Rate = 0.1000, Train Count = 41774\n",
      "Episode 5027: Reward = 582.00, Steps = 8, Loss = 14.0877, Exploration Rate = 0.1000, Train Count = 41782\n",
      "Episode 5028: Reward = 588.00, Steps = 6, Loss = 13.9014, Exploration Rate = 0.1000, Train Count = 41788\n",
      "Episode 5029: Reward = 597.00, Steps = 3, Loss = 10.7476, Exploration Rate = 0.1000, Train Count = 41791\n",
      "Episode 5030: Reward = 538.00, Steps = 7, Loss = 9.8969, Exploration Rate = 0.1000, Train Count = 41798\n",
      "Episode 5031: Reward = 582.00, Steps = 8, Loss = 31.6663, Exploration Rate = 0.1000, Train Count = 41806\n",
      "Episode 5032: Reward = 591.00, Steps = 5, Loss = 29.4879, Exploration Rate = 0.1000, Train Count = 41811\n",
      "Episode 5033: Reward = 585.00, Steps = 7, Loss = 26.4396, Exploration Rate = 0.1000, Train Count = 41818\n",
      "Episode 5034: Reward = 588.00, Steps = 6, Loss = 24.6020, Exploration Rate = 0.1000, Train Count = 41824\n",
      "Episode 5035: Reward = 588.00, Steps = 6, Loss = 16.9221, Exploration Rate = 0.1000, Train Count = 41830\n",
      "Episode 5036: Reward = 594.00, Steps = 4, Loss = 16.2208, Exploration Rate = 0.1000, Train Count = 41834\n",
      "Episode 5037: Reward = 597.00, Steps = 3, Loss = 20.0509, Exploration Rate = 0.1000, Train Count = 41837\n",
      "Episode 5038: Reward = 591.00, Steps = 5, Loss = 12.9995, Exploration Rate = 0.1000, Train Count = 41842\n",
      "Episode 5039: Reward = 600.00, Steps = 2, Loss = 13.6915, Exploration Rate = 0.1000, Train Count = 41844\n",
      "Episode 5040: Reward = 594.00, Steps = 4, Loss = 9.4137, Exploration Rate = 0.1000, Train Count = 41848\n",
      "Episode 5041: Reward = 582.00, Steps = 8, Loss = 17.7093, Exploration Rate = 0.1000, Train Count = 41856\n",
      "Episode 5042: Reward = 582.00, Steps = 8, Loss = 16.4245, Exploration Rate = 0.1000, Train Count = 41864\n",
      "Episode 5043: Reward = 535.00, Steps = 8, Loss = 16.4127, Exploration Rate = 0.1000, Train Count = 41872\n",
      "Episode 5044: Reward = 582.00, Steps = 8, Loss = 12.7164, Exploration Rate = 0.1000, Train Count = 41880\n",
      "Episode 5045: Reward = 582.00, Steps = 8, Loss = 11.9558, Exploration Rate = 0.1000, Train Count = 41888\n",
      "Episode 5046: Reward = 532.00, Steps = 9, Loss = 10.4001, Exploration Rate = 0.1000, Train Count = 41897\n",
      "Episode 5047: Reward = 600.00, Steps = 2, Loss = 10.8581, Exploration Rate = 0.1000, Train Count = 41899\n",
      "Episode 5048: Reward = 585.00, Steps = 7, Loss = 9.0741, Exploration Rate = 0.1000, Train Count = 41906\n",
      "Episode 5049: Reward = 585.00, Steps = 7, Loss = 8.3513, Exploration Rate = 0.1000, Train Count = 41913\n",
      "Episode 5050: Reward = 594.00, Steps = 4, Loss = 6.8321, Exploration Rate = 0.1000, Train Count = 41917\n",
      "Episode 5051: Reward = 588.00, Steps = 6, Loss = 7.6296, Exploration Rate = 0.1000, Train Count = 41923\n",
      "Episode 5052: Reward = 582.00, Steps = 8, Loss = 9.2845, Exploration Rate = 0.1000, Train Count = 41931\n",
      "Episode 5053: Reward = 588.00, Steps = 6, Loss = 7.9986, Exploration Rate = 0.1000, Train Count = 41937\n",
      "Episode 5054: Reward = 585.00, Steps = 7, Loss = 6.1918, Exploration Rate = 0.1000, Train Count = 41944\n",
      "Episode 5055: Reward = 591.00, Steps = 5, Loss = 5.8060, Exploration Rate = 0.1000, Train Count = 41949\n",
      "Episode 5056: Reward = 600.00, Steps = 2, Loss = 8.3326, Exploration Rate = 0.1000, Train Count = 41951\n",
      "Episode 5057: Reward = 591.00, Steps = 5, Loss = 8.1547, Exploration Rate = 0.1000, Train Count = 41956\n",
      "Episode 5058: Reward = 594.00, Steps = 4, Loss = 7.8881, Exploration Rate = 0.1000, Train Count = 41960\n",
      "Episode 5059: Reward = 588.00, Steps = 6, Loss = 8.6921, Exploration Rate = 0.1000, Train Count = 41966\n",
      "Episode 5060: Reward = 585.00, Steps = 7, Loss = 8.0871, Exploration Rate = 0.1000, Train Count = 41973\n",
      "Episode 5061: Reward = 585.00, Steps = 7, Loss = 8.6778, Exploration Rate = 0.1000, Train Count = 41980\n",
      "Episode 5062: Reward = 591.00, Steps = 5, Loss = 10.2009, Exploration Rate = 0.1000, Train Count = 41985\n",
      "Episode 5063: Reward = 594.00, Steps = 4, Loss = 8.6748, Exploration Rate = 0.1000, Train Count = 41989\n",
      "Episode 5064: Reward = 585.00, Steps = 7, Loss = 9.5796, Exploration Rate = 0.1000, Train Count = 41996\n",
      "Episode 5065: Reward = 594.00, Steps = 4, Loss = 6.5176, Exploration Rate = 0.1000, Train Count = 42000\n",
      "Episode 5066: Reward = 591.00, Steps = 5, Loss = 9.0332, Exploration Rate = 0.1000, Train Count = 42005\n",
      "Episode 5067: Reward = 591.00, Steps = 5, Loss = 8.2561, Exploration Rate = 0.1000, Train Count = 42010\n",
      "Episode 5068: Reward = 591.00, Steps = 5, Loss = 5.1333, Exploration Rate = 0.1000, Train Count = 42015\n",
      "Episode 5069: Reward = 591.00, Steps = 5, Loss = 4.4289, Exploration Rate = 0.1000, Train Count = 42020\n",
      "Episode 5070: Reward = 594.00, Steps = 4, Loss = 6.3876, Exploration Rate = 0.1000, Train Count = 42024\n",
      "Episode 5071: Reward = 591.00, Steps = 5, Loss = 8.8684, Exploration Rate = 0.1000, Train Count = 42029\n",
      "Episode 5072: Reward = 588.00, Steps = 6, Loss = 5.7925, Exploration Rate = 0.1000, Train Count = 42035\n",
      "Episode 5073: Reward = 594.00, Steps = 4, Loss = 12.7046, Exploration Rate = 0.1000, Train Count = 42039\n",
      "Episode 5074: Reward = 588.00, Steps = 6, Loss = 9.2899, Exploration Rate = 0.1000, Train Count = 42045\n",
      "Episode 5075: Reward = 591.00, Steps = 5, Loss = 6.4787, Exploration Rate = 0.1000, Train Count = 42050\n",
      "Episode 5076: Reward = 591.00, Steps = 5, Loss = 7.7621, Exploration Rate = 0.1000, Train Count = 42055\n",
      "Episode 5077: Reward = 529.00, Steps = 10, Loss = 14.0178, Exploration Rate = 0.1000, Train Count = 42065\n",
      "Episode 5078: Reward = 576.00, Steps = 10, Loss = 12.1594, Exploration Rate = 0.1000, Train Count = 42075\n",
      "Episode 5079: Reward = 588.00, Steps = 6, Loss = 11.6928, Exploration Rate = 0.1000, Train Count = 42081\n",
      "Episode 5080: Reward = 591.00, Steps = 5, Loss = 8.0786, Exploration Rate = 0.1000, Train Count = 42086\n",
      "Episode 5081: Reward = 588.00, Steps = 6, Loss = 10.8855, Exploration Rate = 0.1000, Train Count = 42092\n",
      "Episode 5082: Reward = 541.00, Steps = 6, Loss = 11.0427, Exploration Rate = 0.1000, Train Count = 42098\n",
      "Episode 5083: Reward = 591.00, Steps = 5, Loss = 6.6186, Exploration Rate = 0.1000, Train Count = 42103\n",
      "Episode 5084: Reward = 594.00, Steps = 4, Loss = 7.3770, Exploration Rate = 0.1000, Train Count = 42107\n",
      "Episode 5085: Reward = 591.00, Steps = 5, Loss = 8.2270, Exploration Rate = 0.1000, Train Count = 42112\n",
      "Episode 5086: Reward = 594.00, Steps = 4, Loss = 11.0962, Exploration Rate = 0.1000, Train Count = 42116\n",
      "Episode 5087: Reward = 585.00, Steps = 7, Loss = 8.4191, Exploration Rate = 0.1000, Train Count = 42123\n",
      "Episode 5088: Reward = 597.00, Steps = 3, Loss = 13.8705, Exploration Rate = 0.1000, Train Count = 42126\n",
      "Episode 5089: Reward = 597.00, Steps = 3, Loss = 8.3841, Exploration Rate = 0.1000, Train Count = 42129\n",
      "Episode 5090: Reward = 588.00, Steps = 6, Loss = 8.1783, Exploration Rate = 0.1000, Train Count = 42135\n",
      "Episode 5091: Reward = 582.00, Steps = 8, Loss = 10.5789, Exploration Rate = 0.1000, Train Count = 42143\n",
      "Episode 5092: Reward = 555.00, Steps = 17, Loss = 10.5912, Exploration Rate = 0.1000, Train Count = 42160\n",
      "Episode 5093: Reward = 591.00, Steps = 5, Loss = 11.4385, Exploration Rate = 0.1000, Train Count = 42165\n",
      "Episode 5094: Reward = 585.00, Steps = 7, Loss = 10.5426, Exploration Rate = 0.1000, Train Count = 42172\n",
      "Episode 5095: Reward = 588.00, Steps = 6, Loss = 9.9105, Exploration Rate = 0.1000, Train Count = 42178\n",
      "Episode 5096: Reward = 570.00, Steps = 12, Loss = 8.3957, Exploration Rate = 0.1000, Train Count = 42190\n",
      "Episode 5097: Reward = 588.00, Steps = 6, Loss = 6.8461, Exploration Rate = 0.1000, Train Count = 42196\n",
      "Episode 5098: Reward = 579.00, Steps = 9, Loss = 7.8263, Exploration Rate = 0.1000, Train Count = 42205\n",
      "Episode 5099: Reward = 591.00, Steps = 5, Loss = 7.6558, Exploration Rate = 0.1000, Train Count = 42210\n",
      "Episode 5100: Reward = 594.00, Steps = 4, Loss = 9.0837, Exploration Rate = 0.1000, Train Count = 42214\n",
      "Episode 5101: Reward = 579.00, Steps = 9, Loss = 8.3658, Exploration Rate = 0.1000, Train Count = 42223\n",
      "Episode 5102: Reward = 591.00, Steps = 5, Loss = 9.4892, Exploration Rate = 0.1000, Train Count = 42228\n",
      "Episode 5103: Reward = 538.00, Steps = 7, Loss = 7.1300, Exploration Rate = 0.1000, Train Count = 42235\n",
      "Episode 5104: Reward = 594.00, Steps = 4, Loss = 8.6725, Exploration Rate = 0.1000, Train Count = 42239\n",
      "Episode 5105: Reward = 582.00, Steps = 8, Loss = 5.7194, Exploration Rate = 0.1000, Train Count = 42247\n",
      "Episode 5106: Reward = 579.00, Steps = 9, Loss = 7.8879, Exploration Rate = 0.1000, Train Count = 42256\n",
      "Episode 5107: Reward = 591.00, Steps = 5, Loss = 10.4008, Exploration Rate = 0.1000, Train Count = 42261\n",
      "Episode 5108: Reward = 579.00, Steps = 9, Loss = 6.9212, Exploration Rate = 0.1000, Train Count = 42270\n",
      "Episode 5109: Reward = 582.00, Steps = 8, Loss = 11.0371, Exploration Rate = 0.1000, Train Count = 42278\n",
      "Episode 5110: Reward = 588.00, Steps = 6, Loss = 11.0821, Exploration Rate = 0.1000, Train Count = 42284\n",
      "Episode 5111: Reward = 594.00, Steps = 4, Loss = 6.7940, Exploration Rate = 0.1000, Train Count = 42288\n",
      "Episode 5112: Reward = 591.00, Steps = 5, Loss = 8.1497, Exploration Rate = 0.1000, Train Count = 42293\n",
      "Episode 5113: Reward = 588.00, Steps = 6, Loss = 8.8969, Exploration Rate = 0.1000, Train Count = 42299\n",
      "Episode 5114: Reward = 579.00, Steps = 9, Loss = 36.4160, Exploration Rate = 0.1000, Train Count = 42308\n",
      "Episode 5115: Reward = 564.00, Steps = 14, Loss = 31.2895, Exploration Rate = 0.1000, Train Count = 42322\n",
      "Episode 5116: Reward = 570.00, Steps = 12, Loss = 18.9450, Exploration Rate = 0.1000, Train Count = 42334\n",
      "Episode 5117: Reward = 588.00, Steps = 6, Loss = 16.3324, Exploration Rate = 0.1000, Train Count = 42340\n",
      "Episode 5118: Reward = 591.00, Steps = 5, Loss = 13.1327, Exploration Rate = 0.1000, Train Count = 42345\n",
      "Episode 5119: Reward = 579.00, Steps = 9, Loss = 11.1669, Exploration Rate = 0.1000, Train Count = 42354\n",
      "Episode 5120: Reward = 567.00, Steps = 13, Loss = 14.5979, Exploration Rate = 0.1000, Train Count = 42367\n",
      "Episode 5121: Reward = 576.00, Steps = 10, Loss = 13.1728, Exploration Rate = 0.1000, Train Count = 42377\n",
      "Episode 5122: Reward = 597.00, Steps = 3, Loss = 15.8829, Exploration Rate = 0.1000, Train Count = 42380\n",
      "Episode 5123: Reward = 591.00, Steps = 5, Loss = 9.7929, Exploration Rate = 0.1000, Train Count = 42385\n",
      "Episode 5124: Reward = 588.00, Steps = 6, Loss = 9.2858, Exploration Rate = 0.1000, Train Count = 42391\n",
      "Episode 5125: Reward = 588.00, Steps = 6, Loss = 6.2455, Exploration Rate = 0.1000, Train Count = 42397\n",
      "Episode 5126: Reward = 600.00, Steps = 2, Loss = 9.6259, Exploration Rate = 0.1000, Train Count = 42399\n",
      "Episode 5127: Reward = 600.00, Steps = 2, Loss = 5.3538, Exploration Rate = 0.1000, Train Count = 42401\n",
      "Episode 5128: Reward = 591.00, Steps = 5, Loss = 7.4098, Exploration Rate = 0.1000, Train Count = 42406\n",
      "Episode 5129: Reward = 588.00, Steps = 6, Loss = 4.6598, Exploration Rate = 0.1000, Train Count = 42412\n",
      "Episode 5130: Reward = 588.00, Steps = 6, Loss = 7.2476, Exploration Rate = 0.1000, Train Count = 42418\n",
      "Episode 5131: Reward = 594.00, Steps = 4, Loss = 6.3040, Exploration Rate = 0.1000, Train Count = 42422\n",
      "Episode 5132: Reward = 594.00, Steps = 4, Loss = 4.5183, Exploration Rate = 0.1000, Train Count = 42426\n",
      "Episode 5133: Reward = 600.00, Steps = 2, Loss = 3.8564, Exploration Rate = 0.1000, Train Count = 42428\n",
      "Episode 5134: Reward = 591.00, Steps = 5, Loss = 5.6546, Exploration Rate = 0.1000, Train Count = 42433\n",
      "Episode 5135: Reward = 585.00, Steps = 7, Loss = 2.8703, Exploration Rate = 0.1000, Train Count = 42440\n",
      "Episode 5136: Reward = 517.00, Steps = 14, Loss = 7.8896, Exploration Rate = 0.1000, Train Count = 42454\n",
      "Episode 5137: Reward = 541.00, Steps = 6, Loss = 8.0549, Exploration Rate = 0.1000, Train Count = 42460\n",
      "Episode 5138: Reward = 591.00, Steps = 5, Loss = 12.6649, Exploration Rate = 0.1000, Train Count = 42465\n",
      "Episode 5139: Reward = 591.00, Steps = 5, Loss = 9.5313, Exploration Rate = 0.1000, Train Count = 42470\n",
      "Episode 5140: Reward = 594.00, Steps = 4, Loss = 20.0547, Exploration Rate = 0.1000, Train Count = 42474\n",
      "Episode 5141: Reward = 594.00, Steps = 4, Loss = 9.6825, Exploration Rate = 0.1000, Train Count = 42478\n",
      "Episode 5142: Reward = 585.00, Steps = 7, Loss = 8.9985, Exploration Rate = 0.1000, Train Count = 42485\n",
      "Episode 5143: Reward = 585.00, Steps = 7, Loss = 7.3259, Exploration Rate = 0.1000, Train Count = 42492\n",
      "Episode 5144: Reward = 591.00, Steps = 5, Loss = 6.3336, Exploration Rate = 0.1000, Train Count = 42497\n",
      "Episode 5145: Reward = 591.00, Steps = 5, Loss = 5.3542, Exploration Rate = 0.1000, Train Count = 42502\n",
      "Episode 5146: Reward = 585.00, Steps = 7, Loss = 6.3964, Exploration Rate = 0.1000, Train Count = 42509\n",
      "Episode 5147: Reward = 597.00, Steps = 3, Loss = 5.1886, Exploration Rate = 0.1000, Train Count = 42512\n",
      "Episode 5148: Reward = 573.00, Steps = 11, Loss = 6.5988, Exploration Rate = 0.1000, Train Count = 42523\n",
      "Episode 5149: Reward = 579.00, Steps = 9, Loss = 5.5852, Exploration Rate = 0.1000, Train Count = 42532\n",
      "Episode 5150: Reward = 597.00, Steps = 3, Loss = 3.5308, Exploration Rate = 0.1000, Train Count = 42535\n",
      "Episode 5151: Reward = 588.00, Steps = 6, Loss = 4.5900, Exploration Rate = 0.1000, Train Count = 42541\n",
      "Episode 5152: Reward = 491.00, Steps = 7, Loss = 9.7099, Exploration Rate = 0.1000, Train Count = 42548\n",
      "Episode 5153: Reward = 594.00, Steps = 4, Loss = 9.0255, Exploration Rate = 0.1000, Train Count = 42552\n",
      "Episode 5154: Reward = 594.00, Steps = 4, Loss = 6.6224, Exploration Rate = 0.1000, Train Count = 42556\n",
      "Episode 5155: Reward = 585.00, Steps = 7, Loss = 7.5992, Exploration Rate = 0.1000, Train Count = 42563\n",
      "Episode 5156: Reward = 597.00, Steps = 3, Loss = 4.8079, Exploration Rate = 0.1000, Train Count = 42566\n",
      "Episode 5157: Reward = 579.00, Steps = 9, Loss = 5.9076, Exploration Rate = 0.1000, Train Count = 42575\n",
      "Episode 5158: Reward = 588.00, Steps = 6, Loss = 8.5476, Exploration Rate = 0.1000, Train Count = 42581\n",
      "Episode 5159: Reward = 594.00, Steps = 4, Loss = 8.0865, Exploration Rate = 0.1000, Train Count = 42585\n",
      "Episode 5160: Reward = 597.00, Steps = 3, Loss = 4.1794, Exploration Rate = 0.1000, Train Count = 42588\n",
      "Episode 5161: Reward = 597.00, Steps = 3, Loss = 10.1603, Exploration Rate = 0.1000, Train Count = 42591\n",
      "Episode 5162: Reward = 588.00, Steps = 6, Loss = 5.7907, Exploration Rate = 0.1000, Train Count = 42597\n",
      "Episode 5163: Reward = 591.00, Steps = 5, Loss = 5.3860, Exploration Rate = 0.1000, Train Count = 42602\n",
      "Episode 5164: Reward = 597.00, Steps = 3, Loss = 6.3834, Exploration Rate = 0.1000, Train Count = 42605\n",
      "Episode 5165: Reward = 597.00, Steps = 3, Loss = 5.5177, Exploration Rate = 0.1000, Train Count = 42608\n",
      "Episode 5166: Reward = 591.00, Steps = 5, Loss = 4.4452, Exploration Rate = 0.1000, Train Count = 42613\n",
      "Episode 5167: Reward = 585.00, Steps = 7, Loss = 5.4299, Exploration Rate = 0.1000, Train Count = 42620\n",
      "Episode 5168: Reward = 550.00, Steps = 3, Loss = 5.7776, Exploration Rate = 0.1000, Train Count = 42623\n",
      "Episode 5169: Reward = 594.00, Steps = 4, Loss = 2.7171, Exploration Rate = 0.1000, Train Count = 42627\n",
      "Episode 5170: Reward = 591.00, Steps = 5, Loss = 4.7969, Exploration Rate = 0.1000, Train Count = 42632\n",
      "Episode 5171: Reward = 585.00, Steps = 7, Loss = 2.7080, Exploration Rate = 0.1000, Train Count = 42639\n",
      "Episode 5172: Reward = 591.00, Steps = 5, Loss = 5.4299, Exploration Rate = 0.1000, Train Count = 42644\n",
      "Episode 5173: Reward = 594.00, Steps = 4, Loss = 4.8273, Exploration Rate = 0.1000, Train Count = 42648\n",
      "Episode 5174: Reward = 594.00, Steps = 4, Loss = 6.1048, Exploration Rate = 0.1000, Train Count = 42652\n",
      "Episode 5175: Reward = 585.00, Steps = 7, Loss = 5.1330, Exploration Rate = 0.1000, Train Count = 42659\n",
      "Episode 5176: Reward = 579.00, Steps = 9, Loss = 3.4701, Exploration Rate = 0.1000, Train Count = 42668\n",
      "Episode 5177: Reward = 594.00, Steps = 4, Loss = 6.1347, Exploration Rate = 0.1000, Train Count = 42672\n",
      "Episode 5178: Reward = 594.00, Steps = 4, Loss = 6.7033, Exploration Rate = 0.1000, Train Count = 42676\n",
      "Episode 5179: Reward = 576.00, Steps = 10, Loss = 5.4552, Exploration Rate = 0.1000, Train Count = 42686\n",
      "Episode 5180: Reward = 585.00, Steps = 7, Loss = 5.2747, Exploration Rate = 0.1000, Train Count = 42693\n",
      "Episode 5181: Reward = 585.00, Steps = 7, Loss = 3.1259, Exploration Rate = 0.1000, Train Count = 42700\n",
      "Episode 5182: Reward = 579.00, Steps = 9, Loss = 4.1295, Exploration Rate = 0.1000, Train Count = 42709\n",
      "Episode 5183: Reward = 588.00, Steps = 6, Loss = 3.0117, Exploration Rate = 0.1000, Train Count = 42715\n",
      "Episode 5184: Reward = 591.00, Steps = 5, Loss = 3.7735, Exploration Rate = 0.1000, Train Count = 42720\n",
      "Episode 5185: Reward = 591.00, Steps = 5, Loss = 3.4698, Exploration Rate = 0.1000, Train Count = 42725\n",
      "Episode 5186: Reward = 591.00, Steps = 5, Loss = 3.8290, Exploration Rate = 0.1000, Train Count = 42730\n",
      "Episode 5187: Reward = 585.00, Steps = 7, Loss = 3.7152, Exploration Rate = 0.1000, Train Count = 42737\n",
      "Episode 5188: Reward = 594.00, Steps = 4, Loss = 3.3226, Exploration Rate = 0.1000, Train Count = 42741\n",
      "Episode 5189: Reward = 588.00, Steps = 6, Loss = 3.5145, Exploration Rate = 0.1000, Train Count = 42747\n",
      "Episode 5190: Reward = 594.00, Steps = 4, Loss = 1.4482, Exploration Rate = 0.1000, Train Count = 42751\n",
      "Episode 5191: Reward = 573.00, Steps = 11, Loss = 10.3744, Exploration Rate = 0.1000, Train Count = 42762\n",
      "Episode 5192: Reward = 591.00, Steps = 5, Loss = 22.9545, Exploration Rate = 0.1000, Train Count = 42767\n",
      "Episode 5193: Reward = 582.00, Steps = 8, Loss = 10.6495, Exploration Rate = 0.1000, Train Count = 42775\n",
      "Episode 5194: Reward = 591.00, Steps = 5, Loss = 11.5699, Exploration Rate = 0.1000, Train Count = 42780\n",
      "Episode 5195: Reward = 538.00, Steps = 7, Loss = 9.1024, Exploration Rate = 0.1000, Train Count = 42787\n",
      "Episode 5196: Reward = 585.00, Steps = 7, Loss = 10.8228, Exploration Rate = 0.1000, Train Count = 42794\n",
      "Episode 5197: Reward = 588.00, Steps = 6, Loss = 9.6314, Exploration Rate = 0.1000, Train Count = 42800\n",
      "Episode 5198: Reward = 579.00, Steps = 9, Loss = 38.7918, Exploration Rate = 0.1000, Train Count = 42809\n",
      "Episode 5199: Reward = 591.00, Steps = 5, Loss = 29.1651, Exploration Rate = 0.1000, Train Count = 42814\n",
      "Episode 5200: Reward = 591.00, Steps = 5, Loss = 25.7048, Exploration Rate = 0.1000, Train Count = 42819\n",
      "Episode 5201: Reward = 582.00, Steps = 8, Loss = 17.2945, Exploration Rate = 0.1000, Train Count = 42827\n",
      "Episode 5202: Reward = 597.00, Steps = 3, Loss = 16.2342, Exploration Rate = 0.1000, Train Count = 42830\n",
      "Episode 5203: Reward = 597.00, Steps = 3, Loss = 15.9396, Exploration Rate = 0.1000, Train Count = 42833\n",
      "Episode 5204: Reward = 532.00, Steps = 9, Loss = 18.5879, Exploration Rate = 0.1000, Train Count = 42842\n",
      "Episode 5205: Reward = 594.00, Steps = 4, Loss = 15.0550, Exploration Rate = 0.1000, Train Count = 42846\n",
      "Episode 5206: Reward = 582.00, Steps = 8, Loss = 15.0519, Exploration Rate = 0.1000, Train Count = 42854\n",
      "Episode 5207: Reward = 591.00, Steps = 5, Loss = 8.9566, Exploration Rate = 0.1000, Train Count = 42859\n",
      "Episode 5208: Reward = 597.00, Steps = 3, Loss = 13.4606, Exploration Rate = 0.1000, Train Count = 42862\n",
      "Episode 5209: Reward = 588.00, Steps = 6, Loss = 10.7477, Exploration Rate = 0.1000, Train Count = 42868\n",
      "Episode 5210: Reward = 588.00, Steps = 6, Loss = 11.1114, Exploration Rate = 0.1000, Train Count = 42874\n",
      "Episode 5211: Reward = 591.00, Steps = 5, Loss = 9.1532, Exploration Rate = 0.1000, Train Count = 42879\n",
      "Episode 5212: Reward = 528.00, Steps = 26, Loss = 11.9455, Exploration Rate = 0.1000, Train Count = 42905\n",
      "Episode 5213: Reward = 594.00, Steps = 4, Loss = 9.2479, Exploration Rate = 0.1000, Train Count = 42909\n",
      "Episode 5214: Reward = 597.00, Steps = 3, Loss = 7.2806, Exploration Rate = 0.1000, Train Count = 42912\n",
      "Episode 5215: Reward = 535.00, Steps = 8, Loss = 9.8211, Exploration Rate = 0.1000, Train Count = 42920\n",
      "Episode 5216: Reward = 588.00, Steps = 6, Loss = 14.6579, Exploration Rate = 0.1000, Train Count = 42926\n",
      "Episode 5217: Reward = 544.00, Steps = 5, Loss = 9.5238, Exploration Rate = 0.1000, Train Count = 42931\n",
      "Episode 5218: Reward = 594.00, Steps = 4, Loss = 8.7158, Exploration Rate = 0.1000, Train Count = 42935\n",
      "Episode 5219: Reward = 597.00, Steps = 3, Loss = 11.5471, Exploration Rate = 0.1000, Train Count = 42938\n",
      "Episode 5220: Reward = 576.00, Steps = 10, Loss = 12.7572, Exploration Rate = 0.1000, Train Count = 42948\n",
      "Episode 5221: Reward = 588.00, Steps = 6, Loss = 11.4839, Exploration Rate = 0.1000, Train Count = 42954\n",
      "Episode 5222: Reward = 591.00, Steps = 5, Loss = 9.4630, Exploration Rate = 0.1000, Train Count = 42959\n",
      "Episode 5223: Reward = 585.00, Steps = 7, Loss = 9.0440, Exploration Rate = 0.1000, Train Count = 42966\n",
      "Episode 5224: Reward = 535.00, Steps = 8, Loss = 8.6207, Exploration Rate = 0.1000, Train Count = 42974\n",
      "Episode 5225: Reward = 597.00, Steps = 3, Loss = 4.4917, Exploration Rate = 0.1000, Train Count = 42977\n",
      "Episode 5226: Reward = 579.00, Steps = 9, Loss = 19.6194, Exploration Rate = 0.1000, Train Count = 42986\n",
      "Episode 5227: Reward = 585.00, Steps = 7, Loss = 8.4849, Exploration Rate = 0.1000, Train Count = 42993\n",
      "Episode 5228: Reward = 588.00, Steps = 6, Loss = 14.4241, Exploration Rate = 0.1000, Train Count = 42999\n",
      "Episode 5229: Reward = 591.00, Steps = 5, Loss = 6.1451, Exploration Rate = 0.1000, Train Count = 43004\n",
      "Episode 5230: Reward = 585.00, Steps = 7, Loss = 9.7738, Exploration Rate = 0.1000, Train Count = 43011\n",
      "Episode 5231: Reward = 594.00, Steps = 4, Loss = 15.5330, Exploration Rate = 0.1000, Train Count = 43015\n",
      "Episode 5232: Reward = 528.00, Steps = 26, Loss = 20.5971, Exploration Rate = 0.1000, Train Count = 43041\n",
      "Episode 5233: Reward = 576.00, Steps = 10, Loss = 18.7522, Exploration Rate = 0.1000, Train Count = 43051\n",
      "Episode 5234: Reward = 585.00, Steps = 7, Loss = 16.3224, Exploration Rate = 0.1000, Train Count = 43058\n",
      "Episode 5235: Reward = 591.00, Steps = 5, Loss = 11.2873, Exploration Rate = 0.1000, Train Count = 43063\n",
      "Episode 5236: Reward = 532.00, Steps = 9, Loss = 15.0052, Exploration Rate = 0.1000, Train Count = 43072\n",
      "Episode 5237: Reward = 573.00, Steps = 11, Loss = 12.4713, Exploration Rate = 0.1000, Train Count = 43083\n",
      "Episode 5238: Reward = 594.00, Steps = 4, Loss = 11.4437, Exploration Rate = 0.1000, Train Count = 43087\n",
      "Episode 5239: Reward = 588.00, Steps = 6, Loss = 8.9891, Exploration Rate = 0.1000, Train Count = 43093\n",
      "Episode 5240: Reward = 588.00, Steps = 6, Loss = 15.7066, Exploration Rate = 0.1000, Train Count = 43099\n",
      "Episode 5241: Reward = 600.00, Steps = 2, Loss = 14.7885, Exploration Rate = 0.1000, Train Count = 43101\n",
      "Episode 5242: Reward = 588.00, Steps = 6, Loss = 12.0101, Exploration Rate = 0.1000, Train Count = 43107\n",
      "Episode 5243: Reward = 582.00, Steps = 8, Loss = 11.5478, Exploration Rate = 0.1000, Train Count = 43115\n",
      "Episode 5244: Reward = 600.00, Steps = 2, Loss = 25.2407, Exploration Rate = 0.1000, Train Count = 43117\n",
      "Episode 5245: Reward = 573.00, Steps = 11, Loss = 13.7324, Exploration Rate = 0.1000, Train Count = 43128\n",
      "Episode 5246: Reward = 585.00, Steps = 7, Loss = 20.1648, Exploration Rate = 0.1000, Train Count = 43135\n",
      "Episode 5247: Reward = 588.00, Steps = 6, Loss = 12.3491, Exploration Rate = 0.1000, Train Count = 43141\n",
      "Episode 5248: Reward = 597.00, Steps = 3, Loss = 18.4202, Exploration Rate = 0.1000, Train Count = 43144\n",
      "Episode 5249: Reward = 591.00, Steps = 5, Loss = 16.9256, Exploration Rate = 0.1000, Train Count = 43149\n",
      "Episode 5250: Reward = 597.00, Steps = 3, Loss = 4.0248, Exploration Rate = 0.1000, Train Count = 43152\n",
      "Episode 5251: Reward = 594.00, Steps = 4, Loss = 10.5782, Exploration Rate = 0.1000, Train Count = 43156\n",
      "Episode 5252: Reward = 541.00, Steps = 6, Loss = 11.9930, Exploration Rate = 0.1000, Train Count = 43162\n",
      "Episode 5253: Reward = 585.00, Steps = 7, Loss = 16.2765, Exploration Rate = 0.1000, Train Count = 43169\n",
      "Episode 5254: Reward = 591.00, Steps = 5, Loss = 12.5117, Exploration Rate = 0.1000, Train Count = 43174\n",
      "Episode 5255: Reward = 588.00, Steps = 6, Loss = 11.9757, Exploration Rate = 0.1000, Train Count = 43180\n",
      "Episode 5256: Reward = 585.00, Steps = 7, Loss = 13.6641, Exploration Rate = 0.1000, Train Count = 43187\n",
      "Episode 5257: Reward = 588.00, Steps = 6, Loss = 13.9528, Exploration Rate = 0.1000, Train Count = 43193\n",
      "Episode 5258: Reward = 582.00, Steps = 8, Loss = 14.6232, Exploration Rate = 0.1000, Train Count = 43201\n",
      "Episode 5259: Reward = 579.00, Steps = 9, Loss = 11.4265, Exploration Rate = 0.1000, Train Count = 43210\n",
      "Episode 5260: Reward = 585.00, Steps = 7, Loss = 13.5727, Exploration Rate = 0.1000, Train Count = 43217\n",
      "Episode 5261: Reward = 591.00, Steps = 5, Loss = 13.4799, Exploration Rate = 0.1000, Train Count = 43222\n",
      "Episode 5262: Reward = 597.00, Steps = 3, Loss = 14.6865, Exploration Rate = 0.1000, Train Count = 43225\n",
      "Episode 5263: Reward = 585.00, Steps = 7, Loss = 15.4313, Exploration Rate = 0.1000, Train Count = 43232\n",
      "Episode 5264: Reward = 552.00, Steps = 18, Loss = 17.0362, Exploration Rate = 0.1000, Train Count = 43250\n",
      "Episode 5265: Reward = 594.00, Steps = 4, Loss = 19.8304, Exploration Rate = 0.1000, Train Count = 43254\n",
      "Episode 5266: Reward = 582.00, Steps = 8, Loss = 14.5992, Exploration Rate = 0.1000, Train Count = 43262\n",
      "Episode 5267: Reward = 585.00, Steps = 7, Loss = 11.5580, Exploration Rate = 0.1000, Train Count = 43269\n",
      "Episode 5268: Reward = 541.00, Steps = 6, Loss = 16.0317, Exploration Rate = 0.1000, Train Count = 43275\n",
      "Episode 5269: Reward = 591.00, Steps = 5, Loss = 16.2073, Exploration Rate = 0.1000, Train Count = 43280\n",
      "Episode 5270: Reward = 582.00, Steps = 8, Loss = 14.3388, Exploration Rate = 0.1000, Train Count = 43288\n",
      "Episode 5271: Reward = 591.00, Steps = 5, Loss = 18.5256, Exploration Rate = 0.1000, Train Count = 43293\n",
      "Episode 5272: Reward = 579.00, Steps = 9, Loss = 23.0319, Exploration Rate = 0.1000, Train Count = 43302\n",
      "Episode 5273: Reward = 594.00, Steps = 4, Loss = 56.0741, Exploration Rate = 0.1000, Train Count = 43306\n",
      "Episode 5274: Reward = 594.00, Steps = 4, Loss = 35.4787, Exploration Rate = 0.1000, Train Count = 43310\n",
      "Episode 5275: Reward = 585.00, Steps = 7, Loss = 34.4385, Exploration Rate = 0.1000, Train Count = 43317\n",
      "Episode 5276: Reward = 585.00, Steps = 7, Loss = 23.4201, Exploration Rate = 0.1000, Train Count = 43324\n",
      "Episode 5277: Reward = 532.00, Steps = 9, Loss = 23.7129, Exploration Rate = 0.1000, Train Count = 43333\n",
      "Episode 5278: Reward = 597.00, Steps = 3, Loss = 29.0509, Exploration Rate = 0.1000, Train Count = 43336\n",
      "Episode 5279: Reward = 597.00, Steps = 3, Loss = 34.5840, Exploration Rate = 0.1000, Train Count = 43339\n",
      "Episode 5280: Reward = 588.00, Steps = 6, Loss = 19.6168, Exploration Rate = 0.1000, Train Count = 43345\n",
      "Episode 5281: Reward = 591.00, Steps = 5, Loss = 19.0282, Exploration Rate = 0.1000, Train Count = 43350\n",
      "Episode 5282: Reward = 594.00, Steps = 4, Loss = 31.1568, Exploration Rate = 0.1000, Train Count = 43354\n",
      "Episode 5283: Reward = 588.00, Steps = 6, Loss = 25.1606, Exploration Rate = 0.1000, Train Count = 43360\n",
      "Episode 5284: Reward = 594.00, Steps = 4, Loss = 22.7480, Exploration Rate = 0.1000, Train Count = 43364\n",
      "Episode 5285: Reward = 585.00, Steps = 7, Loss = 18.8866, Exploration Rate = 0.1000, Train Count = 43371\n",
      "Episode 5286: Reward = 594.00, Steps = 4, Loss = 20.3852, Exploration Rate = 0.1000, Train Count = 43375\n",
      "Episode 5287: Reward = 582.00, Steps = 8, Loss = 14.5820, Exploration Rate = 0.1000, Train Count = 43383\n",
      "Episode 5288: Reward = 591.00, Steps = 5, Loss = 12.6317, Exploration Rate = 0.1000, Train Count = 43388\n",
      "Episode 5289: Reward = 570.00, Steps = 12, Loss = 17.4361, Exploration Rate = 0.1000, Train Count = 43400\n",
      "Episode 5290: Reward = 591.00, Steps = 5, Loss = 18.1010, Exploration Rate = 0.1000, Train Count = 43405\n",
      "Episode 5291: Reward = 582.00, Steps = 8, Loss = 19.1891, Exploration Rate = 0.1000, Train Count = 43413\n",
      "Episode 5292: Reward = 588.00, Steps = 6, Loss = 15.2223, Exploration Rate = 0.1000, Train Count = 43419\n",
      "Episode 5293: Reward = 594.00, Steps = 4, Loss = 14.8805, Exploration Rate = 0.1000, Train Count = 43423\n",
      "Episode 5294: Reward = 526.00, Steps = 11, Loss = 12.9595, Exploration Rate = 0.1000, Train Count = 43434\n",
      "Episode 5295: Reward = 591.00, Steps = 5, Loss = 17.9164, Exploration Rate = 0.1000, Train Count = 43439\n",
      "Episode 5296: Reward = 585.00, Steps = 7, Loss = 12.3323, Exploration Rate = 0.1000, Train Count = 43446\n",
      "Episode 5297: Reward = 585.00, Steps = 7, Loss = 13.2130, Exploration Rate = 0.1000, Train Count = 43453\n",
      "Episode 5298: Reward = 597.00, Steps = 3, Loss = 16.6179, Exploration Rate = 0.1000, Train Count = 43456\n",
      "Episode 5299: Reward = 591.00, Steps = 5, Loss = 15.6501, Exploration Rate = 0.1000, Train Count = 43461\n",
      "Episode 5300: Reward = 591.00, Steps = 5, Loss = 16.3304, Exploration Rate = 0.1000, Train Count = 43466\n",
      "Episode 5301: Reward = 600.00, Steps = 2, Loss = 16.1460, Exploration Rate = 0.1000, Train Count = 43468\n",
      "Episode 5302: Reward = 579.00, Steps = 9, Loss = 11.7043, Exploration Rate = 0.1000, Train Count = 43477\n",
      "Episode 5303: Reward = 582.00, Steps = 8, Loss = 9.4344, Exploration Rate = 0.1000, Train Count = 43485\n",
      "Episode 5304: Reward = 600.00, Steps = 2, Loss = 19.3053, Exploration Rate = 0.1000, Train Count = 43487\n",
      "Episode 5305: Reward = 591.00, Steps = 5, Loss = 7.0514, Exploration Rate = 0.1000, Train Count = 43492\n",
      "Episode 5306: Reward = 585.00, Steps = 7, Loss = 13.9339, Exploration Rate = 0.1000, Train Count = 43499\n",
      "Episode 5307: Reward = 594.00, Steps = 4, Loss = 15.1500, Exploration Rate = 0.1000, Train Count = 43503\n",
      "Episode 5308: Reward = 588.00, Steps = 6, Loss = 10.1077, Exploration Rate = 0.1000, Train Count = 43509\n",
      "Episode 5309: Reward = 585.00, Steps = 7, Loss = 13.9477, Exploration Rate = 0.1000, Train Count = 43516\n",
      "Episode 5310: Reward = 588.00, Steps = 6, Loss = 17.3384, Exploration Rate = 0.1000, Train Count = 43522\n",
      "Episode 5311: Reward = 597.00, Steps = 3, Loss = 13.0933, Exploration Rate = 0.1000, Train Count = 43525\n",
      "Episode 5312: Reward = 585.00, Steps = 7, Loss = 15.5366, Exploration Rate = 0.1000, Train Count = 43532\n",
      "Episode 5313: Reward = 597.00, Steps = 3, Loss = 22.1489, Exploration Rate = 0.1000, Train Count = 43535\n",
      "Episode 5314: Reward = 585.00, Steps = 7, Loss = 11.4314, Exploration Rate = 0.1000, Train Count = 43542\n",
      "Episode 5315: Reward = 582.00, Steps = 8, Loss = 11.8390, Exploration Rate = 0.1000, Train Count = 43550\n",
      "Episode 5316: Reward = 594.00, Steps = 4, Loss = 13.5807, Exploration Rate = 0.1000, Train Count = 43554\n",
      "Episode 5317: Reward = 600.00, Steps = 2, Loss = 8.4276, Exploration Rate = 0.1000, Train Count = 43556\n",
      "Episode 5318: Reward = 597.00, Steps = 3, Loss = 19.6848, Exploration Rate = 0.1000, Train Count = 43559\n",
      "Episode 5319: Reward = 591.00, Steps = 5, Loss = 15.8629, Exploration Rate = 0.1000, Train Count = 43564\n",
      "Episode 5320: Reward = 591.00, Steps = 5, Loss = 15.1314, Exploration Rate = 0.1000, Train Count = 43569\n",
      "Episode 5321: Reward = 588.00, Steps = 6, Loss = 12.9524, Exploration Rate = 0.1000, Train Count = 43575\n",
      "Episode 5322: Reward = 600.00, Steps = 2, Loss = 12.5430, Exploration Rate = 0.1000, Train Count = 43577\n",
      "Episode 5323: Reward = 591.00, Steps = 5, Loss = 13.2858, Exploration Rate = 0.1000, Train Count = 43582\n",
      "Episode 5324: Reward = 535.00, Steps = 8, Loss = 11.7842, Exploration Rate = 0.1000, Train Count = 43590\n",
      "Episode 5325: Reward = 594.00, Steps = 4, Loss = 9.0648, Exploration Rate = 0.1000, Train Count = 43594\n",
      "Episode 5326: Reward = 597.00, Steps = 3, Loss = 14.8297, Exploration Rate = 0.1000, Train Count = 43597\n",
      "Episode 5327: Reward = 579.00, Steps = 9, Loss = 9.9804, Exploration Rate = 0.1000, Train Count = 43606\n",
      "Episode 5328: Reward = 594.00, Steps = 4, Loss = 9.2392, Exploration Rate = 0.1000, Train Count = 43610\n",
      "Episode 5329: Reward = 588.00, Steps = 6, Loss = 13.1141, Exploration Rate = 0.1000, Train Count = 43616\n",
      "Episode 5330: Reward = 588.00, Steps = 6, Loss = 10.0289, Exploration Rate = 0.1000, Train Count = 43622\n",
      "Episode 5331: Reward = 591.00, Steps = 5, Loss = 8.6299, Exploration Rate = 0.1000, Train Count = 43627\n",
      "Episode 5332: Reward = 597.00, Steps = 3, Loss = 7.8423, Exploration Rate = 0.1000, Train Count = 43630\n",
      "Episode 5333: Reward = 594.00, Steps = 4, Loss = 8.2271, Exploration Rate = 0.1000, Train Count = 43634\n",
      "Episode 5334: Reward = 582.00, Steps = 8, Loss = 8.0940, Exploration Rate = 0.1000, Train Count = 43642\n",
      "Episode 5335: Reward = 594.00, Steps = 4, Loss = 4.8137, Exploration Rate = 0.1000, Train Count = 43646\n",
      "Episode 5336: Reward = 594.00, Steps = 4, Loss = 5.0137, Exploration Rate = 0.1000, Train Count = 43650\n",
      "Episode 5337: Reward = 491.00, Steps = 7, Loss = 11.3622, Exploration Rate = 0.1000, Train Count = 43657\n",
      "Episode 5338: Reward = 591.00, Steps = 5, Loss = 11.3452, Exploration Rate = 0.1000, Train Count = 43662\n",
      "Episode 5339: Reward = 594.00, Steps = 4, Loss = 15.2743, Exploration Rate = 0.1000, Train Count = 43666\n",
      "Episode 5340: Reward = 588.00, Steps = 6, Loss = 13.7443, Exploration Rate = 0.1000, Train Count = 43672\n",
      "Episode 5341: Reward = 585.00, Steps = 7, Loss = 9.6144, Exploration Rate = 0.1000, Train Count = 43679\n",
      "Episode 5342: Reward = 582.00, Steps = 8, Loss = 10.0748, Exploration Rate = 0.1000, Train Count = 43687\n",
      "Episode 5343: Reward = 597.00, Steps = 3, Loss = 11.6221, Exploration Rate = 0.1000, Train Count = 43690\n",
      "Episode 5344: Reward = 594.00, Steps = 4, Loss = 10.2164, Exploration Rate = 0.1000, Train Count = 43694\n",
      "Episode 5345: Reward = 594.00, Steps = 4, Loss = 6.5361, Exploration Rate = 0.1000, Train Count = 43698\n",
      "Episode 5346: Reward = 597.00, Steps = 3, Loss = 9.9524, Exploration Rate = 0.1000, Train Count = 43701\n",
      "Episode 5347: Reward = 582.00, Steps = 8, Loss = 6.7685, Exploration Rate = 0.1000, Train Count = 43709\n",
      "Episode 5348: Reward = 532.00, Steps = 9, Loss = 7.7828, Exploration Rate = 0.1000, Train Count = 43718\n",
      "Episode 5349: Reward = 594.00, Steps = 4, Loss = 11.3358, Exploration Rate = 0.1000, Train Count = 43722\n",
      "Episode 5350: Reward = 588.00, Steps = 6, Loss = 13.2286, Exploration Rate = 0.1000, Train Count = 43728\n",
      "Episode 5351: Reward = 591.00, Steps = 5, Loss = 8.8015, Exploration Rate = 0.1000, Train Count = 43733\n",
      "Episode 5352: Reward = 588.00, Steps = 6, Loss = 8.9011, Exploration Rate = 0.1000, Train Count = 43739\n",
      "Episode 5353: Reward = 594.00, Steps = 4, Loss = 10.4697, Exploration Rate = 0.1000, Train Count = 43743\n",
      "Episode 5354: Reward = 591.00, Steps = 5, Loss = 5.7649, Exploration Rate = 0.1000, Train Count = 43748\n",
      "Episode 5355: Reward = 579.00, Steps = 9, Loss = 8.6773, Exploration Rate = 0.1000, Train Count = 43757\n",
      "Episode 5356: Reward = 585.00, Steps = 7, Loss = 8.1053, Exploration Rate = 0.1000, Train Count = 43764\n",
      "Episode 5357: Reward = 597.00, Steps = 3, Loss = 3.8510, Exploration Rate = 0.1000, Train Count = 43767\n",
      "Episode 5358: Reward = 588.00, Steps = 6, Loss = 9.0888, Exploration Rate = 0.1000, Train Count = 43773\n",
      "Episode 5359: Reward = 579.00, Steps = 9, Loss = 5.6713, Exploration Rate = 0.1000, Train Count = 43782\n",
      "Episode 5360: Reward = 591.00, Steps = 5, Loss = 8.3409, Exploration Rate = 0.1000, Train Count = 43787\n",
      "Episode 5361: Reward = 591.00, Steps = 5, Loss = 8.7105, Exploration Rate = 0.1000, Train Count = 43792\n",
      "Episode 5362: Reward = 585.00, Steps = 7, Loss = 8.7164, Exploration Rate = 0.1000, Train Count = 43799\n",
      "Episode 5363: Reward = 588.00, Steps = 6, Loss = 33.5585, Exploration Rate = 0.1000, Train Count = 43805\n",
      "Episode 5364: Reward = 582.00, Steps = 8, Loss = 30.4863, Exploration Rate = 0.1000, Train Count = 43813\n",
      "Episode 5365: Reward = 588.00, Steps = 6, Loss = 21.7979, Exploration Rate = 0.1000, Train Count = 43819\n",
      "Episode 5366: Reward = 582.00, Steps = 8, Loss = 18.9210, Exploration Rate = 0.1000, Train Count = 43827\n",
      "Episode 5367: Reward = 594.00, Steps = 4, Loss = 15.9099, Exploration Rate = 0.1000, Train Count = 43831\n",
      "Episode 5368: Reward = 579.00, Steps = 9, Loss = 15.0085, Exploration Rate = 0.1000, Train Count = 43840\n",
      "Episode 5369: Reward = 597.00, Steps = 3, Loss = 10.8897, Exploration Rate = 0.1000, Train Count = 43843\n",
      "Episode 5370: Reward = 597.00, Steps = 3, Loss = 9.0200, Exploration Rate = 0.1000, Train Count = 43846\n",
      "Episode 5371: Reward = 588.00, Steps = 6, Loss = 10.7841, Exploration Rate = 0.1000, Train Count = 43852\n",
      "Episode 5372: Reward = 591.00, Steps = 5, Loss = 11.4462, Exploration Rate = 0.1000, Train Count = 43857\n",
      "Episode 5373: Reward = 591.00, Steps = 5, Loss = 9.9117, Exploration Rate = 0.1000, Train Count = 43862\n",
      "Episode 5374: Reward = 591.00, Steps = 5, Loss = 12.3882, Exploration Rate = 0.1000, Train Count = 43867\n",
      "Episode 5375: Reward = 594.00, Steps = 4, Loss = 13.1425, Exploration Rate = 0.1000, Train Count = 43871\n",
      "Episode 5376: Reward = 588.00, Steps = 6, Loss = 11.4833, Exploration Rate = 0.1000, Train Count = 43877\n",
      "Episode 5377: Reward = 585.00, Steps = 7, Loss = 7.2654, Exploration Rate = 0.1000, Train Count = 43884\n",
      "Episode 5378: Reward = 591.00, Steps = 5, Loss = 6.3000, Exploration Rate = 0.1000, Train Count = 43889\n",
      "Episode 5379: Reward = 588.00, Steps = 6, Loss = 6.3217, Exploration Rate = 0.1000, Train Count = 43895\n",
      "Episode 5380: Reward = 558.00, Steps = 16, Loss = 12.8927, Exploration Rate = 0.1000, Train Count = 43911\n",
      "Episode 5381: Reward = 591.00, Steps = 5, Loss = 8.8634, Exploration Rate = 0.1000, Train Count = 43916\n",
      "Episode 5382: Reward = 573.00, Steps = 11, Loss = 14.3816, Exploration Rate = 0.1000, Train Count = 43927\n",
      "Episode 5383: Reward = 582.00, Steps = 8, Loss = 9.4648, Exploration Rate = 0.1000, Train Count = 43935\n",
      "Episode 5384: Reward = 591.00, Steps = 5, Loss = 9.1879, Exploration Rate = 0.1000, Train Count = 43940\n",
      "Episode 5385: Reward = 594.00, Steps = 4, Loss = 6.9429, Exploration Rate = 0.1000, Train Count = 43944\n",
      "Episode 5386: Reward = 597.00, Steps = 3, Loss = 8.6844, Exploration Rate = 0.1000, Train Count = 43947\n",
      "Episode 5387: Reward = 555.00, Steps = 17, Loss = 8.1235, Exploration Rate = 0.1000, Train Count = 43964\n",
      "Episode 5388: Reward = 591.00, Steps = 5, Loss = 22.7881, Exploration Rate = 0.1000, Train Count = 43969\n",
      "Episode 5389: Reward = 585.00, Steps = 7, Loss = 13.8583, Exploration Rate = 0.1000, Train Count = 43976\n",
      "Episode 5390: Reward = 591.00, Steps = 5, Loss = 6.6380, Exploration Rate = 0.1000, Train Count = 43981\n",
      "Episode 5391: Reward = 588.00, Steps = 6, Loss = 6.6902, Exploration Rate = 0.1000, Train Count = 43987\n",
      "Episode 5392: Reward = 588.00, Steps = 6, Loss = 7.2708, Exploration Rate = 0.1000, Train Count = 43993\n",
      "Episode 5393: Reward = 597.00, Steps = 3, Loss = 6.1121, Exploration Rate = 0.1000, Train Count = 43996\n",
      "Episode 5394: Reward = 585.00, Steps = 7, Loss = 5.6266, Exploration Rate = 0.1000, Train Count = 44003\n",
      "Episode 5395: Reward = 585.00, Steps = 7, Loss = 5.6825, Exploration Rate = 0.1000, Train Count = 44010\n",
      "Episode 5396: Reward = 591.00, Steps = 5, Loss = 6.1975, Exploration Rate = 0.1000, Train Count = 44015\n",
      "Episode 5397: Reward = 597.00, Steps = 3, Loss = 5.7221, Exploration Rate = 0.1000, Train Count = 44018\n",
      "Episode 5398: Reward = 532.00, Steps = 9, Loss = 6.7867, Exploration Rate = 0.1000, Train Count = 44027\n",
      "Episode 5399: Reward = 588.00, Steps = 6, Loss = 6.1305, Exploration Rate = 0.1000, Train Count = 44033\n",
      "Episode 5400: Reward = 591.00, Steps = 5, Loss = 8.8604, Exploration Rate = 0.1000, Train Count = 44038\n",
      "Episode 5401: Reward = 600.00, Steps = 2, Loss = 11.3827, Exploration Rate = 0.1000, Train Count = 44040\n",
      "Episode 5402: Reward = 582.00, Steps = 8, Loss = 4.4995, Exploration Rate = 0.1000, Train Count = 44048\n",
      "Episode 5403: Reward = 579.00, Steps = 9, Loss = 3.8310, Exploration Rate = 0.1000, Train Count = 44057\n",
      "Episode 5404: Reward = 585.00, Steps = 7, Loss = 4.0528, Exploration Rate = 0.1000, Train Count = 44064\n",
      "Episode 5405: Reward = 594.00, Steps = 4, Loss = 6.0357, Exploration Rate = 0.1000, Train Count = 44068\n",
      "Episode 5406: Reward = 597.00, Steps = 3, Loss = 5.2356, Exploration Rate = 0.1000, Train Count = 44071\n",
      "Episode 5407: Reward = 576.00, Steps = 10, Loss = 7.3364, Exploration Rate = 0.1000, Train Count = 44081\n",
      "Episode 5408: Reward = 573.00, Steps = 11, Loss = 6.2394, Exploration Rate = 0.1000, Train Count = 44092\n",
      "Episode 5409: Reward = 582.00, Steps = 8, Loss = 6.8000, Exploration Rate = 0.1000, Train Count = 44100\n",
      "Episode 5410: Reward = 597.00, Steps = 3, Loss = 5.0918, Exploration Rate = 0.1000, Train Count = 44103\n",
      "Episode 5411: Reward = 564.00, Steps = 14, Loss = 12.1074, Exploration Rate = 0.1000, Train Count = 44117\n",
      "Episode 5412: Reward = 591.00, Steps = 5, Loss = 5.7186, Exploration Rate = 0.1000, Train Count = 44122\n",
      "Episode 5413: Reward = 591.00, Steps = 5, Loss = 5.5769, Exploration Rate = 0.1000, Train Count = 44127\n",
      "Episode 5414: Reward = 597.00, Steps = 3, Loss = 3.9032, Exploration Rate = 0.1000, Train Count = 44130\n",
      "Episode 5415: Reward = 594.00, Steps = 4, Loss = 4.6681, Exploration Rate = 0.1000, Train Count = 44134\n",
      "Episode 5416: Reward = 573.00, Steps = 11, Loss = 12.0411, Exploration Rate = 0.1000, Train Count = 44145\n",
      "Episode 5417: Reward = 526.00, Steps = 11, Loss = 8.0771, Exploration Rate = 0.1000, Train Count = 44156\n",
      "Episode 5418: Reward = 594.00, Steps = 4, Loss = 4.9374, Exploration Rate = 0.1000, Train Count = 44160\n",
      "Episode 5419: Reward = 588.00, Steps = 6, Loss = 6.1373, Exploration Rate = 0.1000, Train Count = 44166\n",
      "Episode 5420: Reward = 594.00, Steps = 4, Loss = 4.6423, Exploration Rate = 0.1000, Train Count = 44170\n",
      "Episode 5421: Reward = 591.00, Steps = 5, Loss = 5.2941, Exploration Rate = 0.1000, Train Count = 44175\n",
      "Episode 5422: Reward = 585.00, Steps = 7, Loss = 4.7438, Exploration Rate = 0.1000, Train Count = 44182\n",
      "Episode 5423: Reward = 591.00, Steps = 5, Loss = 5.5307, Exploration Rate = 0.1000, Train Count = 44187\n",
      "Episode 5424: Reward = 594.00, Steps = 4, Loss = 2.9619, Exploration Rate = 0.1000, Train Count = 44191\n",
      "Episode 5425: Reward = 576.00, Steps = 10, Loss = 5.7784, Exploration Rate = 0.1000, Train Count = 44201\n",
      "Episode 5426: Reward = 591.00, Steps = 5, Loss = 7.6588, Exploration Rate = 0.1000, Train Count = 44206\n",
      "Episode 5427: Reward = 585.00, Steps = 7, Loss = 5.4914, Exploration Rate = 0.1000, Train Count = 44213\n",
      "Episode 5428: Reward = 579.00, Steps = 9, Loss = 4.3069, Exploration Rate = 0.1000, Train Count = 44222\n",
      "Episode 5429: Reward = 579.00, Steps = 9, Loss = 3.9797, Exploration Rate = 0.1000, Train Count = 44231\n",
      "Episode 5430: Reward = 582.00, Steps = 8, Loss = 4.2294, Exploration Rate = 0.1000, Train Count = 44239\n",
      "Episode 5431: Reward = 529.00, Steps = 10, Loss = 3.9814, Exploration Rate = 0.1000, Train Count = 44249\n",
      "Episode 5432: Reward = 591.00, Steps = 5, Loss = 5.2882, Exploration Rate = 0.1000, Train Count = 44254\n",
      "Episode 5433: Reward = 588.00, Steps = 6, Loss = 3.9274, Exploration Rate = 0.1000, Train Count = 44260\n",
      "Episode 5434: Reward = 585.00, Steps = 7, Loss = 6.6141, Exploration Rate = 0.1000, Train Count = 44267\n",
      "Episode 5435: Reward = 588.00, Steps = 6, Loss = 2.2569, Exploration Rate = 0.1000, Train Count = 44273\n",
      "Episode 5436: Reward = 591.00, Steps = 5, Loss = 5.7438, Exploration Rate = 0.1000, Train Count = 44278\n",
      "Episode 5437: Reward = 467.00, Steps = 15, Loss = 5.3674, Exploration Rate = 0.1000, Train Count = 44293\n",
      "Episode 5438: Reward = 535.00, Steps = 8, Loss = 9.1088, Exploration Rate = 0.1000, Train Count = 44301\n",
      "Episode 5439: Reward = 591.00, Steps = 5, Loss = 31.5085, Exploration Rate = 0.1000, Train Count = 44306\n",
      "Episode 5440: Reward = 579.00, Steps = 9, Loss = 30.5272, Exploration Rate = 0.1000, Train Count = 44315\n",
      "Episode 5441: Reward = 597.00, Steps = 3, Loss = 27.5112, Exploration Rate = 0.1000, Train Count = 44318\n",
      "Episode 5442: Reward = 582.00, Steps = 8, Loss = 17.8897, Exploration Rate = 0.1000, Train Count = 44326\n",
      "Episode 5443: Reward = 597.00, Steps = 3, Loss = 13.0419, Exploration Rate = 0.1000, Train Count = 44329\n",
      "Episode 5444: Reward = 591.00, Steps = 5, Loss = 11.6315, Exploration Rate = 0.1000, Train Count = 44334\n",
      "Episode 5445: Reward = 597.00, Steps = 3, Loss = 10.3752, Exploration Rate = 0.1000, Train Count = 44337\n",
      "Episode 5446: Reward = 588.00, Steps = 6, Loss = 14.0069, Exploration Rate = 0.1000, Train Count = 44343\n",
      "Episode 5447: Reward = 585.00, Steps = 7, Loss = 16.8485, Exploration Rate = 0.1000, Train Count = 44350\n",
      "Episode 5448: Reward = 585.00, Steps = 7, Loss = 11.3045, Exploration Rate = 0.1000, Train Count = 44357\n",
      "Episode 5449: Reward = 582.00, Steps = 8, Loss = 6.8674, Exploration Rate = 0.1000, Train Count = 44365\n",
      "Episode 5450: Reward = 482.00, Steps = 10, Loss = 10.8213, Exploration Rate = 0.1000, Train Count = 44375\n",
      "Episode 5451: Reward = 591.00, Steps = 5, Loss = 6.5938, Exploration Rate = 0.1000, Train Count = 44380\n",
      "Episode 5452: Reward = 588.00, Steps = 6, Loss = 9.2094, Exploration Rate = 0.1000, Train Count = 44386\n",
      "Episode 5453: Reward = 594.00, Steps = 4, Loss = 10.0843, Exploration Rate = 0.1000, Train Count = 44390\n",
      "Episode 5454: Reward = 588.00, Steps = 6, Loss = 7.8359, Exploration Rate = 0.1000, Train Count = 44396\n",
      "Episode 5455: Reward = 591.00, Steps = 5, Loss = 10.0752, Exploration Rate = 0.1000, Train Count = 44401\n",
      "Episode 5456: Reward = 585.00, Steps = 7, Loss = 7.5416, Exploration Rate = 0.1000, Train Count = 44408\n",
      "Episode 5457: Reward = 591.00, Steps = 5, Loss = 7.0831, Exploration Rate = 0.1000, Train Count = 44413\n",
      "Episode 5458: Reward = 585.00, Steps = 7, Loss = 10.2735, Exploration Rate = 0.1000, Train Count = 44420\n",
      "Episode 5459: Reward = 600.00, Steps = 2, Loss = 7.5269, Exploration Rate = 0.1000, Train Count = 44422\n",
      "Episode 5460: Reward = 591.00, Steps = 5, Loss = 6.4522, Exploration Rate = 0.1000, Train Count = 44427\n",
      "Episode 5461: Reward = 588.00, Steps = 6, Loss = 5.9698, Exploration Rate = 0.1000, Train Count = 44433\n",
      "Episode 5462: Reward = 597.00, Steps = 3, Loss = 5.0999, Exploration Rate = 0.1000, Train Count = 44436\n",
      "Episode 5463: Reward = 594.00, Steps = 4, Loss = 6.4409, Exploration Rate = 0.1000, Train Count = 44440\n",
      "Episode 5464: Reward = 591.00, Steps = 5, Loss = 3.9373, Exploration Rate = 0.1000, Train Count = 44445\n",
      "Episode 5465: Reward = 585.00, Steps = 7, Loss = 4.8612, Exploration Rate = 0.1000, Train Count = 44452\n",
      "Episode 5466: Reward = 594.00, Steps = 4, Loss = 4.8816, Exploration Rate = 0.1000, Train Count = 44456\n",
      "Episode 5467: Reward = 582.00, Steps = 8, Loss = 5.6047, Exploration Rate = 0.1000, Train Count = 44464\n",
      "Episode 5468: Reward = 529.00, Steps = 10, Loss = 7.6076, Exploration Rate = 0.1000, Train Count = 44474\n",
      "Episode 5469: Reward = 526.00, Steps = 11, Loss = 7.5607, Exploration Rate = 0.1000, Train Count = 44485\n",
      "Episode 5470: Reward = 579.00, Steps = 9, Loss = 6.0633, Exploration Rate = 0.1000, Train Count = 44494\n",
      "Episode 5471: Reward = 520.00, Steps = 13, Loss = 5.8675, Exploration Rate = 0.1000, Train Count = 44507\n",
      "Episode 5472: Reward = 508.00, Steps = 17, Loss = 8.6056, Exploration Rate = 0.1000, Train Count = 44524\n",
      "Episode 5473: Reward = 591.00, Steps = 5, Loss = 6.0880, Exploration Rate = 0.1000, Train Count = 44529\n",
      "Episode 5474: Reward = 597.00, Steps = 3, Loss = 7.1615, Exploration Rate = 0.1000, Train Count = 44532\n",
      "Episode 5475: Reward = 594.00, Steps = 4, Loss = 7.7989, Exploration Rate = 0.1000, Train Count = 44536\n",
      "Episode 5476: Reward = 588.00, Steps = 6, Loss = 5.2188, Exploration Rate = 0.1000, Train Count = 44542\n",
      "Episode 5477: Reward = 597.00, Steps = 3, Loss = 3.4171, Exploration Rate = 0.1000, Train Count = 44545\n",
      "Episode 5478: Reward = 588.00, Steps = 6, Loss = 4.1789, Exploration Rate = 0.1000, Train Count = 44551\n",
      "Episode 5479: Reward = 544.00, Steps = 5, Loss = 3.2988, Exploration Rate = 0.1000, Train Count = 44556\n",
      "Episode 5480: Reward = 594.00, Steps = 4, Loss = 7.2553, Exploration Rate = 0.1000, Train Count = 44560\n",
      "Episode 5481: Reward = 588.00, Steps = 6, Loss = 5.4878, Exploration Rate = 0.1000, Train Count = 44566\n",
      "Episode 5482: Reward = 591.00, Steps = 5, Loss = 4.8140, Exploration Rate = 0.1000, Train Count = 44571\n",
      "Episode 5483: Reward = 591.00, Steps = 5, Loss = 3.8643, Exploration Rate = 0.1000, Train Count = 44576\n",
      "Episode 5484: Reward = 585.00, Steps = 7, Loss = 3.1673, Exploration Rate = 0.1000, Train Count = 44583\n",
      "Episode 5485: Reward = 588.00, Steps = 6, Loss = 3.7583, Exploration Rate = 0.1000, Train Count = 44589\n",
      "Episode 5486: Reward = 594.00, Steps = 4, Loss = 5.3518, Exploration Rate = 0.1000, Train Count = 44593\n",
      "Episode 5487: Reward = 585.00, Steps = 7, Loss = 3.4683, Exploration Rate = 0.1000, Train Count = 44600\n",
      "Episode 5488: Reward = 538.00, Steps = 7, Loss = 2.9167, Exploration Rate = 0.1000, Train Count = 44607\n",
      "Episode 5489: Reward = 594.00, Steps = 4, Loss = 8.5078, Exploration Rate = 0.1000, Train Count = 44611\n",
      "Episode 5490: Reward = 588.00, Steps = 6, Loss = 4.8709, Exploration Rate = 0.1000, Train Count = 44617\n",
      "Episode 5491: Reward = 591.00, Steps = 5, Loss = 4.0928, Exploration Rate = 0.1000, Train Count = 44622\n",
      "Episode 5492: Reward = 544.00, Steps = 5, Loss = 13.5013, Exploration Rate = 0.1000, Train Count = 44627\n",
      "Episode 5493: Reward = 532.00, Steps = 9, Loss = 9.5301, Exploration Rate = 0.1000, Train Count = 44636\n",
      "Episode 5494: Reward = 579.00, Steps = 9, Loss = 10.5399, Exploration Rate = 0.1000, Train Count = 44645\n",
      "Episode 5495: Reward = 514.00, Steps = 15, Loss = 9.8196, Exploration Rate = 0.1000, Train Count = 44660\n",
      "Episode 5496: Reward = 579.00, Steps = 9, Loss = 9.2767, Exploration Rate = 0.1000, Train Count = 44669\n",
      "Episode 5497: Reward = 585.00, Steps = 7, Loss = 6.2718, Exploration Rate = 0.1000, Train Count = 44676\n",
      "Episode 5498: Reward = 588.00, Steps = 6, Loss = 10.1399, Exploration Rate = 0.1000, Train Count = 44682\n",
      "Episode 5499: Reward = 591.00, Steps = 5, Loss = 7.0218, Exploration Rate = 0.1000, Train Count = 44687\n",
      "Episode 5500: Reward = 597.00, Steps = 3, Loss = 3.2356, Exploration Rate = 0.1000, Train Count = 44690\n",
      "Episode 5501: Reward = 538.00, Steps = 7, Loss = 5.3302, Exploration Rate = 0.1000, Train Count = 44697\n",
      "Episode 5502: Reward = 591.00, Steps = 5, Loss = 5.1986, Exploration Rate = 0.1000, Train Count = 44702\n",
      "Episode 5503: Reward = 582.00, Steps = 8, Loss = 5.7042, Exploration Rate = 0.1000, Train Count = 44710\n",
      "Episode 5504: Reward = 573.00, Steps = 11, Loss = 3.8558, Exploration Rate = 0.1000, Train Count = 44721\n",
      "Episode 5505: Reward = 591.00, Steps = 5, Loss = 2.8215, Exploration Rate = 0.1000, Train Count = 44726\n",
      "Episode 5506: Reward = 588.00, Steps = 6, Loss = 4.9475, Exploration Rate = 0.1000, Train Count = 44732\n",
      "Episode 5507: Reward = 582.00, Steps = 8, Loss = 6.4505, Exploration Rate = 0.1000, Train Count = 44740\n",
      "Episode 5508: Reward = 582.00, Steps = 8, Loss = 8.2408, Exploration Rate = 0.1000, Train Count = 44748\n",
      "Episode 5509: Reward = 567.00, Steps = 13, Loss = 8.4316, Exploration Rate = 0.1000, Train Count = 44761\n",
      "Episode 5510: Reward = 591.00, Steps = 5, Loss = 5.3152, Exploration Rate = 0.1000, Train Count = 44766\n",
      "Episode 5511: Reward = 588.00, Steps = 6, Loss = 6.3966, Exploration Rate = 0.1000, Train Count = 44772\n",
      "Episode 5512: Reward = 594.00, Steps = 4, Loss = 7.9752, Exploration Rate = 0.1000, Train Count = 44776\n",
      "Episode 5513: Reward = 576.00, Steps = 10, Loss = 4.1758, Exploration Rate = 0.1000, Train Count = 44786\n",
      "Episode 5514: Reward = 597.00, Steps = 3, Loss = 5.4308, Exploration Rate = 0.1000, Train Count = 44789\n",
      "Episode 5515: Reward = 591.00, Steps = 5, Loss = 5.1808, Exploration Rate = 0.1000, Train Count = 44794\n",
      "Episode 5516: Reward = 585.00, Steps = 7, Loss = 9.6136, Exploration Rate = 0.1000, Train Count = 44801\n",
      "Episode 5517: Reward = 576.00, Steps = 10, Loss = 33.9103, Exploration Rate = 0.1000, Train Count = 44811\n",
      "Episode 5518: Reward = 588.00, Steps = 6, Loss = 28.8049, Exploration Rate = 0.1000, Train Count = 44817\n",
      "Episode 5519: Reward = 594.00, Steps = 4, Loss = 21.9762, Exploration Rate = 0.1000, Train Count = 44821\n",
      "Episode 5520: Reward = 591.00, Steps = 5, Loss = 20.1952, Exploration Rate = 0.1000, Train Count = 44826\n",
      "Episode 5521: Reward = 582.00, Steps = 8, Loss = 16.3793, Exploration Rate = 0.1000, Train Count = 44834\n",
      "Episode 5522: Reward = 591.00, Steps = 5, Loss = 13.8999, Exploration Rate = 0.1000, Train Count = 44839\n",
      "Episode 5523: Reward = 591.00, Steps = 5, Loss = 11.8551, Exploration Rate = 0.1000, Train Count = 44844\n",
      "Episode 5524: Reward = 588.00, Steps = 6, Loss = 10.9575, Exploration Rate = 0.1000, Train Count = 44850\n",
      "Episode 5525: Reward = 588.00, Steps = 6, Loss = 11.3210, Exploration Rate = 0.1000, Train Count = 44856\n",
      "Episode 5526: Reward = 597.00, Steps = 3, Loss = 8.6474, Exploration Rate = 0.1000, Train Count = 44859\n",
      "Episode 5527: Reward = 591.00, Steps = 5, Loss = 10.1625, Exploration Rate = 0.1000, Train Count = 44864\n",
      "Episode 5528: Reward = 591.00, Steps = 5, Loss = 6.9367, Exploration Rate = 0.1000, Train Count = 44869\n",
      "Episode 5529: Reward = 597.00, Steps = 3, Loss = 7.0461, Exploration Rate = 0.1000, Train Count = 44872\n",
      "Episode 5530: Reward = 588.00, Steps = 6, Loss = 4.5381, Exploration Rate = 0.1000, Train Count = 44878\n",
      "Episode 5531: Reward = 579.00, Steps = 9, Loss = 6.2810, Exploration Rate = 0.1000, Train Count = 44887\n",
      "Episode 5532: Reward = 588.00, Steps = 6, Loss = 4.1677, Exploration Rate = 0.1000, Train Count = 44893\n",
      "Episode 5533: Reward = 597.00, Steps = 3, Loss = 4.8704, Exploration Rate = 0.1000, Train Count = 44896\n",
      "Episode 5534: Reward = 588.00, Steps = 6, Loss = 3.2644, Exploration Rate = 0.1000, Train Count = 44902\n",
      "Episode 5535: Reward = 594.00, Steps = 4, Loss = 2.4416, Exploration Rate = 0.1000, Train Count = 44906\n",
      "Episode 5536: Reward = 591.00, Steps = 5, Loss = 3.7538, Exploration Rate = 0.1000, Train Count = 44911\n",
      "Episode 5537: Reward = 594.00, Steps = 4, Loss = 5.0276, Exploration Rate = 0.1000, Train Count = 44915\n",
      "Episode 5538: Reward = 570.00, Steps = 12, Loss = 5.2556, Exploration Rate = 0.1000, Train Count = 44927\n",
      "Episode 5539: Reward = 579.00, Steps = 9, Loss = 10.0436, Exploration Rate = 0.1000, Train Count = 44936\n",
      "Episode 5540: Reward = 588.00, Steps = 6, Loss = 9.7764, Exploration Rate = 0.1000, Train Count = 44942\n",
      "Episode 5541: Reward = 594.00, Steps = 4, Loss = 6.8329, Exploration Rate = 0.1000, Train Count = 44946\n",
      "Episode 5542: Reward = 585.00, Steps = 7, Loss = 8.1036, Exploration Rate = 0.1000, Train Count = 44953\n",
      "Episode 5543: Reward = 576.00, Steps = 10, Loss = 6.3730, Exploration Rate = 0.1000, Train Count = 44963\n",
      "Episode 5544: Reward = 585.00, Steps = 7, Loss = 5.3985, Exploration Rate = 0.1000, Train Count = 44970\n",
      "Episode 5545: Reward = 591.00, Steps = 5, Loss = 10.6068, Exploration Rate = 0.1000, Train Count = 44975\n",
      "Episode 5546: Reward = 597.00, Steps = 3, Loss = 7.3048, Exploration Rate = 0.1000, Train Count = 44978\n",
      "Episode 5547: Reward = 597.00, Steps = 3, Loss = 6.4140, Exploration Rate = 0.1000, Train Count = 44981\n",
      "Episode 5548: Reward = 576.00, Steps = 10, Loss = 7.5098, Exploration Rate = 0.1000, Train Count = 44991\n",
      "Episode 5549: Reward = 532.00, Steps = 9, Loss = 10.0538, Exploration Rate = 0.1000, Train Count = 45000\n",
      "Episode 5550: Reward = 585.00, Steps = 7, Loss = 6.8530, Exploration Rate = 0.1000, Train Count = 45007\n",
      "Episode 5551: Reward = 594.00, Steps = 4, Loss = 3.8096, Exploration Rate = 0.1000, Train Count = 45011\n",
      "Episode 5552: Reward = 588.00, Steps = 6, Loss = 7.6503, Exploration Rate = 0.1000, Train Count = 45017\n",
      "Episode 5553: Reward = 591.00, Steps = 5, Loss = 4.4537, Exploration Rate = 0.1000, Train Count = 45022\n",
      "Episode 5554: Reward = 594.00, Steps = 4, Loss = 7.5507, Exploration Rate = 0.1000, Train Count = 45026\n",
      "Episode 5555: Reward = 579.00, Steps = 9, Loss = 7.7560, Exploration Rate = 0.1000, Train Count = 45035\n",
      "Episode 5556: Reward = 597.00, Steps = 3, Loss = 4.6798, Exploration Rate = 0.1000, Train Count = 45038\n",
      "Episode 5557: Reward = 594.00, Steps = 4, Loss = 14.6533, Exploration Rate = 0.1000, Train Count = 45042\n",
      "Episode 5558: Reward = 591.00, Steps = 5, Loss = 8.4548, Exploration Rate = 0.1000, Train Count = 45047\n",
      "Episode 5559: Reward = 588.00, Steps = 6, Loss = 6.4774, Exploration Rate = 0.1000, Train Count = 45053\n",
      "Episode 5560: Reward = 591.00, Steps = 5, Loss = 4.9584, Exploration Rate = 0.1000, Train Count = 45058\n",
      "Episode 5561: Reward = 579.00, Steps = 9, Loss = 3.9138, Exploration Rate = 0.1000, Train Count = 45067\n",
      "Episode 5562: Reward = 591.00, Steps = 5, Loss = 4.2212, Exploration Rate = 0.1000, Train Count = 45072\n",
      "Episode 5563: Reward = 591.00, Steps = 5, Loss = 3.3486, Exploration Rate = 0.1000, Train Count = 45077\n",
      "Episode 5564: Reward = 591.00, Steps = 5, Loss = 6.1320, Exploration Rate = 0.1000, Train Count = 45082\n",
      "Episode 5565: Reward = 594.00, Steps = 4, Loss = 4.8746, Exploration Rate = 0.1000, Train Count = 45086\n",
      "Episode 5566: Reward = 585.00, Steps = 7, Loss = 9.3298, Exploration Rate = 0.1000, Train Count = 45093\n",
      "Episode 5567: Reward = 588.00, Steps = 6, Loss = 4.9639, Exploration Rate = 0.1000, Train Count = 45099\n",
      "Episode 5568: Reward = 588.00, Steps = 6, Loss = 4.2560, Exploration Rate = 0.1000, Train Count = 45105\n",
      "Episode 5569: Reward = 594.00, Steps = 4, Loss = 7.2431, Exploration Rate = 0.1000, Train Count = 45109\n",
      "Episode 5570: Reward = 576.00, Steps = 10, Loss = 4.6212, Exploration Rate = 0.1000, Train Count = 45119\n",
      "Episode 5571: Reward = 600.00, Steps = 2, Loss = 5.5972, Exploration Rate = 0.1000, Train Count = 45121\n",
      "Episode 5572: Reward = 594.00, Steps = 4, Loss = 2.7070, Exploration Rate = 0.1000, Train Count = 45125\n",
      "Episode 5573: Reward = 585.00, Steps = 7, Loss = 5.9506, Exploration Rate = 0.1000, Train Count = 45132\n",
      "Episode 5574: Reward = 564.00, Steps = 14, Loss = 4.5585, Exploration Rate = 0.1000, Train Count = 45146\n",
      "Episode 5575: Reward = 591.00, Steps = 5, Loss = 5.5663, Exploration Rate = 0.1000, Train Count = 45151\n",
      "Episode 5576: Reward = 585.00, Steps = 7, Loss = 4.5072, Exploration Rate = 0.1000, Train Count = 45158\n",
      "Episode 5577: Reward = 585.00, Steps = 7, Loss = 4.4819, Exploration Rate = 0.1000, Train Count = 45165\n",
      "Episode 5578: Reward = 600.00, Steps = 2, Loss = 4.4568, Exploration Rate = 0.1000, Train Count = 45167\n",
      "Episode 5579: Reward = 588.00, Steps = 6, Loss = 3.5502, Exploration Rate = 0.1000, Train Count = 45173\n",
      "Episode 5580: Reward = 591.00, Steps = 5, Loss = 5.5160, Exploration Rate = 0.1000, Train Count = 45178\n",
      "Episode 5581: Reward = 594.00, Steps = 4, Loss = 6.2287, Exploration Rate = 0.1000, Train Count = 45182\n",
      "Episode 5582: Reward = 582.00, Steps = 8, Loss = 3.3815, Exploration Rate = 0.1000, Train Count = 45190\n",
      "Episode 5583: Reward = 591.00, Steps = 5, Loss = 4.0057, Exploration Rate = 0.1000, Train Count = 45195\n",
      "Episode 5584: Reward = 585.00, Steps = 7, Loss = 4.1074, Exploration Rate = 0.1000, Train Count = 45202\n",
      "Episode 5585: Reward = 588.00, Steps = 6, Loss = 3.1182, Exploration Rate = 0.1000, Train Count = 45208\n",
      "Episode 5586: Reward = 594.00, Steps = 4, Loss = 3.0663, Exploration Rate = 0.1000, Train Count = 45212\n",
      "Episode 5587: Reward = 588.00, Steps = 6, Loss = 4.5406, Exploration Rate = 0.1000, Train Count = 45218\n",
      "Episode 5588: Reward = 588.00, Steps = 6, Loss = 3.6960, Exploration Rate = 0.1000, Train Count = 45224\n",
      "Episode 5589: Reward = 591.00, Steps = 5, Loss = 2.0067, Exploration Rate = 0.1000, Train Count = 45229\n",
      "Episode 5590: Reward = 579.00, Steps = 9, Loss = 3.9969, Exploration Rate = 0.1000, Train Count = 45238\n",
      "Episode 5591: Reward = 594.00, Steps = 4, Loss = 3.9357, Exploration Rate = 0.1000, Train Count = 45242\n",
      "Episode 5592: Reward = 597.00, Steps = 3, Loss = 8.6300, Exploration Rate = 0.1000, Train Count = 45245\n",
      "Episode 5593: Reward = 591.00, Steps = 5, Loss = 5.5738, Exploration Rate = 0.1000, Train Count = 45250\n",
      "Episode 5594: Reward = 564.00, Steps = 14, Loss = 4.4355, Exploration Rate = 0.1000, Train Count = 45264\n",
      "Episode 5595: Reward = 594.00, Steps = 4, Loss = 3.6399, Exploration Rate = 0.1000, Train Count = 45268\n",
      "Episode 5596: Reward = 597.00, Steps = 3, Loss = 1.8313, Exploration Rate = 0.1000, Train Count = 45271\n",
      "Episode 5597: Reward = 576.00, Steps = 10, Loss = 4.7438, Exploration Rate = 0.1000, Train Count = 45281\n",
      "Episode 5598: Reward = 591.00, Steps = 5, Loss = 3.0716, Exploration Rate = 0.1000, Train Count = 45286\n",
      "Episode 5599: Reward = 588.00, Steps = 6, Loss = 5.3804, Exploration Rate = 0.1000, Train Count = 45292\n",
      "Episode 5600: Reward = 591.00, Steps = 5, Loss = 10.2446, Exploration Rate = 0.1000, Train Count = 45297\n",
      "Episode 5601: Reward = 594.00, Steps = 4, Loss = 15.0484, Exploration Rate = 0.1000, Train Count = 45301\n",
      "Episode 5602: Reward = 594.00, Steps = 4, Loss = 41.0965, Exploration Rate = 0.1000, Train Count = 45305\n",
      "Episode 5603: Reward = 594.00, Steps = 4, Loss = 26.1693, Exploration Rate = 0.1000, Train Count = 45309\n",
      "Episode 5604: Reward = 591.00, Steps = 5, Loss = 24.0723, Exploration Rate = 0.1000, Train Count = 45314\n",
      "Episode 5605: Reward = 579.00, Steps = 9, Loss = 16.8903, Exploration Rate = 0.1000, Train Count = 45323\n",
      "Episode 5606: Reward = 597.00, Steps = 3, Loss = 14.1595, Exploration Rate = 0.1000, Train Count = 45326\n",
      "Episode 5607: Reward = 588.00, Steps = 6, Loss = 9.4947, Exploration Rate = 0.1000, Train Count = 45332\n",
      "Episode 5608: Reward = 585.00, Steps = 7, Loss = 9.6940, Exploration Rate = 0.1000, Train Count = 45339\n",
      "Episode 5609: Reward = 585.00, Steps = 7, Loss = 7.7496, Exploration Rate = 0.1000, Train Count = 45346\n",
      "Episode 5610: Reward = 491.00, Steps = 7, Loss = 6.0494, Exploration Rate = 0.1000, Train Count = 45353\n",
      "Episode 5611: Reward = 597.00, Steps = 3, Loss = 4.9869, Exploration Rate = 0.1000, Train Count = 45356\n",
      "Episode 5612: Reward = 491.00, Steps = 7, Loss = 6.5481, Exploration Rate = 0.1000, Train Count = 45363\n",
      "Episode 5613: Reward = 588.00, Steps = 6, Loss = 13.9186, Exploration Rate = 0.1000, Train Count = 45369\n",
      "Episode 5614: Reward = 588.00, Steps = 6, Loss = 9.1251, Exploration Rate = 0.1000, Train Count = 45375\n",
      "Episode 5615: Reward = 588.00, Steps = 6, Loss = 8.3778, Exploration Rate = 0.1000, Train Count = 45381\n",
      "Episode 5616: Reward = 526.00, Steps = 11, Loss = 10.9585, Exploration Rate = 0.1000, Train Count = 45392\n",
      "Episode 5617: Reward = 579.00, Steps = 9, Loss = 9.4988, Exploration Rate = 0.1000, Train Count = 45401\n",
      "Episode 5618: Reward = 585.00, Steps = 7, Loss = 6.4740, Exploration Rate = 0.1000, Train Count = 45408\n",
      "Episode 5619: Reward = 591.00, Steps = 5, Loss = 4.3093, Exploration Rate = 0.1000, Train Count = 45413\n",
      "Episode 5620: Reward = 582.00, Steps = 8, Loss = 6.7676, Exploration Rate = 0.1000, Train Count = 45421\n",
      "Episode 5621: Reward = 594.00, Steps = 4, Loss = 4.9488, Exploration Rate = 0.1000, Train Count = 45425\n",
      "Episode 5622: Reward = 588.00, Steps = 6, Loss = 8.3752, Exploration Rate = 0.1000, Train Count = 45431\n",
      "Episode 5623: Reward = 588.00, Steps = 6, Loss = 10.7126, Exploration Rate = 0.1000, Train Count = 45437\n",
      "Episode 5624: Reward = 594.00, Steps = 4, Loss = 3.2666, Exploration Rate = 0.1000, Train Count = 45441\n",
      "Episode 5625: Reward = 567.00, Steps = 13, Loss = 7.3416, Exploration Rate = 0.1000, Train Count = 45454\n",
      "Episode 5626: Reward = 597.00, Steps = 3, Loss = 7.3587, Exploration Rate = 0.1000, Train Count = 45457\n",
      "Episode 5627: Reward = 591.00, Steps = 5, Loss = 5.7430, Exploration Rate = 0.1000, Train Count = 45462\n",
      "Episode 5628: Reward = 600.00, Steps = 2, Loss = 2.6500, Exploration Rate = 0.1000, Train Count = 45464\n",
      "Episode 5629: Reward = 585.00, Steps = 7, Loss = 4.7304, Exploration Rate = 0.1000, Train Count = 45471\n",
      "Episode 5630: Reward = 588.00, Steps = 6, Loss = 7.1065, Exploration Rate = 0.1000, Train Count = 45477\n",
      "Episode 5631: Reward = 597.00, Steps = 3, Loss = 7.2336, Exploration Rate = 0.1000, Train Count = 45480\n",
      "Episode 5632: Reward = 594.00, Steps = 4, Loss = 3.1810, Exploration Rate = 0.1000, Train Count = 45484\n",
      "Episode 5633: Reward = 585.00, Steps = 7, Loss = 5.8786, Exploration Rate = 0.1000, Train Count = 45491\n",
      "Episode 5634: Reward = 588.00, Steps = 6, Loss = 3.2635, Exploration Rate = 0.1000, Train Count = 45497\n",
      "Episode 5635: Reward = 588.00, Steps = 6, Loss = 4.4257, Exploration Rate = 0.1000, Train Count = 45503\n",
      "Episode 5636: Reward = 541.00, Steps = 6, Loss = 4.1062, Exploration Rate = 0.1000, Train Count = 45509\n",
      "Episode 5637: Reward = 579.00, Steps = 9, Loss = 8.4612, Exploration Rate = 0.1000, Train Count = 45518\n",
      "Episode 5638: Reward = 585.00, Steps = 7, Loss = 12.4745, Exploration Rate = 0.1000, Train Count = 45525\n",
      "Episode 5639: Reward = 594.00, Steps = 4, Loss = 7.7903, Exploration Rate = 0.1000, Train Count = 45529\n",
      "Episode 5640: Reward = 597.00, Steps = 3, Loss = 4.7610, Exploration Rate = 0.1000, Train Count = 45532\n",
      "Episode 5641: Reward = 600.00, Steps = 2, Loss = 4.4953, Exploration Rate = 0.1000, Train Count = 45534\n",
      "Episode 5642: Reward = 588.00, Steps = 6, Loss = 15.4809, Exploration Rate = 0.1000, Train Count = 45540\n",
      "Episode 5643: Reward = 588.00, Steps = 6, Loss = 9.5470, Exploration Rate = 0.1000, Train Count = 45546\n",
      "Episode 5644: Reward = 597.00, Steps = 3, Loss = 6.9085, Exploration Rate = 0.1000, Train Count = 45549\n",
      "Episode 5645: Reward = 529.00, Steps = 10, Loss = 9.1784, Exploration Rate = 0.1000, Train Count = 45559\n",
      "Episode 5646: Reward = 576.00, Steps = 10, Loss = 11.5990, Exploration Rate = 0.1000, Train Count = 45569\n",
      "Episode 5647: Reward = 585.00, Steps = 7, Loss = 7.4227, Exploration Rate = 0.1000, Train Count = 45576\n",
      "Episode 5648: Reward = 597.00, Steps = 3, Loss = 6.8255, Exploration Rate = 0.1000, Train Count = 45579\n",
      "Episode 5649: Reward = 597.00, Steps = 3, Loss = 4.4644, Exploration Rate = 0.1000, Train Count = 45582\n",
      "Episode 5650: Reward = 597.00, Steps = 3, Loss = 3.0521, Exploration Rate = 0.1000, Train Count = 45585\n",
      "Episode 5651: Reward = 594.00, Steps = 4, Loss = 7.1933, Exploration Rate = 0.1000, Train Count = 45589\n",
      "Episode 5652: Reward = 594.00, Steps = 4, Loss = 8.8759, Exploration Rate = 0.1000, Train Count = 45593\n",
      "Episode 5653: Reward = 585.00, Steps = 7, Loss = 6.6598, Exploration Rate = 0.1000, Train Count = 45600\n",
      "Episode 5654: Reward = 582.00, Steps = 8, Loss = 5.9948, Exploration Rate = 0.1000, Train Count = 45608\n",
      "Episode 5655: Reward = 585.00, Steps = 7, Loss = 6.0088, Exploration Rate = 0.1000, Train Count = 45615\n",
      "Episode 5656: Reward = 591.00, Steps = 5, Loss = 4.0855, Exploration Rate = 0.1000, Train Count = 45620\n",
      "Episode 5657: Reward = 594.00, Steps = 4, Loss = 2.9982, Exploration Rate = 0.1000, Train Count = 45624\n",
      "Episode 5658: Reward = 576.00, Steps = 10, Loss = 4.7205, Exploration Rate = 0.1000, Train Count = 45634\n",
      "Episode 5659: Reward = 585.00, Steps = 7, Loss = 7.5136, Exploration Rate = 0.1000, Train Count = 45641\n",
      "Episode 5660: Reward = 585.00, Steps = 7, Loss = 7.0767, Exploration Rate = 0.1000, Train Count = 45648\n",
      "Episode 5661: Reward = 579.00, Steps = 9, Loss = 5.4545, Exploration Rate = 0.1000, Train Count = 45657\n",
      "Episode 5662: Reward = 588.00, Steps = 6, Loss = 4.3141, Exploration Rate = 0.1000, Train Count = 45663\n",
      "Episode 5663: Reward = 594.00, Steps = 4, Loss = 4.7888, Exploration Rate = 0.1000, Train Count = 45667\n",
      "Episode 5664: Reward = 597.00, Steps = 3, Loss = 4.3170, Exploration Rate = 0.1000, Train Count = 45670\n",
      "Episode 5665: Reward = 597.00, Steps = 3, Loss = 3.3648, Exploration Rate = 0.1000, Train Count = 45673\n",
      "Episode 5666: Reward = 567.00, Steps = 13, Loss = 6.5463, Exploration Rate = 0.1000, Train Count = 45686\n",
      "Episode 5667: Reward = 585.00, Steps = 7, Loss = 6.7065, Exploration Rate = 0.1000, Train Count = 45693\n",
      "Episode 5668: Reward = 591.00, Steps = 5, Loss = 6.0115, Exploration Rate = 0.1000, Train Count = 45698\n",
      "Episode 5669: Reward = 597.00, Steps = 3, Loss = 6.4377, Exploration Rate = 0.1000, Train Count = 45701\n",
      "Episode 5670: Reward = 585.00, Steps = 7, Loss = 6.1679, Exploration Rate = 0.1000, Train Count = 45708\n",
      "Episode 5671: Reward = 567.00, Steps = 13, Loss = 9.7457, Exploration Rate = 0.1000, Train Count = 45721\n",
      "Episode 5672: Reward = 585.00, Steps = 7, Loss = 8.2011, Exploration Rate = 0.1000, Train Count = 45728\n",
      "Episode 5673: Reward = 582.00, Steps = 8, Loss = 6.7453, Exploration Rate = 0.1000, Train Count = 45736\n",
      "Episode 5674: Reward = 585.00, Steps = 7, Loss = 3.3528, Exploration Rate = 0.1000, Train Count = 45743\n",
      "Episode 5675: Reward = 591.00, Steps = 5, Loss = 4.4612, Exploration Rate = 0.1000, Train Count = 45748\n",
      "Episode 5676: Reward = 588.00, Steps = 6, Loss = 4.8539, Exploration Rate = 0.1000, Train Count = 45754\n",
      "Episode 5677: Reward = 579.00, Steps = 9, Loss = 3.8532, Exploration Rate = 0.1000, Train Count = 45763\n",
      "Episode 5678: Reward = 594.00, Steps = 4, Loss = 2.3552, Exploration Rate = 0.1000, Train Count = 45767\n",
      "Episode 5679: Reward = 579.00, Steps = 9, Loss = 3.0061, Exploration Rate = 0.1000, Train Count = 45776\n",
      "Episode 5680: Reward = 591.00, Steps = 5, Loss = 4.6134, Exploration Rate = 0.1000, Train Count = 45781\n",
      "Episode 5681: Reward = 579.00, Steps = 9, Loss = 6.3241, Exploration Rate = 0.1000, Train Count = 45790\n",
      "Episode 5682: Reward = 579.00, Steps = 9, Loss = 7.6203, Exploration Rate = 0.1000, Train Count = 45799\n",
      "Episode 5683: Reward = 591.00, Steps = 5, Loss = 20.7428, Exploration Rate = 0.1000, Train Count = 45804\n",
      "Episode 5684: Reward = 588.00, Steps = 6, Loss = 21.6681, Exploration Rate = 0.1000, Train Count = 45810\n",
      "Episode 5685: Reward = 591.00, Steps = 5, Loss = 25.1449, Exploration Rate = 0.1000, Train Count = 45815\n",
      "Episode 5686: Reward = 588.00, Steps = 6, Loss = 16.6863, Exploration Rate = 0.1000, Train Count = 45821\n",
      "Episode 5687: Reward = 588.00, Steps = 6, Loss = 14.8667, Exploration Rate = 0.1000, Train Count = 45827\n",
      "Episode 5688: Reward = 576.00, Steps = 10, Loss = 13.3931, Exploration Rate = 0.1000, Train Count = 45837\n",
      "Episode 5689: Reward = 547.00, Steps = 4, Loss = 8.9899, Exploration Rate = 0.1000, Train Count = 45841\n",
      "Episode 5690: Reward = 597.00, Steps = 3, Loss = 12.7836, Exploration Rate = 0.1000, Train Count = 45844\n",
      "Episode 5691: Reward = 591.00, Steps = 5, Loss = 15.6755, Exploration Rate = 0.1000, Train Count = 45849\n",
      "Episode 5692: Reward = 591.00, Steps = 5, Loss = 13.0418, Exploration Rate = 0.1000, Train Count = 45854\n",
      "Episode 5693: Reward = 541.00, Steps = 6, Loss = 10.2232, Exploration Rate = 0.1000, Train Count = 45860\n",
      "Episode 5694: Reward = 588.00, Steps = 6, Loss = 17.2350, Exploration Rate = 0.1000, Train Count = 45866\n",
      "Episode 5695: Reward = 552.00, Steps = 18, Loss = 13.6262, Exploration Rate = 0.1000, Train Count = 45884\n",
      "Episode 5696: Reward = 588.00, Steps = 6, Loss = 9.0548, Exploration Rate = 0.1000, Train Count = 45890\n",
      "Episode 5697: Reward = 591.00, Steps = 5, Loss = 7.5964, Exploration Rate = 0.1000, Train Count = 45895\n",
      "Episode 5698: Reward = 576.00, Steps = 10, Loss = 6.1740, Exploration Rate = 0.1000, Train Count = 45905\n",
      "Episode 5699: Reward = 585.00, Steps = 7, Loss = 4.4642, Exploration Rate = 0.1000, Train Count = 45912\n",
      "Episode 5700: Reward = 591.00, Steps = 5, Loss = 4.8425, Exploration Rate = 0.1000, Train Count = 45917\n",
      "Episode 5701: Reward = 594.00, Steps = 4, Loss = 4.6971, Exploration Rate = 0.1000, Train Count = 45921\n",
      "Episode 5702: Reward = 588.00, Steps = 6, Loss = 3.9988, Exploration Rate = 0.1000, Train Count = 45927\n",
      "Episode 5703: Reward = 591.00, Steps = 5, Loss = 3.3755, Exploration Rate = 0.1000, Train Count = 45932\n",
      "Episode 5704: Reward = 591.00, Steps = 5, Loss = 3.2932, Exploration Rate = 0.1000, Train Count = 45937\n",
      "Episode 5705: Reward = 585.00, Steps = 7, Loss = 2.5852, Exploration Rate = 0.1000, Train Count = 45944\n",
      "Episode 5706: Reward = 585.00, Steps = 7, Loss = 2.6910, Exploration Rate = 0.1000, Train Count = 45951\n",
      "Episode 5707: Reward = 585.00, Steps = 7, Loss = 2.0057, Exploration Rate = 0.1000, Train Count = 45958\n",
      "Episode 5708: Reward = 591.00, Steps = 5, Loss = 2.0194, Exploration Rate = 0.1000, Train Count = 45963\n",
      "Episode 5709: Reward = 588.00, Steps = 6, Loss = 1.9244, Exploration Rate = 0.1000, Train Count = 45969\n",
      "Episode 5710: Reward = 588.00, Steps = 6, Loss = 3.8043, Exploration Rate = 0.1000, Train Count = 45975\n",
      "Episode 5711: Reward = 582.00, Steps = 8, Loss = 3.1235, Exploration Rate = 0.1000, Train Count = 45983\n",
      "Episode 5712: Reward = 585.00, Steps = 7, Loss = 2.2364, Exploration Rate = 0.1000, Train Count = 45990\n",
      "Episode 5713: Reward = 594.00, Steps = 4, Loss = 2.3652, Exploration Rate = 0.1000, Train Count = 45994\n",
      "Episode 5714: Reward = 588.00, Steps = 6, Loss = 3.6450, Exploration Rate = 0.1000, Train Count = 46000\n",
      "Episode 5715: Reward = 591.00, Steps = 5, Loss = 2.8984, Exploration Rate = 0.1000, Train Count = 46005\n",
      "Episode 5716: Reward = 600.00, Steps = 2, Loss = 3.5780, Exploration Rate = 0.1000, Train Count = 46007\n",
      "Episode 5717: Reward = 520.00, Steps = 13, Loss = 4.6381, Exploration Rate = 0.1000, Train Count = 46020\n",
      "Episode 5718: Reward = 576.00, Steps = 10, Loss = 3.3224, Exploration Rate = 0.1000, Train Count = 46030\n",
      "Episode 5719: Reward = 594.00, Steps = 4, Loss = 3.3978, Exploration Rate = 0.1000, Train Count = 46034\n",
      "Episode 5720: Reward = 579.00, Steps = 9, Loss = 5.0475, Exploration Rate = 0.1000, Train Count = 46043\n",
      "Episode 5721: Reward = 588.00, Steps = 6, Loss = 2.0419, Exploration Rate = 0.1000, Train Count = 46049\n",
      "Episode 5722: Reward = 585.00, Steps = 7, Loss = 2.8789, Exploration Rate = 0.1000, Train Count = 46056\n",
      "Episode 5723: Reward = 588.00, Steps = 6, Loss = 2.0670, Exploration Rate = 0.1000, Train Count = 46062\n",
      "Episode 5724: Reward = 594.00, Steps = 4, Loss = 2.0829, Exploration Rate = 0.1000, Train Count = 46066\n",
      "Episode 5725: Reward = 600.00, Steps = 2, Loss = 4.6213, Exploration Rate = 0.1000, Train Count = 46068\n",
      "Episode 5726: Reward = 597.00, Steps = 3, Loss = 4.8756, Exploration Rate = 0.1000, Train Count = 46071\n",
      "Episode 5727: Reward = 588.00, Steps = 6, Loss = 4.6080, Exploration Rate = 0.1000, Train Count = 46077\n",
      "Episode 5728: Reward = 579.00, Steps = 9, Loss = 4.8122, Exploration Rate = 0.1000, Train Count = 46086\n",
      "Episode 5729: Reward = 585.00, Steps = 7, Loss = 6.9027, Exploration Rate = 0.1000, Train Count = 46093\n",
      "Episode 5730: Reward = 582.00, Steps = 8, Loss = 3.9977, Exploration Rate = 0.1000, Train Count = 46101\n",
      "Episode 5731: Reward = 588.00, Steps = 6, Loss = 3.6191, Exploration Rate = 0.1000, Train Count = 46107\n",
      "Episode 5732: Reward = 591.00, Steps = 5, Loss = 3.2805, Exploration Rate = 0.1000, Train Count = 46112\n",
      "Episode 5733: Reward = 541.00, Steps = 6, Loss = 2.1977, Exploration Rate = 0.1000, Train Count = 46118\n",
      "Episode 5734: Reward = 594.00, Steps = 4, Loss = 1.6897, Exploration Rate = 0.1000, Train Count = 46122\n",
      "Episode 5735: Reward = 588.00, Steps = 6, Loss = 2.1113, Exploration Rate = 0.1000, Train Count = 46128\n",
      "Episode 5736: Reward = 579.00, Steps = 9, Loss = 2.5427, Exploration Rate = 0.1000, Train Count = 46137\n",
      "Episode 5737: Reward = 582.00, Steps = 8, Loss = 3.0711, Exploration Rate = 0.1000, Train Count = 46145\n",
      "Episode 5738: Reward = 529.00, Steps = 10, Loss = 2.8777, Exploration Rate = 0.1000, Train Count = 46155\n",
      "Episode 5739: Reward = 597.00, Steps = 3, Loss = 1.7589, Exploration Rate = 0.1000, Train Count = 46158\n",
      "Episode 5740: Reward = 594.00, Steps = 4, Loss = 1.6391, Exploration Rate = 0.1000, Train Count = 46162\n",
      "Episode 5741: Reward = 588.00, Steps = 6, Loss = 2.0672, Exploration Rate = 0.1000, Train Count = 46168\n",
      "Episode 5742: Reward = 576.00, Steps = 10, Loss = 2.0999, Exploration Rate = 0.1000, Train Count = 46178\n",
      "Episode 5743: Reward = 582.00, Steps = 8, Loss = 3.4695, Exploration Rate = 0.1000, Train Count = 46186\n",
      "Episode 5744: Reward = 582.00, Steps = 8, Loss = 1.9441, Exploration Rate = 0.1000, Train Count = 46194\n",
      "Episode 5745: Reward = 588.00, Steps = 6, Loss = 2.3774, Exploration Rate = 0.1000, Train Count = 46200\n",
      "Episode 5746: Reward = 597.00, Steps = 3, Loss = 1.6196, Exploration Rate = 0.1000, Train Count = 46203\n",
      "Episode 5747: Reward = 597.00, Steps = 3, Loss = 1.3982, Exploration Rate = 0.1000, Train Count = 46206\n",
      "Episode 5748: Reward = 585.00, Steps = 7, Loss = 1.3017, Exploration Rate = 0.1000, Train Count = 46213\n",
      "Episode 5749: Reward = 594.00, Steps = 4, Loss = 1.5909, Exploration Rate = 0.1000, Train Count = 46217\n",
      "Episode 5750: Reward = 582.00, Steps = 8, Loss = 3.3780, Exploration Rate = 0.1000, Train Count = 46225\n",
      "Episode 5751: Reward = 594.00, Steps = 4, Loss = 3.1345, Exploration Rate = 0.1000, Train Count = 46229\n",
      "Episode 5752: Reward = 588.00, Steps = 6, Loss = 2.1930, Exploration Rate = 0.1000, Train Count = 46235\n",
      "Episode 5753: Reward = 591.00, Steps = 5, Loss = 2.4089, Exploration Rate = 0.1000, Train Count = 46240\n",
      "Episode 5754: Reward = 585.00, Steps = 7, Loss = 2.6497, Exploration Rate = 0.1000, Train Count = 46247\n",
      "Episode 5755: Reward = 588.00, Steps = 6, Loss = 1.7605, Exploration Rate = 0.1000, Train Count = 46253\n",
      "Episode 5756: Reward = 541.00, Steps = 6, Loss = 2.4150, Exploration Rate = 0.1000, Train Count = 46259\n",
      "Episode 5757: Reward = 582.00, Steps = 8, Loss = 1.4928, Exploration Rate = 0.1000, Train Count = 46267\n",
      "Episode 5758: Reward = 591.00, Steps = 5, Loss = 1.1880, Exploration Rate = 0.1000, Train Count = 46272\n",
      "Episode 5759: Reward = 597.00, Steps = 3, Loss = 1.4013, Exploration Rate = 0.1000, Train Count = 46275\n",
      "Episode 5760: Reward = 594.00, Steps = 4, Loss = 0.9404, Exploration Rate = 0.1000, Train Count = 46279\n",
      "Episode 5761: Reward = 597.00, Steps = 3, Loss = 0.7457, Exploration Rate = 0.1000, Train Count = 46282\n",
      "Episode 5762: Reward = 591.00, Steps = 5, Loss = 1.3115, Exploration Rate = 0.1000, Train Count = 46287\n",
      "Episode 5763: Reward = 594.00, Steps = 4, Loss = 1.9682, Exploration Rate = 0.1000, Train Count = 46291\n",
      "Episode 5764: Reward = 564.00, Steps = 14, Loss = 12.3441, Exploration Rate = 0.1000, Train Count = 46305\n",
      "Episode 5765: Reward = 579.00, Steps = 9, Loss = 22.9515, Exploration Rate = 0.1000, Train Count = 46314\n",
      "Episode 5766: Reward = 591.00, Steps = 5, Loss = 16.0328, Exploration Rate = 0.1000, Train Count = 46319\n",
      "Episode 5767: Reward = 588.00, Steps = 6, Loss = 11.0322, Exploration Rate = 0.1000, Train Count = 46325\n",
      "Episode 5768: Reward = 588.00, Steps = 6, Loss = 10.7674, Exploration Rate = 0.1000, Train Count = 46331\n",
      "Episode 5769: Reward = 567.00, Steps = 13, Loss = 6.8038, Exploration Rate = 0.1000, Train Count = 46344\n",
      "Episode 5770: Reward = 585.00, Steps = 7, Loss = 7.3135, Exploration Rate = 0.1000, Train Count = 46351\n",
      "Episode 5771: Reward = 588.00, Steps = 6, Loss = 8.0880, Exploration Rate = 0.1000, Train Count = 46357\n",
      "Episode 5772: Reward = 594.00, Steps = 4, Loss = 8.4106, Exploration Rate = 0.1000, Train Count = 46361\n",
      "Episode 5773: Reward = 585.00, Steps = 7, Loss = 6.5952, Exploration Rate = 0.1000, Train Count = 46368\n",
      "Episode 5774: Reward = 588.00, Steps = 6, Loss = 6.5593, Exploration Rate = 0.1000, Train Count = 46374\n",
      "Episode 5775: Reward = 529.00, Steps = 10, Loss = 7.9053, Exploration Rate = 0.1000, Train Count = 46384\n",
      "Episode 5776: Reward = 597.00, Steps = 3, Loss = 7.8391, Exploration Rate = 0.1000, Train Count = 46387\n",
      "Episode 5777: Reward = 585.00, Steps = 7, Loss = 4.6377, Exploration Rate = 0.1000, Train Count = 46394\n",
      "Episode 5778: Reward = 591.00, Steps = 5, Loss = 3.6739, Exploration Rate = 0.1000, Train Count = 46399\n",
      "Episode 5779: Reward = 585.00, Steps = 7, Loss = 4.7630, Exploration Rate = 0.1000, Train Count = 46406\n",
      "Episode 5780: Reward = 588.00, Steps = 6, Loss = 5.5924, Exploration Rate = 0.1000, Train Count = 46412\n",
      "Episode 5781: Reward = 594.00, Steps = 4, Loss = 2.4029, Exploration Rate = 0.1000, Train Count = 46416\n",
      "Episode 5782: Reward = 585.00, Steps = 7, Loss = 3.8423, Exploration Rate = 0.1000, Train Count = 46423\n",
      "Episode 5783: Reward = 597.00, Steps = 3, Loss = 4.1672, Exploration Rate = 0.1000, Train Count = 46426\n",
      "Episode 5784: Reward = 582.00, Steps = 8, Loss = 2.7308, Exploration Rate = 0.1000, Train Count = 46434\n",
      "Episode 5785: Reward = 576.00, Steps = 10, Loss = 6.2897, Exploration Rate = 0.1000, Train Count = 46444\n",
      "Episode 5786: Reward = 591.00, Steps = 5, Loss = 2.2301, Exploration Rate = 0.1000, Train Count = 46449\n",
      "Episode 5787: Reward = 600.00, Steps = 2, Loss = 2.9504, Exploration Rate = 0.1000, Train Count = 46451\n",
      "Episode 5788: Reward = 597.00, Steps = 3, Loss = 1.7080, Exploration Rate = 0.1000, Train Count = 46454\n",
      "Episode 5789: Reward = 597.00, Steps = 3, Loss = 1.6887, Exploration Rate = 0.1000, Train Count = 46457\n",
      "Episode 5790: Reward = 585.00, Steps = 7, Loss = 2.9912, Exploration Rate = 0.1000, Train Count = 46464\n",
      "Episode 5791: Reward = 579.00, Steps = 9, Loss = 2.6091, Exploration Rate = 0.1000, Train Count = 46473\n",
      "Episode 5792: Reward = 591.00, Steps = 5, Loss = 3.9827, Exploration Rate = 0.1000, Train Count = 46478\n",
      "Episode 5793: Reward = 591.00, Steps = 5, Loss = 2.5021, Exploration Rate = 0.1000, Train Count = 46483\n",
      "Episode 5794: Reward = 535.00, Steps = 8, Loss = 2.0143, Exploration Rate = 0.1000, Train Count = 46491\n",
      "Episode 5795: Reward = 600.00, Steps = 2, Loss = 1.4163, Exploration Rate = 0.1000, Train Count = 46493\n",
      "Episode 5796: Reward = 582.00, Steps = 8, Loss = 5.1796, Exploration Rate = 0.1000, Train Count = 46501\n",
      "Episode 5797: Reward = 588.00, Steps = 6, Loss = 6.7326, Exploration Rate = 0.1000, Train Count = 46507\n",
      "Episode 5798: Reward = 585.00, Steps = 7, Loss = 9.4709, Exploration Rate = 0.1000, Train Count = 46514\n",
      "Episode 5799: Reward = 585.00, Steps = 7, Loss = 7.0066, Exploration Rate = 0.1000, Train Count = 46521\n",
      "Episode 5800: Reward = 585.00, Steps = 7, Loss = 5.7630, Exploration Rate = 0.1000, Train Count = 46528\n",
      "Episode 5801: Reward = 579.00, Steps = 9, Loss = 4.5903, Exploration Rate = 0.1000, Train Count = 46537\n",
      "Episode 5802: Reward = 597.00, Steps = 3, Loss = 9.6838, Exploration Rate = 0.1000, Train Count = 46540\n",
      "Episode 5803: Reward = 588.00, Steps = 6, Loss = 4.9127, Exploration Rate = 0.1000, Train Count = 46546\n",
      "Episode 5804: Reward = 591.00, Steps = 5, Loss = 4.4127, Exploration Rate = 0.1000, Train Count = 46551\n",
      "Episode 5805: Reward = 582.00, Steps = 8, Loss = 9.5262, Exploration Rate = 0.1000, Train Count = 46559\n",
      "Episode 5806: Reward = 582.00, Steps = 8, Loss = 7.3403, Exploration Rate = 0.1000, Train Count = 46567\n",
      "Episode 5807: Reward = 588.00, Steps = 6, Loss = 11.0776, Exploration Rate = 0.1000, Train Count = 46573\n",
      "Episode 5808: Reward = 585.00, Steps = 7, Loss = 10.9515, Exploration Rate = 0.1000, Train Count = 46580\n",
      "Episode 5809: Reward = 585.00, Steps = 7, Loss = 7.0741, Exploration Rate = 0.1000, Train Count = 46587\n",
      "Episode 5810: Reward = 582.00, Steps = 8, Loss = 5.8646, Exploration Rate = 0.1000, Train Count = 46595\n",
      "Episode 5811: Reward = 573.00, Steps = 11, Loss = 3.7345, Exploration Rate = 0.1000, Train Count = 46606\n",
      "Episode 5812: Reward = 541.00, Steps = 6, Loss = 4.1098, Exploration Rate = 0.1000, Train Count = 46612\n",
      "Episode 5813: Reward = 585.00, Steps = 7, Loss = 4.6746, Exploration Rate = 0.1000, Train Count = 46619\n",
      "Episode 5814: Reward = 585.00, Steps = 7, Loss = 3.6813, Exploration Rate = 0.1000, Train Count = 46626\n",
      "Episode 5815: Reward = 588.00, Steps = 6, Loss = 5.3345, Exploration Rate = 0.1000, Train Count = 46632\n",
      "Episode 5816: Reward = 585.00, Steps = 7, Loss = 3.4460, Exploration Rate = 0.1000, Train Count = 46639\n",
      "Episode 5817: Reward = 597.00, Steps = 3, Loss = 5.9181, Exploration Rate = 0.1000, Train Count = 46642\n",
      "Episode 5818: Reward = 544.00, Steps = 5, Loss = 6.2733, Exploration Rate = 0.1000, Train Count = 46647\n",
      "Episode 5819: Reward = 576.00, Steps = 10, Loss = 6.5493, Exploration Rate = 0.1000, Train Count = 46657\n",
      "Episode 5820: Reward = 582.00, Steps = 8, Loss = 4.0902, Exploration Rate = 0.1000, Train Count = 46665\n",
      "Episode 5821: Reward = 579.00, Steps = 9, Loss = 5.9849, Exploration Rate = 0.1000, Train Count = 46674\n",
      "Episode 5822: Reward = 594.00, Steps = 4, Loss = 2.2703, Exploration Rate = 0.1000, Train Count = 46678\n",
      "Episode 5823: Reward = 594.00, Steps = 4, Loss = 5.7615, Exploration Rate = 0.1000, Train Count = 46682\n",
      "Episode 5824: Reward = 594.00, Steps = 4, Loss = 3.3838, Exploration Rate = 0.1000, Train Count = 46686\n",
      "Episode 5825: Reward = 538.00, Steps = 7, Loss = 5.0131, Exploration Rate = 0.1000, Train Count = 46693\n",
      "Episode 5826: Reward = 582.00, Steps = 8, Loss = 7.0467, Exploration Rate = 0.1000, Train Count = 46701\n",
      "Episode 5827: Reward = 588.00, Steps = 6, Loss = 3.7587, Exploration Rate = 0.1000, Train Count = 46707\n",
      "Episode 5828: Reward = 594.00, Steps = 4, Loss = 9.0095, Exploration Rate = 0.1000, Train Count = 46711\n",
      "Episode 5829: Reward = 591.00, Steps = 5, Loss = 5.5320, Exploration Rate = 0.1000, Train Count = 46716\n",
      "Episode 5830: Reward = 591.00, Steps = 5, Loss = 4.3475, Exploration Rate = 0.1000, Train Count = 46721\n",
      "Episode 5831: Reward = 526.00, Steps = 11, Loss = 5.3091, Exploration Rate = 0.1000, Train Count = 46732\n",
      "Episode 5832: Reward = 594.00, Steps = 4, Loss = 4.2446, Exploration Rate = 0.1000, Train Count = 46736\n",
      "Episode 5833: Reward = 591.00, Steps = 5, Loss = 4.0395, Exploration Rate = 0.1000, Train Count = 46741\n",
      "Episode 5834: Reward = 529.00, Steps = 10, Loss = 5.9203, Exploration Rate = 0.1000, Train Count = 46751\n",
      "Episode 5835: Reward = 588.00, Steps = 6, Loss = 4.2276, Exploration Rate = 0.1000, Train Count = 46757\n",
      "Episode 5836: Reward = 588.00, Steps = 6, Loss = 5.7712, Exploration Rate = 0.1000, Train Count = 46763\n",
      "Episode 5837: Reward = 600.00, Steps = 2, Loss = 5.2636, Exploration Rate = 0.1000, Train Count = 46765\n",
      "Episode 5838: Reward = 573.00, Steps = 11, Loss = 8.6310, Exploration Rate = 0.1000, Train Count = 46776\n",
      "Episode 5839: Reward = 579.00, Steps = 9, Loss = 7.9553, Exploration Rate = 0.1000, Train Count = 46785\n",
      "Episode 5840: Reward = 582.00, Steps = 8, Loss = 9.9921, Exploration Rate = 0.1000, Train Count = 46793\n",
      "Episode 5841: Reward = 582.00, Steps = 8, Loss = 13.6854, Exploration Rate = 0.1000, Train Count = 46801\n",
      "Episode 5842: Reward = 585.00, Steps = 7, Loss = 31.8581, Exploration Rate = 0.1000, Train Count = 46808\n",
      "Episode 5843: Reward = 588.00, Steps = 6, Loss = 22.9722, Exploration Rate = 0.1000, Train Count = 46814\n",
      "Episode 5844: Reward = 544.00, Steps = 5, Loss = 21.3805, Exploration Rate = 0.1000, Train Count = 46819\n",
      "Episode 5845: Reward = 585.00, Steps = 7, Loss = 18.4857, Exploration Rate = 0.1000, Train Count = 46826\n",
      "Episode 5846: Reward = 579.00, Steps = 9, Loss = 15.2640, Exploration Rate = 0.1000, Train Count = 46835\n",
      "Episode 5847: Reward = 588.00, Steps = 6, Loss = 19.3600, Exploration Rate = 0.1000, Train Count = 46841\n",
      "Episode 5848: Reward = 600.00, Steps = 2, Loss = 13.7020, Exploration Rate = 0.1000, Train Count = 46843\n",
      "Episode 5849: Reward = 594.00, Steps = 4, Loss = 15.2115, Exploration Rate = 0.1000, Train Count = 46847\n",
      "Episode 5850: Reward = 588.00, Steps = 6, Loss = 14.4342, Exploration Rate = 0.1000, Train Count = 46853\n",
      "Episode 5851: Reward = 588.00, Steps = 6, Loss = 13.0658, Exploration Rate = 0.1000, Train Count = 46859\n",
      "Episode 5852: Reward = 579.00, Steps = 9, Loss = 10.9472, Exploration Rate = 0.1000, Train Count = 46868\n",
      "Episode 5853: Reward = 594.00, Steps = 4, Loss = 11.0509, Exploration Rate = 0.1000, Train Count = 46872\n",
      "Episode 5854: Reward = 579.00, Steps = 9, Loss = 9.1881, Exploration Rate = 0.1000, Train Count = 46881\n",
      "Episode 5855: Reward = 594.00, Steps = 4, Loss = 6.5603, Exploration Rate = 0.1000, Train Count = 46885\n",
      "Episode 5856: Reward = 588.00, Steps = 6, Loss = 9.6763, Exploration Rate = 0.1000, Train Count = 46891\n",
      "Episode 5857: Reward = 532.00, Steps = 9, Loss = 5.6815, Exploration Rate = 0.1000, Train Count = 46900\n",
      "Episode 5858: Reward = 600.00, Steps = 2, Loss = 6.5009, Exploration Rate = 0.1000, Train Count = 46902\n",
      "Episode 5859: Reward = 591.00, Steps = 5, Loss = 7.9651, Exploration Rate = 0.1000, Train Count = 46907\n",
      "Episode 5860: Reward = 597.00, Steps = 3, Loss = 11.8692, Exploration Rate = 0.1000, Train Count = 46910\n",
      "Episode 5861: Reward = 591.00, Steps = 5, Loss = 7.0379, Exploration Rate = 0.1000, Train Count = 46915\n",
      "Episode 5862: Reward = 594.00, Steps = 4, Loss = 9.1499, Exploration Rate = 0.1000, Train Count = 46919\n",
      "Episode 5863: Reward = 591.00, Steps = 5, Loss = 6.9554, Exploration Rate = 0.1000, Train Count = 46924\n",
      "Episode 5864: Reward = 585.00, Steps = 7, Loss = 8.5598, Exploration Rate = 0.1000, Train Count = 46931\n",
      "Episode 5865: Reward = 585.00, Steps = 7, Loss = 5.7922, Exploration Rate = 0.1000, Train Count = 46938\n",
      "Episode 5866: Reward = 591.00, Steps = 5, Loss = 4.6742, Exploration Rate = 0.1000, Train Count = 46943\n",
      "Episode 5867: Reward = 582.00, Steps = 8, Loss = 8.8903, Exploration Rate = 0.1000, Train Count = 46951\n",
      "Episode 5868: Reward = 594.00, Steps = 4, Loss = 8.0989, Exploration Rate = 0.1000, Train Count = 46955\n",
      "Episode 5869: Reward = 576.00, Steps = 10, Loss = 8.2382, Exploration Rate = 0.1000, Train Count = 46965\n",
      "Episode 5870: Reward = 594.00, Steps = 4, Loss = 7.6940, Exploration Rate = 0.1000, Train Count = 46969\n",
      "Episode 5871: Reward = 579.00, Steps = 9, Loss = 6.1367, Exploration Rate = 0.1000, Train Count = 46978\n",
      "Episode 5872: Reward = 594.00, Steps = 4, Loss = 6.4714, Exploration Rate = 0.1000, Train Count = 46982\n",
      "Episode 5873: Reward = 591.00, Steps = 5, Loss = 9.4216, Exploration Rate = 0.1000, Train Count = 46987\n",
      "Episode 5874: Reward = 588.00, Steps = 6, Loss = 9.0404, Exploration Rate = 0.1000, Train Count = 46993\n",
      "Episode 5875: Reward = 585.00, Steps = 7, Loss = 11.4242, Exploration Rate = 0.1000, Train Count = 47000\n",
      "Episode 5876: Reward = 588.00, Steps = 6, Loss = 8.2551, Exploration Rate = 0.1000, Train Count = 47006\n",
      "Episode 5877: Reward = 567.00, Steps = 13, Loss = 11.0501, Exploration Rate = 0.1000, Train Count = 47019\n",
      "Episode 5878: Reward = 591.00, Steps = 5, Loss = 8.5647, Exploration Rate = 0.1000, Train Count = 47024\n",
      "Episode 5879: Reward = 594.00, Steps = 4, Loss = 8.7008, Exploration Rate = 0.1000, Train Count = 47028\n",
      "Episode 5880: Reward = 582.00, Steps = 8, Loss = 9.5574, Exploration Rate = 0.1000, Train Count = 47036\n",
      "Episode 5881: Reward = 585.00, Steps = 7, Loss = 5.9884, Exploration Rate = 0.1000, Train Count = 47043\n",
      "Episode 5882: Reward = 585.00, Steps = 7, Loss = 6.7134, Exploration Rate = 0.1000, Train Count = 47050\n",
      "Episode 5883: Reward = 582.00, Steps = 8, Loss = 7.7733, Exploration Rate = 0.1000, Train Count = 47058\n",
      "Episode 5884: Reward = 594.00, Steps = 4, Loss = 9.4353, Exploration Rate = 0.1000, Train Count = 47062\n",
      "Episode 5885: Reward = 588.00, Steps = 6, Loss = 9.8983, Exploration Rate = 0.1000, Train Count = 47068\n",
      "Episode 5886: Reward = 517.00, Steps = 14, Loss = 9.9237, Exploration Rate = 0.1000, Train Count = 47082\n",
      "Episode 5887: Reward = 579.00, Steps = 9, Loss = 10.2148, Exploration Rate = 0.1000, Train Count = 47091\n",
      "Episode 5888: Reward = 585.00, Steps = 7, Loss = 10.1606, Exploration Rate = 0.1000, Train Count = 47098\n",
      "Episode 5889: Reward = 579.00, Steps = 9, Loss = 9.5411, Exploration Rate = 0.1000, Train Count = 47107\n",
      "Episode 5890: Reward = 573.00, Steps = 11, Loss = 9.7982, Exploration Rate = 0.1000, Train Count = 47118\n",
      "Episode 5891: Reward = 594.00, Steps = 4, Loss = 7.5055, Exploration Rate = 0.1000, Train Count = 47122\n",
      "Episode 5892: Reward = 588.00, Steps = 6, Loss = 8.7292, Exploration Rate = 0.1000, Train Count = 47128\n",
      "Episode 5893: Reward = 591.00, Steps = 5, Loss = 8.9046, Exploration Rate = 0.1000, Train Count = 47133\n",
      "Episode 5894: Reward = 585.00, Steps = 7, Loss = 8.4876, Exploration Rate = 0.1000, Train Count = 47140\n",
      "Episode 5895: Reward = 597.00, Steps = 3, Loss = 6.8006, Exploration Rate = 0.1000, Train Count = 47143\n",
      "Episode 5896: Reward = 585.00, Steps = 7, Loss = 4.3279, Exploration Rate = 0.1000, Train Count = 47150\n",
      "Episode 5897: Reward = 591.00, Steps = 5, Loss = 6.2447, Exploration Rate = 0.1000, Train Count = 47155\n",
      "Episode 5898: Reward = 576.00, Steps = 10, Loss = 9.9225, Exploration Rate = 0.1000, Train Count = 47165\n",
      "Episode 5899: Reward = 591.00, Steps = 5, Loss = 12.6342, Exploration Rate = 0.1000, Train Count = 47170\n",
      "Episode 5900: Reward = 591.00, Steps = 5, Loss = 11.8138, Exploration Rate = 0.1000, Train Count = 47175\n",
      "Episode 5901: Reward = 597.00, Steps = 3, Loss = 8.0068, Exploration Rate = 0.1000, Train Count = 47178\n",
      "Episode 5902: Reward = 579.00, Steps = 9, Loss = 9.6521, Exploration Rate = 0.1000, Train Count = 47187\n",
      "Episode 5903: Reward = 591.00, Steps = 5, Loss = 9.2299, Exploration Rate = 0.1000, Train Count = 47192\n",
      "Episode 5904: Reward = 594.00, Steps = 4, Loss = 8.0395, Exploration Rate = 0.1000, Train Count = 47196\n",
      "Episode 5905: Reward = 588.00, Steps = 6, Loss = 6.7540, Exploration Rate = 0.1000, Train Count = 47202\n",
      "Episode 5906: Reward = 597.00, Steps = 3, Loss = 5.3787, Exploration Rate = 0.1000, Train Count = 47205\n",
      "Episode 5907: Reward = 585.00, Steps = 7, Loss = 8.0369, Exploration Rate = 0.1000, Train Count = 47212\n",
      "Episode 5908: Reward = 585.00, Steps = 7, Loss = 7.8996, Exploration Rate = 0.1000, Train Count = 47219\n",
      "Episode 5909: Reward = 591.00, Steps = 5, Loss = 8.5184, Exploration Rate = 0.1000, Train Count = 47224\n",
      "Episode 5910: Reward = 585.00, Steps = 7, Loss = 5.0503, Exploration Rate = 0.1000, Train Count = 47231\n",
      "Episode 5911: Reward = 582.00, Steps = 8, Loss = 6.2750, Exploration Rate = 0.1000, Train Count = 47239\n",
      "Episode 5912: Reward = 585.00, Steps = 7, Loss = 4.7868, Exploration Rate = 0.1000, Train Count = 47246\n",
      "Episode 5913: Reward = 591.00, Steps = 5, Loss = 4.3913, Exploration Rate = 0.1000, Train Count = 47251\n",
      "Episode 5914: Reward = 591.00, Steps = 5, Loss = 3.4662, Exploration Rate = 0.1000, Train Count = 47256\n",
      "Episode 5915: Reward = 591.00, Steps = 5, Loss = 4.5468, Exploration Rate = 0.1000, Train Count = 47261\n",
      "Episode 5916: Reward = 585.00, Steps = 7, Loss = 2.6428, Exploration Rate = 0.1000, Train Count = 47268\n",
      "Episode 5917: Reward = 538.00, Steps = 7, Loss = 3.7578, Exploration Rate = 0.1000, Train Count = 47275\n",
      "Episode 5918: Reward = 585.00, Steps = 7, Loss = 6.0198, Exploration Rate = 0.1000, Train Count = 47282\n",
      "Episode 5919: Reward = 597.00, Steps = 3, Loss = 5.7466, Exploration Rate = 0.1000, Train Count = 47285\n",
      "Episode 5920: Reward = 591.00, Steps = 5, Loss = 4.1211, Exploration Rate = 0.1000, Train Count = 47290\n",
      "Episode 5921: Reward = 582.00, Steps = 8, Loss = 5.5419, Exploration Rate = 0.1000, Train Count = 47298\n",
      "Episode 5922: Reward = 594.00, Steps = 4, Loss = 12.0297, Exploration Rate = 0.1000, Train Count = 47302\n",
      "Episode 5923: Reward = 594.00, Steps = 4, Loss = 27.1190, Exploration Rate = 0.1000, Train Count = 47306\n",
      "Episode 5924: Reward = 573.00, Steps = 11, Loss = 26.7672, Exploration Rate = 0.1000, Train Count = 47317\n",
      "Episode 5925: Reward = 591.00, Steps = 5, Loss = 21.8607, Exploration Rate = 0.1000, Train Count = 47322\n",
      "Episode 5926: Reward = 588.00, Steps = 6, Loss = 15.2707, Exploration Rate = 0.1000, Train Count = 47328\n",
      "Episode 5927: Reward = 597.00, Steps = 3, Loss = 17.8237, Exploration Rate = 0.1000, Train Count = 47331\n",
      "Episode 5928: Reward = 594.00, Steps = 4, Loss = 15.1557, Exploration Rate = 0.1000, Train Count = 47335\n",
      "Episode 5929: Reward = 582.00, Steps = 8, Loss = 10.0991, Exploration Rate = 0.1000, Train Count = 47343\n",
      "Episode 5930: Reward = 582.00, Steps = 8, Loss = 11.1855, Exploration Rate = 0.1000, Train Count = 47351\n",
      "Episode 5931: Reward = 579.00, Steps = 9, Loss = 7.0954, Exploration Rate = 0.1000, Train Count = 47360\n",
      "Episode 5932: Reward = 588.00, Steps = 6, Loss = 7.0546, Exploration Rate = 0.1000, Train Count = 47366\n",
      "Episode 5933: Reward = 585.00, Steps = 7, Loss = 5.9951, Exploration Rate = 0.1000, Train Count = 47373\n",
      "Episode 5934: Reward = 597.00, Steps = 3, Loss = 6.7786, Exploration Rate = 0.1000, Train Count = 47376\n",
      "Episode 5935: Reward = 582.00, Steps = 8, Loss = 8.1093, Exploration Rate = 0.1000, Train Count = 47384\n",
      "Episode 5936: Reward = 597.00, Steps = 3, Loss = 6.8821, Exploration Rate = 0.1000, Train Count = 47387\n",
      "Episode 5937: Reward = 594.00, Steps = 4, Loss = 7.8222, Exploration Rate = 0.1000, Train Count = 47391\n",
      "Episode 5938: Reward = 588.00, Steps = 6, Loss = 7.0933, Exploration Rate = 0.1000, Train Count = 47397\n",
      "Episode 5939: Reward = 588.00, Steps = 6, Loss = 6.7443, Exploration Rate = 0.1000, Train Count = 47403\n",
      "Episode 5940: Reward = 588.00, Steps = 6, Loss = 9.0814, Exploration Rate = 0.1000, Train Count = 47409\n",
      "Episode 5941: Reward = 594.00, Steps = 4, Loss = 6.7092, Exploration Rate = 0.1000, Train Count = 47413\n",
      "Episode 5942: Reward = 594.00, Steps = 4, Loss = 6.5887, Exploration Rate = 0.1000, Train Count = 47417\n",
      "Episode 5943: Reward = 591.00, Steps = 5, Loss = 6.3831, Exploration Rate = 0.1000, Train Count = 47422\n",
      "Episode 5944: Reward = 594.00, Steps = 4, Loss = 6.0552, Exploration Rate = 0.1000, Train Count = 47426\n",
      "Episode 5945: Reward = 585.00, Steps = 7, Loss = 8.0932, Exploration Rate = 0.1000, Train Count = 47433\n",
      "Episode 5946: Reward = 591.00, Steps = 5, Loss = 8.6881, Exploration Rate = 0.1000, Train Count = 47438\n",
      "Episode 5947: Reward = 541.00, Steps = 6, Loss = 5.5362, Exploration Rate = 0.1000, Train Count = 47444\n",
      "Episode 5948: Reward = 588.00, Steps = 6, Loss = 7.0923, Exploration Rate = 0.1000, Train Count = 47450\n",
      "Episode 5949: Reward = 585.00, Steps = 7, Loss = 6.9462, Exploration Rate = 0.1000, Train Count = 47457\n",
      "Episode 5950: Reward = 582.00, Steps = 8, Loss = 9.3688, Exploration Rate = 0.1000, Train Count = 47465\n",
      "Episode 5951: Reward = 573.00, Steps = 11, Loss = 5.7577, Exploration Rate = 0.1000, Train Count = 47476\n",
      "Episode 5952: Reward = 594.00, Steps = 4, Loss = 4.8761, Exploration Rate = 0.1000, Train Count = 47480\n",
      "Episode 5953: Reward = 594.00, Steps = 4, Loss = 2.4234, Exploration Rate = 0.1000, Train Count = 47484\n",
      "Episode 5954: Reward = 582.00, Steps = 8, Loss = 5.6669, Exploration Rate = 0.1000, Train Count = 47492\n",
      "Episode 5955: Reward = 591.00, Steps = 5, Loss = 8.2904, Exploration Rate = 0.1000, Train Count = 47497\n",
      "Episode 5956: Reward = 594.00, Steps = 4, Loss = 5.6208, Exploration Rate = 0.1000, Train Count = 47501\n",
      "Episode 5957: Reward = 594.00, Steps = 4, Loss = 3.1654, Exploration Rate = 0.1000, Train Count = 47505\n",
      "Episode 5958: Reward = 591.00, Steps = 5, Loss = 5.2819, Exploration Rate = 0.1000, Train Count = 47510\n",
      "Episode 5959: Reward = 591.00, Steps = 5, Loss = 4.7145, Exploration Rate = 0.1000, Train Count = 47515\n",
      "Episode 5960: Reward = 588.00, Steps = 6, Loss = 4.4446, Exploration Rate = 0.1000, Train Count = 47521\n",
      "Episode 5961: Reward = 588.00, Steps = 6, Loss = 3.4297, Exploration Rate = 0.1000, Train Count = 47527\n",
      "Episode 5962: Reward = 591.00, Steps = 5, Loss = 7.9758, Exploration Rate = 0.1000, Train Count = 47532\n",
      "Episode 5963: Reward = 585.00, Steps = 7, Loss = 4.8639, Exploration Rate = 0.1000, Train Count = 47539\n",
      "Episode 5964: Reward = 579.00, Steps = 9, Loss = 4.8943, Exploration Rate = 0.1000, Train Count = 47548\n",
      "Episode 5965: Reward = 597.00, Steps = 3, Loss = 3.7011, Exploration Rate = 0.1000, Train Count = 47551\n",
      "Episode 5966: Reward = 594.00, Steps = 4, Loss = 6.9039, Exploration Rate = 0.1000, Train Count = 47555\n",
      "Episode 5967: Reward = 588.00, Steps = 6, Loss = 7.3674, Exploration Rate = 0.1000, Train Count = 47561\n",
      "Episode 5968: Reward = 597.00, Steps = 3, Loss = 3.8043, Exploration Rate = 0.1000, Train Count = 47564\n",
      "Episode 5969: Reward = 538.00, Steps = 7, Loss = 5.5912, Exploration Rate = 0.1000, Train Count = 47571\n",
      "Episode 5970: Reward = 585.00, Steps = 7, Loss = 5.7356, Exploration Rate = 0.1000, Train Count = 47578\n",
      "Episode 5971: Reward = 588.00, Steps = 6, Loss = 4.8912, Exploration Rate = 0.1000, Train Count = 47584\n",
      "Episode 5972: Reward = 585.00, Steps = 7, Loss = 5.7155, Exploration Rate = 0.1000, Train Count = 47591\n",
      "Episode 5973: Reward = 585.00, Steps = 7, Loss = 2.3159, Exploration Rate = 0.1000, Train Count = 47598\n",
      "Episode 5974: Reward = 594.00, Steps = 4, Loss = 4.1453, Exploration Rate = 0.1000, Train Count = 47602\n",
      "Episode 5975: Reward = 591.00, Steps = 5, Loss = 5.7592, Exploration Rate = 0.1000, Train Count = 47607\n",
      "Episode 5976: Reward = 582.00, Steps = 8, Loss = 4.3178, Exploration Rate = 0.1000, Train Count = 47615\n",
      "Episode 5977: Reward = 591.00, Steps = 5, Loss = 3.0031, Exploration Rate = 0.1000, Train Count = 47620\n",
      "Episode 5978: Reward = 591.00, Steps = 5, Loss = 3.9736, Exploration Rate = 0.1000, Train Count = 47625\n",
      "Episode 5979: Reward = 591.00, Steps = 5, Loss = 6.8730, Exploration Rate = 0.1000, Train Count = 47630\n",
      "Episode 5980: Reward = 588.00, Steps = 6, Loss = 5.6428, Exploration Rate = 0.1000, Train Count = 47636\n",
      "Episode 5981: Reward = 594.00, Steps = 4, Loss = 3.1200, Exploration Rate = 0.1000, Train Count = 47640\n",
      "Episode 5982: Reward = 591.00, Steps = 5, Loss = 3.2878, Exploration Rate = 0.1000, Train Count = 47645\n",
      "Episode 5983: Reward = 573.00, Steps = 11, Loss = 5.7555, Exploration Rate = 0.1000, Train Count = 47656\n",
      "Episode 5984: Reward = 576.00, Steps = 10, Loss = 4.8712, Exploration Rate = 0.1000, Train Count = 47666\n",
      "Episode 5985: Reward = 582.00, Steps = 8, Loss = 4.5320, Exploration Rate = 0.1000, Train Count = 47674\n",
      "Episode 5986: Reward = 570.00, Steps = 12, Loss = 10.6407, Exploration Rate = 0.1000, Train Count = 47686\n",
      "Episode 5987: Reward = 597.00, Steps = 3, Loss = 6.8733, Exploration Rate = 0.1000, Train Count = 47689\n",
      "Episode 5988: Reward = 591.00, Steps = 5, Loss = 4.0237, Exploration Rate = 0.1000, Train Count = 47694\n",
      "Episode 5989: Reward = 582.00, Steps = 8, Loss = 6.6524, Exploration Rate = 0.1000, Train Count = 47702\n",
      "Episode 5990: Reward = 597.00, Steps = 3, Loss = 3.3866, Exploration Rate = 0.1000, Train Count = 47705\n",
      "Episode 5991: Reward = 585.00, Steps = 7, Loss = 7.7755, Exploration Rate = 0.1000, Train Count = 47712\n",
      "Episode 5992: Reward = 594.00, Steps = 4, Loss = 4.1906, Exploration Rate = 0.1000, Train Count = 47716\n",
      "Episode 5993: Reward = 588.00, Steps = 6, Loss = 8.2139, Exploration Rate = 0.1000, Train Count = 47722\n",
      "Episode 5994: Reward = 594.00, Steps = 4, Loss = 4.3712, Exploration Rate = 0.1000, Train Count = 47726\n",
      "Episode 5995: Reward = 564.00, Steps = 14, Loss = 5.2453, Exploration Rate = 0.1000, Train Count = 47740\n",
      "Episode 5996: Reward = 538.00, Steps = 7, Loss = 6.2608, Exploration Rate = 0.1000, Train Count = 47747\n",
      "Episode 5997: Reward = 585.00, Steps = 7, Loss = 8.9090, Exploration Rate = 0.1000, Train Count = 47754\n",
      "Episode 5998: Reward = 591.00, Steps = 5, Loss = 5.3863, Exploration Rate = 0.1000, Train Count = 47759\n",
      "Episode 5999: Reward = 541.00, Steps = 6, Loss = 7.6935, Exploration Rate = 0.1000, Train Count = 47765\n",
      "Episode 6000: Reward = 582.00, Steps = 8, Loss = 11.4625, Exploration Rate = 0.1000, Train Count = 47773\n",
      "Episode 6001: Reward = 597.00, Steps = 3, Loss = 8.3027, Exploration Rate = 0.1000, Train Count = 47776\n",
      "Episode 6002: Reward = 588.00, Steps = 6, Loss = 7.8236, Exploration Rate = 0.1000, Train Count = 47782\n",
      "Episode 6003: Reward = 582.00, Steps = 8, Loss = 6.1715, Exploration Rate = 0.1000, Train Count = 47790\n",
      "Episode 6004: Reward = 576.00, Steps = 10, Loss = 13.2884, Exploration Rate = 0.1000, Train Count = 47800\n",
      "Episode 6005: Reward = 588.00, Steps = 6, Loss = 30.2034, Exploration Rate = 0.1000, Train Count = 47806\n",
      "Episode 6006: Reward = 582.00, Steps = 8, Loss = 27.5225, Exploration Rate = 0.1000, Train Count = 47814\n",
      "Episode 6007: Reward = 600.00, Steps = 2, Loss = 24.4067, Exploration Rate = 0.1000, Train Count = 47816\n",
      "Episode 6008: Reward = 597.00, Steps = 3, Loss = 17.0804, Exploration Rate = 0.1000, Train Count = 47819\n",
      "Episode 6009: Reward = 594.00, Steps = 4, Loss = 25.4632, Exploration Rate = 0.1000, Train Count = 47823\n",
      "Episode 6010: Reward = 588.00, Steps = 6, Loss = 18.7712, Exploration Rate = 0.1000, Train Count = 47829\n",
      "Episode 6011: Reward = 582.00, Steps = 8, Loss = 15.1703, Exploration Rate = 0.1000, Train Count = 47837\n",
      "Episode 6012: Reward = 588.00, Steps = 6, Loss = 15.4844, Exploration Rate = 0.1000, Train Count = 47843\n",
      "Episode 6013: Reward = 582.00, Steps = 8, Loss = 10.1754, Exploration Rate = 0.1000, Train Count = 47851\n",
      "Episode 6014: Reward = 594.00, Steps = 4, Loss = 10.5997, Exploration Rate = 0.1000, Train Count = 47855\n",
      "Episode 6015: Reward = 597.00, Steps = 3, Loss = 6.1712, Exploration Rate = 0.1000, Train Count = 47858\n",
      "Episode 6016: Reward = 588.00, Steps = 6, Loss = 7.3365, Exploration Rate = 0.1000, Train Count = 47864\n",
      "Episode 6017: Reward = 597.00, Steps = 3, Loss = 4.3003, Exploration Rate = 0.1000, Train Count = 47867\n",
      "Episode 6018: Reward = 573.00, Steps = 11, Loss = 8.8273, Exploration Rate = 0.1000, Train Count = 47878\n",
      "Episode 6019: Reward = 591.00, Steps = 5, Loss = 7.1449, Exploration Rate = 0.1000, Train Count = 47883\n",
      "Episode 6020: Reward = 594.00, Steps = 4, Loss = 5.4680, Exploration Rate = 0.1000, Train Count = 47887\n",
      "Episode 6021: Reward = 591.00, Steps = 5, Loss = 6.0009, Exploration Rate = 0.1000, Train Count = 47892\n",
      "Episode 6022: Reward = 526.00, Steps = 11, Loss = 5.9983, Exploration Rate = 0.1000, Train Count = 47903\n",
      "Episode 6023: Reward = 591.00, Steps = 5, Loss = 8.6552, Exploration Rate = 0.1000, Train Count = 47908\n",
      "Episode 6024: Reward = 591.00, Steps = 5, Loss = 3.8746, Exploration Rate = 0.1000, Train Count = 47913\n",
      "Episode 6025: Reward = 600.00, Steps = 2, Loss = 3.2000, Exploration Rate = 0.1000, Train Count = 47915\n",
      "Episode 6026: Reward = 597.00, Steps = 3, Loss = 8.7330, Exploration Rate = 0.1000, Train Count = 47918\n",
      "Episode 6027: Reward = 591.00, Steps = 5, Loss = 6.8136, Exploration Rate = 0.1000, Train Count = 47923\n",
      "Episode 6028: Reward = 585.00, Steps = 7, Loss = 4.3747, Exploration Rate = 0.1000, Train Count = 47930\n",
      "Episode 6029: Reward = 585.00, Steps = 7, Loss = 5.5858, Exploration Rate = 0.1000, Train Count = 47937\n",
      "Episode 6030: Reward = 591.00, Steps = 5, Loss = 8.9075, Exploration Rate = 0.1000, Train Count = 47942\n",
      "Episode 6031: Reward = 582.00, Steps = 8, Loss = 6.0264, Exploration Rate = 0.1000, Train Count = 47950\n",
      "Episode 6032: Reward = 579.00, Steps = 9, Loss = 5.5447, Exploration Rate = 0.1000, Train Count = 47959\n",
      "Episode 6033: Reward = 544.00, Steps = 5, Loss = 2.4362, Exploration Rate = 0.1000, Train Count = 47964\n",
      "Episode 6034: Reward = 585.00, Steps = 7, Loss = 6.9641, Exploration Rate = 0.1000, Train Count = 47971\n",
      "Episode 6035: Reward = 582.00, Steps = 8, Loss = 5.8401, Exploration Rate = 0.1000, Train Count = 47979\n",
      "Episode 6036: Reward = 541.00, Steps = 6, Loss = 9.7124, Exploration Rate = 0.1000, Train Count = 47985\n",
      "Episode 6037: Reward = 582.00, Steps = 8, Loss = 6.4073, Exploration Rate = 0.1000, Train Count = 47993\n",
      "Episode 6038: Reward = 591.00, Steps = 5, Loss = 5.0910, Exploration Rate = 0.1000, Train Count = 47998\n",
      "Episode 6039: Reward = 585.00, Steps = 7, Loss = 5.4343, Exploration Rate = 0.1000, Train Count = 48005\n",
      "Episode 6040: Reward = 597.00, Steps = 3, Loss = 1.9601, Exploration Rate = 0.1000, Train Count = 48008\n",
      "Episode 6041: Reward = 579.00, Steps = 9, Loss = 5.9247, Exploration Rate = 0.1000, Train Count = 48017\n",
      "Episode 6042: Reward = 591.00, Steps = 5, Loss = 9.9785, Exploration Rate = 0.1000, Train Count = 48022\n",
      "Episode 6043: Reward = 597.00, Steps = 3, Loss = 5.0338, Exploration Rate = 0.1000, Train Count = 48025\n",
      "Episode 6044: Reward = 570.00, Steps = 12, Loss = 8.1414, Exploration Rate = 0.1000, Train Count = 48037\n",
      "Episode 6045: Reward = 532.00, Steps = 9, Loss = 6.7628, Exploration Rate = 0.1000, Train Count = 48046\n",
      "Episode 6046: Reward = 597.00, Steps = 3, Loss = 2.9863, Exploration Rate = 0.1000, Train Count = 48049\n",
      "Episode 6047: Reward = 585.00, Steps = 7, Loss = 6.2964, Exploration Rate = 0.1000, Train Count = 48056\n",
      "Episode 6048: Reward = 582.00, Steps = 8, Loss = 6.3424, Exploration Rate = 0.1000, Train Count = 48064\n",
      "Episode 6049: Reward = 585.00, Steps = 7, Loss = 6.5967, Exploration Rate = 0.1000, Train Count = 48071\n",
      "Episode 6050: Reward = 582.00, Steps = 8, Loss = 6.8340, Exploration Rate = 0.1000, Train Count = 48079\n",
      "Episode 6051: Reward = 591.00, Steps = 5, Loss = 6.5824, Exploration Rate = 0.1000, Train Count = 48084\n",
      "Episode 6052: Reward = 573.00, Steps = 11, Loss = 6.3108, Exploration Rate = 0.1000, Train Count = 48095\n",
      "Episode 6053: Reward = 529.00, Steps = 10, Loss = 4.6002, Exploration Rate = 0.1000, Train Count = 48105\n",
      "Episode 6054: Reward = 591.00, Steps = 5, Loss = 6.9140, Exploration Rate = 0.1000, Train Count = 48110\n",
      "Episode 6055: Reward = 591.00, Steps = 5, Loss = 4.4314, Exploration Rate = 0.1000, Train Count = 48115\n",
      "Episode 6056: Reward = 597.00, Steps = 3, Loss = 8.8710, Exploration Rate = 0.1000, Train Count = 48118\n",
      "Episode 6057: Reward = 594.00, Steps = 4, Loss = 8.7287, Exploration Rate = 0.1000, Train Count = 48122\n",
      "Episode 6058: Reward = 582.00, Steps = 8, Loss = 6.2013, Exploration Rate = 0.1000, Train Count = 48130\n",
      "Episode 6059: Reward = 594.00, Steps = 4, Loss = 6.7293, Exploration Rate = 0.1000, Train Count = 48134\n",
      "Episode 6060: Reward = 591.00, Steps = 5, Loss = 8.7428, Exploration Rate = 0.1000, Train Count = 48139\n",
      "Episode 6061: Reward = 591.00, Steps = 5, Loss = 7.5054, Exploration Rate = 0.1000, Train Count = 48144\n",
      "Episode 6062: Reward = 585.00, Steps = 7, Loss = 7.9945, Exploration Rate = 0.1000, Train Count = 48151\n",
      "Episode 6063: Reward = 597.00, Steps = 3, Loss = 3.7395, Exploration Rate = 0.1000, Train Count = 48154\n",
      "Episode 6064: Reward = 591.00, Steps = 5, Loss = 11.2997, Exploration Rate = 0.1000, Train Count = 48159\n",
      "Episode 6065: Reward = 558.00, Steps = 16, Loss = 5.7515, Exploration Rate = 0.1000, Train Count = 48175\n",
      "Episode 6066: Reward = 532.00, Steps = 9, Loss = 10.0247, Exploration Rate = 0.1000, Train Count = 48184\n",
      "Episode 6067: Reward = 597.00, Steps = 3, Loss = 20.5456, Exploration Rate = 0.1000, Train Count = 48187\n",
      "Episode 6068: Reward = 573.00, Steps = 11, Loss = 10.3740, Exploration Rate = 0.1000, Train Count = 48198\n",
      "Episode 6069: Reward = 594.00, Steps = 4, Loss = 7.8803, Exploration Rate = 0.1000, Train Count = 48202\n",
      "Episode 6070: Reward = 579.00, Steps = 9, Loss = 9.5503, Exploration Rate = 0.1000, Train Count = 48211\n",
      "Episode 6071: Reward = 582.00, Steps = 8, Loss = 8.5809, Exploration Rate = 0.1000, Train Count = 48219\n",
      "Episode 6072: Reward = 597.00, Steps = 3, Loss = 9.8981, Exploration Rate = 0.1000, Train Count = 48222\n",
      "Episode 6073: Reward = 597.00, Steps = 3, Loss = 9.0432, Exploration Rate = 0.1000, Train Count = 48225\n",
      "Episode 6074: Reward = 591.00, Steps = 5, Loss = 6.2416, Exploration Rate = 0.1000, Train Count = 48230\n",
      "Episode 6075: Reward = 582.00, Steps = 8, Loss = 10.2492, Exploration Rate = 0.1000, Train Count = 48238\n",
      "Episode 6076: Reward = 591.00, Steps = 5, Loss = 5.0749, Exploration Rate = 0.1000, Train Count = 48243\n",
      "Episode 6077: Reward = 585.00, Steps = 7, Loss = 7.7899, Exploration Rate = 0.1000, Train Count = 48250\n",
      "Episode 6078: Reward = 591.00, Steps = 5, Loss = 7.1902, Exploration Rate = 0.1000, Train Count = 48255\n",
      "Episode 6079: Reward = 582.00, Steps = 8, Loss = 4.8789, Exploration Rate = 0.1000, Train Count = 48263\n",
      "Episode 6080: Reward = 588.00, Steps = 6, Loss = 8.0371, Exploration Rate = 0.1000, Train Count = 48269\n",
      "Episode 6081: Reward = 582.00, Steps = 8, Loss = 7.8084, Exploration Rate = 0.1000, Train Count = 48277\n",
      "Episode 6082: Reward = 591.00, Steps = 5, Loss = 6.9220, Exploration Rate = 0.1000, Train Count = 48282\n",
      "Episode 6083: Reward = 591.00, Steps = 5, Loss = 5.3861, Exploration Rate = 0.1000, Train Count = 48287\n",
      "Episode 6084: Reward = 594.00, Steps = 4, Loss = 5.9942, Exploration Rate = 0.1000, Train Count = 48291\n",
      "Episode 6085: Reward = 597.00, Steps = 3, Loss = 4.4217, Exploration Rate = 0.1000, Train Count = 48294\n",
      "Episode 6086: Reward = 588.00, Steps = 6, Loss = 7.0246, Exploration Rate = 0.1000, Train Count = 48300\n",
      "Episode 6087: Reward = 594.00, Steps = 4, Loss = 23.6412, Exploration Rate = 0.1000, Train Count = 48304\n",
      "Episode 6088: Reward = 591.00, Steps = 5, Loss = 17.6900, Exploration Rate = 0.1000, Train Count = 48309\n",
      "Episode 6089: Reward = 588.00, Steps = 6, Loss = 17.3518, Exploration Rate = 0.1000, Train Count = 48315\n",
      "Episode 6090: Reward = 591.00, Steps = 5, Loss = 16.0189, Exploration Rate = 0.1000, Train Count = 48320\n",
      "Episode 6091: Reward = 591.00, Steps = 5, Loss = 14.1093, Exploration Rate = 0.1000, Train Count = 48325\n",
      "Episode 6092: Reward = 570.00, Steps = 12, Loss = 9.3710, Exploration Rate = 0.1000, Train Count = 48337\n",
      "Episode 6093: Reward = 600.00, Steps = 2, Loss = 6.6768, Exploration Rate = 0.1000, Train Count = 48339\n",
      "Episode 6094: Reward = 585.00, Steps = 7, Loss = 7.1992, Exploration Rate = 0.1000, Train Count = 48346\n",
      "Episode 6095: Reward = 576.00, Steps = 10, Loss = 8.4232, Exploration Rate = 0.1000, Train Count = 48356\n",
      "Episode 6096: Reward = 585.00, Steps = 7, Loss = 5.0705, Exploration Rate = 0.1000, Train Count = 48363\n",
      "Episode 6097: Reward = 594.00, Steps = 4, Loss = 6.6891, Exploration Rate = 0.1000, Train Count = 48367\n",
      "Episode 6098: Reward = 594.00, Steps = 4, Loss = 6.3802, Exploration Rate = 0.1000, Train Count = 48371\n",
      "Episode 6099: Reward = 597.00, Steps = 3, Loss = 7.7505, Exploration Rate = 0.1000, Train Count = 48374\n",
      "Episode 6100: Reward = 579.00, Steps = 9, Loss = 8.4240, Exploration Rate = 0.1000, Train Count = 48383\n",
      "Episode 6101: Reward = 597.00, Steps = 3, Loss = 3.9566, Exploration Rate = 0.1000, Train Count = 48386\n",
      "Episode 6102: Reward = 591.00, Steps = 5, Loss = 6.1888, Exploration Rate = 0.1000, Train Count = 48391\n",
      "Episode 6103: Reward = 588.00, Steps = 6, Loss = 9.2888, Exploration Rate = 0.1000, Train Count = 48397\n",
      "Episode 6104: Reward = 594.00, Steps = 4, Loss = 9.9855, Exploration Rate = 0.1000, Train Count = 48401\n",
      "Episode 6105: Reward = 579.00, Steps = 9, Loss = 7.6753, Exploration Rate = 0.1000, Train Count = 48410\n",
      "Episode 6106: Reward = 597.00, Steps = 3, Loss = 6.8869, Exploration Rate = 0.1000, Train Count = 48413\n",
      "Episode 6107: Reward = 594.00, Steps = 4, Loss = 8.5498, Exploration Rate = 0.1000, Train Count = 48417\n",
      "Episode 6108: Reward = 588.00, Steps = 6, Loss = 5.9895, Exploration Rate = 0.1000, Train Count = 48423\n",
      "Episode 6109: Reward = 597.00, Steps = 3, Loss = 5.7450, Exploration Rate = 0.1000, Train Count = 48426\n",
      "Episode 6110: Reward = 585.00, Steps = 7, Loss = 4.3709, Exploration Rate = 0.1000, Train Count = 48433\n",
      "Episode 6111: Reward = 585.00, Steps = 7, Loss = 5.3889, Exploration Rate = 0.1000, Train Count = 48440\n",
      "Episode 6112: Reward = 585.00, Steps = 7, Loss = 7.7912, Exploration Rate = 0.1000, Train Count = 48447\n",
      "Episode 6113: Reward = 576.00, Steps = 10, Loss = 9.3135, Exploration Rate = 0.1000, Train Count = 48457\n",
      "Episode 6114: Reward = 579.00, Steps = 9, Loss = 8.7461, Exploration Rate = 0.1000, Train Count = 48466\n",
      "Episode 6115: Reward = 591.00, Steps = 5, Loss = 6.5441, Exploration Rate = 0.1000, Train Count = 48471\n",
      "Episode 6116: Reward = 588.00, Steps = 6, Loss = 4.9577, Exploration Rate = 0.1000, Train Count = 48477\n",
      "Episode 6117: Reward = 579.00, Steps = 9, Loss = 5.7699, Exploration Rate = 0.1000, Train Count = 48486\n",
      "Episode 6118: Reward = 588.00, Steps = 6, Loss = 5.9926, Exploration Rate = 0.1000, Train Count = 48492\n",
      "Episode 6119: Reward = 588.00, Steps = 6, Loss = 4.3426, Exploration Rate = 0.1000, Train Count = 48498\n",
      "Episode 6120: Reward = 582.00, Steps = 8, Loss = 3.5019, Exploration Rate = 0.1000, Train Count = 48506\n",
      "Episode 6121: Reward = 594.00, Steps = 4, Loss = 4.6427, Exploration Rate = 0.1000, Train Count = 48510\n",
      "Episode 6122: Reward = 588.00, Steps = 6, Loss = 8.4585, Exploration Rate = 0.1000, Train Count = 48516\n",
      "Episode 6123: Reward = 588.00, Steps = 6, Loss = 5.1530, Exploration Rate = 0.1000, Train Count = 48522\n",
      "Episode 6124: Reward = 597.00, Steps = 3, Loss = 2.5434, Exploration Rate = 0.1000, Train Count = 48525\n",
      "Episode 6125: Reward = 597.00, Steps = 3, Loss = 5.2235, Exploration Rate = 0.1000, Train Count = 48528\n",
      "Episode 6126: Reward = 570.00, Steps = 12, Loss = 8.9191, Exploration Rate = 0.1000, Train Count = 48540\n",
      "Episode 6127: Reward = 582.00, Steps = 8, Loss = 5.0508, Exploration Rate = 0.1000, Train Count = 48548\n",
      "Episode 6128: Reward = 594.00, Steps = 4, Loss = 5.3554, Exploration Rate = 0.1000, Train Count = 48552\n",
      "Episode 6129: Reward = 588.00, Steps = 6, Loss = 5.9805, Exploration Rate = 0.1000, Train Count = 48558\n",
      "Episode 6130: Reward = 585.00, Steps = 7, Loss = 2.6253, Exploration Rate = 0.1000, Train Count = 48565\n",
      "Episode 6131: Reward = 585.00, Steps = 7, Loss = 6.2927, Exploration Rate = 0.1000, Train Count = 48572\n",
      "Episode 6132: Reward = 582.00, Steps = 8, Loss = 6.5456, Exploration Rate = 0.1000, Train Count = 48580\n",
      "Episode 6133: Reward = 588.00, Steps = 6, Loss = 3.8808, Exploration Rate = 0.1000, Train Count = 48586\n",
      "Episode 6134: Reward = 594.00, Steps = 4, Loss = 6.1550, Exploration Rate = 0.1000, Train Count = 48590\n",
      "Episode 6135: Reward = 544.00, Steps = 5, Loss = 4.6237, Exploration Rate = 0.1000, Train Count = 48595\n",
      "Episode 6136: Reward = 579.00, Steps = 9, Loss = 14.9439, Exploration Rate = 0.1000, Train Count = 48604\n",
      "Episode 6137: Reward = 523.00, Steps = 12, Loss = 8.3361, Exploration Rate = 0.1000, Train Count = 48616\n",
      "Episode 6138: Reward = 588.00, Steps = 6, Loss = 11.0455, Exploration Rate = 0.1000, Train Count = 48622\n",
      "Episode 6139: Reward = 579.00, Steps = 9, Loss = 7.4195, Exploration Rate = 0.1000, Train Count = 48631\n",
      "Episode 6140: Reward = 594.00, Steps = 4, Loss = 12.3480, Exploration Rate = 0.1000, Train Count = 48635\n",
      "Episode 6141: Reward = 597.00, Steps = 3, Loss = 11.4724, Exploration Rate = 0.1000, Train Count = 48638\n",
      "Episode 6142: Reward = 585.00, Steps = 7, Loss = 9.5920, Exploration Rate = 0.1000, Train Count = 48645\n",
      "Episode 6143: Reward = 585.00, Steps = 7, Loss = 12.7201, Exploration Rate = 0.1000, Train Count = 48652\n",
      "Episode 6144: Reward = 591.00, Steps = 5, Loss = 7.1074, Exploration Rate = 0.1000, Train Count = 48657\n",
      "Episode 6145: Reward = 588.00, Steps = 6, Loss = 7.4542, Exploration Rate = 0.1000, Train Count = 48663\n",
      "Episode 6146: Reward = 579.00, Steps = 9, Loss = 8.3777, Exploration Rate = 0.1000, Train Count = 48672\n",
      "Episode 6147: Reward = 579.00, Steps = 9, Loss = 5.8300, Exploration Rate = 0.1000, Train Count = 48681\n",
      "Episode 6148: Reward = 588.00, Steps = 6, Loss = 9.4168, Exploration Rate = 0.1000, Train Count = 48687\n",
      "Episode 6149: Reward = 576.00, Steps = 10, Loss = 6.0896, Exploration Rate = 0.1000, Train Count = 48697\n",
      "Episode 6150: Reward = 588.00, Steps = 6, Loss = 6.2931, Exploration Rate = 0.1000, Train Count = 48703\n",
      "Episode 6151: Reward = 579.00, Steps = 9, Loss = 6.9087, Exploration Rate = 0.1000, Train Count = 48712\n",
      "Episode 6152: Reward = 591.00, Steps = 5, Loss = 9.5001, Exploration Rate = 0.1000, Train Count = 48717\n",
      "Episode 6153: Reward = 582.00, Steps = 8, Loss = 6.4309, Exploration Rate = 0.1000, Train Count = 48725\n",
      "Episode 6154: Reward = 594.00, Steps = 4, Loss = 5.0461, Exploration Rate = 0.1000, Train Count = 48729\n",
      "Episode 6155: Reward = 588.00, Steps = 6, Loss = 3.6628, Exploration Rate = 0.1000, Train Count = 48735\n",
      "Episode 6156: Reward = 600.00, Steps = 2, Loss = 10.4300, Exploration Rate = 0.1000, Train Count = 48737\n",
      "Episode 6157: Reward = 597.00, Steps = 3, Loss = 10.7985, Exploration Rate = 0.1000, Train Count = 48740\n",
      "Episode 6158: Reward = 588.00, Steps = 6, Loss = 6.0598, Exploration Rate = 0.1000, Train Count = 48746\n",
      "Episode 6159: Reward = 585.00, Steps = 7, Loss = 5.7571, Exploration Rate = 0.1000, Train Count = 48753\n",
      "Episode 6160: Reward = 591.00, Steps = 5, Loss = 5.3365, Exploration Rate = 0.1000, Train Count = 48758\n",
      "Episode 6161: Reward = 588.00, Steps = 6, Loss = 3.9967, Exploration Rate = 0.1000, Train Count = 48764\n",
      "Episode 6162: Reward = 597.00, Steps = 3, Loss = 4.5235, Exploration Rate = 0.1000, Train Count = 48767\n",
      "Episode 6163: Reward = 591.00, Steps = 5, Loss = 8.0564, Exploration Rate = 0.1000, Train Count = 48772\n",
      "Episode 6164: Reward = 582.00, Steps = 8, Loss = 9.3667, Exploration Rate = 0.1000, Train Count = 48780\n",
      "Episode 6165: Reward = 594.00, Steps = 4, Loss = 4.1311, Exploration Rate = 0.1000, Train Count = 48784\n",
      "Episode 6166: Reward = 591.00, Steps = 5, Loss = 7.8247, Exploration Rate = 0.1000, Train Count = 48789\n",
      "Episode 6167: Reward = 588.00, Steps = 6, Loss = 6.3819, Exploration Rate = 0.1000, Train Count = 48795\n",
      "Episode 6168: Reward = 585.00, Steps = 7, Loss = 13.4696, Exploration Rate = 0.1000, Train Count = 48802\n",
      "Episode 6169: Reward = 600.00, Steps = 2, Loss = 28.4387, Exploration Rate = 0.1000, Train Count = 48804\n",
      "Episode 6170: Reward = 594.00, Steps = 4, Loss = 24.3101, Exploration Rate = 0.1000, Train Count = 48808\n",
      "Episode 6171: Reward = 588.00, Steps = 6, Loss = 22.1070, Exploration Rate = 0.1000, Train Count = 48814\n",
      "Episode 6172: Reward = 535.00, Steps = 8, Loss = 16.2131, Exploration Rate = 0.1000, Train Count = 48822\n",
      "Episode 6173: Reward = 591.00, Steps = 5, Loss = 17.5853, Exploration Rate = 0.1000, Train Count = 48827\n",
      "Episode 6174: Reward = 573.00, Steps = 11, Loss = 12.7746, Exploration Rate = 0.1000, Train Count = 48838\n",
      "Episode 6175: Reward = 591.00, Steps = 5, Loss = 12.1784, Exploration Rate = 0.1000, Train Count = 48843\n",
      "Episode 6176: Reward = 579.00, Steps = 9, Loss = 16.4785, Exploration Rate = 0.1000, Train Count = 48852\n",
      "Episode 6177: Reward = 591.00, Steps = 5, Loss = 12.8993, Exploration Rate = 0.1000, Train Count = 48857\n",
      "Episode 6178: Reward = 585.00, Steps = 7, Loss = 9.5692, Exploration Rate = 0.1000, Train Count = 48864\n",
      "Episode 6179: Reward = 549.00, Steps = 19, Loss = 8.8529, Exploration Rate = 0.1000, Train Count = 48883\n",
      "Episode 6180: Reward = 585.00, Steps = 7, Loss = 8.3928, Exploration Rate = 0.1000, Train Count = 48890\n",
      "Episode 6181: Reward = 579.00, Steps = 9, Loss = 5.9617, Exploration Rate = 0.1000, Train Count = 48899\n",
      "Episode 6182: Reward = 585.00, Steps = 7, Loss = 7.0825, Exploration Rate = 0.1000, Train Count = 48906\n",
      "Episode 6183: Reward = 600.00, Steps = 2, Loss = 11.9892, Exploration Rate = 0.1000, Train Count = 48908\n",
      "Episode 6184: Reward = 538.00, Steps = 7, Loss = 5.0203, Exploration Rate = 0.1000, Train Count = 48915\n",
      "Episode 6185: Reward = 597.00, Steps = 3, Loss = 7.6286, Exploration Rate = 0.1000, Train Count = 48918\n",
      "Episode 6186: Reward = 588.00, Steps = 6, Loss = 5.0580, Exploration Rate = 0.1000, Train Count = 48924\n",
      "Episode 6187: Reward = 573.00, Steps = 11, Loss = 9.6193, Exploration Rate = 0.1000, Train Count = 48935\n",
      "Episode 6188: Reward = 591.00, Steps = 5, Loss = 5.5246, Exploration Rate = 0.1000, Train Count = 48940\n",
      "Episode 6189: Reward = 585.00, Steps = 7, Loss = 9.3763, Exploration Rate = 0.1000, Train Count = 48947\n",
      "Episode 6190: Reward = 588.00, Steps = 6, Loss = 9.1648, Exploration Rate = 0.1000, Train Count = 48953\n",
      "Episode 6191: Reward = 591.00, Steps = 5, Loss = 6.4748, Exploration Rate = 0.1000, Train Count = 48958\n",
      "Episode 6192: Reward = 582.00, Steps = 8, Loss = 6.9081, Exploration Rate = 0.1000, Train Count = 48966\n",
      "Episode 6193: Reward = 597.00, Steps = 3, Loss = 8.3437, Exploration Rate = 0.1000, Train Count = 48969\n",
      "Episode 6194: Reward = 591.00, Steps = 5, Loss = 9.6664, Exploration Rate = 0.1000, Train Count = 48974\n",
      "Episode 6195: Reward = 591.00, Steps = 5, Loss = 5.0620, Exploration Rate = 0.1000, Train Count = 48979\n",
      "Episode 6196: Reward = 579.00, Steps = 9, Loss = 6.5888, Exploration Rate = 0.1000, Train Count = 48988\n",
      "Episode 6197: Reward = 594.00, Steps = 4, Loss = 5.1941, Exploration Rate = 0.1000, Train Count = 48992\n",
      "Episode 6198: Reward = 591.00, Steps = 5, Loss = 3.4965, Exploration Rate = 0.1000, Train Count = 48997\n",
      "Episode 6199: Reward = 591.00, Steps = 5, Loss = 3.4945, Exploration Rate = 0.1000, Train Count = 49002\n",
      "Episode 6200: Reward = 579.00, Steps = 9, Loss = 3.9267, Exploration Rate = 0.1000, Train Count = 49011\n",
      "Episode 6201: Reward = 588.00, Steps = 6, Loss = 2.2375, Exploration Rate = 0.1000, Train Count = 49017\n",
      "Episode 6202: Reward = 579.00, Steps = 9, Loss = 2.7904, Exploration Rate = 0.1000, Train Count = 49026\n",
      "Episode 6203: Reward = 585.00, Steps = 7, Loss = 2.9783, Exploration Rate = 0.1000, Train Count = 49033\n",
      "Episode 6204: Reward = 526.00, Steps = 11, Loss = 10.6395, Exploration Rate = 0.1000, Train Count = 49044\n",
      "Episode 6205: Reward = 594.00, Steps = 4, Loss = 11.7261, Exploration Rate = 0.1000, Train Count = 49048\n",
      "Episode 6206: Reward = 594.00, Steps = 4, Loss = 12.5092, Exploration Rate = 0.1000, Train Count = 49052\n",
      "Episode 6207: Reward = 591.00, Steps = 5, Loss = 8.3606, Exploration Rate = 0.1000, Train Count = 49057\n",
      "Episode 6208: Reward = 585.00, Steps = 7, Loss = 5.6609, Exploration Rate = 0.1000, Train Count = 49064\n",
      "Episode 6209: Reward = 591.00, Steps = 5, Loss = 5.0041, Exploration Rate = 0.1000, Train Count = 49069\n",
      "Episode 6210: Reward = 591.00, Steps = 5, Loss = 7.2653, Exploration Rate = 0.1000, Train Count = 49074\n",
      "Episode 6211: Reward = 597.00, Steps = 3, Loss = 7.4011, Exploration Rate = 0.1000, Train Count = 49077\n",
      "Episode 6212: Reward = 594.00, Steps = 4, Loss = 6.5431, Exploration Rate = 0.1000, Train Count = 49081\n",
      "Episode 6213: Reward = 579.00, Steps = 9, Loss = 5.4054, Exploration Rate = 0.1000, Train Count = 49090\n",
      "Episode 6214: Reward = 594.00, Steps = 4, Loss = 6.2773, Exploration Rate = 0.1000, Train Count = 49094\n",
      "Episode 6215: Reward = 585.00, Steps = 7, Loss = 4.6473, Exploration Rate = 0.1000, Train Count = 49101\n",
      "Episode 6216: Reward = 582.00, Steps = 8, Loss = 5.3675, Exploration Rate = 0.1000, Train Count = 49109\n",
      "Episode 6217: Reward = 591.00, Steps = 5, Loss = 5.9480, Exploration Rate = 0.1000, Train Count = 49114\n",
      "Episode 6218: Reward = 582.00, Steps = 8, Loss = 3.9725, Exploration Rate = 0.1000, Train Count = 49122\n",
      "Episode 6219: Reward = 544.00, Steps = 5, Loss = 5.9262, Exploration Rate = 0.1000, Train Count = 49127\n",
      "Episode 6220: Reward = 588.00, Steps = 6, Loss = 7.6934, Exploration Rate = 0.1000, Train Count = 49133\n",
      "Episode 6221: Reward = 591.00, Steps = 5, Loss = 7.8700, Exploration Rate = 0.1000, Train Count = 49138\n",
      "Episode 6222: Reward = 585.00, Steps = 7, Loss = 8.5407, Exploration Rate = 0.1000, Train Count = 49145\n",
      "Episode 6223: Reward = 585.00, Steps = 7, Loss = 7.0604, Exploration Rate = 0.1000, Train Count = 49152\n",
      "Episode 6224: Reward = 588.00, Steps = 6, Loss = 7.9299, Exploration Rate = 0.1000, Train Count = 49158\n",
      "Episode 6225: Reward = 591.00, Steps = 5, Loss = 4.2741, Exploration Rate = 0.1000, Train Count = 49163\n",
      "Episode 6226: Reward = 573.00, Steps = 11, Loss = 11.6282, Exploration Rate = 0.1000, Train Count = 49174\n",
      "Episode 6227: Reward = 579.00, Steps = 9, Loss = 6.2223, Exploration Rate = 0.1000, Train Count = 49183\n",
      "Episode 6228: Reward = 579.00, Steps = 9, Loss = 8.8765, Exploration Rate = 0.1000, Train Count = 49192\n",
      "Episode 6229: Reward = 597.00, Steps = 3, Loss = 2.3356, Exploration Rate = 0.1000, Train Count = 49195\n",
      "Episode 6230: Reward = 588.00, Steps = 6, Loss = 8.0819, Exploration Rate = 0.1000, Train Count = 49201\n",
      "Episode 6231: Reward = 591.00, Steps = 5, Loss = 8.3393, Exploration Rate = 0.1000, Train Count = 49206\n",
      "Episode 6232: Reward = 594.00, Steps = 4, Loss = 7.4999, Exploration Rate = 0.1000, Train Count = 49210\n",
      "Episode 6233: Reward = 591.00, Steps = 5, Loss = 5.0908, Exploration Rate = 0.1000, Train Count = 49215\n",
      "Episode 6234: Reward = 585.00, Steps = 7, Loss = 6.9371, Exploration Rate = 0.1000, Train Count = 49222\n",
      "Episode 6235: Reward = 582.00, Steps = 8, Loss = 4.2574, Exploration Rate = 0.1000, Train Count = 49230\n",
      "Episode 6236: Reward = 588.00, Steps = 6, Loss = 5.9771, Exploration Rate = 0.1000, Train Count = 49236\n",
      "Episode 6237: Reward = 594.00, Steps = 4, Loss = 4.7913, Exploration Rate = 0.1000, Train Count = 49240\n",
      "Episode 6238: Reward = 579.00, Steps = 9, Loss = 6.4175, Exploration Rate = 0.1000, Train Count = 49249\n",
      "Episode 6239: Reward = 579.00, Steps = 9, Loss = 6.8139, Exploration Rate = 0.1000, Train Count = 49258\n",
      "Episode 6240: Reward = 597.00, Steps = 3, Loss = 4.5482, Exploration Rate = 0.1000, Train Count = 49261\n",
      "Episode 6241: Reward = 597.00, Steps = 3, Loss = 8.5857, Exploration Rate = 0.1000, Train Count = 49264\n",
      "Episode 6242: Reward = 588.00, Steps = 6, Loss = 7.7963, Exploration Rate = 0.1000, Train Count = 49270\n",
      "Episode 6243: Reward = 541.00, Steps = 6, Loss = 9.9907, Exploration Rate = 0.1000, Train Count = 49276\n",
      "Episode 6244: Reward = 594.00, Steps = 4, Loss = 5.2897, Exploration Rate = 0.1000, Train Count = 49280\n",
      "Episode 6245: Reward = 597.00, Steps = 3, Loss = 5.6664, Exploration Rate = 0.1000, Train Count = 49283\n",
      "Episode 6246: Reward = 588.00, Steps = 6, Loss = 6.3707, Exploration Rate = 0.1000, Train Count = 49289\n",
      "Episode 6247: Reward = 579.00, Steps = 9, Loss = 4.8763, Exploration Rate = 0.1000, Train Count = 49298\n",
      "Episode 6248: Reward = 591.00, Steps = 5, Loss = 26.7590, Exploration Rate = 0.1000, Train Count = 49303\n",
      "Episode 6249: Reward = 600.00, Steps = 2, Loss = 28.1838, Exploration Rate = 0.1000, Train Count = 49305\n",
      "Episode 6250: Reward = 588.00, Steps = 6, Loss = 32.6627, Exploration Rate = 0.1000, Train Count = 49311\n",
      "Episode 6251: Reward = 591.00, Steps = 5, Loss = 25.9329, Exploration Rate = 0.1000, Train Count = 49316\n",
      "Episode 6252: Reward = 594.00, Steps = 4, Loss = 21.1570, Exploration Rate = 0.1000, Train Count = 49320\n",
      "Episode 6253: Reward = 597.00, Steps = 3, Loss = 17.1529, Exploration Rate = 0.1000, Train Count = 49323\n",
      "Episode 6254: Reward = 514.00, Steps = 15, Loss = 14.2531, Exploration Rate = 0.1000, Train Count = 49338\n",
      "Episode 6255: Reward = 579.00, Steps = 9, Loss = 14.9187, Exploration Rate = 0.1000, Train Count = 49347\n",
      "Episode 6256: Reward = 585.00, Steps = 7, Loss = 11.6474, Exploration Rate = 0.1000, Train Count = 49354\n",
      "Episode 6257: Reward = 597.00, Steps = 3, Loss = 5.8771, Exploration Rate = 0.1000, Train Count = 49357\n",
      "Episode 6258: Reward = 573.00, Steps = 11, Loss = 7.3063, Exploration Rate = 0.1000, Train Count = 49368\n",
      "Episode 6259: Reward = 594.00, Steps = 4, Loss = 12.8413, Exploration Rate = 0.1000, Train Count = 49372\n",
      "Episode 6260: Reward = 591.00, Steps = 5, Loss = 10.8814, Exploration Rate = 0.1000, Train Count = 49377\n",
      "Episode 6261: Reward = 591.00, Steps = 5, Loss = 9.2476, Exploration Rate = 0.1000, Train Count = 49382\n",
      "Episode 6262: Reward = 600.00, Steps = 2, Loss = 9.3816, Exploration Rate = 0.1000, Train Count = 49384\n",
      "Episode 6263: Reward = 597.00, Steps = 3, Loss = 9.8913, Exploration Rate = 0.1000, Train Count = 49387\n",
      "Episode 6264: Reward = 588.00, Steps = 6, Loss = 5.3091, Exploration Rate = 0.1000, Train Count = 49393\n",
      "Episode 6265: Reward = 579.00, Steps = 9, Loss = 5.8368, Exploration Rate = 0.1000, Train Count = 49402\n",
      "Episode 6266: Reward = 579.00, Steps = 9, Loss = 7.4803, Exploration Rate = 0.1000, Train Count = 49411\n",
      "Episode 6267: Reward = 585.00, Steps = 7, Loss = 6.2091, Exploration Rate = 0.1000, Train Count = 49418\n",
      "Episode 6268: Reward = 573.00, Steps = 11, Loss = 5.9622, Exploration Rate = 0.1000, Train Count = 49429\n",
      "Episode 6269: Reward = 576.00, Steps = 10, Loss = 5.2082, Exploration Rate = 0.1000, Train Count = 49439\n",
      "Episode 6270: Reward = 585.00, Steps = 7, Loss = 8.4606, Exploration Rate = 0.1000, Train Count = 49446\n",
      "Episode 6271: Reward = 588.00, Steps = 6, Loss = 3.3513, Exploration Rate = 0.1000, Train Count = 49452\n",
      "Episode 6272: Reward = 591.00, Steps = 5, Loss = 4.5883, Exploration Rate = 0.1000, Train Count = 49457\n",
      "Episode 6273: Reward = 591.00, Steps = 5, Loss = 6.1575, Exploration Rate = 0.1000, Train Count = 49462\n",
      "Episode 6274: Reward = 573.00, Steps = 11, Loss = 8.5526, Exploration Rate = 0.1000, Train Count = 49473\n",
      "Episode 6275: Reward = 585.00, Steps = 7, Loss = 7.3695, Exploration Rate = 0.1000, Train Count = 49480\n",
      "Episode 6276: Reward = 535.00, Steps = 8, Loss = 7.2099, Exploration Rate = 0.1000, Train Count = 49488\n",
      "Episode 6277: Reward = 582.00, Steps = 8, Loss = 6.9917, Exploration Rate = 0.1000, Train Count = 49496\n",
      "Episode 6278: Reward = 591.00, Steps = 5, Loss = 5.4868, Exploration Rate = 0.1000, Train Count = 49501\n",
      "Episode 6279: Reward = 591.00, Steps = 5, Loss = 3.8062, Exploration Rate = 0.1000, Train Count = 49506\n",
      "Episode 6280: Reward = 526.00, Steps = 11, Loss = 4.9247, Exploration Rate = 0.1000, Train Count = 49517\n",
      "Episode 6281: Reward = 544.00, Steps = 5, Loss = 7.0818, Exploration Rate = 0.1000, Train Count = 49522\n",
      "Episode 6282: Reward = 600.00, Steps = 2, Loss = 6.2003, Exploration Rate = 0.1000, Train Count = 49524\n",
      "Episode 6283: Reward = 582.00, Steps = 8, Loss = 7.6353, Exploration Rate = 0.1000, Train Count = 49532\n",
      "Episode 6284: Reward = 597.00, Steps = 3, Loss = 3.3057, Exploration Rate = 0.1000, Train Count = 49535\n",
      "Episode 6285: Reward = 594.00, Steps = 4, Loss = 6.1781, Exploration Rate = 0.1000, Train Count = 49539\n",
      "Episode 6286: Reward = 579.00, Steps = 9, Loss = 6.2853, Exploration Rate = 0.1000, Train Count = 49548\n",
      "Episode 6287: Reward = 591.00, Steps = 5, Loss = 4.1497, Exploration Rate = 0.1000, Train Count = 49553\n",
      "Episode 6288: Reward = 585.00, Steps = 7, Loss = 5.0758, Exploration Rate = 0.1000, Train Count = 49560\n",
      "Episode 6289: Reward = 594.00, Steps = 4, Loss = 2.6884, Exploration Rate = 0.1000, Train Count = 49564\n",
      "Episode 6290: Reward = 570.00, Steps = 12, Loss = 5.9298, Exploration Rate = 0.1000, Train Count = 49576\n",
      "Episode 6291: Reward = 573.00, Steps = 11, Loss = 3.6560, Exploration Rate = 0.1000, Train Count = 49587\n",
      "Episode 6292: Reward = 597.00, Steps = 3, Loss = 2.1701, Exploration Rate = 0.1000, Train Count = 49590\n",
      "Episode 6293: Reward = 594.00, Steps = 4, Loss = 1.8098, Exploration Rate = 0.1000, Train Count = 49594\n",
      "Episode 6294: Reward = 594.00, Steps = 4, Loss = 2.4644, Exploration Rate = 0.1000, Train Count = 49598\n",
      "Episode 6295: Reward = 558.00, Steps = 16, Loss = 2.7465, Exploration Rate = 0.1000, Train Count = 49614\n",
      "Episode 6296: Reward = 591.00, Steps = 5, Loss = 2.4796, Exploration Rate = 0.1000, Train Count = 49619\n",
      "Episode 6297: Reward = 594.00, Steps = 4, Loss = 2.9397, Exploration Rate = 0.1000, Train Count = 49623\n",
      "Episode 6298: Reward = 535.00, Steps = 8, Loss = 3.4604, Exploration Rate = 0.1000, Train Count = 49631\n",
      "Episode 6299: Reward = 582.00, Steps = 8, Loss = 3.9766, Exploration Rate = 0.1000, Train Count = 49639\n",
      "Episode 6300: Reward = 597.00, Steps = 3, Loss = 3.6929, Exploration Rate = 0.1000, Train Count = 49642\n",
      "Episode 6301: Reward = 591.00, Steps = 5, Loss = 2.3305, Exploration Rate = 0.1000, Train Count = 49647\n",
      "Episode 6302: Reward = 485.00, Steps = 9, Loss = 2.8003, Exploration Rate = 0.1000, Train Count = 49656\n",
      "Episode 6303: Reward = 529.00, Steps = 10, Loss = 5.0110, Exploration Rate = 0.1000, Train Count = 49666\n",
      "Episode 6304: Reward = 576.00, Steps = 10, Loss = 5.3324, Exploration Rate = 0.1000, Train Count = 49676\n",
      "Episode 6305: Reward = 591.00, Steps = 5, Loss = 4.0342, Exploration Rate = 0.1000, Train Count = 49681\n",
      "Episode 6306: Reward = 594.00, Steps = 4, Loss = 2.4127, Exploration Rate = 0.1000, Train Count = 49685\n",
      "Episode 6307: Reward = 597.00, Steps = 3, Loss = 2.5867, Exploration Rate = 0.1000, Train Count = 49688\n",
      "Episode 6308: Reward = 588.00, Steps = 6, Loss = 3.4480, Exploration Rate = 0.1000, Train Count = 49694\n",
      "Episode 6309: Reward = 597.00, Steps = 3, Loss = 3.9223, Exploration Rate = 0.1000, Train Count = 49697\n",
      "Episode 6310: Reward = 541.00, Steps = 6, Loss = 7.4222, Exploration Rate = 0.1000, Train Count = 49703\n",
      "Episode 6311: Reward = 597.00, Steps = 3, Loss = 4.6093, Exploration Rate = 0.1000, Train Count = 49706\n",
      "Episode 6312: Reward = 588.00, Steps = 6, Loss = 5.4994, Exploration Rate = 0.1000, Train Count = 49712\n",
      "Episode 6313: Reward = 591.00, Steps = 5, Loss = 5.1955, Exploration Rate = 0.1000, Train Count = 49717\n",
      "Episode 6314: Reward = 588.00, Steps = 6, Loss = 3.2259, Exploration Rate = 0.1000, Train Count = 49723\n",
      "Episode 6315: Reward = 600.00, Steps = 2, Loss = 3.0438, Exploration Rate = 0.1000, Train Count = 49725\n",
      "Episode 6316: Reward = 591.00, Steps = 5, Loss = 3.4163, Exploration Rate = 0.1000, Train Count = 49730\n",
      "Episode 6317: Reward = 585.00, Steps = 7, Loss = 3.2894, Exploration Rate = 0.1000, Train Count = 49737\n",
      "Episode 6318: Reward = 594.00, Steps = 4, Loss = 6.5527, Exploration Rate = 0.1000, Train Count = 49741\n",
      "Episode 6319: Reward = 591.00, Steps = 5, Loss = 4.2531, Exploration Rate = 0.1000, Train Count = 49746\n",
      "Episode 6320: Reward = 520.00, Steps = 13, Loss = 8.0758, Exploration Rate = 0.1000, Train Count = 49759\n",
      "Episode 6321: Reward = 585.00, Steps = 7, Loss = 8.9131, Exploration Rate = 0.1000, Train Count = 49766\n",
      "Episode 6322: Reward = 591.00, Steps = 5, Loss = 2.9655, Exploration Rate = 0.1000, Train Count = 49771\n",
      "Episode 6323: Reward = 529.00, Steps = 10, Loss = 9.1760, Exploration Rate = 0.1000, Train Count = 49781\n",
      "Episode 6324: Reward = 585.00, Steps = 7, Loss = 4.9652, Exploration Rate = 0.1000, Train Count = 49788\n",
      "Episode 6325: Reward = 585.00, Steps = 7, Loss = 6.3485, Exploration Rate = 0.1000, Train Count = 49795\n",
      "Episode 6326: Reward = 579.00, Steps = 9, Loss = 13.8154, Exploration Rate = 0.1000, Train Count = 49804\n",
      "Episode 6327: Reward = 579.00, Steps = 9, Loss = 21.6942, Exploration Rate = 0.1000, Train Count = 49813\n",
      "Episode 6328: Reward = 576.00, Steps = 10, Loss = 20.1510, Exploration Rate = 0.1000, Train Count = 49823\n",
      "Episode 6329: Reward = 588.00, Steps = 6, Loss = 15.4513, Exploration Rate = 0.1000, Train Count = 49829\n",
      "Episode 6330: Reward = 591.00, Steps = 5, Loss = 12.5232, Exploration Rate = 0.1000, Train Count = 49834\n",
      "Episode 6331: Reward = 585.00, Steps = 7, Loss = 9.0193, Exploration Rate = 0.1000, Train Count = 49841\n",
      "Episode 6332: Reward = 588.00, Steps = 6, Loss = 7.8929, Exploration Rate = 0.1000, Train Count = 49847\n",
      "Episode 6333: Reward = 597.00, Steps = 3, Loss = 6.8442, Exploration Rate = 0.1000, Train Count = 49850\n",
      "Episode 6334: Reward = 585.00, Steps = 7, Loss = 6.9413, Exploration Rate = 0.1000, Train Count = 49857\n",
      "Episode 6335: Reward = 591.00, Steps = 5, Loss = 8.7144, Exploration Rate = 0.1000, Train Count = 49862\n",
      "Episode 6336: Reward = 588.00, Steps = 6, Loss = 5.8554, Exploration Rate = 0.1000, Train Count = 49868\n",
      "Episode 6337: Reward = 582.00, Steps = 8, Loss = 4.1399, Exploration Rate = 0.1000, Train Count = 49876\n",
      "Episode 6338: Reward = 591.00, Steps = 5, Loss = 5.2464, Exploration Rate = 0.1000, Train Count = 49881\n",
      "Episode 6339: Reward = 591.00, Steps = 5, Loss = 3.7524, Exploration Rate = 0.1000, Train Count = 49886\n",
      "Episode 6340: Reward = 591.00, Steps = 5, Loss = 4.3354, Exploration Rate = 0.1000, Train Count = 49891\n",
      "Episode 6341: Reward = 588.00, Steps = 6, Loss = 6.3247, Exploration Rate = 0.1000, Train Count = 49897\n",
      "Episode 6342: Reward = 582.00, Steps = 8, Loss = 8.0472, Exploration Rate = 0.1000, Train Count = 49905\n",
      "Episode 6343: Reward = 591.00, Steps = 5, Loss = 5.9797, Exploration Rate = 0.1000, Train Count = 49910\n",
      "Episode 6344: Reward = 585.00, Steps = 7, Loss = 5.1135, Exploration Rate = 0.1000, Train Count = 49917\n",
      "Episode 6345: Reward = 585.00, Steps = 7, Loss = 3.6360, Exploration Rate = 0.1000, Train Count = 49924\n",
      "Episode 6346: Reward = 567.00, Steps = 13, Loss = 2.9498, Exploration Rate = 0.1000, Train Count = 49937\n",
      "Episode 6347: Reward = 579.00, Steps = 9, Loss = 3.0803, Exploration Rate = 0.1000, Train Count = 49946\n",
      "Episode 6348: Reward = 588.00, Steps = 6, Loss = 3.0930, Exploration Rate = 0.1000, Train Count = 49952\n",
      "Episode 6349: Reward = 594.00, Steps = 4, Loss = 1.6632, Exploration Rate = 0.1000, Train Count = 49956\n",
      "Episode 6350: Reward = 588.00, Steps = 6, Loss = 3.2999, Exploration Rate = 0.1000, Train Count = 49962\n",
      "Episode 6351: Reward = 582.00, Steps = 8, Loss = 4.9943, Exploration Rate = 0.1000, Train Count = 49970\n",
      "Episode 6352: Reward = 594.00, Steps = 4, Loss = 5.3657, Exploration Rate = 0.1000, Train Count = 49974\n",
      "Episode 6353: Reward = 588.00, Steps = 6, Loss = 3.9156, Exploration Rate = 0.1000, Train Count = 49980\n",
      "Episode 6354: Reward = 594.00, Steps = 4, Loss = 4.9086, Exploration Rate = 0.1000, Train Count = 49984\n",
      "Episode 6355: Reward = 582.00, Steps = 8, Loss = 3.0798, Exploration Rate = 0.1000, Train Count = 49992\n",
      "Episode 6356: Reward = 588.00, Steps = 6, Loss = 2.9796, Exploration Rate = 0.1000, Train Count = 49998\n",
      "Episode 6357: Reward = 579.00, Steps = 9, Loss = 3.2690, Exploration Rate = 0.1000, Train Count = 50007\n",
      "Episode 6358: Reward = 576.00, Steps = 10, Loss = 2.5088, Exploration Rate = 0.1000, Train Count = 50017\n",
      "Episode 6359: Reward = 588.00, Steps = 6, Loss = 1.9186, Exploration Rate = 0.1000, Train Count = 50023\n",
      "Episode 6360: Reward = 538.00, Steps = 7, Loss = 3.8677, Exploration Rate = 0.1000, Train Count = 50030\n",
      "Episode 6361: Reward = 588.00, Steps = 6, Loss = 1.4988, Exploration Rate = 0.1000, Train Count = 50036\n",
      "Episode 6362: Reward = 576.00, Steps = 10, Loss = 8.4778, Exploration Rate = 0.1000, Train Count = 50046\n",
      "Episode 6363: Reward = 591.00, Steps = 5, Loss = 4.9152, Exploration Rate = 0.1000, Train Count = 50051\n",
      "Episode 6364: Reward = 588.00, Steps = 6, Loss = 6.7058, Exploration Rate = 0.1000, Train Count = 50057\n",
      "Episode 6365: Reward = 588.00, Steps = 6, Loss = 3.9949, Exploration Rate = 0.1000, Train Count = 50063\n",
      "Episode 6366: Reward = 588.00, Steps = 6, Loss = 3.5509, Exploration Rate = 0.1000, Train Count = 50069\n",
      "Episode 6367: Reward = 544.00, Steps = 5, Loss = 3.2135, Exploration Rate = 0.1000, Train Count = 50074\n",
      "Episode 6368: Reward = 570.00, Steps = 12, Loss = 4.9987, Exploration Rate = 0.1000, Train Count = 50086\n",
      "Episode 6369: Reward = 594.00, Steps = 4, Loss = 9.0768, Exploration Rate = 0.1000, Train Count = 50090\n",
      "Episode 6370: Reward = 585.00, Steps = 7, Loss = 3.3804, Exploration Rate = 0.1000, Train Count = 50097\n",
      "Episode 6371: Reward = 579.00, Steps = 9, Loss = 4.8874, Exploration Rate = 0.1000, Train Count = 50106\n",
      "Episode 6372: Reward = 585.00, Steps = 7, Loss = 2.8499, Exploration Rate = 0.1000, Train Count = 50113\n",
      "Episode 6373: Reward = 588.00, Steps = 6, Loss = 3.9327, Exploration Rate = 0.1000, Train Count = 50119\n",
      "Episode 6374: Reward = 588.00, Steps = 6, Loss = 2.9907, Exploration Rate = 0.1000, Train Count = 50125\n",
      "Episode 6375: Reward = 597.00, Steps = 3, Loss = 4.3293, Exploration Rate = 0.1000, Train Count = 50128\n",
      "Episode 6376: Reward = 597.00, Steps = 3, Loss = 3.3532, Exploration Rate = 0.1000, Train Count = 50131\n",
      "Episode 6377: Reward = 585.00, Steps = 7, Loss = 3.7834, Exploration Rate = 0.1000, Train Count = 50138\n",
      "Episode 6378: Reward = 582.00, Steps = 8, Loss = 2.8866, Exploration Rate = 0.1000, Train Count = 50146\n",
      "Episode 6379: Reward = 585.00, Steps = 7, Loss = 2.5533, Exploration Rate = 0.1000, Train Count = 50153\n",
      "Episode 6380: Reward = 588.00, Steps = 6, Loss = 3.1476, Exploration Rate = 0.1000, Train Count = 50159\n",
      "Episode 6381: Reward = 588.00, Steps = 6, Loss = 5.3346, Exploration Rate = 0.1000, Train Count = 50165\n",
      "Episode 6382: Reward = 582.00, Steps = 8, Loss = 3.4092, Exploration Rate = 0.1000, Train Count = 50173\n",
      "Episode 6383: Reward = 582.00, Steps = 8, Loss = 4.4963, Exploration Rate = 0.1000, Train Count = 50181\n",
      "Episode 6384: Reward = 594.00, Steps = 4, Loss = 4.5045, Exploration Rate = 0.1000, Train Count = 50185\n",
      "Episode 6385: Reward = 585.00, Steps = 7, Loss = 4.6680, Exploration Rate = 0.1000, Train Count = 50192\n",
      "Episode 6386: Reward = 594.00, Steps = 4, Loss = 2.8888, Exploration Rate = 0.1000, Train Count = 50196\n",
      "Episode 6387: Reward = 591.00, Steps = 5, Loss = 4.3603, Exploration Rate = 0.1000, Train Count = 50201\n",
      "Episode 6388: Reward = 588.00, Steps = 6, Loss = 1.4133, Exploration Rate = 0.1000, Train Count = 50207\n",
      "Episode 6389: Reward = 591.00, Steps = 5, Loss = 5.6224, Exploration Rate = 0.1000, Train Count = 50212\n",
      "Episode 6390: Reward = 588.00, Steps = 6, Loss = 3.9959, Exploration Rate = 0.1000, Train Count = 50218\n",
      "Episode 6391: Reward = 594.00, Steps = 4, Loss = 1.4676, Exploration Rate = 0.1000, Train Count = 50222\n",
      "Episode 6392: Reward = 594.00, Steps = 4, Loss = 1.2602, Exploration Rate = 0.1000, Train Count = 50226\n",
      "Episode 6393: Reward = 597.00, Steps = 3, Loss = 1.5509, Exploration Rate = 0.1000, Train Count = 50229\n",
      "Episode 6394: Reward = 591.00, Steps = 5, Loss = 1.1184, Exploration Rate = 0.1000, Train Count = 50234\n",
      "Episode 6395: Reward = 588.00, Steps = 6, Loss = 2.6447, Exploration Rate = 0.1000, Train Count = 50240\n",
      "Episode 6396: Reward = 585.00, Steps = 7, Loss = 4.3482, Exploration Rate = 0.1000, Train Count = 50247\n",
      "Episode 6397: Reward = 547.00, Steps = 4, Loss = 4.0733, Exploration Rate = 0.1000, Train Count = 50251\n",
      "Episode 6398: Reward = 594.00, Steps = 4, Loss = 5.8412, Exploration Rate = 0.1000, Train Count = 50255\n",
      "Episode 6399: Reward = 594.00, Steps = 4, Loss = 4.6409, Exploration Rate = 0.1000, Train Count = 50259\n",
      "Episode 6400: Reward = 585.00, Steps = 7, Loss = 4.3953, Exploration Rate = 0.1000, Train Count = 50266\n",
      "Episode 6401: Reward = 570.00, Steps = 12, Loss = 3.6786, Exploration Rate = 0.1000, Train Count = 50278\n",
      "Episode 6402: Reward = 594.00, Steps = 4, Loss = 3.4644, Exploration Rate = 0.1000, Train Count = 50282\n",
      "Episode 6403: Reward = 591.00, Steps = 5, Loss = 3.8412, Exploration Rate = 0.1000, Train Count = 50287\n",
      "Episode 6404: Reward = 588.00, Steps = 6, Loss = 2.5223, Exploration Rate = 0.1000, Train Count = 50293\n",
      "Episode 6405: Reward = 588.00, Steps = 6, Loss = 4.1856, Exploration Rate = 0.1000, Train Count = 50299\n",
      "Episode 6406: Reward = 588.00, Steps = 6, Loss = 23.6828, Exploration Rate = 0.1000, Train Count = 50305\n",
      "Episode 6407: Reward = 582.00, Steps = 8, Loss = 19.6982, Exploration Rate = 0.1000, Train Count = 50313\n",
      "Episode 6408: Reward = 594.00, Steps = 4, Loss = 15.9466, Exploration Rate = 0.1000, Train Count = 50317\n",
      "Episode 6409: Reward = 594.00, Steps = 4, Loss = 13.8447, Exploration Rate = 0.1000, Train Count = 50321\n",
      "Episode 6410: Reward = 591.00, Steps = 5, Loss = 13.4382, Exploration Rate = 0.1000, Train Count = 50326\n",
      "Episode 6411: Reward = 588.00, Steps = 6, Loss = 11.7221, Exploration Rate = 0.1000, Train Count = 50332\n",
      "Episode 6412: Reward = 582.00, Steps = 8, Loss = 8.3181, Exploration Rate = 0.1000, Train Count = 50340\n",
      "Episode 6413: Reward = 588.00, Steps = 6, Loss = 6.3087, Exploration Rate = 0.1000, Train Count = 50346\n",
      "Episode 6414: Reward = 597.00, Steps = 3, Loss = 3.8293, Exploration Rate = 0.1000, Train Count = 50349\n",
      "Episode 6415: Reward = 585.00, Steps = 7, Loss = 5.5757, Exploration Rate = 0.1000, Train Count = 50356\n",
      "Episode 6416: Reward = 597.00, Steps = 3, Loss = 5.1775, Exploration Rate = 0.1000, Train Count = 50359\n",
      "Episode 6417: Reward = 597.00, Steps = 3, Loss = 8.2108, Exploration Rate = 0.1000, Train Count = 50362\n",
      "Episode 6418: Reward = 594.00, Steps = 4, Loss = 3.4026, Exploration Rate = 0.1000, Train Count = 50366\n",
      "Episode 6419: Reward = 597.00, Steps = 3, Loss = 4.0877, Exploration Rate = 0.1000, Train Count = 50369\n",
      "Episode 6420: Reward = 535.00, Steps = 8, Loss = 5.6998, Exploration Rate = 0.1000, Train Count = 50377\n",
      "Episode 6421: Reward = 582.00, Steps = 8, Loss = 10.9205, Exploration Rate = 0.1000, Train Count = 50385\n",
      "Episode 6422: Reward = 594.00, Steps = 4, Loss = 6.5359, Exploration Rate = 0.1000, Train Count = 50389\n",
      "Episode 6423: Reward = 573.00, Steps = 11, Loss = 8.3821, Exploration Rate = 0.1000, Train Count = 50400\n",
      "Episode 6424: Reward = 588.00, Steps = 6, Loss = 3.5300, Exploration Rate = 0.1000, Train Count = 50406\n",
      "Episode 6425: Reward = 594.00, Steps = 4, Loss = 4.6416, Exploration Rate = 0.1000, Train Count = 50410\n",
      "Episode 6426: Reward = 588.00, Steps = 6, Loss = 7.5731, Exploration Rate = 0.1000, Train Count = 50416\n",
      "Episode 6427: Reward = 585.00, Steps = 7, Loss = 6.4815, Exploration Rate = 0.1000, Train Count = 50423\n",
      "Episode 6428: Reward = 597.00, Steps = 3, Loss = 6.5266, Exploration Rate = 0.1000, Train Count = 50426\n",
      "Episode 6429: Reward = 585.00, Steps = 7, Loss = 8.0549, Exploration Rate = 0.1000, Train Count = 50433\n",
      "Episode 6430: Reward = 591.00, Steps = 5, Loss = 4.1618, Exploration Rate = 0.1000, Train Count = 50438\n",
      "Episode 6431: Reward = 585.00, Steps = 7, Loss = 5.9197, Exploration Rate = 0.1000, Train Count = 50445\n",
      "Episode 6432: Reward = 597.00, Steps = 3, Loss = 6.4965, Exploration Rate = 0.1000, Train Count = 50448\n",
      "Episode 6433: Reward = 591.00, Steps = 5, Loss = 4.6217, Exploration Rate = 0.1000, Train Count = 50453\n",
      "Episode 6434: Reward = 594.00, Steps = 4, Loss = 5.8002, Exploration Rate = 0.1000, Train Count = 50457\n",
      "Episode 6435: Reward = 532.00, Steps = 9, Loss = 2.7869, Exploration Rate = 0.1000, Train Count = 50466\n",
      "Episode 6436: Reward = 594.00, Steps = 4, Loss = 5.4926, Exploration Rate = 0.1000, Train Count = 50470\n",
      "Episode 6437: Reward = 573.00, Steps = 11, Loss = 6.9027, Exploration Rate = 0.1000, Train Count = 50481\n",
      "Episode 6438: Reward = 594.00, Steps = 4, Loss = 7.5992, Exploration Rate = 0.1000, Train Count = 50485\n",
      "Episode 6439: Reward = 564.00, Steps = 14, Loss = 10.2412, Exploration Rate = 0.1000, Train Count = 50499\n",
      "Episode 6440: Reward = 594.00, Steps = 4, Loss = 3.4216, Exploration Rate = 0.1000, Train Count = 50503\n",
      "Episode 6441: Reward = 576.00, Steps = 10, Loss = 5.0249, Exploration Rate = 0.1000, Train Count = 50513\n",
      "Episode 6442: Reward = 576.00, Steps = 10, Loss = 9.5519, Exploration Rate = 0.1000, Train Count = 50523\n",
      "Episode 6443: Reward = 588.00, Steps = 6, Loss = 5.8994, Exploration Rate = 0.1000, Train Count = 50529\n",
      "Episode 6444: Reward = 588.00, Steps = 6, Loss = 3.7758, Exploration Rate = 0.1000, Train Count = 50535\n",
      "Episode 6445: Reward = 594.00, Steps = 4, Loss = 4.2977, Exploration Rate = 0.1000, Train Count = 50539\n",
      "Episode 6446: Reward = 591.00, Steps = 5, Loss = 7.6073, Exploration Rate = 0.1000, Train Count = 50544\n",
      "Episode 6447: Reward = 582.00, Steps = 8, Loss = 4.4564, Exploration Rate = 0.1000, Train Count = 50552\n",
      "Episode 6448: Reward = 594.00, Steps = 4, Loss = 4.4614, Exploration Rate = 0.1000, Train Count = 50556\n",
      "Episode 6449: Reward = 594.00, Steps = 4, Loss = 5.9498, Exploration Rate = 0.1000, Train Count = 50560\n",
      "Episode 6450: Reward = 579.00, Steps = 9, Loss = 5.8057, Exploration Rate = 0.1000, Train Count = 50569\n",
      "Episode 6451: Reward = 591.00, Steps = 5, Loss = 5.7636, Exploration Rate = 0.1000, Train Count = 50574\n",
      "Episode 6452: Reward = 538.00, Steps = 7, Loss = 4.3413, Exploration Rate = 0.1000, Train Count = 50581\n",
      "Episode 6453: Reward = 594.00, Steps = 4, Loss = 11.7789, Exploration Rate = 0.1000, Train Count = 50585\n",
      "Episode 6454: Reward = 582.00, Steps = 8, Loss = 11.1815, Exploration Rate = 0.1000, Train Count = 50593\n",
      "Episode 6455: Reward = 535.00, Steps = 8, Loss = 7.6203, Exploration Rate = 0.1000, Train Count = 50601\n",
      "Episode 6456: Reward = 579.00, Steps = 9, Loss = 5.8161, Exploration Rate = 0.1000, Train Count = 50610\n",
      "Episode 6457: Reward = 594.00, Steps = 4, Loss = 5.6282, Exploration Rate = 0.1000, Train Count = 50614\n",
      "Episode 6458: Reward = 591.00, Steps = 5, Loss = 6.9667, Exploration Rate = 0.1000, Train Count = 50619\n",
      "Episode 6459: Reward = 588.00, Steps = 6, Loss = 6.8836, Exploration Rate = 0.1000, Train Count = 50625\n",
      "Episode 6460: Reward = 585.00, Steps = 7, Loss = 6.2337, Exploration Rate = 0.1000, Train Count = 50632\n",
      "Episode 6461: Reward = 591.00, Steps = 5, Loss = 6.0159, Exploration Rate = 0.1000, Train Count = 50637\n",
      "Episode 6462: Reward = 591.00, Steps = 5, Loss = 5.8769, Exploration Rate = 0.1000, Train Count = 50642\n",
      "Episode 6463: Reward = 591.00, Steps = 5, Loss = 5.9201, Exploration Rate = 0.1000, Train Count = 50647\n",
      "Episode 6464: Reward = 591.00, Steps = 5, Loss = 8.0985, Exploration Rate = 0.1000, Train Count = 50652\n",
      "Episode 6465: Reward = 582.00, Steps = 8, Loss = 5.6976, Exploration Rate = 0.1000, Train Count = 50660\n",
      "Episode 6466: Reward = 594.00, Steps = 4, Loss = 1.9821, Exploration Rate = 0.1000, Train Count = 50664\n",
      "Episode 6467: Reward = 585.00, Steps = 7, Loss = 4.5702, Exploration Rate = 0.1000, Train Count = 50671\n",
      "Episode 6468: Reward = 591.00, Steps = 5, Loss = 3.3807, Exploration Rate = 0.1000, Train Count = 50676\n",
      "Episode 6469: Reward = 594.00, Steps = 4, Loss = 9.3842, Exploration Rate = 0.1000, Train Count = 50680\n",
      "Episode 6470: Reward = 585.00, Steps = 7, Loss = 7.7835, Exploration Rate = 0.1000, Train Count = 50687\n",
      "Episode 6471: Reward = 567.00, Steps = 13, Loss = 6.8356, Exploration Rate = 0.1000, Train Count = 50700\n",
      "Episode 6472: Reward = 567.00, Steps = 13, Loss = 6.9754, Exploration Rate = 0.1000, Train Count = 50713\n",
      "Episode 6473: Reward = 588.00, Steps = 6, Loss = 8.8390, Exploration Rate = 0.1000, Train Count = 50719\n",
      "Episode 6474: Reward = 582.00, Steps = 8, Loss = 5.4066, Exploration Rate = 0.1000, Train Count = 50727\n",
      "Episode 6475: Reward = 594.00, Steps = 4, Loss = 4.1949, Exploration Rate = 0.1000, Train Count = 50731\n",
      "Episode 6476: Reward = 585.00, Steps = 7, Loss = 3.9215, Exploration Rate = 0.1000, Train Count = 50738\n",
      "Episode 6477: Reward = 588.00, Steps = 6, Loss = 3.0722, Exploration Rate = 0.1000, Train Count = 50744\n",
      "Episode 6478: Reward = 573.00, Steps = 11, Loss = 4.6452, Exploration Rate = 0.1000, Train Count = 50755\n",
      "Episode 6479: Reward = 588.00, Steps = 6, Loss = 3.5652, Exploration Rate = 0.1000, Train Count = 50761\n",
      "Episode 6480: Reward = 585.00, Steps = 7, Loss = 4.7066, Exploration Rate = 0.1000, Train Count = 50768\n",
      "Episode 6481: Reward = 597.00, Steps = 3, Loss = 3.1648, Exploration Rate = 0.1000, Train Count = 50771\n",
      "Episode 6482: Reward = 585.00, Steps = 7, Loss = 5.7169, Exploration Rate = 0.1000, Train Count = 50778\n",
      "Episode 6483: Reward = 594.00, Steps = 4, Loss = 5.4566, Exploration Rate = 0.1000, Train Count = 50782\n",
      "Episode 6484: Reward = 588.00, Steps = 6, Loss = 5.7937, Exploration Rate = 0.1000, Train Count = 50788\n",
      "Episode 6485: Reward = 585.00, Steps = 7, Loss = 5.1436, Exploration Rate = 0.1000, Train Count = 50795\n",
      "Episode 6486: Reward = 529.00, Steps = 10, Loss = 17.5470, Exploration Rate = 0.1000, Train Count = 50805\n",
      "Episode 6487: Reward = 594.00, Steps = 4, Loss = 21.5469, Exploration Rate = 0.1000, Train Count = 50809\n",
      "Episode 6488: Reward = 594.00, Steps = 4, Loss = 18.7347, Exploration Rate = 0.1000, Train Count = 50813\n",
      "Episode 6489: Reward = 600.00, Steps = 2, Loss = 15.5222, Exploration Rate = 0.1000, Train Count = 50815\n",
      "Episode 6490: Reward = 588.00, Steps = 6, Loss = 15.0624, Exploration Rate = 0.1000, Train Count = 50821\n",
      "Episode 6491: Reward = 564.00, Steps = 14, Loss = 13.8382, Exploration Rate = 0.1000, Train Count = 50835\n",
      "Episode 6492: Reward = 582.00, Steps = 8, Loss = 10.7778, Exploration Rate = 0.1000, Train Count = 50843\n",
      "Episode 6493: Reward = 544.00, Steps = 5, Loss = 11.4549, Exploration Rate = 0.1000, Train Count = 50848\n",
      "Episode 6494: Reward = 582.00, Steps = 8, Loss = 11.1885, Exploration Rate = 0.1000, Train Count = 50856\n",
      "Episode 6495: Reward = 585.00, Steps = 7, Loss = 9.6521, Exploration Rate = 0.1000, Train Count = 50863\n",
      "Episode 6496: Reward = 576.00, Steps = 10, Loss = 8.5363, Exploration Rate = 0.1000, Train Count = 50873\n",
      "Episode 6497: Reward = 591.00, Steps = 5, Loss = 6.6654, Exploration Rate = 0.1000, Train Count = 50878\n",
      "Episode 6498: Reward = 594.00, Steps = 4, Loss = 11.3460, Exploration Rate = 0.1000, Train Count = 50882\n",
      "Episode 6499: Reward = 588.00, Steps = 6, Loss = 6.8456, Exploration Rate = 0.1000, Train Count = 50888\n",
      "Episode 6500: Reward = 585.00, Steps = 7, Loss = 10.8935, Exploration Rate = 0.1000, Train Count = 50895\n",
      "Episode 6501: Reward = 597.00, Steps = 3, Loss = 11.0817, Exploration Rate = 0.1000, Train Count = 50898\n",
      "Episode 6502: Reward = 588.00, Steps = 6, Loss = 5.9274, Exploration Rate = 0.1000, Train Count = 50904\n",
      "Episode 6503: Reward = 582.00, Steps = 8, Loss = 5.1660, Exploration Rate = 0.1000, Train Count = 50912\n",
      "Episode 6504: Reward = 588.00, Steps = 6, Loss = 5.8693, Exploration Rate = 0.1000, Train Count = 50918\n",
      "Episode 6505: Reward = 588.00, Steps = 6, Loss = 4.5731, Exploration Rate = 0.1000, Train Count = 50924\n",
      "Episode 6506: Reward = 579.00, Steps = 9, Loss = 5.4763, Exploration Rate = 0.1000, Train Count = 50933\n",
      "Episode 6507: Reward = 576.00, Steps = 10, Loss = 5.2999, Exploration Rate = 0.1000, Train Count = 50943\n",
      "Episode 6508: Reward = 585.00, Steps = 7, Loss = 7.8406, Exploration Rate = 0.1000, Train Count = 50950\n",
      "Episode 6509: Reward = 594.00, Steps = 4, Loss = 5.8264, Exploration Rate = 0.1000, Train Count = 50954\n",
      "Episode 6510: Reward = 594.00, Steps = 4, Loss = 7.5037, Exploration Rate = 0.1000, Train Count = 50958\n",
      "Episode 6511: Reward = 597.00, Steps = 3, Loss = 4.9410, Exploration Rate = 0.1000, Train Count = 50961\n",
      "Episode 6512: Reward = 591.00, Steps = 5, Loss = 6.9341, Exploration Rate = 0.1000, Train Count = 50966\n",
      "Episode 6513: Reward = 594.00, Steps = 4, Loss = 5.5182, Exploration Rate = 0.1000, Train Count = 50970\n",
      "Episode 6514: Reward = 588.00, Steps = 6, Loss = 7.7497, Exploration Rate = 0.1000, Train Count = 50976\n",
      "Episode 6515: Reward = 591.00, Steps = 5, Loss = 8.6063, Exploration Rate = 0.1000, Train Count = 50981\n",
      "Episode 6516: Reward = 594.00, Steps = 4, Loss = 5.5054, Exploration Rate = 0.1000, Train Count = 50985\n",
      "Episode 6517: Reward = 588.00, Steps = 6, Loss = 4.5608, Exploration Rate = 0.1000, Train Count = 50991\n",
      "Episode 6518: Reward = 588.00, Steps = 6, Loss = 5.2346, Exploration Rate = 0.1000, Train Count = 50997\n",
      "Episode 6519: Reward = 588.00, Steps = 6, Loss = 8.8085, Exploration Rate = 0.1000, Train Count = 51003\n",
      "Episode 6520: Reward = 594.00, Steps = 4, Loss = 6.3157, Exploration Rate = 0.1000, Train Count = 51007\n",
      "Episode 6521: Reward = 591.00, Steps = 5, Loss = 4.6968, Exploration Rate = 0.1000, Train Count = 51012\n",
      "Episode 6522: Reward = 585.00, Steps = 7, Loss = 7.5814, Exploration Rate = 0.1000, Train Count = 51019\n",
      "Episode 6523: Reward = 600.00, Steps = 2, Loss = 9.1053, Exploration Rate = 0.1000, Train Count = 51021\n",
      "Episode 6524: Reward = 588.00, Steps = 6, Loss = 5.9648, Exploration Rate = 0.1000, Train Count = 51027\n",
      "Episode 6525: Reward = 582.00, Steps = 8, Loss = 5.4327, Exploration Rate = 0.1000, Train Count = 51035\n",
      "Episode 6526: Reward = 585.00, Steps = 7, Loss = 5.0039, Exploration Rate = 0.1000, Train Count = 51042\n",
      "Episode 6527: Reward = 529.00, Steps = 10, Loss = 6.6195, Exploration Rate = 0.1000, Train Count = 51052\n",
      "Episode 6528: Reward = 588.00, Steps = 6, Loss = 10.8681, Exploration Rate = 0.1000, Train Count = 51058\n",
      "Episode 6529: Reward = 588.00, Steps = 6, Loss = 5.1761, Exploration Rate = 0.1000, Train Count = 51064\n",
      "Episode 6530: Reward = 585.00, Steps = 7, Loss = 7.7766, Exploration Rate = 0.1000, Train Count = 51071\n",
      "Episode 6531: Reward = 582.00, Steps = 8, Loss = 10.1073, Exploration Rate = 0.1000, Train Count = 51079\n",
      "Episode 6532: Reward = 594.00, Steps = 4, Loss = 16.1552, Exploration Rate = 0.1000, Train Count = 51083\n",
      "Episode 6533: Reward = 597.00, Steps = 3, Loss = 7.7770, Exploration Rate = 0.1000, Train Count = 51086\n",
      "Episode 6534: Reward = 544.00, Steps = 5, Loss = 5.2395, Exploration Rate = 0.1000, Train Count = 51091\n",
      "Episode 6535: Reward = 591.00, Steps = 5, Loss = 6.9547, Exploration Rate = 0.1000, Train Count = 51096\n",
      "Episode 6536: Reward = 591.00, Steps = 5, Loss = 5.8613, Exploration Rate = 0.1000, Train Count = 51101\n",
      "Episode 6537: Reward = 591.00, Steps = 5, Loss = 10.7207, Exploration Rate = 0.1000, Train Count = 51106\n",
      "Episode 6538: Reward = 591.00, Steps = 5, Loss = 5.0593, Exploration Rate = 0.1000, Train Count = 51111\n",
      "Episode 6539: Reward = 588.00, Steps = 6, Loss = 11.6602, Exploration Rate = 0.1000, Train Count = 51117\n",
      "Episode 6540: Reward = 594.00, Steps = 4, Loss = 12.2457, Exploration Rate = 0.1000, Train Count = 51121\n",
      "Episode 6541: Reward = 594.00, Steps = 4, Loss = 10.1998, Exploration Rate = 0.1000, Train Count = 51125\n",
      "Episode 6542: Reward = 591.00, Steps = 5, Loss = 8.5886, Exploration Rate = 0.1000, Train Count = 51130\n",
      "Episode 6543: Reward = 582.00, Steps = 8, Loss = 8.8796, Exploration Rate = 0.1000, Train Count = 51138\n",
      "Episode 6544: Reward = 591.00, Steps = 5, Loss = 10.2328, Exploration Rate = 0.1000, Train Count = 51143\n",
      "Episode 6545: Reward = 588.00, Steps = 6, Loss = 5.1200, Exploration Rate = 0.1000, Train Count = 51149\n",
      "Episode 6546: Reward = 591.00, Steps = 5, Loss = 8.5056, Exploration Rate = 0.1000, Train Count = 51154\n",
      "Episode 6547: Reward = 582.00, Steps = 8, Loss = 7.7828, Exploration Rate = 0.1000, Train Count = 51162\n",
      "Episode 6548: Reward = 579.00, Steps = 9, Loss = 10.0106, Exploration Rate = 0.1000, Train Count = 51171\n",
      "Episode 6549: Reward = 585.00, Steps = 7, Loss = 7.7216, Exploration Rate = 0.1000, Train Count = 51178\n",
      "Episode 6550: Reward = 588.00, Steps = 6, Loss = 5.9950, Exploration Rate = 0.1000, Train Count = 51184\n",
      "Episode 6551: Reward = 594.00, Steps = 4, Loss = 8.2977, Exploration Rate = 0.1000, Train Count = 51188\n",
      "Episode 6552: Reward = 588.00, Steps = 6, Loss = 8.6473, Exploration Rate = 0.1000, Train Count = 51194\n",
      "Episode 6553: Reward = 597.00, Steps = 3, Loss = 7.8147, Exploration Rate = 0.1000, Train Count = 51197\n",
      "Episode 6554: Reward = 541.00, Steps = 6, Loss = 6.8335, Exploration Rate = 0.1000, Train Count = 51203\n",
      "Episode 6555: Reward = 585.00, Steps = 7, Loss = 11.0005, Exploration Rate = 0.1000, Train Count = 51210\n",
      "Episode 6556: Reward = 594.00, Steps = 4, Loss = 10.6945, Exploration Rate = 0.1000, Train Count = 51214\n",
      "Episode 6557: Reward = 588.00, Steps = 6, Loss = 11.5451, Exploration Rate = 0.1000, Train Count = 51220\n",
      "Episode 6558: Reward = 573.00, Steps = 11, Loss = 10.8819, Exploration Rate = 0.1000, Train Count = 51231\n",
      "Episode 6559: Reward = 594.00, Steps = 4, Loss = 6.0987, Exploration Rate = 0.1000, Train Count = 51235\n",
      "Episode 6560: Reward = 585.00, Steps = 7, Loss = 10.5849, Exploration Rate = 0.1000, Train Count = 51242\n",
      "Episode 6561: Reward = 573.00, Steps = 11, Loss = 11.1667, Exploration Rate = 0.1000, Train Count = 51253\n",
      "Episode 6562: Reward = 585.00, Steps = 7, Loss = 11.5480, Exploration Rate = 0.1000, Train Count = 51260\n",
      "Episode 6563: Reward = 588.00, Steps = 6, Loss = 9.5540, Exploration Rate = 0.1000, Train Count = 51266\n",
      "Episode 6564: Reward = 591.00, Steps = 5, Loss = 10.5625, Exploration Rate = 0.1000, Train Count = 51271\n",
      "Episode 6565: Reward = 591.00, Steps = 5, Loss = 9.7913, Exploration Rate = 0.1000, Train Count = 51276\n",
      "Episode 6566: Reward = 591.00, Steps = 5, Loss = 7.6374, Exploration Rate = 0.1000, Train Count = 51281\n",
      "Episode 6567: Reward = 588.00, Steps = 6, Loss = 11.6170, Exploration Rate = 0.1000, Train Count = 51287\n",
      "Episode 6568: Reward = 600.00, Steps = 2, Loss = 11.6557, Exploration Rate = 0.1000, Train Count = 51289\n",
      "Episode 6569: Reward = 591.00, Steps = 5, Loss = 7.9457, Exploration Rate = 0.1000, Train Count = 51294\n",
      "Episode 6570: Reward = 597.00, Steps = 3, Loss = 9.3576, Exploration Rate = 0.1000, Train Count = 51297\n",
      "Episode 6571: Reward = 597.00, Steps = 3, Loss = 12.9648, Exploration Rate = 0.1000, Train Count = 51300\n",
      "Episode 6572: Reward = 579.00, Steps = 9, Loss = 24.8856, Exploration Rate = 0.1000, Train Count = 51309\n",
      "Episode 6573: Reward = 582.00, Steps = 8, Loss = 24.2802, Exploration Rate = 0.1000, Train Count = 51317\n",
      "Episode 6574: Reward = 591.00, Steps = 5, Loss = 22.2470, Exploration Rate = 0.1000, Train Count = 51322\n",
      "Episode 6575: Reward = 600.00, Steps = 2, Loss = 18.8036, Exploration Rate = 0.1000, Train Count = 51324\n",
      "Episode 6576: Reward = 594.00, Steps = 4, Loss = 19.0197, Exploration Rate = 0.1000, Train Count = 51328\n",
      "Episode 6577: Reward = 597.00, Steps = 3, Loss = 16.9751, Exploration Rate = 0.1000, Train Count = 51331\n",
      "Episode 6578: Reward = 582.00, Steps = 8, Loss = 13.7422, Exploration Rate = 0.1000, Train Count = 51339\n",
      "Episode 6579: Reward = 582.00, Steps = 8, Loss = 13.4312, Exploration Rate = 0.1000, Train Count = 51347\n",
      "Episode 6580: Reward = 523.00, Steps = 12, Loss = 12.0799, Exploration Rate = 0.1000, Train Count = 51359\n",
      "Episode 6581: Reward = 594.00, Steps = 4, Loss = 10.2668, Exploration Rate = 0.1000, Train Count = 51363\n",
      "Episode 6582: Reward = 588.00, Steps = 6, Loss = 7.8871, Exploration Rate = 0.1000, Train Count = 51369\n",
      "Episode 6583: Reward = 594.00, Steps = 4, Loss = 11.2504, Exploration Rate = 0.1000, Train Count = 51373\n",
      "Episode 6584: Reward = 591.00, Steps = 5, Loss = 8.5442, Exploration Rate = 0.1000, Train Count = 51378\n",
      "Episode 6585: Reward = 588.00, Steps = 6, Loss = 10.1386, Exploration Rate = 0.1000, Train Count = 51384\n",
      "Episode 6586: Reward = 585.00, Steps = 7, Loss = 13.5803, Exploration Rate = 0.1000, Train Count = 51391\n",
      "Episode 6587: Reward = 591.00, Steps = 5, Loss = 12.8766, Exploration Rate = 0.1000, Train Count = 51396\n",
      "Episode 6588: Reward = 600.00, Steps = 2, Loss = 8.7567, Exploration Rate = 0.1000, Train Count = 51398\n",
      "Episode 6589: Reward = 588.00, Steps = 6, Loss = 13.1784, Exploration Rate = 0.1000, Train Count = 51404\n",
      "Episode 6590: Reward = 588.00, Steps = 6, Loss = 5.8907, Exploration Rate = 0.1000, Train Count = 51410\n",
      "Episode 6591: Reward = 594.00, Steps = 4, Loss = 10.2052, Exploration Rate = 0.1000, Train Count = 51414\n",
      "Episode 6592: Reward = 535.00, Steps = 8, Loss = 11.6826, Exploration Rate = 0.1000, Train Count = 51422\n",
      "Episode 6593: Reward = 588.00, Steps = 6, Loss = 10.3543, Exploration Rate = 0.1000, Train Count = 51428\n",
      "Episode 6594: Reward = 585.00, Steps = 7, Loss = 11.5345, Exploration Rate = 0.1000, Train Count = 51435\n",
      "Episode 6595: Reward = 591.00, Steps = 5, Loss = 12.9896, Exploration Rate = 0.1000, Train Count = 51440\n",
      "Episode 6596: Reward = 585.00, Steps = 7, Loss = 10.1096, Exploration Rate = 0.1000, Train Count = 51447\n",
      "Episode 6597: Reward = 597.00, Steps = 3, Loss = 9.9623, Exploration Rate = 0.1000, Train Count = 51450\n",
      "Episode 6598: Reward = 594.00, Steps = 4, Loss = 15.5935, Exploration Rate = 0.1000, Train Count = 51454\n",
      "Episode 6599: Reward = 594.00, Steps = 4, Loss = 10.2572, Exploration Rate = 0.1000, Train Count = 51458\n",
      "Episode 6600: Reward = 594.00, Steps = 4, Loss = 7.3603, Exploration Rate = 0.1000, Train Count = 51462\n",
      "Episode 6601: Reward = 594.00, Steps = 4, Loss = 15.3832, Exploration Rate = 0.1000, Train Count = 51466\n",
      "Episode 6602: Reward = 591.00, Steps = 5, Loss = 9.4664, Exploration Rate = 0.1000, Train Count = 51471\n",
      "Episode 6603: Reward = 561.00, Steps = 15, Loss = 16.5477, Exploration Rate = 0.1000, Train Count = 51486\n",
      "Episode 6604: Reward = 594.00, Steps = 4, Loss = 6.8697, Exploration Rate = 0.1000, Train Count = 51490\n",
      "Episode 6605: Reward = 588.00, Steps = 6, Loss = 14.7255, Exploration Rate = 0.1000, Train Count = 51496\n",
      "Episode 6606: Reward = 591.00, Steps = 5, Loss = 14.8989, Exploration Rate = 0.1000, Train Count = 51501\n",
      "Episode 6607: Reward = 585.00, Steps = 7, Loss = 11.7388, Exploration Rate = 0.1000, Train Count = 51508\n",
      "Episode 6608: Reward = 585.00, Steps = 7, Loss = 11.1812, Exploration Rate = 0.1000, Train Count = 51515\n",
      "Episode 6609: Reward = 585.00, Steps = 7, Loss = 8.7716, Exploration Rate = 0.1000, Train Count = 51522\n",
      "Episode 6610: Reward = 532.00, Steps = 9, Loss = 12.6300, Exploration Rate = 0.1000, Train Count = 51531\n",
      "Episode 6611: Reward = 579.00, Steps = 9, Loss = 11.6452, Exploration Rate = 0.1000, Train Count = 51540\n",
      "Episode 6612: Reward = 585.00, Steps = 7, Loss = 10.8351, Exploration Rate = 0.1000, Train Count = 51547\n",
      "Episode 6613: Reward = 591.00, Steps = 5, Loss = 12.2553, Exploration Rate = 0.1000, Train Count = 51552\n",
      "Episode 6614: Reward = 532.00, Steps = 9, Loss = 10.4490, Exploration Rate = 0.1000, Train Count = 51561\n",
      "Episode 6615: Reward = 591.00, Steps = 5, Loss = 7.8929, Exploration Rate = 0.1000, Train Count = 51566\n",
      "Episode 6616: Reward = 585.00, Steps = 7, Loss = 9.3339, Exploration Rate = 0.1000, Train Count = 51573\n",
      "Episode 6617: Reward = 597.00, Steps = 3, Loss = 7.9509, Exploration Rate = 0.1000, Train Count = 51576\n",
      "Episode 6618: Reward = 588.00, Steps = 6, Loss = 6.9366, Exploration Rate = 0.1000, Train Count = 51582\n",
      "Episode 6619: Reward = 588.00, Steps = 6, Loss = 12.3191, Exploration Rate = 0.1000, Train Count = 51588\n",
      "Episode 6620: Reward = 594.00, Steps = 4, Loss = 11.3828, Exploration Rate = 0.1000, Train Count = 51592\n",
      "Episode 6621: Reward = 591.00, Steps = 5, Loss = 8.7809, Exploration Rate = 0.1000, Train Count = 51597\n",
      "Episode 6622: Reward = 591.00, Steps = 5, Loss = 10.7832, Exploration Rate = 0.1000, Train Count = 51602\n",
      "Episode 6623: Reward = 582.00, Steps = 8, Loss = 16.6508, Exploration Rate = 0.1000, Train Count = 51610\n",
      "Episode 6624: Reward = 594.00, Steps = 4, Loss = 12.5939, Exploration Rate = 0.1000, Train Count = 51614\n",
      "Episode 6625: Reward = 591.00, Steps = 5, Loss = 14.7565, Exploration Rate = 0.1000, Train Count = 51619\n",
      "Episode 6626: Reward = 541.00, Steps = 6, Loss = 14.6622, Exploration Rate = 0.1000, Train Count = 51625\n",
      "Episode 6627: Reward = 585.00, Steps = 7, Loss = 14.5050, Exploration Rate = 0.1000, Train Count = 51632\n",
      "Episode 6628: Reward = 600.00, Steps = 2, Loss = 19.2572, Exploration Rate = 0.1000, Train Count = 51634\n",
      "Episode 6629: Reward = 582.00, Steps = 8, Loss = 12.8914, Exploration Rate = 0.1000, Train Count = 51642\n",
      "Episode 6630: Reward = 588.00, Steps = 6, Loss = 11.1692, Exploration Rate = 0.1000, Train Count = 51648\n",
      "Episode 6631: Reward = 588.00, Steps = 6, Loss = 11.6777, Exploration Rate = 0.1000, Train Count = 51654\n",
      "Episode 6632: Reward = 591.00, Steps = 5, Loss = 15.4460, Exploration Rate = 0.1000, Train Count = 51659\n",
      "Episode 6633: Reward = 597.00, Steps = 3, Loss = 14.1243, Exploration Rate = 0.1000, Train Count = 51662\n",
      "Episode 6634: Reward = 591.00, Steps = 5, Loss = 12.0979, Exploration Rate = 0.1000, Train Count = 51667\n",
      "Episode 6635: Reward = 597.00, Steps = 3, Loss = 13.8999, Exploration Rate = 0.1000, Train Count = 51670\n",
      "Episode 6636: Reward = 582.00, Steps = 8, Loss = 14.3881, Exploration Rate = 0.1000, Train Count = 51678\n",
      "Episode 6637: Reward = 579.00, Steps = 9, Loss = 11.3561, Exploration Rate = 0.1000, Train Count = 51687\n",
      "Episode 6638: Reward = 585.00, Steps = 7, Loss = 12.1676, Exploration Rate = 0.1000, Train Count = 51694\n",
      "Episode 6639: Reward = 582.00, Steps = 8, Loss = 12.8066, Exploration Rate = 0.1000, Train Count = 51702\n",
      "Episode 6640: Reward = 594.00, Steps = 4, Loss = 10.8878, Exploration Rate = 0.1000, Train Count = 51706\n",
      "Episode 6641: Reward = 588.00, Steps = 6, Loss = 10.1772, Exploration Rate = 0.1000, Train Count = 51712\n",
      "Episode 6642: Reward = 594.00, Steps = 4, Loss = 15.5480, Exploration Rate = 0.1000, Train Count = 51716\n",
      "Episode 6643: Reward = 570.00, Steps = 12, Loss = 12.2901, Exploration Rate = 0.1000, Train Count = 51728\n",
      "Episode 6644: Reward = 594.00, Steps = 4, Loss = 12.8677, Exploration Rate = 0.1000, Train Count = 51732\n",
      "Episode 6645: Reward = 582.00, Steps = 8, Loss = 10.9092, Exploration Rate = 0.1000, Train Count = 51740\n",
      "Episode 6646: Reward = 582.00, Steps = 8, Loss = 12.4747, Exploration Rate = 0.1000, Train Count = 51748\n",
      "Episode 6647: Reward = 588.00, Steps = 6, Loss = 7.5611, Exploration Rate = 0.1000, Train Count = 51754\n",
      "Episode 6648: Reward = 582.00, Steps = 8, Loss = 13.7498, Exploration Rate = 0.1000, Train Count = 51762\n",
      "Episode 6649: Reward = 588.00, Steps = 6, Loss = 10.1578, Exploration Rate = 0.1000, Train Count = 51768\n",
      "Episode 6650: Reward = 591.00, Steps = 5, Loss = 10.6255, Exploration Rate = 0.1000, Train Count = 51773\n",
      "Episode 6651: Reward = 585.00, Steps = 7, Loss = 12.2794, Exploration Rate = 0.1000, Train Count = 51780\n",
      "Episode 6652: Reward = 585.00, Steps = 7, Loss = 15.5957, Exploration Rate = 0.1000, Train Count = 51787\n",
      "Episode 6653: Reward = 585.00, Steps = 7, Loss = 13.8935, Exploration Rate = 0.1000, Train Count = 51794\n",
      "Episode 6654: Reward = 588.00, Steps = 6, Loss = 10.8203, Exploration Rate = 0.1000, Train Count = 51800\n",
      "Episode 6655: Reward = 591.00, Steps = 5, Loss = 31.0819, Exploration Rate = 0.1000, Train Count = 51805\n",
      "Episode 6656: Reward = 588.00, Steps = 6, Loss = 27.6848, Exploration Rate = 0.1000, Train Count = 51811\n",
      "Episode 6657: Reward = 535.00, Steps = 8, Loss = 23.5572, Exploration Rate = 0.1000, Train Count = 51819\n",
      "Episode 6658: Reward = 576.00, Steps = 10, Loss = 17.9123, Exploration Rate = 0.1000, Train Count = 51829\n",
      "Episode 6659: Reward = 579.00, Steps = 9, Loss = 12.1251, Exploration Rate = 0.1000, Train Count = 51838\n",
      "Episode 6660: Reward = 594.00, Steps = 4, Loss = 15.6251, Exploration Rate = 0.1000, Train Count = 51842\n",
      "Episode 6661: Reward = 594.00, Steps = 4, Loss = 14.0562, Exploration Rate = 0.1000, Train Count = 51846\n",
      "Episode 6662: Reward = 597.00, Steps = 3, Loss = 14.1879, Exploration Rate = 0.1000, Train Count = 51849\n",
      "Episode 6663: Reward = 588.00, Steps = 6, Loss = 15.2750, Exploration Rate = 0.1000, Train Count = 51855\n",
      "Episode 6664: Reward = 591.00, Steps = 5, Loss = 13.8378, Exploration Rate = 0.1000, Train Count = 51860\n",
      "Episode 6665: Reward = 585.00, Steps = 7, Loss = 14.7241, Exploration Rate = 0.1000, Train Count = 51867\n",
      "Episode 6666: Reward = 591.00, Steps = 5, Loss = 10.9417, Exploration Rate = 0.1000, Train Count = 51872\n",
      "Episode 6667: Reward = 597.00, Steps = 3, Loss = 11.9558, Exploration Rate = 0.1000, Train Count = 51875\n",
      "Episode 6668: Reward = 570.00, Steps = 12, Loss = 11.3334, Exploration Rate = 0.1000, Train Count = 51887\n",
      "Episode 6669: Reward = 588.00, Steps = 6, Loss = 13.0140, Exploration Rate = 0.1000, Train Count = 51893\n",
      "Episode 6670: Reward = 576.00, Steps = 10, Loss = 14.9151, Exploration Rate = 0.1000, Train Count = 51903\n",
      "Episode 6671: Reward = 591.00, Steps = 5, Loss = 5.5839, Exploration Rate = 0.1000, Train Count = 51908\n",
      "Episode 6672: Reward = 585.00, Steps = 7, Loss = 8.5157, Exploration Rate = 0.1000, Train Count = 51915\n",
      "Episode 6673: Reward = 585.00, Steps = 7, Loss = 11.7995, Exploration Rate = 0.1000, Train Count = 51922\n",
      "Episode 6674: Reward = 582.00, Steps = 8, Loss = 12.9566, Exploration Rate = 0.1000, Train Count = 51930\n",
      "Episode 6675: Reward = 591.00, Steps = 5, Loss = 13.7945, Exploration Rate = 0.1000, Train Count = 51935\n",
      "Episode 6676: Reward = 582.00, Steps = 8, Loss = 12.1346, Exploration Rate = 0.1000, Train Count = 51943\n",
      "Episode 6677: Reward = 591.00, Steps = 5, Loss = 10.6212, Exploration Rate = 0.1000, Train Count = 51948\n",
      "Episode 6678: Reward = 600.00, Steps = 2, Loss = 13.0036, Exploration Rate = 0.1000, Train Count = 51950\n",
      "Episode 6679: Reward = 591.00, Steps = 5, Loss = 13.7313, Exploration Rate = 0.1000, Train Count = 51955\n",
      "Episode 6680: Reward = 579.00, Steps = 9, Loss = 9.6828, Exploration Rate = 0.1000, Train Count = 51964\n",
      "Episode 6681: Reward = 594.00, Steps = 4, Loss = 8.6813, Exploration Rate = 0.1000, Train Count = 51968\n",
      "Episode 6682: Reward = 588.00, Steps = 6, Loss = 10.9035, Exploration Rate = 0.1000, Train Count = 51974\n",
      "Episode 6683: Reward = 588.00, Steps = 6, Loss = 5.0499, Exploration Rate = 0.1000, Train Count = 51980\n",
      "Episode 6684: Reward = 594.00, Steps = 4, Loss = 11.4018, Exploration Rate = 0.1000, Train Count = 51984\n",
      "Episode 6685: Reward = 597.00, Steps = 3, Loss = 6.2617, Exploration Rate = 0.1000, Train Count = 51987\n",
      "Episode 6686: Reward = 591.00, Steps = 5, Loss = 11.2286, Exploration Rate = 0.1000, Train Count = 51992\n",
      "Episode 6687: Reward = 594.00, Steps = 4, Loss = 6.3891, Exploration Rate = 0.1000, Train Count = 51996\n",
      "Episode 6688: Reward = 591.00, Steps = 5, Loss = 12.7921, Exploration Rate = 0.1000, Train Count = 52001\n",
      "Episode 6689: Reward = 588.00, Steps = 6, Loss = 6.5880, Exploration Rate = 0.1000, Train Count = 52007\n",
      "Episode 6690: Reward = 588.00, Steps = 6, Loss = 9.4268, Exploration Rate = 0.1000, Train Count = 52013\n",
      "Episode 6691: Reward = 579.00, Steps = 9, Loss = 11.7946, Exploration Rate = 0.1000, Train Count = 52022\n",
      "Episode 6692: Reward = 585.00, Steps = 7, Loss = 8.1403, Exploration Rate = 0.1000, Train Count = 52029\n",
      "Episode 6693: Reward = 591.00, Steps = 5, Loss = 7.2965, Exploration Rate = 0.1000, Train Count = 52034\n",
      "Episode 6694: Reward = 585.00, Steps = 7, Loss = 8.9524, Exploration Rate = 0.1000, Train Count = 52041\n",
      "Episode 6695: Reward = 582.00, Steps = 8, Loss = 9.4046, Exploration Rate = 0.1000, Train Count = 52049\n",
      "Episode 6696: Reward = 585.00, Steps = 7, Loss = 7.3112, Exploration Rate = 0.1000, Train Count = 52056\n",
      "Episode 6697: Reward = 594.00, Steps = 4, Loss = 5.5667, Exploration Rate = 0.1000, Train Count = 52060\n",
      "Episode 6698: Reward = 582.00, Steps = 8, Loss = 7.7804, Exploration Rate = 0.1000, Train Count = 52068\n",
      "Episode 6699: Reward = 585.00, Steps = 7, Loss = 6.8512, Exploration Rate = 0.1000, Train Count = 52075\n",
      "Episode 6700: Reward = 582.00, Steps = 8, Loss = 8.2533, Exploration Rate = 0.1000, Train Count = 52083\n",
      "Episode 6701: Reward = 591.00, Steps = 5, Loss = 9.4043, Exploration Rate = 0.1000, Train Count = 52088\n",
      "Episode 6702: Reward = 535.00, Steps = 8, Loss = 10.4518, Exploration Rate = 0.1000, Train Count = 52096\n",
      "Episode 6703: Reward = 582.00, Steps = 8, Loss = 6.2710, Exploration Rate = 0.1000, Train Count = 52104\n",
      "Episode 6704: Reward = 579.00, Steps = 9, Loss = 7.2248, Exploration Rate = 0.1000, Train Count = 52113\n",
      "Episode 6705: Reward = 600.00, Steps = 2, Loss = 8.8171, Exploration Rate = 0.1000, Train Count = 52115\n",
      "Episode 6706: Reward = 594.00, Steps = 4, Loss = 4.1434, Exploration Rate = 0.1000, Train Count = 52119\n",
      "Episode 6707: Reward = 600.00, Steps = 2, Loss = 17.2768, Exploration Rate = 0.1000, Train Count = 52121\n",
      "Episode 6708: Reward = 579.00, Steps = 9, Loss = 6.7521, Exploration Rate = 0.1000, Train Count = 52130\n",
      "Episode 6709: Reward = 597.00, Steps = 3, Loss = 11.6035, Exploration Rate = 0.1000, Train Count = 52133\n",
      "Episode 6710: Reward = 541.00, Steps = 6, Loss = 11.7316, Exploration Rate = 0.1000, Train Count = 52139\n",
      "Episode 6711: Reward = 588.00, Steps = 6, Loss = 9.2625, Exploration Rate = 0.1000, Train Count = 52145\n",
      "Episode 6712: Reward = 585.00, Steps = 7, Loss = 8.9460, Exploration Rate = 0.1000, Train Count = 52152\n",
      "Episode 6713: Reward = 591.00, Steps = 5, Loss = 13.4451, Exploration Rate = 0.1000, Train Count = 52157\n",
      "Episode 6714: Reward = 591.00, Steps = 5, Loss = 9.8120, Exploration Rate = 0.1000, Train Count = 52162\n",
      "Episode 6715: Reward = 594.00, Steps = 4, Loss = 9.4442, Exploration Rate = 0.1000, Train Count = 52166\n",
      "Episode 6716: Reward = 597.00, Steps = 3, Loss = 13.5244, Exploration Rate = 0.1000, Train Count = 52169\n",
      "Episode 6717: Reward = 594.00, Steps = 4, Loss = 5.2923, Exploration Rate = 0.1000, Train Count = 52173\n",
      "Episode 6718: Reward = 588.00, Steps = 6, Loss = 8.7961, Exploration Rate = 0.1000, Train Count = 52179\n",
      "Episode 6719: Reward = 591.00, Steps = 5, Loss = 10.1412, Exploration Rate = 0.1000, Train Count = 52184\n",
      "Episode 6720: Reward = 588.00, Steps = 6, Loss = 8.8302, Exploration Rate = 0.1000, Train Count = 52190\n",
      "Episode 6721: Reward = 591.00, Steps = 5, Loss = 9.3140, Exploration Rate = 0.1000, Train Count = 52195\n",
      "Episode 6722: Reward = 594.00, Steps = 4, Loss = 10.4084, Exploration Rate = 0.1000, Train Count = 52199\n",
      "Episode 6723: Reward = 576.00, Steps = 10, Loss = 5.9194, Exploration Rate = 0.1000, Train Count = 52209\n",
      "Episode 6724: Reward = 588.00, Steps = 6, Loss = 10.1206, Exploration Rate = 0.1000, Train Count = 52215\n",
      "Episode 6725: Reward = 582.00, Steps = 8, Loss = 7.7489, Exploration Rate = 0.1000, Train Count = 52223\n",
      "Episode 6726: Reward = 588.00, Steps = 6, Loss = 7.1354, Exploration Rate = 0.1000, Train Count = 52229\n",
      "Episode 6727: Reward = 588.00, Steps = 6, Loss = 9.1754, Exploration Rate = 0.1000, Train Count = 52235\n",
      "Episode 6728: Reward = 600.00, Steps = 2, Loss = 6.0307, Exploration Rate = 0.1000, Train Count = 52237\n",
      "Episode 6729: Reward = 588.00, Steps = 6, Loss = 8.4582, Exploration Rate = 0.1000, Train Count = 52243\n",
      "Episode 6730: Reward = 588.00, Steps = 6, Loss = 7.2734, Exploration Rate = 0.1000, Train Count = 52249\n",
      "Episode 6731: Reward = 597.00, Steps = 3, Loss = 3.4670, Exploration Rate = 0.1000, Train Count = 52252\n",
      "Episode 6732: Reward = 582.00, Steps = 8, Loss = 8.7642, Exploration Rate = 0.1000, Train Count = 52260\n",
      "Episode 6733: Reward = 600.00, Steps = 2, Loss = 3.5904, Exploration Rate = 0.1000, Train Count = 52262\n",
      "Episode 6734: Reward = 591.00, Steps = 5, Loss = 5.5340, Exploration Rate = 0.1000, Train Count = 52267\n",
      "Episode 6735: Reward = 594.00, Steps = 4, Loss = 4.2951, Exploration Rate = 0.1000, Train Count = 52271\n",
      "Episode 6736: Reward = 588.00, Steps = 6, Loss = 8.6732, Exploration Rate = 0.1000, Train Count = 52277\n",
      "Episode 6737: Reward = 573.00, Steps = 11, Loss = 4.8664, Exploration Rate = 0.1000, Train Count = 52288\n",
      "Episode 6738: Reward = 591.00, Steps = 5, Loss = 3.3478, Exploration Rate = 0.1000, Train Count = 52293\n",
      "Episode 6739: Reward = 582.00, Steps = 8, Loss = 3.7190, Exploration Rate = 0.1000, Train Count = 52301\n",
      "Episode 6740: Reward = 591.00, Steps = 5, Loss = 17.6059, Exploration Rate = 0.1000, Train Count = 52306\n",
      "Episode 6741: Reward = 591.00, Steps = 5, Loss = 17.1694, Exploration Rate = 0.1000, Train Count = 52311\n",
      "Episode 6742: Reward = 541.00, Steps = 6, Loss = 16.8947, Exploration Rate = 0.1000, Train Count = 52317\n",
      "Episode 6743: Reward = 582.00, Steps = 8, Loss = 13.1844, Exploration Rate = 0.1000, Train Count = 52325\n",
      "Episode 6744: Reward = 591.00, Steps = 5, Loss = 14.5787, Exploration Rate = 0.1000, Train Count = 52330\n",
      "Episode 6745: Reward = 594.00, Steps = 4, Loss = 9.5419, Exploration Rate = 0.1000, Train Count = 52334\n",
      "Episode 6746: Reward = 594.00, Steps = 4, Loss = 13.9852, Exploration Rate = 0.1000, Train Count = 52338\n",
      "Episode 6747: Reward = 585.00, Steps = 7, Loss = 9.9166, Exploration Rate = 0.1000, Train Count = 52345\n",
      "Episode 6748: Reward = 582.00, Steps = 8, Loss = 7.8642, Exploration Rate = 0.1000, Train Count = 52353\n",
      "Episode 6749: Reward = 597.00, Steps = 3, Loss = 5.7327, Exploration Rate = 0.1000, Train Count = 52356\n",
      "Episode 6750: Reward = 597.00, Steps = 3, Loss = 7.1663, Exploration Rate = 0.1000, Train Count = 52359\n",
      "Episode 6751: Reward = 585.00, Steps = 7, Loss = 8.1900, Exploration Rate = 0.1000, Train Count = 52366\n",
      "Episode 6752: Reward = 591.00, Steps = 5, Loss = 6.0509, Exploration Rate = 0.1000, Train Count = 52371\n",
      "Episode 6753: Reward = 594.00, Steps = 4, Loss = 8.2867, Exploration Rate = 0.1000, Train Count = 52375\n",
      "Episode 6754: Reward = 585.00, Steps = 7, Loss = 4.1516, Exploration Rate = 0.1000, Train Count = 52382\n",
      "Episode 6755: Reward = 582.00, Steps = 8, Loss = 5.0285, Exploration Rate = 0.1000, Train Count = 52390\n",
      "Episode 6756: Reward = 585.00, Steps = 7, Loss = 4.5631, Exploration Rate = 0.1000, Train Count = 52397\n",
      "Episode 6757: Reward = 594.00, Steps = 4, Loss = 1.8516, Exploration Rate = 0.1000, Train Count = 52401\n",
      "Episode 6758: Reward = 576.00, Steps = 10, Loss = 5.9360, Exploration Rate = 0.1000, Train Count = 52411\n",
      "Episode 6759: Reward = 597.00, Steps = 3, Loss = 7.3728, Exploration Rate = 0.1000, Train Count = 52414\n",
      "Episode 6760: Reward = 585.00, Steps = 7, Loss = 5.4708, Exploration Rate = 0.1000, Train Count = 52421\n",
      "Episode 6761: Reward = 588.00, Steps = 6, Loss = 6.7163, Exploration Rate = 0.1000, Train Count = 52427\n",
      "Episode 6762: Reward = 588.00, Steps = 6, Loss = 4.6022, Exploration Rate = 0.1000, Train Count = 52433\n",
      "Episode 6763: Reward = 588.00, Steps = 6, Loss = 10.6938, Exploration Rate = 0.1000, Train Count = 52439\n",
      "Episode 6764: Reward = 597.00, Steps = 3, Loss = 10.1625, Exploration Rate = 0.1000, Train Count = 52442\n",
      "Episode 6765: Reward = 588.00, Steps = 6, Loss = 9.2507, Exploration Rate = 0.1000, Train Count = 52448\n",
      "Episode 6766: Reward = 526.00, Steps = 11, Loss = 9.8939, Exploration Rate = 0.1000, Train Count = 52459\n",
      "Episode 6767: Reward = 582.00, Steps = 8, Loss = 6.5602, Exploration Rate = 0.1000, Train Count = 52467\n",
      "Episode 6768: Reward = 591.00, Steps = 5, Loss = 5.9612, Exploration Rate = 0.1000, Train Count = 52472\n",
      "Episode 6769: Reward = 582.00, Steps = 8, Loss = 5.4862, Exploration Rate = 0.1000, Train Count = 52480\n",
      "Episode 6770: Reward = 579.00, Steps = 9, Loss = 7.1208, Exploration Rate = 0.1000, Train Count = 52489\n",
      "Episode 6771: Reward = 597.00, Steps = 3, Loss = 5.8205, Exploration Rate = 0.1000, Train Count = 52492\n",
      "Episode 6772: Reward = 594.00, Steps = 4, Loss = 3.5176, Exploration Rate = 0.1000, Train Count = 52496\n",
      "Episode 6773: Reward = 594.00, Steps = 4, Loss = 9.7582, Exploration Rate = 0.1000, Train Count = 52500\n",
      "Episode 6774: Reward = 594.00, Steps = 4, Loss = 8.7987, Exploration Rate = 0.1000, Train Count = 52504\n",
      "Episode 6775: Reward = 582.00, Steps = 8, Loss = 7.8400, Exploration Rate = 0.1000, Train Count = 52512\n",
      "Episode 6776: Reward = 526.00, Steps = 11, Loss = 9.1677, Exploration Rate = 0.1000, Train Count = 52523\n",
      "Episode 6777: Reward = 588.00, Steps = 6, Loss = 8.7822, Exploration Rate = 0.1000, Train Count = 52529\n",
      "Episode 6778: Reward = 567.00, Steps = 13, Loss = 9.9603, Exploration Rate = 0.1000, Train Count = 52542\n",
      "Episode 6779: Reward = 588.00, Steps = 6, Loss = 4.7554, Exploration Rate = 0.1000, Train Count = 52548\n",
      "Episode 6780: Reward = 597.00, Steps = 3, Loss = 6.6873, Exploration Rate = 0.1000, Train Count = 52551\n",
      "Episode 6781: Reward = 591.00, Steps = 5, Loss = 5.6239, Exploration Rate = 0.1000, Train Count = 52556\n",
      "Episode 6782: Reward = 600.00, Steps = 2, Loss = 4.6277, Exploration Rate = 0.1000, Train Count = 52558\n",
      "Episode 6783: Reward = 585.00, Steps = 7, Loss = 5.3757, Exploration Rate = 0.1000, Train Count = 52565\n",
      "Episode 6784: Reward = 591.00, Steps = 5, Loss = 6.8735, Exploration Rate = 0.1000, Train Count = 52570\n",
      "Episode 6785: Reward = 576.00, Steps = 10, Loss = 6.1108, Exploration Rate = 0.1000, Train Count = 52580\n",
      "Episode 6786: Reward = 591.00, Steps = 5, Loss = 5.0082, Exploration Rate = 0.1000, Train Count = 52585\n",
      "Episode 6787: Reward = 588.00, Steps = 6, Loss = 7.0468, Exploration Rate = 0.1000, Train Count = 52591\n",
      "Episode 6788: Reward = 597.00, Steps = 3, Loss = 7.1811, Exploration Rate = 0.1000, Train Count = 52594\n",
      "Episode 6789: Reward = 597.00, Steps = 3, Loss = 8.7530, Exploration Rate = 0.1000, Train Count = 52597\n",
      "Episode 6790: Reward = 591.00, Steps = 5, Loss = 3.3126, Exploration Rate = 0.1000, Train Count = 52602\n",
      "Episode 6791: Reward = 588.00, Steps = 6, Loss = 5.6879, Exploration Rate = 0.1000, Train Count = 52608\n",
      "Episode 6792: Reward = 591.00, Steps = 5, Loss = 5.5365, Exploration Rate = 0.1000, Train Count = 52613\n",
      "Episode 6793: Reward = 579.00, Steps = 9, Loss = 4.0873, Exploration Rate = 0.1000, Train Count = 52622\n",
      "Episode 6794: Reward = 600.00, Steps = 2, Loss = 6.8244, Exploration Rate = 0.1000, Train Count = 52624\n",
      "Episode 6795: Reward = 588.00, Steps = 6, Loss = 6.0816, Exploration Rate = 0.1000, Train Count = 52630\n",
      "Episode 6796: Reward = 591.00, Steps = 5, Loss = 5.0944, Exploration Rate = 0.1000, Train Count = 52635\n",
      "Episode 6797: Reward = 591.00, Steps = 5, Loss = 7.2442, Exploration Rate = 0.1000, Train Count = 52640\n",
      "Episode 6798: Reward = 582.00, Steps = 8, Loss = 5.6751, Exploration Rate = 0.1000, Train Count = 52648\n",
      "Episode 6799: Reward = 544.00, Steps = 5, Loss = 3.9189, Exploration Rate = 0.1000, Train Count = 52653\n",
      "Episode 6800: Reward = 535.00, Steps = 8, Loss = 6.4162, Exploration Rate = 0.1000, Train Count = 52661\n",
      "Episode 6801: Reward = 579.00, Steps = 9, Loss = 4.1943, Exploration Rate = 0.1000, Train Count = 52670\n",
      "Episode 6802: Reward = 594.00, Steps = 4, Loss = 5.7311, Exploration Rate = 0.1000, Train Count = 52674\n",
      "Episode 6803: Reward = 591.00, Steps = 5, Loss = 3.0792, Exploration Rate = 0.1000, Train Count = 52679\n",
      "Episode 6804: Reward = 597.00, Steps = 3, Loss = 3.9248, Exploration Rate = 0.1000, Train Count = 52682\n",
      "Episode 6805: Reward = 523.00, Steps = 12, Loss = 6.1196, Exploration Rate = 0.1000, Train Count = 52694\n",
      "Episode 6806: Reward = 588.00, Steps = 6, Loss = 5.8444, Exploration Rate = 0.1000, Train Count = 52700\n",
      "Episode 6807: Reward = 588.00, Steps = 6, Loss = 5.8556, Exploration Rate = 0.1000, Train Count = 52706\n",
      "Episode 6808: Reward = 585.00, Steps = 7, Loss = 3.5372, Exploration Rate = 0.1000, Train Count = 52713\n",
      "Episode 6809: Reward = 585.00, Steps = 7, Loss = 7.2104, Exploration Rate = 0.1000, Train Count = 52720\n",
      "Episode 6810: Reward = 588.00, Steps = 6, Loss = 8.4025, Exploration Rate = 0.1000, Train Count = 52726\n",
      "Episode 6811: Reward = 591.00, Steps = 5, Loss = 7.6752, Exploration Rate = 0.1000, Train Count = 52731\n",
      "Episode 6812: Reward = 594.00, Steps = 4, Loss = 3.9115, Exploration Rate = 0.1000, Train Count = 52735\n",
      "Episode 6813: Reward = 591.00, Steps = 5, Loss = 12.3100, Exploration Rate = 0.1000, Train Count = 52740\n",
      "Episode 6814: Reward = 535.00, Steps = 8, Loss = 7.7678, Exploration Rate = 0.1000, Train Count = 52748\n",
      "Episode 6815: Reward = 579.00, Steps = 9, Loss = 12.2523, Exploration Rate = 0.1000, Train Count = 52757\n",
      "Episode 6816: Reward = 588.00, Steps = 6, Loss = 6.4473, Exploration Rate = 0.1000, Train Count = 52763\n",
      "Episode 6817: Reward = 588.00, Steps = 6, Loss = 4.8909, Exploration Rate = 0.1000, Train Count = 52769\n",
      "Episode 6818: Reward = 576.00, Steps = 10, Loss = 6.6587, Exploration Rate = 0.1000, Train Count = 52779\n",
      "Episode 6819: Reward = 585.00, Steps = 7, Loss = 7.5182, Exploration Rate = 0.1000, Train Count = 52786\n",
      "Episode 6820: Reward = 591.00, Steps = 5, Loss = 5.4014, Exploration Rate = 0.1000, Train Count = 52791\n",
      "Episode 6821: Reward = 591.00, Steps = 5, Loss = 5.2203, Exploration Rate = 0.1000, Train Count = 52796\n",
      "Episode 6822: Reward = 588.00, Steps = 6, Loss = 15.6950, Exploration Rate = 0.1000, Train Count = 52802\n",
      "Episode 6823: Reward = 588.00, Steps = 6, Loss = 19.7620, Exploration Rate = 0.1000, Train Count = 52808\n",
      "Episode 6824: Reward = 579.00, Steps = 9, Loss = 17.9370, Exploration Rate = 0.1000, Train Count = 52817\n",
      "Episode 6825: Reward = 588.00, Steps = 6, Loss = 16.3349, Exploration Rate = 0.1000, Train Count = 52823\n",
      "Episode 6826: Reward = 585.00, Steps = 7, Loss = 12.1688, Exploration Rate = 0.1000, Train Count = 52830\n",
      "Episode 6827: Reward = 597.00, Steps = 3, Loss = 9.3140, Exploration Rate = 0.1000, Train Count = 52833\n",
      "Episode 6828: Reward = 576.00, Steps = 10, Loss = 10.1745, Exploration Rate = 0.1000, Train Count = 52843\n",
      "Episode 6829: Reward = 579.00, Steps = 9, Loss = 7.8662, Exploration Rate = 0.1000, Train Count = 52852\n",
      "Episode 6830: Reward = 585.00, Steps = 7, Loss = 9.2307, Exploration Rate = 0.1000, Train Count = 52859\n",
      "Episode 6831: Reward = 600.00, Steps = 2, Loss = 4.6911, Exploration Rate = 0.1000, Train Count = 52861\n",
      "Episode 6832: Reward = 585.00, Steps = 7, Loss = 4.3295, Exploration Rate = 0.1000, Train Count = 52868\n",
      "Episode 6833: Reward = 597.00, Steps = 3, Loss = 6.8290, Exploration Rate = 0.1000, Train Count = 52871\n",
      "Episode 6834: Reward = 597.00, Steps = 3, Loss = 4.5881, Exploration Rate = 0.1000, Train Count = 52874\n",
      "Episode 6835: Reward = 576.00, Steps = 10, Loss = 4.8639, Exploration Rate = 0.1000, Train Count = 52884\n",
      "Episode 6836: Reward = 588.00, Steps = 6, Loss = 6.4922, Exploration Rate = 0.1000, Train Count = 52890\n",
      "Episode 6837: Reward = 582.00, Steps = 8, Loss = 8.1762, Exploration Rate = 0.1000, Train Count = 52898\n",
      "Episode 6838: Reward = 597.00, Steps = 3, Loss = 5.3460, Exploration Rate = 0.1000, Train Count = 52901\n",
      "Episode 6839: Reward = 591.00, Steps = 5, Loss = 8.7413, Exploration Rate = 0.1000, Train Count = 52906\n",
      "Episode 6840: Reward = 520.00, Steps = 13, Loss = 4.2830, Exploration Rate = 0.1000, Train Count = 52919\n",
      "Episode 6841: Reward = 582.00, Steps = 8, Loss = 4.5135, Exploration Rate = 0.1000, Train Count = 52927\n",
      "Episode 6842: Reward = 588.00, Steps = 6, Loss = 4.7066, Exploration Rate = 0.1000, Train Count = 52933\n",
      "Episode 6843: Reward = 594.00, Steps = 4, Loss = 7.1135, Exploration Rate = 0.1000, Train Count = 52937\n",
      "Episode 6844: Reward = 594.00, Steps = 4, Loss = 5.2030, Exploration Rate = 0.1000, Train Count = 52941\n",
      "Episode 6845: Reward = 591.00, Steps = 5, Loss = 5.8224, Exploration Rate = 0.1000, Train Count = 52946\n",
      "Episode 6846: Reward = 588.00, Steps = 6, Loss = 5.6725, Exploration Rate = 0.1000, Train Count = 52952\n",
      "Episode 6847: Reward = 585.00, Steps = 7, Loss = 4.4512, Exploration Rate = 0.1000, Train Count = 52959\n",
      "Episode 6848: Reward = 585.00, Steps = 7, Loss = 5.5892, Exploration Rate = 0.1000, Train Count = 52966\n",
      "Episode 6849: Reward = 582.00, Steps = 8, Loss = 7.0416, Exploration Rate = 0.1000, Train Count = 52974\n",
      "Episode 6850: Reward = 594.00, Steps = 4, Loss = 3.6838, Exploration Rate = 0.1000, Train Count = 52978\n",
      "Episode 6851: Reward = 594.00, Steps = 4, Loss = 5.7462, Exploration Rate = 0.1000, Train Count = 52982\n",
      "Episode 6852: Reward = 588.00, Steps = 6, Loss = 5.3657, Exploration Rate = 0.1000, Train Count = 52988\n",
      "Episode 6853: Reward = 597.00, Steps = 3, Loss = 5.1937, Exploration Rate = 0.1000, Train Count = 52991\n",
      "Episode 6854: Reward = 594.00, Steps = 4, Loss = 7.2863, Exploration Rate = 0.1000, Train Count = 52995\n",
      "Episode 6855: Reward = 582.00, Steps = 8, Loss = 7.9090, Exploration Rate = 0.1000, Train Count = 53003\n",
      "Episode 6856: Reward = 591.00, Steps = 5, Loss = 7.4860, Exploration Rate = 0.1000, Train Count = 53008\n",
      "Episode 6857: Reward = 588.00, Steps = 6, Loss = 6.3969, Exploration Rate = 0.1000, Train Count = 53014\n",
      "Episode 6858: Reward = 594.00, Steps = 4, Loss = 6.2334, Exploration Rate = 0.1000, Train Count = 53018\n",
      "Episode 6859: Reward = 585.00, Steps = 7, Loss = 6.8889, Exploration Rate = 0.1000, Train Count = 53025\n",
      "Episode 6860: Reward = 555.00, Steps = 17, Loss = 9.7056, Exploration Rate = 0.1000, Train Count = 53042\n",
      "Episode 6861: Reward = 582.00, Steps = 8, Loss = 8.6116, Exploration Rate = 0.1000, Train Count = 53050\n",
      "Episode 6862: Reward = 582.00, Steps = 8, Loss = 8.0655, Exploration Rate = 0.1000, Train Count = 53058\n",
      "Episode 6863: Reward = 585.00, Steps = 7, Loss = 10.7920, Exploration Rate = 0.1000, Train Count = 53065\n",
      "Episode 6864: Reward = 579.00, Steps = 9, Loss = 6.3463, Exploration Rate = 0.1000, Train Count = 53074\n",
      "Episode 6865: Reward = 585.00, Steps = 7, Loss = 9.4795, Exploration Rate = 0.1000, Train Count = 53081\n",
      "Episode 6866: Reward = 585.00, Steps = 7, Loss = 9.2167, Exploration Rate = 0.1000, Train Count = 53088\n",
      "Episode 6867: Reward = 591.00, Steps = 5, Loss = 4.0938, Exploration Rate = 0.1000, Train Count = 53093\n",
      "Episode 6868: Reward = 588.00, Steps = 6, Loss = 6.5074, Exploration Rate = 0.1000, Train Count = 53099\n",
      "Episode 6869: Reward = 585.00, Steps = 7, Loss = 4.3560, Exploration Rate = 0.1000, Train Count = 53106\n",
      "Episode 6870: Reward = 576.00, Steps = 10, Loss = 5.5621, Exploration Rate = 0.1000, Train Count = 53116\n",
      "Episode 6871: Reward = 582.00, Steps = 8, Loss = 4.5021, Exploration Rate = 0.1000, Train Count = 53124\n",
      "Episode 6872: Reward = 576.00, Steps = 10, Loss = 5.8965, Exploration Rate = 0.1000, Train Count = 53134\n",
      "Episode 6873: Reward = 526.00, Steps = 11, Loss = 7.6247, Exploration Rate = 0.1000, Train Count = 53145\n",
      "Episode 6874: Reward = 597.00, Steps = 3, Loss = 3.5895, Exploration Rate = 0.1000, Train Count = 53148\n",
      "Episode 6875: Reward = 588.00, Steps = 6, Loss = 4.6993, Exploration Rate = 0.1000, Train Count = 53154\n",
      "Episode 6876: Reward = 597.00, Steps = 3, Loss = 2.9281, Exploration Rate = 0.1000, Train Count = 53157\n",
      "Episode 6877: Reward = 582.00, Steps = 8, Loss = 5.2403, Exploration Rate = 0.1000, Train Count = 53165\n",
      "Episode 6878: Reward = 585.00, Steps = 7, Loss = 3.8855, Exploration Rate = 0.1000, Train Count = 53172\n",
      "Episode 6879: Reward = 576.00, Steps = 10, Loss = 4.4537, Exploration Rate = 0.1000, Train Count = 53182\n",
      "Episode 6880: Reward = 576.00, Steps = 10, Loss = 4.2785, Exploration Rate = 0.1000, Train Count = 53192\n",
      "Episode 6881: Reward = 585.00, Steps = 7, Loss = 6.4642, Exploration Rate = 0.1000, Train Count = 53199\n",
      "Episode 6882: Reward = 585.00, Steps = 7, Loss = 5.5903, Exploration Rate = 0.1000, Train Count = 53206\n",
      "Episode 6883: Reward = 591.00, Steps = 5, Loss = 5.8727, Exploration Rate = 0.1000, Train Count = 53211\n",
      "Episode 6884: Reward = 585.00, Steps = 7, Loss = 3.1760, Exploration Rate = 0.1000, Train Count = 53218\n",
      "Episode 6885: Reward = 591.00, Steps = 5, Loss = 4.2183, Exploration Rate = 0.1000, Train Count = 53223\n",
      "Episode 6886: Reward = 591.00, Steps = 5, Loss = 7.0399, Exploration Rate = 0.1000, Train Count = 53228\n",
      "Episode 6887: Reward = 570.00, Steps = 12, Loss = 4.6352, Exploration Rate = 0.1000, Train Count = 53240\n",
      "Episode 6888: Reward = 591.00, Steps = 5, Loss = 5.4202, Exploration Rate = 0.1000, Train Count = 53245\n",
      "Episode 6889: Reward = 585.00, Steps = 7, Loss = 3.3470, Exploration Rate = 0.1000, Train Count = 53252\n",
      "Episode 6890: Reward = 591.00, Steps = 5, Loss = 5.7451, Exploration Rate = 0.1000, Train Count = 53257\n",
      "Episode 6891: Reward = 585.00, Steps = 7, Loss = 5.4874, Exploration Rate = 0.1000, Train Count = 53264\n",
      "Episode 6892: Reward = 597.00, Steps = 3, Loss = 7.6561, Exploration Rate = 0.1000, Train Count = 53267\n",
      "Episode 6893: Reward = 585.00, Steps = 7, Loss = 6.7535, Exploration Rate = 0.1000, Train Count = 53274\n",
      "Episode 6894: Reward = 585.00, Steps = 7, Loss = 5.4037, Exploration Rate = 0.1000, Train Count = 53281\n",
      "Episode 6895: Reward = 591.00, Steps = 5, Loss = 6.8819, Exploration Rate = 0.1000, Train Count = 53286\n",
      "Episode 6896: Reward = 591.00, Steps = 5, Loss = 4.6051, Exploration Rate = 0.1000, Train Count = 53291\n",
      "Episode 6897: Reward = 535.00, Steps = 8, Loss = 5.2910, Exploration Rate = 0.1000, Train Count = 53299\n",
      "Episode 6898: Reward = 585.00, Steps = 7, Loss = 32.5577, Exploration Rate = 0.1000, Train Count = 53306\n",
      "Episode 6899: Reward = 597.00, Steps = 3, Loss = 22.1790, Exploration Rate = 0.1000, Train Count = 53309\n",
      "Episode 6900: Reward = 591.00, Steps = 5, Loss = 24.2127, Exploration Rate = 0.1000, Train Count = 53314\n",
      "Episode 6901: Reward = 582.00, Steps = 8, Loss = 14.3566, Exploration Rate = 0.1000, Train Count = 53322\n",
      "Episode 6902: Reward = 576.00, Steps = 10, Loss = 12.1344, Exploration Rate = 0.1000, Train Count = 53332\n",
      "Episode 6903: Reward = 591.00, Steps = 5, Loss = 11.5626, Exploration Rate = 0.1000, Train Count = 53337\n",
      "Episode 6904: Reward = 576.00, Steps = 10, Loss = 9.2781, Exploration Rate = 0.1000, Train Count = 53347\n",
      "Episode 6905: Reward = 535.00, Steps = 8, Loss = 12.3070, Exploration Rate = 0.1000, Train Count = 53355\n",
      "Episode 6906: Reward = 588.00, Steps = 6, Loss = 11.4867, Exploration Rate = 0.1000, Train Count = 53361\n",
      "Episode 6907: Reward = 594.00, Steps = 4, Loss = 7.5627, Exploration Rate = 0.1000, Train Count = 53365\n",
      "Episode 6908: Reward = 585.00, Steps = 7, Loss = 5.6445, Exploration Rate = 0.1000, Train Count = 53372\n",
      "Episode 6909: Reward = 597.00, Steps = 3, Loss = 7.4377, Exploration Rate = 0.1000, Train Count = 53375\n",
      "Episode 6910: Reward = 588.00, Steps = 6, Loss = 5.8496, Exploration Rate = 0.1000, Train Count = 53381\n",
      "Episode 6911: Reward = 582.00, Steps = 8, Loss = 8.0627, Exploration Rate = 0.1000, Train Count = 53389\n",
      "Episode 6912: Reward = 588.00, Steps = 6, Loss = 4.7010, Exploration Rate = 0.1000, Train Count = 53395\n",
      "Episode 6913: Reward = 585.00, Steps = 7, Loss = 5.5159, Exploration Rate = 0.1000, Train Count = 53402\n",
      "Episode 6914: Reward = 597.00, Steps = 3, Loss = 4.6237, Exploration Rate = 0.1000, Train Count = 53405\n",
      "Episode 6915: Reward = 594.00, Steps = 4, Loss = 4.3627, Exploration Rate = 0.1000, Train Count = 53409\n",
      "Episode 6916: Reward = 579.00, Steps = 9, Loss = 3.3456, Exploration Rate = 0.1000, Train Count = 53418\n",
      "Episode 6917: Reward = 588.00, Steps = 6, Loss = 2.7509, Exploration Rate = 0.1000, Train Count = 53424\n",
      "Episode 6918: Reward = 585.00, Steps = 7, Loss = 3.3901, Exploration Rate = 0.1000, Train Count = 53431\n",
      "Episode 6919: Reward = 597.00, Steps = 3, Loss = 2.5535, Exploration Rate = 0.1000, Train Count = 53434\n",
      "Episode 6920: Reward = 579.00, Steps = 9, Loss = 1.5154, Exploration Rate = 0.1000, Train Count = 53443\n",
      "Episode 6921: Reward = 591.00, Steps = 5, Loss = 1.7853, Exploration Rate = 0.1000, Train Count = 53448\n",
      "Episode 6922: Reward = 579.00, Steps = 9, Loss = 2.6963, Exploration Rate = 0.1000, Train Count = 53457\n",
      "Episode 6923: Reward = 594.00, Steps = 4, Loss = 3.3728, Exploration Rate = 0.1000, Train Count = 53461\n",
      "Episode 6924: Reward = 591.00, Steps = 5, Loss = 4.0071, Exploration Rate = 0.1000, Train Count = 53466\n",
      "Episode 6925: Reward = 594.00, Steps = 4, Loss = 3.8118, Exploration Rate = 0.1000, Train Count = 53470\n",
      "Episode 6926: Reward = 538.00, Steps = 7, Loss = 4.3005, Exploration Rate = 0.1000, Train Count = 53477\n",
      "Episode 6927: Reward = 585.00, Steps = 7, Loss = 3.9594, Exploration Rate = 0.1000, Train Count = 53484\n",
      "Episode 6928: Reward = 579.00, Steps = 9, Loss = 4.5902, Exploration Rate = 0.1000, Train Count = 53493\n",
      "Episode 6929: Reward = 570.00, Steps = 12, Loss = 4.0358, Exploration Rate = 0.1000, Train Count = 53505\n",
      "Episode 6930: Reward = 597.00, Steps = 3, Loss = 6.8951, Exploration Rate = 0.1000, Train Count = 53508\n",
      "Episode 6931: Reward = 597.00, Steps = 3, Loss = 7.2677, Exploration Rate = 0.1000, Train Count = 53511\n",
      "Episode 6932: Reward = 591.00, Steps = 5, Loss = 8.4917, Exploration Rate = 0.1000, Train Count = 53516\n",
      "Episode 6933: Reward = 585.00, Steps = 7, Loss = 6.1033, Exploration Rate = 0.1000, Train Count = 53523\n",
      "Episode 6934: Reward = 585.00, Steps = 7, Loss = 5.7513, Exploration Rate = 0.1000, Train Count = 53530\n",
      "Episode 6935: Reward = 588.00, Steps = 6, Loss = 2.8095, Exploration Rate = 0.1000, Train Count = 53536\n",
      "Episode 6936: Reward = 588.00, Steps = 6, Loss = 3.7328, Exploration Rate = 0.1000, Train Count = 53542\n",
      "Episode 6937: Reward = 597.00, Steps = 3, Loss = 1.1869, Exploration Rate = 0.1000, Train Count = 53545\n",
      "Episode 6938: Reward = 588.00, Steps = 6, Loss = 4.6401, Exploration Rate = 0.1000, Train Count = 53551\n",
      "Episode 6939: Reward = 491.00, Steps = 7, Loss = 3.9857, Exploration Rate = 0.1000, Train Count = 53558\n",
      "Episode 6940: Reward = 588.00, Steps = 6, Loss = 13.4601, Exploration Rate = 0.1000, Train Count = 53564\n",
      "Episode 6941: Reward = 597.00, Steps = 3, Loss = 12.6059, Exploration Rate = 0.1000, Train Count = 53567\n",
      "Episode 6942: Reward = 594.00, Steps = 4, Loss = 6.8801, Exploration Rate = 0.1000, Train Count = 53571\n",
      "Episode 6943: Reward = 588.00, Steps = 6, Loss = 5.3844, Exploration Rate = 0.1000, Train Count = 53577\n",
      "Episode 6944: Reward = 591.00, Steps = 5, Loss = 4.9043, Exploration Rate = 0.1000, Train Count = 53582\n",
      "Episode 6945: Reward = 594.00, Steps = 4, Loss = 5.9062, Exploration Rate = 0.1000, Train Count = 53586\n",
      "Episode 6946: Reward = 585.00, Steps = 7, Loss = 4.5199, Exploration Rate = 0.1000, Train Count = 53593\n",
      "Episode 6947: Reward = 594.00, Steps = 4, Loss = 3.9437, Exploration Rate = 0.1000, Train Count = 53597\n",
      "Episode 6948: Reward = 526.00, Steps = 11, Loss = 4.2396, Exploration Rate = 0.1000, Train Count = 53608\n",
      "Episode 6949: Reward = 594.00, Steps = 4, Loss = 2.8104, Exploration Rate = 0.1000, Train Count = 53612\n",
      "Episode 6950: Reward = 579.00, Steps = 9, Loss = 2.6627, Exploration Rate = 0.1000, Train Count = 53621\n",
      "Episode 6951: Reward = 582.00, Steps = 8, Loss = 3.5131, Exploration Rate = 0.1000, Train Count = 53629\n",
      "Episode 6952: Reward = 588.00, Steps = 6, Loss = 4.5961, Exploration Rate = 0.1000, Train Count = 53635\n",
      "Episode 6953: Reward = 591.00, Steps = 5, Loss = 5.5219, Exploration Rate = 0.1000, Train Count = 53640\n",
      "Episode 6954: Reward = 582.00, Steps = 8, Loss = 6.5305, Exploration Rate = 0.1000, Train Count = 53648\n",
      "Episode 6955: Reward = 576.00, Steps = 10, Loss = 4.3760, Exploration Rate = 0.1000, Train Count = 53658\n",
      "Episode 6956: Reward = 591.00, Steps = 5, Loss = 2.5609, Exploration Rate = 0.1000, Train Count = 53663\n",
      "Episode 6957: Reward = 582.00, Steps = 8, Loss = 2.1991, Exploration Rate = 0.1000, Train Count = 53671\n",
      "Episode 6958: Reward = 591.00, Steps = 5, Loss = 3.1559, Exploration Rate = 0.1000, Train Count = 53676\n",
      "Episode 6959: Reward = 591.00, Steps = 5, Loss = 2.2146, Exploration Rate = 0.1000, Train Count = 53681\n",
      "Episode 6960: Reward = 582.00, Steps = 8, Loss = 2.7838, Exploration Rate = 0.1000, Train Count = 53689\n",
      "Episode 6961: Reward = 597.00, Steps = 3, Loss = 3.2721, Exploration Rate = 0.1000, Train Count = 53692\n",
      "Episode 6962: Reward = 594.00, Steps = 4, Loss = 2.3151, Exploration Rate = 0.1000, Train Count = 53696\n",
      "Episode 6963: Reward = 585.00, Steps = 7, Loss = 4.5163, Exploration Rate = 0.1000, Train Count = 53703\n",
      "Episode 6964: Reward = 582.00, Steps = 8, Loss = 5.1242, Exploration Rate = 0.1000, Train Count = 53711\n",
      "Episode 6965: Reward = 582.00, Steps = 8, Loss = 5.6820, Exploration Rate = 0.1000, Train Count = 53719\n",
      "Episode 6966: Reward = 588.00, Steps = 6, Loss = 4.6362, Exploration Rate = 0.1000, Train Count = 53725\n",
      "Episode 6967: Reward = 597.00, Steps = 3, Loss = 3.3974, Exploration Rate = 0.1000, Train Count = 53728\n",
      "Episode 6968: Reward = 585.00, Steps = 7, Loss = 2.4431, Exploration Rate = 0.1000, Train Count = 53735\n",
      "Episode 6969: Reward = 597.00, Steps = 3, Loss = 1.5442, Exploration Rate = 0.1000, Train Count = 53738\n",
      "Episode 6970: Reward = 582.00, Steps = 8, Loss = 4.3496, Exploration Rate = 0.1000, Train Count = 53746\n",
      "Episode 6971: Reward = 576.00, Steps = 10, Loss = 3.7694, Exploration Rate = 0.1000, Train Count = 53756\n",
      "Episode 6972: Reward = 582.00, Steps = 8, Loss = 3.4080, Exploration Rate = 0.1000, Train Count = 53764\n",
      "Episode 6973: Reward = 591.00, Steps = 5, Loss = 3.3055, Exploration Rate = 0.1000, Train Count = 53769\n",
      "Episode 6974: Reward = 588.00, Steps = 6, Loss = 1.0687, Exploration Rate = 0.1000, Train Count = 53775\n",
      "Episode 6975: Reward = 579.00, Steps = 9, Loss = 1.1886, Exploration Rate = 0.1000, Train Count = 53784\n",
      "Episode 6976: Reward = 582.00, Steps = 8, Loss = 1.7061, Exploration Rate = 0.1000, Train Count = 53792\n",
      "Episode 6977: Reward = 597.00, Steps = 3, Loss = 3.5386, Exploration Rate = 0.1000, Train Count = 53795\n",
      "Episode 6978: Reward = 591.00, Steps = 5, Loss = 1.8683, Exploration Rate = 0.1000, Train Count = 53800\n",
      "Episode 6979: Reward = 594.00, Steps = 4, Loss = 28.1657, Exploration Rate = 0.1000, Train Count = 53804\n",
      "Episode 6980: Reward = 532.00, Steps = 9, Loss = 22.2412, Exploration Rate = 0.1000, Train Count = 53813\n",
      "Episode 6981: Reward = 585.00, Steps = 7, Loss = 22.0427, Exploration Rate = 0.1000, Train Count = 53820\n",
      "Episode 6982: Reward = 600.00, Steps = 2, Loss = 16.7946, Exploration Rate = 0.1000, Train Count = 53822\n",
      "Episode 6983: Reward = 594.00, Steps = 4, Loss = 17.3105, Exploration Rate = 0.1000, Train Count = 53826\n",
      "Episode 6984: Reward = 591.00, Steps = 5, Loss = 12.8381, Exploration Rate = 0.1000, Train Count = 53831\n",
      "Episode 6985: Reward = 588.00, Steps = 6, Loss = 10.7711, Exploration Rate = 0.1000, Train Count = 53837\n",
      "Episode 6986: Reward = 582.00, Steps = 8, Loss = 9.1325, Exploration Rate = 0.1000, Train Count = 53845\n",
      "Episode 6987: Reward = 591.00, Steps = 5, Loss = 8.0256, Exploration Rate = 0.1000, Train Count = 53850\n",
      "Episode 6988: Reward = 588.00, Steps = 6, Loss = 7.3015, Exploration Rate = 0.1000, Train Count = 53856\n",
      "Episode 6989: Reward = 594.00, Steps = 4, Loss = 6.8903, Exploration Rate = 0.1000, Train Count = 53860\n",
      "Episode 6990: Reward = 579.00, Steps = 9, Loss = 5.2395, Exploration Rate = 0.1000, Train Count = 53869\n",
      "Episode 6991: Reward = 585.00, Steps = 7, Loss = 7.2163, Exploration Rate = 0.1000, Train Count = 53876\n",
      "Episode 6992: Reward = 541.00, Steps = 6, Loss = 4.8414, Exploration Rate = 0.1000, Train Count = 53882\n",
      "Episode 6993: Reward = 591.00, Steps = 5, Loss = 5.2935, Exploration Rate = 0.1000, Train Count = 53887\n",
      "Episode 6994: Reward = 573.00, Steps = 11, Loss = 7.3129, Exploration Rate = 0.1000, Train Count = 53898\n",
      "Episode 6995: Reward = 588.00, Steps = 6, Loss = 4.1506, Exploration Rate = 0.1000, Train Count = 53904\n",
      "Episode 6996: Reward = 591.00, Steps = 5, Loss = 4.9444, Exploration Rate = 0.1000, Train Count = 53909\n",
      "Episode 6997: Reward = 585.00, Steps = 7, Loss = 4.8883, Exploration Rate = 0.1000, Train Count = 53916\n",
      "Episode 6998: Reward = 594.00, Steps = 4, Loss = 6.8754, Exploration Rate = 0.1000, Train Count = 53920\n",
      "Episode 6999: Reward = 585.00, Steps = 7, Loss = 4.9112, Exploration Rate = 0.1000, Train Count = 53927\n",
      "Episode 7000: Reward = 597.00, Steps = 3, Loss = 4.1202, Exploration Rate = 0.1000, Train Count = 53930\n",
      "Episode 7001: Reward = 579.00, Steps = 9, Loss = 7.0617, Exploration Rate = 0.1000, Train Count = 53939\n",
      "Episode 7002: Reward = 529.00, Steps = 10, Loss = 4.3677, Exploration Rate = 0.1000, Train Count = 53949\n",
      "Episode 7003: Reward = 535.00, Steps = 8, Loss = 5.4833, Exploration Rate = 0.1000, Train Count = 53957\n",
      "Episode 7004: Reward = 588.00, Steps = 6, Loss = 2.8353, Exploration Rate = 0.1000, Train Count = 53963\n",
      "Episode 7005: Reward = 588.00, Steps = 6, Loss = 4.5157, Exploration Rate = 0.1000, Train Count = 53969\n",
      "Episode 7006: Reward = 582.00, Steps = 8, Loss = 6.1905, Exploration Rate = 0.1000, Train Count = 53977\n",
      "Episode 7007: Reward = 588.00, Steps = 6, Loss = 5.3804, Exploration Rate = 0.1000, Train Count = 53983\n",
      "Episode 7008: Reward = 573.00, Steps = 11, Loss = 3.6663, Exploration Rate = 0.1000, Train Count = 53994\n",
      "Episode 7009: Reward = 579.00, Steps = 9, Loss = 5.7528, Exploration Rate = 0.1000, Train Count = 54003\n",
      "Episode 7010: Reward = 532.00, Steps = 9, Loss = 5.7152, Exploration Rate = 0.1000, Train Count = 54012\n",
      "Episode 7011: Reward = 591.00, Steps = 5, Loss = 9.0537, Exploration Rate = 0.1000, Train Count = 54017\n",
      "Episode 7012: Reward = 591.00, Steps = 5, Loss = 12.7819, Exploration Rate = 0.1000, Train Count = 54022\n",
      "Episode 7013: Reward = 541.00, Steps = 6, Loss = 11.3267, Exploration Rate = 0.1000, Train Count = 54028\n",
      "Episode 7014: Reward = 582.00, Steps = 8, Loss = 15.5698, Exploration Rate = 0.1000, Train Count = 54036\n",
      "Episode 7015: Reward = 600.00, Steps = 2, Loss = 10.7724, Exploration Rate = 0.1000, Train Count = 54038\n",
      "Episode 7016: Reward = 585.00, Steps = 7, Loss = 8.8614, Exploration Rate = 0.1000, Train Count = 54045\n",
      "Episode 7017: Reward = 573.00, Steps = 11, Loss = 7.7249, Exploration Rate = 0.1000, Train Count = 54056\n",
      "Episode 7018: Reward = 588.00, Steps = 6, Loss = 5.7965, Exploration Rate = 0.1000, Train Count = 54062\n",
      "Episode 7019: Reward = 594.00, Steps = 4, Loss = 5.4124, Exploration Rate = 0.1000, Train Count = 54066\n",
      "Episode 7020: Reward = 582.00, Steps = 8, Loss = 8.7255, Exploration Rate = 0.1000, Train Count = 54074\n",
      "Episode 7021: Reward = 597.00, Steps = 3, Loss = 8.9438, Exploration Rate = 0.1000, Train Count = 54077\n",
      "Episode 7022: Reward = 588.00, Steps = 6, Loss = 7.8748, Exploration Rate = 0.1000, Train Count = 54083\n",
      "Episode 7023: Reward = 594.00, Steps = 4, Loss = 7.4813, Exploration Rate = 0.1000, Train Count = 54087\n",
      "Episode 7024: Reward = 594.00, Steps = 4, Loss = 8.7925, Exploration Rate = 0.1000, Train Count = 54091\n",
      "Episode 7025: Reward = 594.00, Steps = 4, Loss = 5.8725, Exploration Rate = 0.1000, Train Count = 54095\n",
      "Episode 7026: Reward = 594.00, Steps = 4, Loss = 5.7534, Exploration Rate = 0.1000, Train Count = 54099\n",
      "Episode 7027: Reward = 591.00, Steps = 5, Loss = 3.4983, Exploration Rate = 0.1000, Train Count = 54104\n",
      "Episode 7028: Reward = 600.00, Steps = 2, Loss = 2.7761, Exploration Rate = 0.1000, Train Count = 54106\n",
      "Episode 7029: Reward = 588.00, Steps = 6, Loss = 7.4981, Exploration Rate = 0.1000, Train Count = 54112\n",
      "Episode 7030: Reward = 588.00, Steps = 6, Loss = 7.5427, Exploration Rate = 0.1000, Train Count = 54118\n",
      "Episode 7031: Reward = 585.00, Steps = 7, Loss = 5.0896, Exploration Rate = 0.1000, Train Count = 54125\n",
      "Episode 7032: Reward = 597.00, Steps = 3, Loss = 5.7673, Exploration Rate = 0.1000, Train Count = 54128\n",
      "Episode 7033: Reward = 541.00, Steps = 6, Loss = 7.7197, Exploration Rate = 0.1000, Train Count = 54134\n",
      "Episode 7034: Reward = 591.00, Steps = 5, Loss = 8.5486, Exploration Rate = 0.1000, Train Count = 54139\n",
      "Episode 7035: Reward = 591.00, Steps = 5, Loss = 7.6674, Exploration Rate = 0.1000, Train Count = 54144\n",
      "Episode 7036: Reward = 547.00, Steps = 4, Loss = 9.5212, Exploration Rate = 0.1000, Train Count = 54148\n",
      "Episode 7037: Reward = 600.00, Steps = 2, Loss = 14.9516, Exploration Rate = 0.1000, Train Count = 54150\n",
      "Episode 7038: Reward = 585.00, Steps = 7, Loss = 9.4049, Exploration Rate = 0.1000, Train Count = 54157\n",
      "Episode 7039: Reward = 588.00, Steps = 6, Loss = 9.2419, Exploration Rate = 0.1000, Train Count = 54163\n",
      "Episode 7040: Reward = 594.00, Steps = 4, Loss = 10.1743, Exploration Rate = 0.1000, Train Count = 54167\n",
      "Episode 7041: Reward = 594.00, Steps = 4, Loss = 12.9081, Exploration Rate = 0.1000, Train Count = 54171\n",
      "Episode 7042: Reward = 591.00, Steps = 5, Loss = 5.5724, Exploration Rate = 0.1000, Train Count = 54176\n",
      "Episode 7043: Reward = 585.00, Steps = 7, Loss = 7.9877, Exploration Rate = 0.1000, Train Count = 54183\n",
      "Episode 7044: Reward = 585.00, Steps = 7, Loss = 8.9050, Exploration Rate = 0.1000, Train Count = 54190\n",
      "Episode 7045: Reward = 594.00, Steps = 4, Loss = 10.1916, Exploration Rate = 0.1000, Train Count = 54194\n",
      "Episode 7046: Reward = 594.00, Steps = 4, Loss = 13.6993, Exploration Rate = 0.1000, Train Count = 54198\n",
      "Episode 7047: Reward = 585.00, Steps = 7, Loss = 10.3046, Exploration Rate = 0.1000, Train Count = 54205\n",
      "Episode 7048: Reward = 585.00, Steps = 7, Loss = 8.5802, Exploration Rate = 0.1000, Train Count = 54212\n",
      "Episode 7049: Reward = 588.00, Steps = 6, Loss = 8.9563, Exploration Rate = 0.1000, Train Count = 54218\n",
      "Episode 7050: Reward = 538.00, Steps = 7, Loss = 12.8265, Exploration Rate = 0.1000, Train Count = 54225\n",
      "Episode 7051: Reward = 591.00, Steps = 5, Loss = 9.1179, Exploration Rate = 0.1000, Train Count = 54230\n",
      "Episode 7052: Reward = 576.00, Steps = 10, Loss = 9.1940, Exploration Rate = 0.1000, Train Count = 54240\n",
      "Episode 7053: Reward = 582.00, Steps = 8, Loss = 8.6022, Exploration Rate = 0.1000, Train Count = 54248\n",
      "Episode 7054: Reward = 579.00, Steps = 9, Loss = 7.8937, Exploration Rate = 0.1000, Train Count = 54257\n",
      "Episode 7055: Reward = 597.00, Steps = 3, Loss = 10.2267, Exploration Rate = 0.1000, Train Count = 54260\n",
      "Episode 7056: Reward = 591.00, Steps = 5, Loss = 8.3771, Exploration Rate = 0.1000, Train Count = 54265\n",
      "Episode 7057: Reward = 588.00, Steps = 6, Loss = 10.3512, Exploration Rate = 0.1000, Train Count = 54271\n",
      "Episode 7058: Reward = 579.00, Steps = 9, Loss = 7.6284, Exploration Rate = 0.1000, Train Count = 54280\n",
      "Episode 7059: Reward = 591.00, Steps = 5, Loss = 10.4536, Exploration Rate = 0.1000, Train Count = 54285\n",
      "Episode 7060: Reward = 591.00, Steps = 5, Loss = 6.8172, Exploration Rate = 0.1000, Train Count = 54290\n",
      "Episode 7061: Reward = 576.00, Steps = 10, Loss = 12.5540, Exploration Rate = 0.1000, Train Count = 54300\n",
      "Episode 7062: Reward = 588.00, Steps = 6, Loss = 23.8621, Exploration Rate = 0.1000, Train Count = 54306\n",
      "Episode 7063: Reward = 594.00, Steps = 4, Loss = 21.2987, Exploration Rate = 0.1000, Train Count = 54310\n",
      "Episode 7064: Reward = 594.00, Steps = 4, Loss = 19.1847, Exploration Rate = 0.1000, Train Count = 54314\n",
      "Episode 7065: Reward = 600.00, Steps = 2, Loss = 17.1542, Exploration Rate = 0.1000, Train Count = 54316\n",
      "Episode 7066: Reward = 579.00, Steps = 9, Loss = 14.1339, Exploration Rate = 0.1000, Train Count = 54325\n",
      "Episode 7067: Reward = 597.00, Steps = 3, Loss = 9.4286, Exploration Rate = 0.1000, Train Count = 54328\n",
      "Episode 7068: Reward = 588.00, Steps = 6, Loss = 13.5732, Exploration Rate = 0.1000, Train Count = 54334\n",
      "Episode 7069: Reward = 591.00, Steps = 5, Loss = 10.8864, Exploration Rate = 0.1000, Train Count = 54339\n",
      "Episode 7070: Reward = 591.00, Steps = 5, Loss = 14.6312, Exploration Rate = 0.1000, Train Count = 54344\n",
      "Episode 7071: Reward = 594.00, Steps = 4, Loss = 10.9114, Exploration Rate = 0.1000, Train Count = 54348\n",
      "Episode 7072: Reward = 585.00, Steps = 7, Loss = 8.4269, Exploration Rate = 0.1000, Train Count = 54355\n",
      "Episode 7073: Reward = 594.00, Steps = 4, Loss = 6.7582, Exploration Rate = 0.1000, Train Count = 54359\n",
      "Episode 7074: Reward = 585.00, Steps = 7, Loss = 11.8262, Exploration Rate = 0.1000, Train Count = 54366\n",
      "Episode 7075: Reward = 520.00, Steps = 13, Loss = 10.5346, Exploration Rate = 0.1000, Train Count = 54379\n",
      "Episode 7076: Reward = 579.00, Steps = 9, Loss = 11.6980, Exploration Rate = 0.1000, Train Count = 54388\n",
      "Episode 7077: Reward = 591.00, Steps = 5, Loss = 10.5845, Exploration Rate = 0.1000, Train Count = 54393\n",
      "Episode 7078: Reward = 588.00, Steps = 6, Loss = 6.9330, Exploration Rate = 0.1000, Train Count = 54399\n",
      "Episode 7079: Reward = 582.00, Steps = 8, Loss = 11.8894, Exploration Rate = 0.1000, Train Count = 54407\n",
      "Episode 7080: Reward = 594.00, Steps = 4, Loss = 13.3018, Exploration Rate = 0.1000, Train Count = 54411\n",
      "Episode 7081: Reward = 585.00, Steps = 7, Loss = 8.7592, Exploration Rate = 0.1000, Train Count = 54418\n",
      "Episode 7082: Reward = 585.00, Steps = 7, Loss = 8.4983, Exploration Rate = 0.1000, Train Count = 54425\n",
      "Episode 7083: Reward = 588.00, Steps = 6, Loss = 9.8912, Exploration Rate = 0.1000, Train Count = 54431\n",
      "Episode 7084: Reward = 588.00, Steps = 6, Loss = 8.5990, Exploration Rate = 0.1000, Train Count = 54437\n",
      "Episode 7085: Reward = 479.00, Steps = 11, Loss = 9.8599, Exploration Rate = 0.1000, Train Count = 54448\n",
      "Episode 7086: Reward = 585.00, Steps = 7, Loss = 6.8177, Exploration Rate = 0.1000, Train Count = 54455\n",
      "Episode 7087: Reward = 582.00, Steps = 8, Loss = 10.1428, Exploration Rate = 0.1000, Train Count = 54463\n",
      "Episode 7088: Reward = 579.00, Steps = 9, Loss = 8.2071, Exploration Rate = 0.1000, Train Count = 54472\n",
      "Episode 7089: Reward = 591.00, Steps = 5, Loss = 7.3217, Exploration Rate = 0.1000, Train Count = 54477\n",
      "Episode 7090: Reward = 535.00, Steps = 8, Loss = 7.7076, Exploration Rate = 0.1000, Train Count = 54485\n",
      "Episode 7091: Reward = 591.00, Steps = 5, Loss = 7.1563, Exploration Rate = 0.1000, Train Count = 54490\n",
      "Episode 7092: Reward = 591.00, Steps = 5, Loss = 11.5916, Exploration Rate = 0.1000, Train Count = 54495\n",
      "Episode 7093: Reward = 597.00, Steps = 3, Loss = 7.8320, Exploration Rate = 0.1000, Train Count = 54498\n",
      "Episode 7094: Reward = 594.00, Steps = 4, Loss = 11.2823, Exploration Rate = 0.1000, Train Count = 54502\n",
      "Episode 7095: Reward = 591.00, Steps = 5, Loss = 9.8213, Exploration Rate = 0.1000, Train Count = 54507\n",
      "Episode 7096: Reward = 594.00, Steps = 4, Loss = 10.2162, Exploration Rate = 0.1000, Train Count = 54511\n",
      "Episode 7097: Reward = 576.00, Steps = 10, Loss = 7.6967, Exploration Rate = 0.1000, Train Count = 54521\n",
      "Episode 7098: Reward = 538.00, Steps = 7, Loss = 5.0339, Exploration Rate = 0.1000, Train Count = 54528\n",
      "Episode 7099: Reward = 588.00, Steps = 6, Loss = 8.2900, Exploration Rate = 0.1000, Train Count = 54534\n",
      "Episode 7100: Reward = 591.00, Steps = 5, Loss = 8.6762, Exploration Rate = 0.1000, Train Count = 54539\n",
      "Episode 7101: Reward = 594.00, Steps = 4, Loss = 8.3695, Exploration Rate = 0.1000, Train Count = 54543\n",
      "Episode 7102: Reward = 573.00, Steps = 11, Loss = 13.9513, Exploration Rate = 0.1000, Train Count = 54554\n",
      "Episode 7103: Reward = 591.00, Steps = 5, Loss = 8.7462, Exploration Rate = 0.1000, Train Count = 54559\n",
      "Episode 7104: Reward = 600.00, Steps = 2, Loss = 7.5710, Exploration Rate = 0.1000, Train Count = 54561\n",
      "Episode 7105: Reward = 594.00, Steps = 4, Loss = 8.8323, Exploration Rate = 0.1000, Train Count = 54565\n",
      "Episode 7106: Reward = 594.00, Steps = 4, Loss = 10.1749, Exploration Rate = 0.1000, Train Count = 54569\n",
      "Episode 7107: Reward = 555.00, Steps = 17, Loss = 7.9348, Exploration Rate = 0.1000, Train Count = 54586\n",
      "Episode 7108: Reward = 585.00, Steps = 7, Loss = 7.0722, Exploration Rate = 0.1000, Train Count = 54593\n",
      "Episode 7109: Reward = 591.00, Steps = 5, Loss = 6.5343, Exploration Rate = 0.1000, Train Count = 54598\n",
      "Episode 7110: Reward = 573.00, Steps = 11, Loss = 5.5998, Exploration Rate = 0.1000, Train Count = 54609\n",
      "Episode 7111: Reward = 588.00, Steps = 6, Loss = 10.5134, Exploration Rate = 0.1000, Train Count = 54615\n",
      "Episode 7112: Reward = 585.00, Steps = 7, Loss = 11.3057, Exploration Rate = 0.1000, Train Count = 54622\n",
      "Episode 7113: Reward = 585.00, Steps = 7, Loss = 8.8314, Exploration Rate = 0.1000, Train Count = 54629\n",
      "Episode 7114: Reward = 594.00, Steps = 4, Loss = 13.9216, Exploration Rate = 0.1000, Train Count = 54633\n",
      "Episode 7115: Reward = 582.00, Steps = 8, Loss = 7.0744, Exploration Rate = 0.1000, Train Count = 54641\n",
      "Episode 7116: Reward = 591.00, Steps = 5, Loss = 6.2437, Exploration Rate = 0.1000, Train Count = 54646\n",
      "Episode 7117: Reward = 588.00, Steps = 6, Loss = 10.0084, Exploration Rate = 0.1000, Train Count = 54652\n",
      "Episode 7118: Reward = 585.00, Steps = 7, Loss = 8.4274, Exploration Rate = 0.1000, Train Count = 54659\n",
      "Episode 7119: Reward = 588.00, Steps = 6, Loss = 9.4747, Exploration Rate = 0.1000, Train Count = 54665\n",
      "Episode 7120: Reward = 594.00, Steps = 4, Loss = 7.8418, Exploration Rate = 0.1000, Train Count = 54669\n",
      "Episode 7121: Reward = 585.00, Steps = 7, Loss = 5.4321, Exploration Rate = 0.1000, Train Count = 54676\n",
      "Episode 7122: Reward = 588.00, Steps = 6, Loss = 7.3808, Exploration Rate = 0.1000, Train Count = 54682\n",
      "Episode 7123: Reward = 597.00, Steps = 3, Loss = 4.0535, Exploration Rate = 0.1000, Train Count = 54685\n",
      "Episode 7124: Reward = 591.00, Steps = 5, Loss = 7.1246, Exploration Rate = 0.1000, Train Count = 54690\n",
      "Episode 7125: Reward = 591.00, Steps = 5, Loss = 6.1471, Exploration Rate = 0.1000, Train Count = 54695\n",
      "Episode 7126: Reward = 529.00, Steps = 10, Loss = 10.8762, Exploration Rate = 0.1000, Train Count = 54705\n",
      "Episode 7127: Reward = 576.00, Steps = 10, Loss = 12.4090, Exploration Rate = 0.1000, Train Count = 54715\n",
      "Episode 7128: Reward = 585.00, Steps = 7, Loss = 10.2629, Exploration Rate = 0.1000, Train Count = 54722\n",
      "Episode 7129: Reward = 585.00, Steps = 7, Loss = 6.5819, Exploration Rate = 0.1000, Train Count = 54729\n",
      "Episode 7130: Reward = 597.00, Steps = 3, Loss = 10.8960, Exploration Rate = 0.1000, Train Count = 54732\n",
      "Episode 7131: Reward = 597.00, Steps = 3, Loss = 8.8744, Exploration Rate = 0.1000, Train Count = 54735\n",
      "Episode 7132: Reward = 588.00, Steps = 6, Loss = 9.7556, Exploration Rate = 0.1000, Train Count = 54741\n",
      "Episode 7133: Reward = 591.00, Steps = 5, Loss = 8.6190, Exploration Rate = 0.1000, Train Count = 54746\n",
      "Episode 7134: Reward = 597.00, Steps = 3, Loss = 7.9439, Exploration Rate = 0.1000, Train Count = 54749\n",
      "Episode 7135: Reward = 591.00, Steps = 5, Loss = 8.0615, Exploration Rate = 0.1000, Train Count = 54754\n",
      "Episode 7136: Reward = 541.00, Steps = 6, Loss = 7.5274, Exploration Rate = 0.1000, Train Count = 54760\n",
      "Episode 7137: Reward = 597.00, Steps = 3, Loss = 12.4084, Exploration Rate = 0.1000, Train Count = 54763\n",
      "Episode 7138: Reward = 544.00, Steps = 5, Loss = 10.5013, Exploration Rate = 0.1000, Train Count = 54768\n",
      "Episode 7139: Reward = 588.00, Steps = 6, Loss = 9.6835, Exploration Rate = 0.1000, Train Count = 54774\n",
      "Episode 7140: Reward = 594.00, Steps = 4, Loss = 8.4125, Exploration Rate = 0.1000, Train Count = 54778\n",
      "Episode 7141: Reward = 600.00, Steps = 2, Loss = 8.0186, Exploration Rate = 0.1000, Train Count = 54780\n",
      "Episode 7142: Reward = 591.00, Steps = 5, Loss = 5.9599, Exploration Rate = 0.1000, Train Count = 54785\n",
      "Episode 7143: Reward = 594.00, Steps = 4, Loss = 7.8462, Exploration Rate = 0.1000, Train Count = 54789\n",
      "Episode 7144: Reward = 579.00, Steps = 9, Loss = 10.0340, Exploration Rate = 0.1000, Train Count = 54798\n",
      "Episode 7145: Reward = 544.00, Steps = 5, Loss = 21.6675, Exploration Rate = 0.1000, Train Count = 54803\n",
      "Episode 7146: Reward = 591.00, Steps = 5, Loss = 27.1470, Exploration Rate = 0.1000, Train Count = 54808\n",
      "Episode 7147: Reward = 585.00, Steps = 7, Loss = 23.4313, Exploration Rate = 0.1000, Train Count = 54815\n",
      "Episode 7148: Reward = 597.00, Steps = 3, Loss = 17.4710, Exploration Rate = 0.1000, Train Count = 54818\n",
      "Episode 7149: Reward = 529.00, Steps = 10, Loss = 16.5085, Exploration Rate = 0.1000, Train Count = 54828\n",
      "Episode 7150: Reward = 585.00, Steps = 7, Loss = 14.2896, Exploration Rate = 0.1000, Train Count = 54835\n",
      "Episode 7151: Reward = 588.00, Steps = 6, Loss = 16.2608, Exploration Rate = 0.1000, Train Count = 54841\n",
      "Episode 7152: Reward = 588.00, Steps = 6, Loss = 16.3220, Exploration Rate = 0.1000, Train Count = 54847\n",
      "Episode 7153: Reward = 591.00, Steps = 5, Loss = 11.4719, Exploration Rate = 0.1000, Train Count = 54852\n",
      "Episode 7154: Reward = 588.00, Steps = 6, Loss = 12.1176, Exploration Rate = 0.1000, Train Count = 54858\n",
      "Episode 7155: Reward = 594.00, Steps = 4, Loss = 9.1890, Exploration Rate = 0.1000, Train Count = 54862\n",
      "Episode 7156: Reward = 585.00, Steps = 7, Loss = 13.1807, Exploration Rate = 0.1000, Train Count = 54869\n",
      "Episode 7157: Reward = 597.00, Steps = 3, Loss = 12.2339, Exploration Rate = 0.1000, Train Count = 54872\n",
      "Episode 7158: Reward = 591.00, Steps = 5, Loss = 11.6860, Exploration Rate = 0.1000, Train Count = 54877\n",
      "Episode 7159: Reward = 573.00, Steps = 11, Loss = 15.9509, Exploration Rate = 0.1000, Train Count = 54888\n",
      "Episode 7160: Reward = 576.00, Steps = 10, Loss = 12.9395, Exploration Rate = 0.1000, Train Count = 54898\n",
      "Episode 7161: Reward = 588.00, Steps = 6, Loss = 13.5903, Exploration Rate = 0.1000, Train Count = 54904\n",
      "Episode 7162: Reward = 594.00, Steps = 4, Loss = 17.0612, Exploration Rate = 0.1000, Train Count = 54908\n",
      "Episode 7163: Reward = 594.00, Steps = 4, Loss = 18.5526, Exploration Rate = 0.1000, Train Count = 54912\n",
      "Episode 7164: Reward = 591.00, Steps = 5, Loss = 11.6423, Exploration Rate = 0.1000, Train Count = 54917\n",
      "Episode 7165: Reward = 535.00, Steps = 8, Loss = 10.7155, Exploration Rate = 0.1000, Train Count = 54925\n",
      "Episode 7166: Reward = 591.00, Steps = 5, Loss = 8.6100, Exploration Rate = 0.1000, Train Count = 54930\n",
      "Episode 7167: Reward = 597.00, Steps = 3, Loss = 17.0206, Exploration Rate = 0.1000, Train Count = 54933\n",
      "Episode 7168: Reward = 588.00, Steps = 6, Loss = 11.1093, Exploration Rate = 0.1000, Train Count = 54939\n",
      "Episode 7169: Reward = 597.00, Steps = 3, Loss = 7.9297, Exploration Rate = 0.1000, Train Count = 54942\n",
      "Episode 7170: Reward = 594.00, Steps = 4, Loss = 8.1455, Exploration Rate = 0.1000, Train Count = 54946\n",
      "Episode 7171: Reward = 597.00, Steps = 3, Loss = 10.1614, Exploration Rate = 0.1000, Train Count = 54949\n",
      "Episode 7172: Reward = 579.00, Steps = 9, Loss = 9.2393, Exploration Rate = 0.1000, Train Count = 54958\n",
      "Episode 7173: Reward = 541.00, Steps = 6, Loss = 14.8199, Exploration Rate = 0.1000, Train Count = 54964\n",
      "Episode 7174: Reward = 591.00, Steps = 5, Loss = 12.4293, Exploration Rate = 0.1000, Train Count = 54969\n",
      "Episode 7175: Reward = 594.00, Steps = 4, Loss = 11.1008, Exploration Rate = 0.1000, Train Count = 54973\n",
      "Episode 7176: Reward = 594.00, Steps = 4, Loss = 14.5106, Exploration Rate = 0.1000, Train Count = 54977\n",
      "Episode 7177: Reward = 588.00, Steps = 6, Loss = 14.6984, Exploration Rate = 0.1000, Train Count = 54983\n",
      "Episode 7178: Reward = 597.00, Steps = 3, Loss = 19.5198, Exploration Rate = 0.1000, Train Count = 54986\n",
      "Episode 7179: Reward = 600.00, Steps = 2, Loss = 14.4539, Exploration Rate = 0.1000, Train Count = 54988\n",
      "Episode 7180: Reward = 594.00, Steps = 4, Loss = 13.0969, Exploration Rate = 0.1000, Train Count = 54992\n",
      "Episode 7181: Reward = 582.00, Steps = 8, Loss = 12.9991, Exploration Rate = 0.1000, Train Count = 55000\n",
      "Episode 7182: Reward = 594.00, Steps = 4, Loss = 10.2997, Exploration Rate = 0.1000, Train Count = 55004\n",
      "Episode 7183: Reward = 597.00, Steps = 3, Loss = 15.6139, Exploration Rate = 0.1000, Train Count = 55007\n",
      "Episode 7184: Reward = 591.00, Steps = 5, Loss = 14.2939, Exploration Rate = 0.1000, Train Count = 55012\n",
      "Episode 7185: Reward = 591.00, Steps = 5, Loss = 12.6822, Exploration Rate = 0.1000, Train Count = 55017\n",
      "Episode 7186: Reward = 591.00, Steps = 5, Loss = 18.2149, Exploration Rate = 0.1000, Train Count = 55022\n",
      "Episode 7187: Reward = 591.00, Steps = 5, Loss = 16.0320, Exploration Rate = 0.1000, Train Count = 55027\n",
      "Episode 7188: Reward = 579.00, Steps = 9, Loss = 11.4722, Exploration Rate = 0.1000, Train Count = 55036\n",
      "Episode 7189: Reward = 591.00, Steps = 5, Loss = 11.1830, Exploration Rate = 0.1000, Train Count = 55041\n",
      "Episode 7190: Reward = 594.00, Steps = 4, Loss = 8.3539, Exploration Rate = 0.1000, Train Count = 55045\n",
      "Episode 7191: Reward = 600.00, Steps = 2, Loss = 8.2111, Exploration Rate = 0.1000, Train Count = 55047\n",
      "Episode 7192: Reward = 591.00, Steps = 5, Loss = 11.3494, Exploration Rate = 0.1000, Train Count = 55052\n",
      "Episode 7193: Reward = 585.00, Steps = 7, Loss = 9.3414, Exploration Rate = 0.1000, Train Count = 55059\n",
      "Episode 7194: Reward = 591.00, Steps = 5, Loss = 7.9900, Exploration Rate = 0.1000, Train Count = 55064\n",
      "Episode 7195: Reward = 591.00, Steps = 5, Loss = 12.2225, Exploration Rate = 0.1000, Train Count = 55069\n",
      "Episode 7196: Reward = 591.00, Steps = 5, Loss = 13.8683, Exploration Rate = 0.1000, Train Count = 55074\n",
      "Episode 7197: Reward = 576.00, Steps = 10, Loss = 8.7820, Exploration Rate = 0.1000, Train Count = 55084\n",
      "Episode 7198: Reward = 588.00, Steps = 6, Loss = 8.3178, Exploration Rate = 0.1000, Train Count = 55090\n",
      "Episode 7199: Reward = 585.00, Steps = 7, Loss = 10.6275, Exploration Rate = 0.1000, Train Count = 55097\n",
      "Episode 7200: Reward = 594.00, Steps = 4, Loss = 7.7322, Exploration Rate = 0.1000, Train Count = 55101\n",
      "Episode 7201: Reward = 588.00, Steps = 6, Loss = 10.2727, Exploration Rate = 0.1000, Train Count = 55107\n",
      "Episode 7202: Reward = 594.00, Steps = 4, Loss = 6.6633, Exploration Rate = 0.1000, Train Count = 55111\n",
      "Episode 7203: Reward = 588.00, Steps = 6, Loss = 10.1333, Exploration Rate = 0.1000, Train Count = 55117\n",
      "Episode 7204: Reward = 588.00, Steps = 6, Loss = 6.7539, Exploration Rate = 0.1000, Train Count = 55123\n",
      "Episode 7205: Reward = 597.00, Steps = 3, Loss = 4.7675, Exploration Rate = 0.1000, Train Count = 55126\n",
      "Episode 7206: Reward = 582.00, Steps = 8, Loss = 8.5323, Exploration Rate = 0.1000, Train Count = 55134\n",
      "Episode 7207: Reward = 588.00, Steps = 6, Loss = 7.0823, Exploration Rate = 0.1000, Train Count = 55140\n",
      "Episode 7208: Reward = 588.00, Steps = 6, Loss = 9.6773, Exploration Rate = 0.1000, Train Count = 55146\n",
      "Episode 7209: Reward = 579.00, Steps = 9, Loss = 6.4896, Exploration Rate = 0.1000, Train Count = 55155\n",
      "Episode 7210: Reward = 588.00, Steps = 6, Loss = 3.3033, Exploration Rate = 0.1000, Train Count = 55161\n",
      "Episode 7211: Reward = 594.00, Steps = 4, Loss = 5.2630, Exploration Rate = 0.1000, Train Count = 55165\n",
      "Episode 7212: Reward = 597.00, Steps = 3, Loss = 2.6670, Exploration Rate = 0.1000, Train Count = 55168\n",
      "Episode 7213: Reward = 579.00, Steps = 9, Loss = 5.5438, Exploration Rate = 0.1000, Train Count = 55177\n",
      "Episode 7214: Reward = 588.00, Steps = 6, Loss = 3.7382, Exploration Rate = 0.1000, Train Count = 55183\n",
      "Episode 7215: Reward = 588.00, Steps = 6, Loss = 4.1344, Exploration Rate = 0.1000, Train Count = 55189\n",
      "Episode 7216: Reward = 585.00, Steps = 7, Loss = 6.6241, Exploration Rate = 0.1000, Train Count = 55196\n",
      "Episode 7217: Reward = 582.00, Steps = 8, Loss = 5.4292, Exploration Rate = 0.1000, Train Count = 55204\n",
      "Episode 7218: Reward = 588.00, Steps = 6, Loss = 8.4992, Exploration Rate = 0.1000, Train Count = 55210\n",
      "Episode 7219: Reward = 585.00, Steps = 7, Loss = 3.5191, Exploration Rate = 0.1000, Train Count = 55217\n",
      "Episode 7220: Reward = 594.00, Steps = 4, Loss = 3.6476, Exploration Rate = 0.1000, Train Count = 55221\n",
      "Episode 7221: Reward = 585.00, Steps = 7, Loss = 4.9186, Exploration Rate = 0.1000, Train Count = 55228\n",
      "Episode 7222: Reward = 582.00, Steps = 8, Loss = 3.8096, Exploration Rate = 0.1000, Train Count = 55236\n",
      "Episode 7223: Reward = 582.00, Steps = 8, Loss = 5.5676, Exploration Rate = 0.1000, Train Count = 55244\n",
      "Episode 7224: Reward = 591.00, Steps = 5, Loss = 4.4734, Exploration Rate = 0.1000, Train Count = 55249\n",
      "Episode 7225: Reward = 594.00, Steps = 4, Loss = 3.8893, Exploration Rate = 0.1000, Train Count = 55253\n",
      "Episode 7226: Reward = 535.00, Steps = 8, Loss = 5.2142, Exploration Rate = 0.1000, Train Count = 55261\n",
      "Episode 7227: Reward = 591.00, Steps = 5, Loss = 5.0020, Exploration Rate = 0.1000, Train Count = 55266\n",
      "Episode 7228: Reward = 594.00, Steps = 4, Loss = 3.8576, Exploration Rate = 0.1000, Train Count = 55270\n",
      "Episode 7229: Reward = 588.00, Steps = 6, Loss = 6.2749, Exploration Rate = 0.1000, Train Count = 55276\n",
      "Episode 7230: Reward = 597.00, Steps = 3, Loss = 5.3274, Exploration Rate = 0.1000, Train Count = 55279\n",
      "Episode 7231: Reward = 585.00, Steps = 7, Loss = 3.7849, Exploration Rate = 0.1000, Train Count = 55286\n",
      "Episode 7232: Reward = 597.00, Steps = 3, Loss = 5.6869, Exploration Rate = 0.1000, Train Count = 55289\n",
      "Episode 7233: Reward = 579.00, Steps = 9, Loss = 7.0686, Exploration Rate = 0.1000, Train Count = 55298\n",
      "Episode 7234: Reward = 588.00, Steps = 6, Loss = 29.4739, Exploration Rate = 0.1000, Train Count = 55304\n",
      "Episode 7235: Reward = 597.00, Steps = 3, Loss = 33.5404, Exploration Rate = 0.1000, Train Count = 55307\n",
      "Episode 7236: Reward = 591.00, Steps = 5, Loss = 23.8560, Exploration Rate = 0.1000, Train Count = 55312\n",
      "Episode 7237: Reward = 588.00, Steps = 6, Loss = 23.5120, Exploration Rate = 0.1000, Train Count = 55318\n",
      "Episode 7238: Reward = 588.00, Steps = 6, Loss = 19.7703, Exploration Rate = 0.1000, Train Count = 55324\n",
      "Episode 7239: Reward = 585.00, Steps = 7, Loss = 13.7926, Exploration Rate = 0.1000, Train Count = 55331\n",
      "Episode 7240: Reward = 585.00, Steps = 7, Loss = 11.4847, Exploration Rate = 0.1000, Train Count = 55338\n",
      "Episode 7241: Reward = 594.00, Steps = 4, Loss = 8.4455, Exploration Rate = 0.1000, Train Count = 55342\n",
      "Episode 7242: Reward = 597.00, Steps = 3, Loss = 8.5636, Exploration Rate = 0.1000, Train Count = 55345\n",
      "Episode 7243: Reward = 588.00, Steps = 6, Loss = 13.2365, Exploration Rate = 0.1000, Train Count = 55351\n",
      "Episode 7244: Reward = 588.00, Steps = 6, Loss = 8.6496, Exploration Rate = 0.1000, Train Count = 55357\n",
      "Episode 7245: Reward = 588.00, Steps = 6, Loss = 6.0683, Exploration Rate = 0.1000, Train Count = 55363\n",
      "Episode 7246: Reward = 591.00, Steps = 5, Loss = 4.6397, Exploration Rate = 0.1000, Train Count = 55368\n",
      "Episode 7247: Reward = 591.00, Steps = 5, Loss = 6.2468, Exploration Rate = 0.1000, Train Count = 55373\n",
      "Episode 7248: Reward = 526.00, Steps = 11, Loss = 4.5001, Exploration Rate = 0.1000, Train Count = 55384\n",
      "Episode 7249: Reward = 585.00, Steps = 7, Loss = 17.5664, Exploration Rate = 0.1000, Train Count = 55391\n",
      "Episode 7250: Reward = 597.00, Steps = 3, Loss = 11.3901, Exploration Rate = 0.1000, Train Count = 55394\n",
      "Episode 7251: Reward = 597.00, Steps = 3, Loss = 7.3939, Exploration Rate = 0.1000, Train Count = 55397\n",
      "Episode 7252: Reward = 588.00, Steps = 6, Loss = 4.6490, Exploration Rate = 0.1000, Train Count = 55403\n",
      "Episode 7253: Reward = 570.00, Steps = 12, Loss = 6.4395, Exploration Rate = 0.1000, Train Count = 55415\n",
      "Episode 7254: Reward = 594.00, Steps = 4, Loss = 4.1078, Exploration Rate = 0.1000, Train Count = 55419\n",
      "Episode 7255: Reward = 585.00, Steps = 7, Loss = 4.6984, Exploration Rate = 0.1000, Train Count = 55426\n",
      "Episode 7256: Reward = 591.00, Steps = 5, Loss = 6.3458, Exploration Rate = 0.1000, Train Count = 55431\n",
      "Episode 7257: Reward = 597.00, Steps = 3, Loss = 4.4454, Exploration Rate = 0.1000, Train Count = 55434\n",
      "Episode 7258: Reward = 594.00, Steps = 4, Loss = 3.7144, Exploration Rate = 0.1000, Train Count = 55438\n",
      "Episode 7259: Reward = 594.00, Steps = 4, Loss = 3.8518, Exploration Rate = 0.1000, Train Count = 55442\n",
      "Episode 7260: Reward = 532.00, Steps = 9, Loss = 3.4105, Exploration Rate = 0.1000, Train Count = 55451\n",
      "Episode 7261: Reward = 597.00, Steps = 3, Loss = 3.7314, Exploration Rate = 0.1000, Train Count = 55454\n",
      "Episode 7262: Reward = 585.00, Steps = 7, Loss = 3.5663, Exploration Rate = 0.1000, Train Count = 55461\n",
      "Episode 7263: Reward = 538.00, Steps = 7, Loss = 5.3458, Exploration Rate = 0.1000, Train Count = 55468\n",
      "Episode 7264: Reward = 594.00, Steps = 4, Loss = 5.2013, Exploration Rate = 0.1000, Train Count = 55472\n",
      "Episode 7265: Reward = 594.00, Steps = 4, Loss = 5.7838, Exploration Rate = 0.1000, Train Count = 55476\n",
      "Episode 7266: Reward = 597.00, Steps = 3, Loss = 7.9598, Exploration Rate = 0.1000, Train Count = 55479\n",
      "Episode 7267: Reward = 594.00, Steps = 4, Loss = 5.0135, Exploration Rate = 0.1000, Train Count = 55483\n",
      "Episode 7268: Reward = 570.00, Steps = 12, Loss = 5.3693, Exploration Rate = 0.1000, Train Count = 55495\n",
      "Episode 7269: Reward = 597.00, Steps = 3, Loss = 7.7463, Exploration Rate = 0.1000, Train Count = 55498\n",
      "Episode 7270: Reward = 591.00, Steps = 5, Loss = 7.2059, Exploration Rate = 0.1000, Train Count = 55503\n",
      "Episode 7271: Reward = 585.00, Steps = 7, Loss = 8.5904, Exploration Rate = 0.1000, Train Count = 55510\n",
      "Episode 7272: Reward = 588.00, Steps = 6, Loss = 11.9923, Exploration Rate = 0.1000, Train Count = 55516\n",
      "Episode 7273: Reward = 582.00, Steps = 8, Loss = 14.0418, Exploration Rate = 0.1000, Train Count = 55524\n",
      "Episode 7274: Reward = 597.00, Steps = 3, Loss = 14.4393, Exploration Rate = 0.1000, Train Count = 55527\n",
      "Episode 7275: Reward = 576.00, Steps = 10, Loss = 11.3673, Exploration Rate = 0.1000, Train Count = 55537\n",
      "Episode 7276: Reward = 588.00, Steps = 6, Loss = 8.2049, Exploration Rate = 0.1000, Train Count = 55543\n",
      "Episode 7277: Reward = 597.00, Steps = 3, Loss = 8.5253, Exploration Rate = 0.1000, Train Count = 55546\n",
      "Episode 7278: Reward = 588.00, Steps = 6, Loss = 6.0756, Exploration Rate = 0.1000, Train Count = 55552\n",
      "Episode 7279: Reward = 538.00, Steps = 7, Loss = 5.8053, Exploration Rate = 0.1000, Train Count = 55559\n",
      "Episode 7280: Reward = 529.00, Steps = 10, Loss = 11.9534, Exploration Rate = 0.1000, Train Count = 55569\n",
      "Episode 7281: Reward = 594.00, Steps = 4, Loss = 5.6906, Exploration Rate = 0.1000, Train Count = 55573\n",
      "Episode 7282: Reward = 591.00, Steps = 5, Loss = 5.6422, Exploration Rate = 0.1000, Train Count = 55578\n",
      "Episode 7283: Reward = 591.00, Steps = 5, Loss = 6.4292, Exploration Rate = 0.1000, Train Count = 55583\n",
      "Episode 7284: Reward = 573.00, Steps = 11, Loss = 11.0257, Exploration Rate = 0.1000, Train Count = 55594\n",
      "Episode 7285: Reward = 591.00, Steps = 5, Loss = 13.2398, Exploration Rate = 0.1000, Train Count = 55599\n",
      "Episode 7286: Reward = 511.00, Steps = 16, Loss = 9.8735, Exploration Rate = 0.1000, Train Count = 55615\n",
      "Episode 7287: Reward = 594.00, Steps = 4, Loss = 6.3202, Exploration Rate = 0.1000, Train Count = 55619\n",
      "Episode 7288: Reward = 591.00, Steps = 5, Loss = 11.2572, Exploration Rate = 0.1000, Train Count = 55624\n",
      "Episode 7289: Reward = 591.00, Steps = 5, Loss = 7.7167, Exploration Rate = 0.1000, Train Count = 55629\n",
      "Episode 7290: Reward = 594.00, Steps = 4, Loss = 11.2569, Exploration Rate = 0.1000, Train Count = 55633\n",
      "Episode 7291: Reward = 585.00, Steps = 7, Loss = 15.2758, Exploration Rate = 0.1000, Train Count = 55640\n",
      "Episode 7292: Reward = 576.00, Steps = 10, Loss = 6.4745, Exploration Rate = 0.1000, Train Count = 55650\n",
      "Episode 7293: Reward = 594.00, Steps = 4, Loss = 18.6782, Exploration Rate = 0.1000, Train Count = 55654\n",
      "Episode 7294: Reward = 588.00, Steps = 6, Loss = 14.5807, Exploration Rate = 0.1000, Train Count = 55660\n",
      "Episode 7295: Reward = 532.00, Steps = 9, Loss = 17.9822, Exploration Rate = 0.1000, Train Count = 55669\n",
      "Episode 7296: Reward = 541.00, Steps = 6, Loss = 11.6641, Exploration Rate = 0.1000, Train Count = 55675\n",
      "Episode 7297: Reward = 591.00, Steps = 5, Loss = 9.4182, Exploration Rate = 0.1000, Train Count = 55680\n",
      "Episode 7298: Reward = 594.00, Steps = 4, Loss = 6.3665, Exploration Rate = 0.1000, Train Count = 55684\n",
      "Episode 7299: Reward = 585.00, Steps = 7, Loss = 17.3974, Exploration Rate = 0.1000, Train Count = 55691\n",
      "Episode 7300: Reward = 535.00, Steps = 8, Loss = 11.6671, Exploration Rate = 0.1000, Train Count = 55699\n",
      "Episode 7301: Reward = 591.00, Steps = 5, Loss = 9.7274, Exploration Rate = 0.1000, Train Count = 55704\n",
      "Episode 7302: Reward = 585.00, Steps = 7, Loss = 10.0726, Exploration Rate = 0.1000, Train Count = 55711\n",
      "Episode 7303: Reward = 591.00, Steps = 5, Loss = 7.4598, Exploration Rate = 0.1000, Train Count = 55716\n",
      "Episode 7304: Reward = 594.00, Steps = 4, Loss = 7.9894, Exploration Rate = 0.1000, Train Count = 55720\n",
      "Episode 7305: Reward = 597.00, Steps = 3, Loss = 11.4578, Exploration Rate = 0.1000, Train Count = 55723\n",
      "Episode 7306: Reward = 585.00, Steps = 7, Loss = 7.1352, Exploration Rate = 0.1000, Train Count = 55730\n",
      "Episode 7307: Reward = 594.00, Steps = 4, Loss = 4.6199, Exploration Rate = 0.1000, Train Count = 55734\n",
      "Episode 7308: Reward = 597.00, Steps = 3, Loss = 6.1268, Exploration Rate = 0.1000, Train Count = 55737\n",
      "Episode 7309: Reward = 591.00, Steps = 5, Loss = 6.7707, Exploration Rate = 0.1000, Train Count = 55742\n",
      "Episode 7310: Reward = 582.00, Steps = 8, Loss = 13.8452, Exploration Rate = 0.1000, Train Count = 55750\n",
      "Episode 7311: Reward = 582.00, Steps = 8, Loss = 11.8076, Exploration Rate = 0.1000, Train Count = 55758\n",
      "Episode 7312: Reward = 594.00, Steps = 4, Loss = 7.2420, Exploration Rate = 0.1000, Train Count = 55762\n",
      "Episode 7313: Reward = 588.00, Steps = 6, Loss = 7.7757, Exploration Rate = 0.1000, Train Count = 55768\n",
      "Episode 7314: Reward = 538.00, Steps = 7, Loss = 9.1925, Exploration Rate = 0.1000, Train Count = 55775\n",
      "Episode 7315: Reward = 591.00, Steps = 5, Loss = 10.4891, Exploration Rate = 0.1000, Train Count = 55780\n",
      "Episode 7316: Reward = 597.00, Steps = 3, Loss = 5.8910, Exploration Rate = 0.1000, Train Count = 55783\n",
      "Episode 7317: Reward = 579.00, Steps = 9, Loss = 9.4754, Exploration Rate = 0.1000, Train Count = 55792\n",
      "Episode 7318: Reward = 579.00, Steps = 9, Loss = 18.7330, Exploration Rate = 0.1000, Train Count = 55801\n",
      "Episode 7319: Reward = 588.00, Steps = 6, Loss = 46.0934, Exploration Rate = 0.1000, Train Count = 55807\n",
      "Episode 7320: Reward = 544.00, Steps = 5, Loss = 40.6467, Exploration Rate = 0.1000, Train Count = 55812\n",
      "Episode 7321: Reward = 591.00, Steps = 5, Loss = 27.0609, Exploration Rate = 0.1000, Train Count = 55817\n",
      "Episode 7322: Reward = 582.00, Steps = 8, Loss = 24.6896, Exploration Rate = 0.1000, Train Count = 55825\n",
      "Episode 7323: Reward = 588.00, Steps = 6, Loss = 16.1564, Exploration Rate = 0.1000, Train Count = 55831\n",
      "Episode 7324: Reward = 594.00, Steps = 4, Loss = 15.6703, Exploration Rate = 0.1000, Train Count = 55835\n",
      "Episode 7325: Reward = 600.00, Steps = 2, Loss = 19.6825, Exploration Rate = 0.1000, Train Count = 55837\n",
      "Episode 7326: Reward = 579.00, Steps = 9, Loss = 14.2625, Exploration Rate = 0.1000, Train Count = 55846\n",
      "Episode 7327: Reward = 576.00, Steps = 10, Loss = 11.0808, Exploration Rate = 0.1000, Train Count = 55856\n",
      "Episode 7328: Reward = 588.00, Steps = 6, Loss = 13.2847, Exploration Rate = 0.1000, Train Count = 55862\n",
      "Episode 7329: Reward = 532.00, Steps = 9, Loss = 13.2173, Exploration Rate = 0.1000, Train Count = 55871\n",
      "Episode 7330: Reward = 573.00, Steps = 11, Loss = 13.6929, Exploration Rate = 0.1000, Train Count = 55882\n",
      "Episode 7331: Reward = 600.00, Steps = 2, Loss = 15.6471, Exploration Rate = 0.1000, Train Count = 55884\n",
      "Episode 7332: Reward = 585.00, Steps = 7, Loss = 11.3439, Exploration Rate = 0.1000, Train Count = 55891\n",
      "Episode 7333: Reward = 594.00, Steps = 4, Loss = 9.3995, Exploration Rate = 0.1000, Train Count = 55895\n",
      "Episode 7334: Reward = 588.00, Steps = 6, Loss = 8.1637, Exploration Rate = 0.1000, Train Count = 55901\n",
      "Episode 7335: Reward = 597.00, Steps = 3, Loss = 7.1620, Exploration Rate = 0.1000, Train Count = 55904\n",
      "Episode 7336: Reward = 597.00, Steps = 3, Loss = 8.7474, Exploration Rate = 0.1000, Train Count = 55907\n",
      "Episode 7337: Reward = 585.00, Steps = 7, Loss = 7.7009, Exploration Rate = 0.1000, Train Count = 55914\n",
      "Episode 7338: Reward = 594.00, Steps = 4, Loss = 7.3322, Exploration Rate = 0.1000, Train Count = 55918\n",
      "Episode 7339: Reward = 594.00, Steps = 4, Loss = 7.8298, Exploration Rate = 0.1000, Train Count = 55922\n",
      "Episode 7340: Reward = 582.00, Steps = 8, Loss = 6.6937, Exploration Rate = 0.1000, Train Count = 55930\n",
      "Episode 7341: Reward = 588.00, Steps = 6, Loss = 4.7816, Exploration Rate = 0.1000, Train Count = 55936\n",
      "Episode 7342: Reward = 582.00, Steps = 8, Loss = 6.6519, Exploration Rate = 0.1000, Train Count = 55944\n",
      "Episode 7343: Reward = 585.00, Steps = 7, Loss = 6.9846, Exploration Rate = 0.1000, Train Count = 55951\n",
      "Episode 7344: Reward = 535.00, Steps = 8, Loss = 6.7681, Exploration Rate = 0.1000, Train Count = 55959\n",
      "Episode 7345: Reward = 597.00, Steps = 3, Loss = 4.4218, Exploration Rate = 0.1000, Train Count = 55962\n",
      "Episode 7346: Reward = 597.00, Steps = 3, Loss = 6.1194, Exploration Rate = 0.1000, Train Count = 55965\n",
      "Episode 7347: Reward = 588.00, Steps = 6, Loss = 3.8602, Exploration Rate = 0.1000, Train Count = 55971\n",
      "Episode 7348: Reward = 585.00, Steps = 7, Loss = 6.6938, Exploration Rate = 0.1000, Train Count = 55978\n",
      "Episode 7349: Reward = 594.00, Steps = 4, Loss = 7.0727, Exploration Rate = 0.1000, Train Count = 55982\n",
      "Episode 7350: Reward = 579.00, Steps = 9, Loss = 8.0496, Exploration Rate = 0.1000, Train Count = 55991\n",
      "Episode 7351: Reward = 597.00, Steps = 3, Loss = 5.5376, Exploration Rate = 0.1000, Train Count = 55994\n",
      "Episode 7352: Reward = 591.00, Steps = 5, Loss = 9.4244, Exploration Rate = 0.1000, Train Count = 55999\n",
      "Episode 7353: Reward = 588.00, Steps = 6, Loss = 8.2127, Exploration Rate = 0.1000, Train Count = 56005\n",
      "Episode 7354: Reward = 588.00, Steps = 6, Loss = 7.9534, Exploration Rate = 0.1000, Train Count = 56011\n",
      "Episode 7355: Reward = 582.00, Steps = 8, Loss = 7.0483, Exploration Rate = 0.1000, Train Count = 56019\n",
      "Episode 7356: Reward = 585.00, Steps = 7, Loss = 8.1568, Exploration Rate = 0.1000, Train Count = 56026\n",
      "Episode 7357: Reward = 594.00, Steps = 4, Loss = 7.6949, Exploration Rate = 0.1000, Train Count = 56030\n",
      "Episode 7358: Reward = 588.00, Steps = 6, Loss = 5.7638, Exploration Rate = 0.1000, Train Count = 56036\n",
      "Episode 7359: Reward = 585.00, Steps = 7, Loss = 6.7284, Exploration Rate = 0.1000, Train Count = 56043\n",
      "Episode 7360: Reward = 585.00, Steps = 7, Loss = 4.5056, Exploration Rate = 0.1000, Train Count = 56050\n",
      "Episode 7361: Reward = 585.00, Steps = 7, Loss = 6.8326, Exploration Rate = 0.1000, Train Count = 56057\n",
      "Episode 7362: Reward = 585.00, Steps = 7, Loss = 5.4552, Exploration Rate = 0.1000, Train Count = 56064\n",
      "Episode 7363: Reward = 597.00, Steps = 3, Loss = 5.3229, Exploration Rate = 0.1000, Train Count = 56067\n",
      "Episode 7364: Reward = 585.00, Steps = 7, Loss = 9.0362, Exploration Rate = 0.1000, Train Count = 56074\n",
      "Episode 7365: Reward = 594.00, Steps = 4, Loss = 6.9910, Exploration Rate = 0.1000, Train Count = 56078\n",
      "Episode 7366: Reward = 588.00, Steps = 6, Loss = 6.1439, Exploration Rate = 0.1000, Train Count = 56084\n",
      "Episode 7367: Reward = 588.00, Steps = 6, Loss = 6.6489, Exploration Rate = 0.1000, Train Count = 56090\n",
      "Episode 7368: Reward = 588.00, Steps = 6, Loss = 5.2328, Exploration Rate = 0.1000, Train Count = 56096\n",
      "Episode 7369: Reward = 594.00, Steps = 4, Loss = 4.3226, Exploration Rate = 0.1000, Train Count = 56100\n",
      "Episode 7370: Reward = 588.00, Steps = 6, Loss = 7.6879, Exploration Rate = 0.1000, Train Count = 56106\n",
      "Episode 7371: Reward = 585.00, Steps = 7, Loss = 4.7554, Exploration Rate = 0.1000, Train Count = 56113\n",
      "Episode 7372: Reward = 594.00, Steps = 4, Loss = 4.0562, Exploration Rate = 0.1000, Train Count = 56117\n",
      "Episode 7373: Reward = 482.00, Steps = 10, Loss = 7.9408, Exploration Rate = 0.1000, Train Count = 56127\n",
      "Episode 7374: Reward = 547.00, Steps = 4, Loss = 6.1509, Exploration Rate = 0.1000, Train Count = 56131\n",
      "Episode 7375: Reward = 588.00, Steps = 6, Loss = 8.9859, Exploration Rate = 0.1000, Train Count = 56137\n",
      "Episode 7376: Reward = 597.00, Steps = 3, Loss = 4.8200, Exploration Rate = 0.1000, Train Count = 56140\n",
      "Episode 7377: Reward = 585.00, Steps = 7, Loss = 12.0959, Exploration Rate = 0.1000, Train Count = 56147\n",
      "Episode 7378: Reward = 588.00, Steps = 6, Loss = 5.0846, Exploration Rate = 0.1000, Train Count = 56153\n",
      "Episode 7379: Reward = 585.00, Steps = 7, Loss = 8.8960, Exploration Rate = 0.1000, Train Count = 56160\n",
      "Episode 7380: Reward = 591.00, Steps = 5, Loss = 7.6483, Exploration Rate = 0.1000, Train Count = 56165\n",
      "Episode 7381: Reward = 582.00, Steps = 8, Loss = 10.2495, Exploration Rate = 0.1000, Train Count = 56173\n",
      "Episode 7382: Reward = 591.00, Steps = 5, Loss = 8.1961, Exploration Rate = 0.1000, Train Count = 56178\n",
      "Episode 7383: Reward = 579.00, Steps = 9, Loss = 7.7271, Exploration Rate = 0.1000, Train Count = 56187\n",
      "Episode 7384: Reward = 591.00, Steps = 5, Loss = 6.4736, Exploration Rate = 0.1000, Train Count = 56192\n",
      "Episode 7385: Reward = 582.00, Steps = 8, Loss = 7.6908, Exploration Rate = 0.1000, Train Count = 56200\n",
      "Episode 7386: Reward = 588.00, Steps = 6, Loss = 14.2890, Exploration Rate = 0.1000, Train Count = 56206\n",
      "Episode 7387: Reward = 591.00, Steps = 5, Loss = 11.3648, Exploration Rate = 0.1000, Train Count = 56211\n",
      "Episode 7388: Reward = 588.00, Steps = 6, Loss = 12.8146, Exploration Rate = 0.1000, Train Count = 56217\n",
      "Episode 7389: Reward = 505.00, Steps = 18, Loss = 12.7721, Exploration Rate = 0.1000, Train Count = 56235\n",
      "Episode 7390: Reward = 588.00, Steps = 6, Loss = 11.5865, Exploration Rate = 0.1000, Train Count = 56241\n",
      "Episode 7391: Reward = 594.00, Steps = 4, Loss = 8.3363, Exploration Rate = 0.1000, Train Count = 56245\n",
      "Episode 7392: Reward = 532.00, Steps = 9, Loss = 9.4659, Exploration Rate = 0.1000, Train Count = 56254\n",
      "Episode 7393: Reward = 526.00, Steps = 11, Loss = 11.3282, Exploration Rate = 0.1000, Train Count = 56265\n",
      "Episode 7394: Reward = 585.00, Steps = 7, Loss = 9.6921, Exploration Rate = 0.1000, Train Count = 56272\n",
      "Episode 7395: Reward = 597.00, Steps = 3, Loss = 8.6189, Exploration Rate = 0.1000, Train Count = 56275\n",
      "Episode 7396: Reward = 567.00, Steps = 13, Loss = 11.3850, Exploration Rate = 0.1000, Train Count = 56288\n",
      "Episode 7397: Reward = 594.00, Steps = 4, Loss = 10.4739, Exploration Rate = 0.1000, Train Count = 56292\n",
      "Episode 7398: Reward = 591.00, Steps = 5, Loss = 5.2568, Exploration Rate = 0.1000, Train Count = 56297\n",
      "Episode 7399: Reward = 594.00, Steps = 4, Loss = 19.5192, Exploration Rate = 0.1000, Train Count = 56301\n",
      "Episode 7400: Reward = 591.00, Steps = 5, Loss = 37.0428, Exploration Rate = 0.1000, Train Count = 56306\n",
      "Episode 7401: Reward = 585.00, Steps = 7, Loss = 36.2268, Exploration Rate = 0.1000, Train Count = 56313\n",
      "Episode 7402: Reward = 591.00, Steps = 5, Loss = 31.4116, Exploration Rate = 0.1000, Train Count = 56318\n",
      "Episode 7403: Reward = 582.00, Steps = 8, Loss = 21.7093, Exploration Rate = 0.1000, Train Count = 56326\n",
      "Episode 7404: Reward = 594.00, Steps = 4, Loss = 19.4801, Exploration Rate = 0.1000, Train Count = 56330\n",
      "Episode 7405: Reward = 570.00, Steps = 12, Loss = 17.5148, Exploration Rate = 0.1000, Train Count = 56342\n",
      "Episode 7406: Reward = 594.00, Steps = 4, Loss = 17.4695, Exploration Rate = 0.1000, Train Count = 56346\n",
      "Episode 7407: Reward = 538.00, Steps = 7, Loss = 11.2920, Exploration Rate = 0.1000, Train Count = 56353\n",
      "Episode 7408: Reward = 591.00, Steps = 5, Loss = 12.0274, Exploration Rate = 0.1000, Train Count = 56358\n",
      "Episode 7409: Reward = 588.00, Steps = 6, Loss = 12.3031, Exploration Rate = 0.1000, Train Count = 56364\n",
      "Episode 7410: Reward = 585.00, Steps = 7, Loss = 8.7020, Exploration Rate = 0.1000, Train Count = 56371\n",
      "Episode 7411: Reward = 579.00, Steps = 9, Loss = 11.0079, Exploration Rate = 0.1000, Train Count = 56380\n",
      "Episode 7412: Reward = 594.00, Steps = 4, Loss = 13.1879, Exploration Rate = 0.1000, Train Count = 56384\n",
      "Episode 7413: Reward = 582.00, Steps = 8, Loss = 8.8848, Exploration Rate = 0.1000, Train Count = 56392\n",
      "Episode 7414: Reward = 588.00, Steps = 6, Loss = 7.7133, Exploration Rate = 0.1000, Train Count = 56398\n",
      "Episode 7415: Reward = 588.00, Steps = 6, Loss = 8.0855, Exploration Rate = 0.1000, Train Count = 56404\n",
      "Episode 7416: Reward = 541.00, Steps = 6, Loss = 6.2992, Exploration Rate = 0.1000, Train Count = 56410\n",
      "Episode 7417: Reward = 591.00, Steps = 5, Loss = 5.1979, Exploration Rate = 0.1000, Train Count = 56415\n",
      "Episode 7418: Reward = 594.00, Steps = 4, Loss = 13.1227, Exploration Rate = 0.1000, Train Count = 56419\n",
      "Episode 7419: Reward = 591.00, Steps = 5, Loss = 10.4376, Exploration Rate = 0.1000, Train Count = 56424\n",
      "Episode 7420: Reward = 594.00, Steps = 4, Loss = 10.1420, Exploration Rate = 0.1000, Train Count = 56428\n",
      "Episode 7421: Reward = 585.00, Steps = 7, Loss = 7.8340, Exploration Rate = 0.1000, Train Count = 56435\n",
      "Episode 7422: Reward = 585.00, Steps = 7, Loss = 8.1689, Exploration Rate = 0.1000, Train Count = 56442\n",
      "Episode 7423: Reward = 588.00, Steps = 6, Loss = 8.3877, Exploration Rate = 0.1000, Train Count = 56448\n",
      "Episode 7424: Reward = 594.00, Steps = 4, Loss = 12.9903, Exploration Rate = 0.1000, Train Count = 56452\n",
      "Episode 7425: Reward = 600.00, Steps = 2, Loss = 12.9130, Exploration Rate = 0.1000, Train Count = 56454\n",
      "Episode 7426: Reward = 597.00, Steps = 3, Loss = 13.4080, Exploration Rate = 0.1000, Train Count = 56457\n",
      "Episode 7427: Reward = 526.00, Steps = 11, Loss = 9.4829, Exploration Rate = 0.1000, Train Count = 56468\n",
      "Episode 7428: Reward = 588.00, Steps = 6, Loss = 11.5089, Exploration Rate = 0.1000, Train Count = 56474\n",
      "Episode 7429: Reward = 588.00, Steps = 6, Loss = 12.1201, Exploration Rate = 0.1000, Train Count = 56480\n",
      "Episode 7430: Reward = 594.00, Steps = 4, Loss = 7.6096, Exploration Rate = 0.1000, Train Count = 56484\n",
      "Episode 7431: Reward = 585.00, Steps = 7, Loss = 8.2810, Exploration Rate = 0.1000, Train Count = 56491\n",
      "Episode 7432: Reward = 579.00, Steps = 9, Loss = 9.8413, Exploration Rate = 0.1000, Train Count = 56500\n",
      "Episode 7433: Reward = 585.00, Steps = 7, Loss = 8.9445, Exploration Rate = 0.1000, Train Count = 56507\n",
      "Episode 7434: Reward = 591.00, Steps = 5, Loss = 10.0129, Exploration Rate = 0.1000, Train Count = 56512\n",
      "Episode 7435: Reward = 585.00, Steps = 7, Loss = 6.7816, Exploration Rate = 0.1000, Train Count = 56519\n",
      "Episode 7436: Reward = 538.00, Steps = 7, Loss = 8.6299, Exploration Rate = 0.1000, Train Count = 56526\n",
      "Episode 7437: Reward = 591.00, Steps = 5, Loss = 11.9890, Exploration Rate = 0.1000, Train Count = 56531\n",
      "Episode 7438: Reward = 582.00, Steps = 8, Loss = 8.1294, Exploration Rate = 0.1000, Train Count = 56539\n",
      "Episode 7439: Reward = 588.00, Steps = 6, Loss = 9.4646, Exploration Rate = 0.1000, Train Count = 56545\n",
      "Episode 7440: Reward = 582.00, Steps = 8, Loss = 11.9533, Exploration Rate = 0.1000, Train Count = 56553\n",
      "Episode 7441: Reward = 594.00, Steps = 4, Loss = 10.1138, Exploration Rate = 0.1000, Train Count = 56557\n",
      "Episode 7442: Reward = 591.00, Steps = 5, Loss = 10.3686, Exploration Rate = 0.1000, Train Count = 56562\n",
      "Episode 7443: Reward = 588.00, Steps = 6, Loss = 7.7555, Exploration Rate = 0.1000, Train Count = 56568\n",
      "Episode 7444: Reward = 591.00, Steps = 5, Loss = 5.1080, Exploration Rate = 0.1000, Train Count = 56573\n",
      "Episode 7445: Reward = 585.00, Steps = 7, Loss = 8.1173, Exploration Rate = 0.1000, Train Count = 56580\n",
      "Episode 7446: Reward = 597.00, Steps = 3, Loss = 7.2402, Exploration Rate = 0.1000, Train Count = 56583\n",
      "Episode 7447: Reward = 529.00, Steps = 10, Loss = 11.1460, Exploration Rate = 0.1000, Train Count = 56593\n",
      "Episode 7448: Reward = 591.00, Steps = 5, Loss = 10.7450, Exploration Rate = 0.1000, Train Count = 56598\n",
      "Episode 7449: Reward = 538.00, Steps = 7, Loss = 13.6705, Exploration Rate = 0.1000, Train Count = 56605\n",
      "Episode 7450: Reward = 597.00, Steps = 3, Loss = 7.9270, Exploration Rate = 0.1000, Train Count = 56608\n",
      "Episode 7451: Reward = 576.00, Steps = 10, Loss = 11.3563, Exploration Rate = 0.1000, Train Count = 56618\n",
      "Episode 7452: Reward = 541.00, Steps = 6, Loss = 5.2779, Exploration Rate = 0.1000, Train Count = 56624\n",
      "Episode 7453: Reward = 585.00, Steps = 7, Loss = 6.9254, Exploration Rate = 0.1000, Train Count = 56631\n",
      "Episode 7454: Reward = 588.00, Steps = 6, Loss = 9.7599, Exploration Rate = 0.1000, Train Count = 56637\n",
      "Episode 7455: Reward = 591.00, Steps = 5, Loss = 7.2690, Exploration Rate = 0.1000, Train Count = 56642\n",
      "Episode 7456: Reward = 541.00, Steps = 6, Loss = 5.9961, Exploration Rate = 0.1000, Train Count = 56648\n",
      "Episode 7457: Reward = 591.00, Steps = 5, Loss = 6.3622, Exploration Rate = 0.1000, Train Count = 56653\n",
      "Episode 7458: Reward = 573.00, Steps = 11, Loss = 7.6531, Exploration Rate = 0.1000, Train Count = 56664\n",
      "Episode 7459: Reward = 573.00, Steps = 11, Loss = 8.9131, Exploration Rate = 0.1000, Train Count = 56675\n",
      "Episode 7460: Reward = 597.00, Steps = 3, Loss = 5.3186, Exploration Rate = 0.1000, Train Count = 56678\n",
      "Episode 7461: Reward = 544.00, Steps = 5, Loss = 7.9479, Exploration Rate = 0.1000, Train Count = 56683\n",
      "Episode 7462: Reward = 594.00, Steps = 4, Loss = 6.2894, Exploration Rate = 0.1000, Train Count = 56687\n",
      "Episode 7463: Reward = 588.00, Steps = 6, Loss = 6.6831, Exploration Rate = 0.1000, Train Count = 56693\n",
      "Episode 7464: Reward = 588.00, Steps = 6, Loss = 6.5661, Exploration Rate = 0.1000, Train Count = 56699\n",
      "Episode 7465: Reward = 582.00, Steps = 8, Loss = 3.0455, Exploration Rate = 0.1000, Train Count = 56707\n",
      "Episode 7466: Reward = 591.00, Steps = 5, Loss = 5.0574, Exploration Rate = 0.1000, Train Count = 56712\n",
      "Episode 7467: Reward = 585.00, Steps = 7, Loss = 4.6530, Exploration Rate = 0.1000, Train Count = 56719\n",
      "Episode 7468: Reward = 594.00, Steps = 4, Loss = 4.9219, Exploration Rate = 0.1000, Train Count = 56723\n",
      "Episode 7469: Reward = 591.00, Steps = 5, Loss = 4.5677, Exploration Rate = 0.1000, Train Count = 56728\n",
      "Episode 7470: Reward = 591.00, Steps = 5, Loss = 5.6414, Exploration Rate = 0.1000, Train Count = 56733\n",
      "Episode 7471: Reward = 594.00, Steps = 4, Loss = 4.8045, Exploration Rate = 0.1000, Train Count = 56737\n",
      "Episode 7472: Reward = 576.00, Steps = 10, Loss = 3.6089, Exploration Rate = 0.1000, Train Count = 56747\n",
      "Episode 7473: Reward = 597.00, Steps = 3, Loss = 4.3159, Exploration Rate = 0.1000, Train Count = 56750\n",
      "Episode 7474: Reward = 600.00, Steps = 2, Loss = 4.5647, Exploration Rate = 0.1000, Train Count = 56752\n",
      "Episode 7475: Reward = 585.00, Steps = 7, Loss = 3.0326, Exploration Rate = 0.1000, Train Count = 56759\n",
      "Episode 7476: Reward = 591.00, Steps = 5, Loss = 2.9923, Exploration Rate = 0.1000, Train Count = 56764\n",
      "Episode 7477: Reward = 594.00, Steps = 4, Loss = 3.3652, Exploration Rate = 0.1000, Train Count = 56768\n",
      "Episode 7478: Reward = 591.00, Steps = 5, Loss = 3.0364, Exploration Rate = 0.1000, Train Count = 56773\n",
      "Episode 7479: Reward = 532.00, Steps = 9, Loss = 7.4012, Exploration Rate = 0.1000, Train Count = 56782\n",
      "Episode 7480: Reward = 588.00, Steps = 6, Loss = 7.9589, Exploration Rate = 0.1000, Train Count = 56788\n",
      "Episode 7481: Reward = 591.00, Steps = 5, Loss = 6.8830, Exploration Rate = 0.1000, Train Count = 56793\n",
      "Episode 7482: Reward = 588.00, Steps = 6, Loss = 5.5746, Exploration Rate = 0.1000, Train Count = 56799\n",
      "Episode 7483: Reward = 576.00, Steps = 10, Loss = 31.0386, Exploration Rate = 0.1000, Train Count = 56809\n",
      "Episode 7484: Reward = 594.00, Steps = 4, Loss = 26.5028, Exploration Rate = 0.1000, Train Count = 56813\n",
      "Episode 7485: Reward = 573.00, Steps = 11, Loss = 26.6330, Exploration Rate = 0.1000, Train Count = 56824\n",
      "Episode 7486: Reward = 576.00, Steps = 10, Loss = 18.8424, Exploration Rate = 0.1000, Train Count = 56834\n",
      "Episode 7487: Reward = 591.00, Steps = 5, Loss = 11.9959, Exploration Rate = 0.1000, Train Count = 56839\n",
      "Episode 7488: Reward = 591.00, Steps = 5, Loss = 9.8799, Exploration Rate = 0.1000, Train Count = 56844\n",
      "Episode 7489: Reward = 585.00, Steps = 7, Loss = 12.1010, Exploration Rate = 0.1000, Train Count = 56851\n",
      "Episode 7490: Reward = 582.00, Steps = 8, Loss = 9.8197, Exploration Rate = 0.1000, Train Count = 56859\n",
      "Episode 7491: Reward = 582.00, Steps = 8, Loss = 7.0154, Exploration Rate = 0.1000, Train Count = 56867\n",
      "Episode 7492: Reward = 591.00, Steps = 5, Loss = 10.2691, Exploration Rate = 0.1000, Train Count = 56872\n",
      "Episode 7493: Reward = 594.00, Steps = 4, Loss = 10.8080, Exploration Rate = 0.1000, Train Count = 56876\n",
      "Episode 7494: Reward = 588.00, Steps = 6, Loss = 8.5046, Exploration Rate = 0.1000, Train Count = 56882\n",
      "Episode 7495: Reward = 591.00, Steps = 5, Loss = 8.5815, Exploration Rate = 0.1000, Train Count = 56887\n",
      "Episode 7496: Reward = 591.00, Steps = 5, Loss = 7.9692, Exploration Rate = 0.1000, Train Count = 56892\n",
      "Episode 7497: Reward = 585.00, Steps = 7, Loss = 6.9389, Exploration Rate = 0.1000, Train Count = 56899\n",
      "Episode 7498: Reward = 582.00, Steps = 8, Loss = 8.5157, Exploration Rate = 0.1000, Train Count = 56907\n",
      "Episode 7499: Reward = 597.00, Steps = 3, Loss = 3.8515, Exploration Rate = 0.1000, Train Count = 56910\n",
      "Episode 7500: Reward = 597.00, Steps = 3, Loss = 8.2803, Exploration Rate = 0.1000, Train Count = 56913\n",
      "Episode 7501: Reward = 594.00, Steps = 4, Loss = 8.1335, Exploration Rate = 0.1000, Train Count = 56917\n",
      "Episode 7502: Reward = 588.00, Steps = 6, Loss = 7.8796, Exploration Rate = 0.1000, Train Count = 56923\n",
      "Episode 7503: Reward = 585.00, Steps = 7, Loss = 9.3546, Exploration Rate = 0.1000, Train Count = 56930\n",
      "Episode 7504: Reward = 597.00, Steps = 3, Loss = 6.9445, Exploration Rate = 0.1000, Train Count = 56933\n",
      "Episode 7505: Reward = 597.00, Steps = 3, Loss = 8.4422, Exploration Rate = 0.1000, Train Count = 56936\n",
      "Episode 7506: Reward = 591.00, Steps = 5, Loss = 8.2208, Exploration Rate = 0.1000, Train Count = 56941\n",
      "Episode 7507: Reward = 585.00, Steps = 7, Loss = 7.8206, Exploration Rate = 0.1000, Train Count = 56948\n",
      "Episode 7508: Reward = 585.00, Steps = 7, Loss = 15.2959, Exploration Rate = 0.1000, Train Count = 56955\n",
      "Episode 7509: Reward = 594.00, Steps = 4, Loss = 16.9971, Exploration Rate = 0.1000, Train Count = 56959\n",
      "Episode 7510: Reward = 588.00, Steps = 6, Loss = 10.9715, Exploration Rate = 0.1000, Train Count = 56965\n",
      "Episode 7511: Reward = 594.00, Steps = 4, Loss = 9.1899, Exploration Rate = 0.1000, Train Count = 56969\n",
      "Episode 7512: Reward = 597.00, Steps = 3, Loss = 10.0499, Exploration Rate = 0.1000, Train Count = 56972\n",
      "Episode 7513: Reward = 588.00, Steps = 6, Loss = 8.3882, Exploration Rate = 0.1000, Train Count = 56978\n",
      "Episode 7514: Reward = 591.00, Steps = 5, Loss = 13.9915, Exploration Rate = 0.1000, Train Count = 56983\n",
      "Episode 7515: Reward = 582.00, Steps = 8, Loss = 8.6988, Exploration Rate = 0.1000, Train Count = 56991\n",
      "Episode 7516: Reward = 597.00, Steps = 3, Loss = 4.1668, Exploration Rate = 0.1000, Train Count = 56994\n",
      "Episode 7517: Reward = 591.00, Steps = 5, Loss = 5.0399, Exploration Rate = 0.1000, Train Count = 56999\n",
      "Episode 7518: Reward = 591.00, Steps = 5, Loss = 8.1150, Exploration Rate = 0.1000, Train Count = 57004\n",
      "Episode 7519: Reward = 588.00, Steps = 6, Loss = 7.8895, Exploration Rate = 0.1000, Train Count = 57010\n",
      "Episode 7520: Reward = 588.00, Steps = 6, Loss = 6.7416, Exploration Rate = 0.1000, Train Count = 57016\n",
      "Episode 7521: Reward = 588.00, Steps = 6, Loss = 6.7595, Exploration Rate = 0.1000, Train Count = 57022\n",
      "Episode 7522: Reward = 588.00, Steps = 6, Loss = 6.0096, Exploration Rate = 0.1000, Train Count = 57028\n",
      "Episode 7523: Reward = 588.00, Steps = 6, Loss = 10.5745, Exploration Rate = 0.1000, Train Count = 57034\n",
      "Episode 7524: Reward = 585.00, Steps = 7, Loss = 5.2362, Exploration Rate = 0.1000, Train Count = 57041\n",
      "Episode 7525: Reward = 570.00, Steps = 12, Loss = 7.4508, Exploration Rate = 0.1000, Train Count = 57053\n",
      "Episode 7526: Reward = 597.00, Steps = 3, Loss = 4.9196, Exploration Rate = 0.1000, Train Count = 57056\n",
      "Episode 7527: Reward = 585.00, Steps = 7, Loss = 4.7574, Exploration Rate = 0.1000, Train Count = 57063\n",
      "Episode 7528: Reward = 591.00, Steps = 5, Loss = 2.9781, Exploration Rate = 0.1000, Train Count = 57068\n",
      "Episode 7529: Reward = 588.00, Steps = 6, Loss = 5.0573, Exploration Rate = 0.1000, Train Count = 57074\n",
      "Episode 7530: Reward = 591.00, Steps = 5, Loss = 3.4882, Exploration Rate = 0.1000, Train Count = 57079\n",
      "Episode 7531: Reward = 579.00, Steps = 9, Loss = 5.9213, Exploration Rate = 0.1000, Train Count = 57088\n",
      "Episode 7532: Reward = 579.00, Steps = 9, Loss = 3.5051, Exploration Rate = 0.1000, Train Count = 57097\n",
      "Episode 7533: Reward = 588.00, Steps = 6, Loss = 3.1127, Exploration Rate = 0.1000, Train Count = 57103\n",
      "Episode 7534: Reward = 588.00, Steps = 6, Loss = 4.4312, Exploration Rate = 0.1000, Train Count = 57109\n",
      "Episode 7535: Reward = 591.00, Steps = 5, Loss = 4.7183, Exploration Rate = 0.1000, Train Count = 57114\n",
      "Episode 7536: Reward = 579.00, Steps = 9, Loss = 5.5350, Exploration Rate = 0.1000, Train Count = 57123\n",
      "Episode 7537: Reward = 591.00, Steps = 5, Loss = 6.2931, Exploration Rate = 0.1000, Train Count = 57128\n",
      "Episode 7538: Reward = 582.00, Steps = 8, Loss = 6.0172, Exploration Rate = 0.1000, Train Count = 57136\n",
      "Episode 7539: Reward = 579.00, Steps = 9, Loss = 5.5567, Exploration Rate = 0.1000, Train Count = 57145\n",
      "Episode 7540: Reward = 535.00, Steps = 8, Loss = 6.1905, Exploration Rate = 0.1000, Train Count = 57153\n",
      "Episode 7541: Reward = 597.00, Steps = 3, Loss = 3.1204, Exploration Rate = 0.1000, Train Count = 57156\n",
      "Episode 7542: Reward = 588.00, Steps = 6, Loss = 3.0574, Exploration Rate = 0.1000, Train Count = 57162\n",
      "Episode 7543: Reward = 579.00, Steps = 9, Loss = 3.2097, Exploration Rate = 0.1000, Train Count = 57171\n",
      "Episode 7544: Reward = 591.00, Steps = 5, Loss = 2.8935, Exploration Rate = 0.1000, Train Count = 57176\n",
      "Episode 7545: Reward = 594.00, Steps = 4, Loss = 3.0707, Exploration Rate = 0.1000, Train Count = 57180\n",
      "Episode 7546: Reward = 591.00, Steps = 5, Loss = 3.3419, Exploration Rate = 0.1000, Train Count = 57185\n",
      "Episode 7547: Reward = 591.00, Steps = 5, Loss = 4.3823, Exploration Rate = 0.1000, Train Count = 57190\n",
      "Episode 7548: Reward = 588.00, Steps = 6, Loss = 1.7894, Exploration Rate = 0.1000, Train Count = 57196\n",
      "Episode 7549: Reward = 582.00, Steps = 8, Loss = 5.2100, Exploration Rate = 0.1000, Train Count = 57204\n",
      "Episode 7550: Reward = 597.00, Steps = 3, Loss = 4.7919, Exploration Rate = 0.1000, Train Count = 57207\n",
      "Episode 7551: Reward = 582.00, Steps = 8, Loss = 3.0208, Exploration Rate = 0.1000, Train Count = 57215\n",
      "Episode 7552: Reward = 591.00, Steps = 5, Loss = 4.7848, Exploration Rate = 0.1000, Train Count = 57220\n",
      "Episode 7553: Reward = 585.00, Steps = 7, Loss = 8.2587, Exploration Rate = 0.1000, Train Count = 57227\n",
      "Episode 7554: Reward = 535.00, Steps = 8, Loss = 4.7366, Exploration Rate = 0.1000, Train Count = 57235\n",
      "Episode 7555: Reward = 588.00, Steps = 6, Loss = 7.9955, Exploration Rate = 0.1000, Train Count = 57241\n",
      "Episode 7556: Reward = 588.00, Steps = 6, Loss = 6.9276, Exploration Rate = 0.1000, Train Count = 57247\n",
      "Episode 7557: Reward = 585.00, Steps = 7, Loss = 12.4093, Exploration Rate = 0.1000, Train Count = 57254\n",
      "Episode 7558: Reward = 591.00, Steps = 5, Loss = 5.3204, Exploration Rate = 0.1000, Train Count = 57259\n",
      "Episode 7559: Reward = 544.00, Steps = 5, Loss = 9.6310, Exploration Rate = 0.1000, Train Count = 57264\n",
      "Episode 7560: Reward = 597.00, Steps = 3, Loss = 11.6380, Exploration Rate = 0.1000, Train Count = 57267\n",
      "Episode 7561: Reward = 594.00, Steps = 4, Loss = 11.2604, Exploration Rate = 0.1000, Train Count = 57271\n",
      "Episode 7562: Reward = 585.00, Steps = 7, Loss = 8.8053, Exploration Rate = 0.1000, Train Count = 57278\n",
      "Episode 7563: Reward = 582.00, Steps = 8, Loss = 7.6811, Exploration Rate = 0.1000, Train Count = 57286\n",
      "Episode 7564: Reward = 576.00, Steps = 10, Loss = 7.7871, Exploration Rate = 0.1000, Train Count = 57296\n",
      "Episode 7565: Reward = 597.00, Steps = 3, Loss = 9.1217, Exploration Rate = 0.1000, Train Count = 57299\n",
      "Episode 7566: Reward = 594.00, Steps = 4, Loss = 42.3904, Exploration Rate = 0.1000, Train Count = 57303\n",
      "Episode 7567: Reward = 591.00, Steps = 5, Loss = 42.8566, Exploration Rate = 0.1000, Train Count = 57308\n",
      "Episode 7568: Reward = 588.00, Steps = 6, Loss = 36.0706, Exploration Rate = 0.1000, Train Count = 57314\n",
      "Episode 7569: Reward = 588.00, Steps = 6, Loss = 29.9222, Exploration Rate = 0.1000, Train Count = 57320\n",
      "Episode 7570: Reward = 591.00, Steps = 5, Loss = 23.5107, Exploration Rate = 0.1000, Train Count = 57325\n",
      "Episode 7571: Reward = 594.00, Steps = 4, Loss = 18.9315, Exploration Rate = 0.1000, Train Count = 57329\n",
      "Episode 7572: Reward = 591.00, Steps = 5, Loss = 17.8022, Exploration Rate = 0.1000, Train Count = 57334\n",
      "Episode 7573: Reward = 594.00, Steps = 4, Loss = 16.8557, Exploration Rate = 0.1000, Train Count = 57338\n",
      "Episode 7574: Reward = 594.00, Steps = 4, Loss = 14.3734, Exploration Rate = 0.1000, Train Count = 57342\n",
      "Episode 7575: Reward = 582.00, Steps = 8, Loss = 17.4713, Exploration Rate = 0.1000, Train Count = 57350\n",
      "Episode 7576: Reward = 588.00, Steps = 6, Loss = 15.2626, Exploration Rate = 0.1000, Train Count = 57356\n",
      "Episode 7577: Reward = 588.00, Steps = 6, Loss = 12.8384, Exploration Rate = 0.1000, Train Count = 57362\n",
      "Episode 7578: Reward = 597.00, Steps = 3, Loss = 11.3208, Exploration Rate = 0.1000, Train Count = 57365\n",
      "Episode 7579: Reward = 579.00, Steps = 9, Loss = 10.4518, Exploration Rate = 0.1000, Train Count = 57374\n",
      "Episode 7580: Reward = 576.00, Steps = 10, Loss = 7.4768, Exploration Rate = 0.1000, Train Count = 57384\n",
      "Episode 7581: Reward = 591.00, Steps = 5, Loss = 9.8324, Exploration Rate = 0.1000, Train Count = 57389\n",
      "Episode 7582: Reward = 600.00, Steps = 2, Loss = 4.4988, Exploration Rate = 0.1000, Train Count = 57391\n",
      "Episode 7583: Reward = 591.00, Steps = 5, Loss = 5.1894, Exploration Rate = 0.1000, Train Count = 57396\n",
      "Episode 7584: Reward = 585.00, Steps = 7, Loss = 7.2978, Exploration Rate = 0.1000, Train Count = 57403\n",
      "Episode 7585: Reward = 591.00, Steps = 5, Loss = 7.1901, Exploration Rate = 0.1000, Train Count = 57408\n",
      "Episode 7586: Reward = 588.00, Steps = 6, Loss = 7.4236, Exploration Rate = 0.1000, Train Count = 57414\n",
      "Episode 7587: Reward = 594.00, Steps = 4, Loss = 9.5505, Exploration Rate = 0.1000, Train Count = 57418\n",
      "Episode 7588: Reward = 585.00, Steps = 7, Loss = 5.6949, Exploration Rate = 0.1000, Train Count = 57425\n",
      "Episode 7589: Reward = 591.00, Steps = 5, Loss = 5.0518, Exploration Rate = 0.1000, Train Count = 57430\n",
      "Episode 7590: Reward = 591.00, Steps = 5, Loss = 5.2217, Exploration Rate = 0.1000, Train Count = 57435\n",
      "Episode 7591: Reward = 576.00, Steps = 10, Loss = 5.6275, Exploration Rate = 0.1000, Train Count = 57445\n",
      "Episode 7592: Reward = 591.00, Steps = 5, Loss = 9.6507, Exploration Rate = 0.1000, Train Count = 57450\n",
      "Episode 7593: Reward = 582.00, Steps = 8, Loss = 6.8421, Exploration Rate = 0.1000, Train Count = 57458\n",
      "Episode 7594: Reward = 573.00, Steps = 11, Loss = 5.2187, Exploration Rate = 0.1000, Train Count = 57469\n",
      "Episode 7595: Reward = 585.00, Steps = 7, Loss = 6.7108, Exploration Rate = 0.1000, Train Count = 57476\n",
      "Episode 7596: Reward = 588.00, Steps = 6, Loss = 4.6307, Exploration Rate = 0.1000, Train Count = 57482\n",
      "Episode 7597: Reward = 591.00, Steps = 5, Loss = 3.4743, Exploration Rate = 0.1000, Train Count = 57487\n",
      "Episode 7598: Reward = 594.00, Steps = 4, Loss = 4.9884, Exploration Rate = 0.1000, Train Count = 57491\n",
      "Episode 7599: Reward = 597.00, Steps = 3, Loss = 5.4951, Exploration Rate = 0.1000, Train Count = 57494\n",
      "Episode 7600: Reward = 582.00, Steps = 8, Loss = 4.0049, Exploration Rate = 0.1000, Train Count = 57502\n",
      "Episode 7601: Reward = 585.00, Steps = 7, Loss = 3.9112, Exploration Rate = 0.1000, Train Count = 57509\n",
      "Episode 7602: Reward = 597.00, Steps = 3, Loss = 3.6343, Exploration Rate = 0.1000, Train Count = 57512\n",
      "Episode 7603: Reward = 588.00, Steps = 6, Loss = 2.4209, Exploration Rate = 0.1000, Train Count = 57518\n",
      "Episode 7604: Reward = 541.00, Steps = 6, Loss = 4.3603, Exploration Rate = 0.1000, Train Count = 57524\n",
      "Episode 7605: Reward = 594.00, Steps = 4, Loss = 4.1086, Exploration Rate = 0.1000, Train Count = 57528\n",
      "Episode 7606: Reward = 594.00, Steps = 4, Loss = 8.5834, Exploration Rate = 0.1000, Train Count = 57532\n",
      "Episode 7607: Reward = 547.00, Steps = 4, Loss = 8.4435, Exploration Rate = 0.1000, Train Count = 57536\n",
      "Episode 7608: Reward = 579.00, Steps = 9, Loss = 6.4979, Exploration Rate = 0.1000, Train Count = 57545\n",
      "Episode 7609: Reward = 582.00, Steps = 8, Loss = 5.8834, Exploration Rate = 0.1000, Train Count = 57553\n",
      "Episode 7610: Reward = 582.00, Steps = 8, Loss = 5.9097, Exploration Rate = 0.1000, Train Count = 57561\n",
      "Episode 7611: Reward = 588.00, Steps = 6, Loss = 5.1137, Exploration Rate = 0.1000, Train Count = 57567\n",
      "Episode 7612: Reward = 594.00, Steps = 4, Loss = 3.3408, Exploration Rate = 0.1000, Train Count = 57571\n",
      "Episode 7613: Reward = 585.00, Steps = 7, Loss = 5.0880, Exploration Rate = 0.1000, Train Count = 57578\n",
      "Episode 7614: Reward = 585.00, Steps = 7, Loss = 5.3564, Exploration Rate = 0.1000, Train Count = 57585\n",
      "Episode 7615: Reward = 591.00, Steps = 5, Loss = 4.1098, Exploration Rate = 0.1000, Train Count = 57590\n",
      "Episode 7616: Reward = 544.00, Steps = 5, Loss = 5.8750, Exploration Rate = 0.1000, Train Count = 57595\n",
      "Episode 7617: Reward = 579.00, Steps = 9, Loss = 4.3750, Exploration Rate = 0.1000, Train Count = 57604\n",
      "Episode 7618: Reward = 582.00, Steps = 8, Loss = 5.1776, Exploration Rate = 0.1000, Train Count = 57612\n",
      "Episode 7619: Reward = 588.00, Steps = 6, Loss = 4.0104, Exploration Rate = 0.1000, Train Count = 57618\n",
      "Episode 7620: Reward = 585.00, Steps = 7, Loss = 4.3208, Exploration Rate = 0.1000, Train Count = 57625\n",
      "Episode 7621: Reward = 573.00, Steps = 11, Loss = 3.0812, Exploration Rate = 0.1000, Train Count = 57636\n",
      "Episode 7622: Reward = 597.00, Steps = 3, Loss = 6.0074, Exploration Rate = 0.1000, Train Count = 57639\n",
      "Episode 7623: Reward = 597.00, Steps = 3, Loss = 6.1950, Exploration Rate = 0.1000, Train Count = 57642\n",
      "Episode 7624: Reward = 597.00, Steps = 3, Loss = 5.6431, Exploration Rate = 0.1000, Train Count = 57645\n",
      "Episode 7625: Reward = 585.00, Steps = 7, Loss = 5.6223, Exploration Rate = 0.1000, Train Count = 57652\n",
      "Episode 7626: Reward = 582.00, Steps = 8, Loss = 4.6091, Exploration Rate = 0.1000, Train Count = 57660\n",
      "Episode 7627: Reward = 591.00, Steps = 5, Loss = 6.7563, Exploration Rate = 0.1000, Train Count = 57665\n",
      "Episode 7628: Reward = 594.00, Steps = 4, Loss = 5.6928, Exploration Rate = 0.1000, Train Count = 57669\n",
      "Episode 7629: Reward = 594.00, Steps = 4, Loss = 4.4880, Exploration Rate = 0.1000, Train Count = 57673\n",
      "Episode 7630: Reward = 594.00, Steps = 4, Loss = 3.1914, Exploration Rate = 0.1000, Train Count = 57677\n",
      "Episode 7631: Reward = 597.00, Steps = 3, Loss = 3.4911, Exploration Rate = 0.1000, Train Count = 57680\n",
      "Episode 7632: Reward = 576.00, Steps = 10, Loss = 3.7618, Exploration Rate = 0.1000, Train Count = 57690\n",
      "Episode 7633: Reward = 585.00, Steps = 7, Loss = 7.0694, Exploration Rate = 0.1000, Train Count = 57697\n",
      "Episode 7634: Reward = 594.00, Steps = 4, Loss = 4.5631, Exploration Rate = 0.1000, Train Count = 57701\n",
      "Episode 7635: Reward = 582.00, Steps = 8, Loss = 4.5495, Exploration Rate = 0.1000, Train Count = 57709\n",
      "Episode 7636: Reward = 588.00, Steps = 6, Loss = 7.1846, Exploration Rate = 0.1000, Train Count = 57715\n",
      "Episode 7637: Reward = 582.00, Steps = 8, Loss = 5.7648, Exploration Rate = 0.1000, Train Count = 57723\n",
      "Episode 7638: Reward = 600.00, Steps = 2, Loss = 6.6833, Exploration Rate = 0.1000, Train Count = 57725\n",
      "Episode 7639: Reward = 594.00, Steps = 4, Loss = 9.4624, Exploration Rate = 0.1000, Train Count = 57729\n",
      "Episode 7640: Reward = 588.00, Steps = 6, Loss = 6.7247, Exploration Rate = 0.1000, Train Count = 57735\n",
      "Episode 7641: Reward = 594.00, Steps = 4, Loss = 6.0581, Exploration Rate = 0.1000, Train Count = 57739\n",
      "Episode 7642: Reward = 588.00, Steps = 6, Loss = 4.5275, Exploration Rate = 0.1000, Train Count = 57745\n",
      "Episode 7643: Reward = 588.00, Steps = 6, Loss = 3.7358, Exploration Rate = 0.1000, Train Count = 57751\n",
      "Episode 7644: Reward = 579.00, Steps = 9, Loss = 3.3246, Exploration Rate = 0.1000, Train Count = 57760\n",
      "Episode 7645: Reward = 594.00, Steps = 4, Loss = 1.8515, Exploration Rate = 0.1000, Train Count = 57764\n",
      "Episode 7646: Reward = 588.00, Steps = 6, Loss = 2.9199, Exploration Rate = 0.1000, Train Count = 57770\n",
      "Episode 7647: Reward = 597.00, Steps = 3, Loss = 4.6470, Exploration Rate = 0.1000, Train Count = 57773\n",
      "Episode 7648: Reward = 585.00, Steps = 7, Loss = 4.1006, Exploration Rate = 0.1000, Train Count = 57780\n",
      "Episode 7649: Reward = 594.00, Steps = 4, Loss = 6.3512, Exploration Rate = 0.1000, Train Count = 57784\n",
      "Episode 7650: Reward = 594.00, Steps = 4, Loss = 3.1601, Exploration Rate = 0.1000, Train Count = 57788\n",
      "Episode 7651: Reward = 582.00, Steps = 8, Loss = 3.6152, Exploration Rate = 0.1000, Train Count = 57796\n",
      "Episode 7652: Reward = 597.00, Steps = 3, Loss = 3.0860, Exploration Rate = 0.1000, Train Count = 57799\n",
      "Episode 7653: Reward = 597.00, Steps = 3, Loss = 20.9086, Exploration Rate = 0.1000, Train Count = 57802\n",
      "Episode 7654: Reward = 591.00, Steps = 5, Loss = 38.1982, Exploration Rate = 0.1000, Train Count = 57807\n",
      "Episode 7655: Reward = 591.00, Steps = 5, Loss = 27.6672, Exploration Rate = 0.1000, Train Count = 57812\n",
      "Episode 7656: Reward = 588.00, Steps = 6, Loss = 24.6471, Exploration Rate = 0.1000, Train Count = 57818\n",
      "Episode 7657: Reward = 594.00, Steps = 4, Loss = 17.0716, Exploration Rate = 0.1000, Train Count = 57822\n",
      "Episode 7658: Reward = 591.00, Steps = 5, Loss = 14.5377, Exploration Rate = 0.1000, Train Count = 57827\n",
      "Episode 7659: Reward = 597.00, Steps = 3, Loss = 13.4026, Exploration Rate = 0.1000, Train Count = 57830\n",
      "Episode 7660: Reward = 597.00, Steps = 3, Loss = 13.4369, Exploration Rate = 0.1000, Train Count = 57833\n",
      "Episode 7661: Reward = 579.00, Steps = 9, Loss = 10.5524, Exploration Rate = 0.1000, Train Count = 57842\n",
      "Episode 7662: Reward = 594.00, Steps = 4, Loss = 8.6272, Exploration Rate = 0.1000, Train Count = 57846\n",
      "Episode 7663: Reward = 591.00, Steps = 5, Loss = 8.7187, Exploration Rate = 0.1000, Train Count = 57851\n",
      "Episode 7664: Reward = 579.00, Steps = 9, Loss = 6.2157, Exploration Rate = 0.1000, Train Count = 57860\n",
      "Episode 7665: Reward = 588.00, Steps = 6, Loss = 6.4462, Exploration Rate = 0.1000, Train Count = 57866\n",
      "Episode 7666: Reward = 582.00, Steps = 8, Loss = 6.9003, Exploration Rate = 0.1000, Train Count = 57874\n",
      "Episode 7667: Reward = 591.00, Steps = 5, Loss = 6.7964, Exploration Rate = 0.1000, Train Count = 57879\n",
      "Episode 7668: Reward = 588.00, Steps = 6, Loss = 5.8459, Exploration Rate = 0.1000, Train Count = 57885\n",
      "Episode 7669: Reward = 579.00, Steps = 9, Loss = 3.4154, Exploration Rate = 0.1000, Train Count = 57894\n",
      "Episode 7670: Reward = 591.00, Steps = 5, Loss = 2.6529, Exploration Rate = 0.1000, Train Count = 57899\n",
      "Episode 7671: Reward = 591.00, Steps = 5, Loss = 2.6098, Exploration Rate = 0.1000, Train Count = 57904\n",
      "Episode 7672: Reward = 591.00, Steps = 5, Loss = 1.9140, Exploration Rate = 0.1000, Train Count = 57909\n",
      "Episode 7673: Reward = 594.00, Steps = 4, Loss = 1.7490, Exploration Rate = 0.1000, Train Count = 57913\n",
      "Episode 7674: Reward = 591.00, Steps = 5, Loss = 1.7873, Exploration Rate = 0.1000, Train Count = 57918\n",
      "Episode 7675: Reward = 597.00, Steps = 3, Loss = 1.1661, Exploration Rate = 0.1000, Train Count = 57921\n",
      "Episode 7676: Reward = 585.00, Steps = 7, Loss = 1.4558, Exploration Rate = 0.1000, Train Count = 57928\n",
      "Episode 7677: Reward = 585.00, Steps = 7, Loss = 1.1311, Exploration Rate = 0.1000, Train Count = 57935\n",
      "Episode 7678: Reward = 597.00, Steps = 3, Loss = 1.3205, Exploration Rate = 0.1000, Train Count = 57938\n",
      "Episode 7679: Reward = 582.00, Steps = 8, Loss = 1.9280, Exploration Rate = 0.1000, Train Count = 57946\n",
      "Episode 7680: Reward = 594.00, Steps = 4, Loss = 1.9197, Exploration Rate = 0.1000, Train Count = 57950\n",
      "Episode 7681: Reward = 585.00, Steps = 7, Loss = 1.2890, Exploration Rate = 0.1000, Train Count = 57957\n",
      "Episode 7682: Reward = 591.00, Steps = 5, Loss = 0.8617, Exploration Rate = 0.1000, Train Count = 57962\n",
      "Episode 7683: Reward = 591.00, Steps = 5, Loss = 1.2407, Exploration Rate = 0.1000, Train Count = 57967\n",
      "Episode 7684: Reward = 585.00, Steps = 7, Loss = 0.9353, Exploration Rate = 0.1000, Train Count = 57974\n",
      "Episode 7685: Reward = 591.00, Steps = 5, Loss = 1.0029, Exploration Rate = 0.1000, Train Count = 57979\n",
      "Episode 7686: Reward = 597.00, Steps = 3, Loss = 0.9800, Exploration Rate = 0.1000, Train Count = 57982\n",
      "Episode 7687: Reward = 594.00, Steps = 4, Loss = 0.8957, Exploration Rate = 0.1000, Train Count = 57986\n",
      "Episode 7688: Reward = 535.00, Steps = 8, Loss = 0.7659, Exploration Rate = 0.1000, Train Count = 57994\n",
      "Episode 7689: Reward = 594.00, Steps = 4, Loss = 1.5371, Exploration Rate = 0.1000, Train Count = 57998\n",
      "Episode 7690: Reward = 588.00, Steps = 6, Loss = 1.4263, Exploration Rate = 0.1000, Train Count = 58004\n",
      "Episode 7691: Reward = 544.00, Steps = 5, Loss = 1.7102, Exploration Rate = 0.1000, Train Count = 58009\n",
      "Episode 7692: Reward = 597.00, Steps = 3, Loss = 2.1932, Exploration Rate = 0.1000, Train Count = 58012\n",
      "Episode 7693: Reward = 585.00, Steps = 7, Loss = 2.3004, Exploration Rate = 0.1000, Train Count = 58019\n",
      "Episode 7694: Reward = 591.00, Steps = 5, Loss = 5.2684, Exploration Rate = 0.1000, Train Count = 58024\n",
      "Episode 7695: Reward = 594.00, Steps = 4, Loss = 1.6700, Exploration Rate = 0.1000, Train Count = 58028\n",
      "Episode 7696: Reward = 591.00, Steps = 5, Loss = 2.1040, Exploration Rate = 0.1000, Train Count = 58033\n",
      "Episode 7697: Reward = 591.00, Steps = 5, Loss = 2.8754, Exploration Rate = 0.1000, Train Count = 58038\n",
      "Episode 7698: Reward = 594.00, Steps = 4, Loss = 2.6737, Exploration Rate = 0.1000, Train Count = 58042\n",
      "Episode 7699: Reward = 594.00, Steps = 4, Loss = 1.2940, Exploration Rate = 0.1000, Train Count = 58046\n",
      "Episode 7700: Reward = 579.00, Steps = 9, Loss = 4.2125, Exploration Rate = 0.1000, Train Count = 58055\n",
      "Episode 7701: Reward = 582.00, Steps = 8, Loss = 2.8962, Exploration Rate = 0.1000, Train Count = 58063\n",
      "Episode 7702: Reward = 585.00, Steps = 7, Loss = 1.6049, Exploration Rate = 0.1000, Train Count = 58070\n",
      "Episode 7703: Reward = 591.00, Steps = 5, Loss = 2.0625, Exploration Rate = 0.1000, Train Count = 58075\n",
      "Episode 7704: Reward = 594.00, Steps = 4, Loss = 2.1430, Exploration Rate = 0.1000, Train Count = 58079\n",
      "Episode 7705: Reward = 594.00, Steps = 4, Loss = 2.0932, Exploration Rate = 0.1000, Train Count = 58083\n",
      "Episode 7706: Reward = 588.00, Steps = 6, Loss = 1.5411, Exploration Rate = 0.1000, Train Count = 58089\n",
      "Episode 7707: Reward = 600.00, Steps = 2, Loss = 2.6872, Exploration Rate = 0.1000, Train Count = 58091\n",
      "Episode 7708: Reward = 588.00, Steps = 6, Loss = 5.1523, Exploration Rate = 0.1000, Train Count = 58097\n",
      "Episode 7709: Reward = 597.00, Steps = 3, Loss = 10.8515, Exploration Rate = 0.1000, Train Count = 58100\n",
      "Episode 7710: Reward = 538.00, Steps = 7, Loss = 4.2619, Exploration Rate = 0.1000, Train Count = 58107\n",
      "Episode 7711: Reward = 585.00, Steps = 7, Loss = 6.4817, Exploration Rate = 0.1000, Train Count = 58114\n",
      "Episode 7712: Reward = 591.00, Steps = 5, Loss = 3.5713, Exploration Rate = 0.1000, Train Count = 58119\n",
      "Episode 7713: Reward = 591.00, Steps = 5, Loss = 3.3777, Exploration Rate = 0.1000, Train Count = 58124\n",
      "Episode 7714: Reward = 588.00, Steps = 6, Loss = 1.8796, Exploration Rate = 0.1000, Train Count = 58130\n",
      "Episode 7715: Reward = 591.00, Steps = 5, Loss = 3.7138, Exploration Rate = 0.1000, Train Count = 58135\n",
      "Episode 7716: Reward = 597.00, Steps = 3, Loss = 2.0113, Exploration Rate = 0.1000, Train Count = 58138\n",
      "Episode 7717: Reward = 594.00, Steps = 4, Loss = 1.2667, Exploration Rate = 0.1000, Train Count = 58142\n",
      "Episode 7718: Reward = 597.00, Steps = 3, Loss = 2.4400, Exploration Rate = 0.1000, Train Count = 58145\n",
      "Episode 7719: Reward = 588.00, Steps = 6, Loss = 1.4938, Exploration Rate = 0.1000, Train Count = 58151\n",
      "Episode 7720: Reward = 594.00, Steps = 4, Loss = 1.5312, Exploration Rate = 0.1000, Train Count = 58155\n",
      "Episode 7721: Reward = 594.00, Steps = 4, Loss = 1.1101, Exploration Rate = 0.1000, Train Count = 58159\n",
      "Episode 7722: Reward = 591.00, Steps = 5, Loss = 5.5169, Exploration Rate = 0.1000, Train Count = 58164\n",
      "Episode 7723: Reward = 579.00, Steps = 9, Loss = 5.5086, Exploration Rate = 0.1000, Train Count = 58173\n",
      "Episode 7724: Reward = 597.00, Steps = 3, Loss = 3.6494, Exploration Rate = 0.1000, Train Count = 58176\n",
      "Episode 7725: Reward = 541.00, Steps = 6, Loss = 3.2082, Exploration Rate = 0.1000, Train Count = 58182\n",
      "Episode 7726: Reward = 594.00, Steps = 4, Loss = 4.9905, Exploration Rate = 0.1000, Train Count = 58186\n",
      "Episode 7727: Reward = 585.00, Steps = 7, Loss = 4.2396, Exploration Rate = 0.1000, Train Count = 58193\n",
      "Episode 7728: Reward = 588.00, Steps = 6, Loss = 3.1142, Exploration Rate = 0.1000, Train Count = 58199\n",
      "Episode 7729: Reward = 591.00, Steps = 5, Loss = 5.3293, Exploration Rate = 0.1000, Train Count = 58204\n",
      "Episode 7730: Reward = 600.00, Steps = 2, Loss = 3.9075, Exploration Rate = 0.1000, Train Count = 58206\n",
      "Episode 7731: Reward = 594.00, Steps = 4, Loss = 2.9550, Exploration Rate = 0.1000, Train Count = 58210\n",
      "Episode 7732: Reward = 591.00, Steps = 5, Loss = 7.1969, Exploration Rate = 0.1000, Train Count = 58215\n",
      "Episode 7733: Reward = 594.00, Steps = 4, Loss = 3.4397, Exploration Rate = 0.1000, Train Count = 58219\n",
      "Episode 7734: Reward = 582.00, Steps = 8, Loss = 3.9963, Exploration Rate = 0.1000, Train Count = 58227\n",
      "Episode 7735: Reward = 582.00, Steps = 8, Loss = 6.5048, Exploration Rate = 0.1000, Train Count = 58235\n",
      "Episode 7736: Reward = 594.00, Steps = 4, Loss = 3.5008, Exploration Rate = 0.1000, Train Count = 58239\n",
      "Episode 7737: Reward = 594.00, Steps = 4, Loss = 4.3379, Exploration Rate = 0.1000, Train Count = 58243\n",
      "Episode 7738: Reward = 579.00, Steps = 9, Loss = 3.7244, Exploration Rate = 0.1000, Train Count = 58252\n",
      "Episode 7739: Reward = 561.00, Steps = 15, Loss = 9.1546, Exploration Rate = 0.1000, Train Count = 58267\n",
      "Episode 7740: Reward = 582.00, Steps = 8, Loss = 5.8356, Exploration Rate = 0.1000, Train Count = 58275\n",
      "Episode 7741: Reward = 591.00, Steps = 5, Loss = 5.7962, Exploration Rate = 0.1000, Train Count = 58280\n",
      "Episode 7742: Reward = 585.00, Steps = 7, Loss = 4.4799, Exploration Rate = 0.1000, Train Count = 58287\n",
      "Episode 7743: Reward = 594.00, Steps = 4, Loss = 5.3889, Exploration Rate = 0.1000, Train Count = 58291\n",
      "Episode 7744: Reward = 582.00, Steps = 8, Loss = 5.6779, Exploration Rate = 0.1000, Train Count = 58299\n",
      "Episode 7745: Reward = 585.00, Steps = 7, Loss = 28.9868, Exploration Rate = 0.1000, Train Count = 58306\n",
      "Episode 7746: Reward = 591.00, Steps = 5, Loss = 21.3250, Exploration Rate = 0.1000, Train Count = 58311\n",
      "Episode 7747: Reward = 597.00, Steps = 3, Loss = 18.8046, Exploration Rate = 0.1000, Train Count = 58314\n",
      "Episode 7748: Reward = 594.00, Steps = 4, Loss = 14.6654, Exploration Rate = 0.1000, Train Count = 58318\n",
      "Episode 7749: Reward = 597.00, Steps = 3, Loss = 12.1357, Exploration Rate = 0.1000, Train Count = 58321\n",
      "Episode 7750: Reward = 597.00, Steps = 3, Loss = 13.2309, Exploration Rate = 0.1000, Train Count = 58324\n",
      "Episode 7751: Reward = 588.00, Steps = 6, Loss = 12.0378, Exploration Rate = 0.1000, Train Count = 58330\n",
      "Episode 7752: Reward = 588.00, Steps = 6, Loss = 9.7860, Exploration Rate = 0.1000, Train Count = 58336\n",
      "Episode 7753: Reward = 594.00, Steps = 4, Loss = 9.7062, Exploration Rate = 0.1000, Train Count = 58340\n",
      "Episode 7754: Reward = 573.00, Steps = 11, Loss = 6.4219, Exploration Rate = 0.1000, Train Count = 58351\n",
      "Episode 7755: Reward = 597.00, Steps = 3, Loss = 5.1839, Exploration Rate = 0.1000, Train Count = 58354\n",
      "Episode 7756: Reward = 591.00, Steps = 5, Loss = 6.3068, Exploration Rate = 0.1000, Train Count = 58359\n",
      "Episode 7757: Reward = 588.00, Steps = 6, Loss = 4.4415, Exploration Rate = 0.1000, Train Count = 58365\n",
      "Episode 7758: Reward = 591.00, Steps = 5, Loss = 4.9849, Exploration Rate = 0.1000, Train Count = 58370\n",
      "Episode 7759: Reward = 576.00, Steps = 10, Loss = 4.5222, Exploration Rate = 0.1000, Train Count = 58380\n",
      "Episode 7760: Reward = 591.00, Steps = 5, Loss = 3.4498, Exploration Rate = 0.1000, Train Count = 58385\n",
      "Episode 7761: Reward = 573.00, Steps = 11, Loss = 4.8368, Exploration Rate = 0.1000, Train Count = 58396\n",
      "Episode 7762: Reward = 588.00, Steps = 6, Loss = 4.7933, Exploration Rate = 0.1000, Train Count = 58402\n",
      "Episode 7763: Reward = 591.00, Steps = 5, Loss = 4.6710, Exploration Rate = 0.1000, Train Count = 58407\n",
      "Episode 7764: Reward = 582.00, Steps = 8, Loss = 2.7392, Exploration Rate = 0.1000, Train Count = 58415\n",
      "Episode 7765: Reward = 582.00, Steps = 8, Loss = 2.3679, Exploration Rate = 0.1000, Train Count = 58423\n",
      "Episode 7766: Reward = 594.00, Steps = 4, Loss = 4.5963, Exploration Rate = 0.1000, Train Count = 58427\n",
      "Episode 7767: Reward = 591.00, Steps = 5, Loss = 3.5005, Exploration Rate = 0.1000, Train Count = 58432\n",
      "Episode 7768: Reward = 585.00, Steps = 7, Loss = 3.5769, Exploration Rate = 0.1000, Train Count = 58439\n",
      "Episode 7769: Reward = 585.00, Steps = 7, Loss = 3.9843, Exploration Rate = 0.1000, Train Count = 58446\n",
      "Episode 7770: Reward = 591.00, Steps = 5, Loss = 2.1748, Exploration Rate = 0.1000, Train Count = 58451\n",
      "Episode 7771: Reward = 591.00, Steps = 5, Loss = 3.4490, Exploration Rate = 0.1000, Train Count = 58456\n",
      "Episode 7772: Reward = 579.00, Steps = 9, Loss = 3.0488, Exploration Rate = 0.1000, Train Count = 58465\n",
      "Episode 7773: Reward = 573.00, Steps = 11, Loss = 3.7435, Exploration Rate = 0.1000, Train Count = 58476\n",
      "Episode 7774: Reward = 538.00, Steps = 7, Loss = 2.5339, Exploration Rate = 0.1000, Train Count = 58483\n",
      "Episode 7775: Reward = 591.00, Steps = 5, Loss = 5.1826, Exploration Rate = 0.1000, Train Count = 58488\n",
      "Episode 7776: Reward = 588.00, Steps = 6, Loss = 4.8226, Exploration Rate = 0.1000, Train Count = 58494\n",
      "Episode 7777: Reward = 585.00, Steps = 7, Loss = 3.2987, Exploration Rate = 0.1000, Train Count = 58501\n",
      "Episode 7778: Reward = 529.00, Steps = 10, Loss = 3.9967, Exploration Rate = 0.1000, Train Count = 58511\n",
      "Episode 7779: Reward = 594.00, Steps = 4, Loss = 3.5825, Exploration Rate = 0.1000, Train Count = 58515\n",
      "Episode 7780: Reward = 591.00, Steps = 5, Loss = 5.6743, Exploration Rate = 0.1000, Train Count = 58520\n",
      "Episode 7781: Reward = 591.00, Steps = 5, Loss = 4.9491, Exploration Rate = 0.1000, Train Count = 58525\n",
      "Episode 7782: Reward = 570.00, Steps = 12, Loss = 3.7596, Exploration Rate = 0.1000, Train Count = 58537\n",
      "Episode 7783: Reward = 482.00, Steps = 10, Loss = 9.3719, Exploration Rate = 0.1000, Train Count = 58547\n",
      "Episode 7784: Reward = 591.00, Steps = 5, Loss = 11.5834, Exploration Rate = 0.1000, Train Count = 58552\n",
      "Episode 7785: Reward = 588.00, Steps = 6, Loss = 10.4616, Exploration Rate = 0.1000, Train Count = 58558\n",
      "Episode 7786: Reward = 541.00, Steps = 6, Loss = 6.7569, Exploration Rate = 0.1000, Train Count = 58564\n",
      "Episode 7787: Reward = 588.00, Steps = 6, Loss = 6.6480, Exploration Rate = 0.1000, Train Count = 58570\n",
      "Episode 7788: Reward = 594.00, Steps = 4, Loss = 7.3952, Exploration Rate = 0.1000, Train Count = 58574\n",
      "Episode 7789: Reward = 585.00, Steps = 7, Loss = 4.2614, Exploration Rate = 0.1000, Train Count = 58581\n",
      "Episode 7790: Reward = 591.00, Steps = 5, Loss = 3.2293, Exploration Rate = 0.1000, Train Count = 58586\n",
      "Episode 7791: Reward = 588.00, Steps = 6, Loss = 2.4134, Exploration Rate = 0.1000, Train Count = 58592\n",
      "Episode 7792: Reward = 585.00, Steps = 7, Loss = 2.6766, Exploration Rate = 0.1000, Train Count = 58599\n",
      "Episode 7793: Reward = 588.00, Steps = 6, Loss = 2.1892, Exploration Rate = 0.1000, Train Count = 58605\n",
      "Episode 7794: Reward = 576.00, Steps = 10, Loss = 7.5863, Exploration Rate = 0.1000, Train Count = 58615\n",
      "Episode 7795: Reward = 597.00, Steps = 3, Loss = 7.5126, Exploration Rate = 0.1000, Train Count = 58618\n",
      "Episode 7796: Reward = 535.00, Steps = 8, Loss = 11.1121, Exploration Rate = 0.1000, Train Count = 58626\n",
      "Episode 7797: Reward = 591.00, Steps = 5, Loss = 3.9342, Exploration Rate = 0.1000, Train Count = 58631\n",
      "Episode 7798: Reward = 579.00, Steps = 9, Loss = 8.5956, Exploration Rate = 0.1000, Train Count = 58640\n",
      "Episode 7799: Reward = 585.00, Steps = 7, Loss = 8.1156, Exploration Rate = 0.1000, Train Count = 58647\n",
      "Episode 7800: Reward = 594.00, Steps = 4, Loss = 7.4662, Exploration Rate = 0.1000, Train Count = 58651\n",
      "Episode 7801: Reward = 585.00, Steps = 7, Loss = 4.9961, Exploration Rate = 0.1000, Train Count = 58658\n",
      "Episode 7802: Reward = 588.00, Steps = 6, Loss = 4.1624, Exploration Rate = 0.1000, Train Count = 58664\n",
      "Episode 7803: Reward = 517.00, Steps = 14, Loss = 5.4650, Exploration Rate = 0.1000, Train Count = 58678\n",
      "Episode 7804: Reward = 585.00, Steps = 7, Loss = 9.0825, Exploration Rate = 0.1000, Train Count = 58685\n",
      "Episode 7805: Reward = 591.00, Steps = 5, Loss = 5.1030, Exploration Rate = 0.1000, Train Count = 58690\n",
      "Episode 7806: Reward = 591.00, Steps = 5, Loss = 5.3461, Exploration Rate = 0.1000, Train Count = 58695\n",
      "Episode 7807: Reward = 582.00, Steps = 8, Loss = 4.6012, Exploration Rate = 0.1000, Train Count = 58703\n",
      "Episode 7808: Reward = 582.00, Steps = 8, Loss = 2.9843, Exploration Rate = 0.1000, Train Count = 58711\n",
      "Episode 7809: Reward = 597.00, Steps = 3, Loss = 2.3264, Exploration Rate = 0.1000, Train Count = 58714\n",
      "Episode 7810: Reward = 591.00, Steps = 5, Loss = 3.2672, Exploration Rate = 0.1000, Train Count = 58719\n",
      "Episode 7811: Reward = 538.00, Steps = 7, Loss = 4.5352, Exploration Rate = 0.1000, Train Count = 58726\n",
      "Episode 7812: Reward = 585.00, Steps = 7, Loss = 2.9478, Exploration Rate = 0.1000, Train Count = 58733\n",
      "Episode 7813: Reward = 588.00, Steps = 6, Loss = 10.1491, Exploration Rate = 0.1000, Train Count = 58739\n",
      "Episode 7814: Reward = 588.00, Steps = 6, Loss = 5.5480, Exploration Rate = 0.1000, Train Count = 58745\n",
      "Episode 7815: Reward = 591.00, Steps = 5, Loss = 4.5878, Exploration Rate = 0.1000, Train Count = 58750\n",
      "Episode 7816: Reward = 585.00, Steps = 7, Loss = 5.9677, Exploration Rate = 0.1000, Train Count = 58757\n",
      "Episode 7817: Reward = 597.00, Steps = 3, Loss = 4.4827, Exploration Rate = 0.1000, Train Count = 58760\n",
      "Episode 7818: Reward = 591.00, Steps = 5, Loss = 5.0920, Exploration Rate = 0.1000, Train Count = 58765\n",
      "Episode 7819: Reward = 579.00, Steps = 9, Loss = 4.2771, Exploration Rate = 0.1000, Train Count = 58774\n",
      "Episode 7820: Reward = 573.00, Steps = 11, Loss = 5.1605, Exploration Rate = 0.1000, Train Count = 58785\n",
      "Episode 7821: Reward = 600.00, Steps = 2, Loss = 2.5192, Exploration Rate = 0.1000, Train Count = 58787\n",
      "Episode 7822: Reward = 597.00, Steps = 3, Loss = 3.7574, Exploration Rate = 0.1000, Train Count = 58790\n",
      "Episode 7823: Reward = 594.00, Steps = 4, Loss = 2.5421, Exploration Rate = 0.1000, Train Count = 58794\n",
      "Episode 7824: Reward = 541.00, Steps = 6, Loss = 8.0653, Exploration Rate = 0.1000, Train Count = 58800\n",
      "Episode 7825: Reward = 588.00, Steps = 6, Loss = 31.3726, Exploration Rate = 0.1000, Train Count = 58806\n",
      "Episode 7826: Reward = 591.00, Steps = 5, Loss = 21.5508, Exploration Rate = 0.1000, Train Count = 58811\n",
      "Episode 7827: Reward = 582.00, Steps = 8, Loss = 20.0976, Exploration Rate = 0.1000, Train Count = 58819\n",
      "Episode 7828: Reward = 585.00, Steps = 7, Loss = 13.5856, Exploration Rate = 0.1000, Train Count = 58826\n",
      "Episode 7829: Reward = 591.00, Steps = 5, Loss = 11.1611, Exploration Rate = 0.1000, Train Count = 58831\n",
      "Episode 7830: Reward = 591.00, Steps = 5, Loss = 8.1456, Exploration Rate = 0.1000, Train Count = 58836\n",
      "Episode 7831: Reward = 591.00, Steps = 5, Loss = 11.7132, Exploration Rate = 0.1000, Train Count = 58841\n",
      "Episode 7832: Reward = 597.00, Steps = 3, Loss = 10.7392, Exploration Rate = 0.1000, Train Count = 58844\n",
      "Episode 7833: Reward = 588.00, Steps = 6, Loss = 7.8085, Exploration Rate = 0.1000, Train Count = 58850\n",
      "Episode 7834: Reward = 585.00, Steps = 7, Loss = 6.9183, Exploration Rate = 0.1000, Train Count = 58857\n",
      "Episode 7835: Reward = 535.00, Steps = 8, Loss = 10.8418, Exploration Rate = 0.1000, Train Count = 58865\n",
      "Episode 7836: Reward = 585.00, Steps = 7, Loss = 14.5636, Exploration Rate = 0.1000, Train Count = 58872\n",
      "Episode 7837: Reward = 588.00, Steps = 6, Loss = 9.2199, Exploration Rate = 0.1000, Train Count = 58878\n",
      "Episode 7838: Reward = 591.00, Steps = 5, Loss = 11.6477, Exploration Rate = 0.1000, Train Count = 58883\n",
      "Episode 7839: Reward = 594.00, Steps = 4, Loss = 11.0565, Exploration Rate = 0.1000, Train Count = 58887\n",
      "Episode 7840: Reward = 597.00, Steps = 3, Loss = 4.1454, Exploration Rate = 0.1000, Train Count = 58890\n",
      "Episode 7841: Reward = 585.00, Steps = 7, Loss = 5.4275, Exploration Rate = 0.1000, Train Count = 58897\n",
      "Episode 7842: Reward = 594.00, Steps = 4, Loss = 12.8399, Exploration Rate = 0.1000, Train Count = 58901\n",
      "Episode 7843: Reward = 588.00, Steps = 6, Loss = 8.8946, Exploration Rate = 0.1000, Train Count = 58907\n",
      "Episode 7844: Reward = 588.00, Steps = 6, Loss = 11.0497, Exploration Rate = 0.1000, Train Count = 58913\n",
      "Episode 7845: Reward = 585.00, Steps = 7, Loss = 5.9814, Exploration Rate = 0.1000, Train Count = 58920\n",
      "Episode 7846: Reward = 573.00, Steps = 11, Loss = 10.0487, Exploration Rate = 0.1000, Train Count = 58931\n",
      "Episode 7847: Reward = 594.00, Steps = 4, Loss = 4.7577, Exploration Rate = 0.1000, Train Count = 58935\n",
      "Episode 7848: Reward = 576.00, Steps = 10, Loss = 8.4281, Exploration Rate = 0.1000, Train Count = 58945\n",
      "Episode 7849: Reward = 579.00, Steps = 9, Loss = 8.6284, Exploration Rate = 0.1000, Train Count = 58954\n",
      "Episode 7850: Reward = 582.00, Steps = 8, Loss = 9.4373, Exploration Rate = 0.1000, Train Count = 58962\n",
      "Episode 7851: Reward = 594.00, Steps = 4, Loss = 10.8099, Exploration Rate = 0.1000, Train Count = 58966\n",
      "Episode 7852: Reward = 594.00, Steps = 4, Loss = 8.2916, Exploration Rate = 0.1000, Train Count = 58970\n",
      "Episode 7853: Reward = 538.00, Steps = 7, Loss = 8.0197, Exploration Rate = 0.1000, Train Count = 58977\n",
      "Episode 7854: Reward = 582.00, Steps = 8, Loss = 8.8630, Exploration Rate = 0.1000, Train Count = 58985\n",
      "Episode 7855: Reward = 573.00, Steps = 11, Loss = 15.5971, Exploration Rate = 0.1000, Train Count = 58996\n",
      "Episode 7856: Reward = 591.00, Steps = 5, Loss = 7.4739, Exploration Rate = 0.1000, Train Count = 59001\n",
      "Episode 7857: Reward = 585.00, Steps = 7, Loss = 9.1108, Exploration Rate = 0.1000, Train Count = 59008\n",
      "Episode 7858: Reward = 594.00, Steps = 4, Loss = 9.1315, Exploration Rate = 0.1000, Train Count = 59012\n",
      "Episode 7859: Reward = 597.00, Steps = 3, Loss = 9.8926, Exploration Rate = 0.1000, Train Count = 59015\n",
      "Episode 7860: Reward = 579.00, Steps = 9, Loss = 12.6031, Exploration Rate = 0.1000, Train Count = 59024\n",
      "Episode 7861: Reward = 594.00, Steps = 4, Loss = 9.7371, Exploration Rate = 0.1000, Train Count = 59028\n",
      "Episode 7862: Reward = 591.00, Steps = 5, Loss = 7.3057, Exploration Rate = 0.1000, Train Count = 59033\n",
      "Episode 7863: Reward = 594.00, Steps = 4, Loss = 9.9575, Exploration Rate = 0.1000, Train Count = 59037\n",
      "Episode 7864: Reward = 579.00, Steps = 9, Loss = 10.3935, Exploration Rate = 0.1000, Train Count = 59046\n",
      "Episode 7865: Reward = 597.00, Steps = 3, Loss = 8.0493, Exploration Rate = 0.1000, Train Count = 59049\n",
      "Episode 7866: Reward = 588.00, Steps = 6, Loss = 8.8522, Exploration Rate = 0.1000, Train Count = 59055\n",
      "Episode 7867: Reward = 576.00, Steps = 10, Loss = 9.9552, Exploration Rate = 0.1000, Train Count = 59065\n",
      "Episode 7868: Reward = 582.00, Steps = 8, Loss = 7.2053, Exploration Rate = 0.1000, Train Count = 59073\n",
      "Episode 7869: Reward = 597.00, Steps = 3, Loss = 11.6887, Exploration Rate = 0.1000, Train Count = 59076\n",
      "Episode 7870: Reward = 544.00, Steps = 5, Loss = 9.2640, Exploration Rate = 0.1000, Train Count = 59081\n",
      "Episode 7871: Reward = 582.00, Steps = 8, Loss = 10.9078, Exploration Rate = 0.1000, Train Count = 59089\n",
      "Episode 7872: Reward = 576.00, Steps = 10, Loss = 5.5941, Exploration Rate = 0.1000, Train Count = 59099\n",
      "Episode 7873: Reward = 576.00, Steps = 10, Loss = 9.3071, Exploration Rate = 0.1000, Train Count = 59109\n",
      "Episode 7874: Reward = 579.00, Steps = 9, Loss = 8.4392, Exploration Rate = 0.1000, Train Count = 59118\n",
      "Episode 7875: Reward = 588.00, Steps = 6, Loss = 6.1626, Exploration Rate = 0.1000, Train Count = 59124\n",
      "Episode 7876: Reward = 591.00, Steps = 5, Loss = 7.3011, Exploration Rate = 0.1000, Train Count = 59129\n",
      "Episode 7877: Reward = 594.00, Steps = 4, Loss = 5.6585, Exploration Rate = 0.1000, Train Count = 59133\n",
      "Episode 7878: Reward = 591.00, Steps = 5, Loss = 4.7590, Exploration Rate = 0.1000, Train Count = 59138\n",
      "Episode 7879: Reward = 597.00, Steps = 3, Loss = 11.8279, Exploration Rate = 0.1000, Train Count = 59141\n",
      "Episode 7880: Reward = 585.00, Steps = 7, Loss = 7.8838, Exploration Rate = 0.1000, Train Count = 59148\n",
      "Episode 7881: Reward = 597.00, Steps = 3, Loss = 11.4392, Exploration Rate = 0.1000, Train Count = 59151\n",
      "Episode 7882: Reward = 591.00, Steps = 5, Loss = 4.1345, Exploration Rate = 0.1000, Train Count = 59156\n",
      "Episode 7883: Reward = 597.00, Steps = 3, Loss = 4.2340, Exploration Rate = 0.1000, Train Count = 59159\n",
      "Episode 7884: Reward = 588.00, Steps = 6, Loss = 10.1543, Exploration Rate = 0.1000, Train Count = 59165\n",
      "Episode 7885: Reward = 582.00, Steps = 8, Loss = 5.9199, Exploration Rate = 0.1000, Train Count = 59173\n",
      "Episode 7886: Reward = 538.00, Steps = 7, Loss = 10.1362, Exploration Rate = 0.1000, Train Count = 59180\n",
      "Episode 7887: Reward = 597.00, Steps = 3, Loss = 11.3345, Exploration Rate = 0.1000, Train Count = 59183\n",
      "Episode 7888: Reward = 591.00, Steps = 5, Loss = 10.5418, Exploration Rate = 0.1000, Train Count = 59188\n",
      "Episode 7889: Reward = 576.00, Steps = 10, Loss = 8.6060, Exploration Rate = 0.1000, Train Count = 59198\n",
      "Episode 7890: Reward = 600.00, Steps = 2, Loss = 11.8355, Exploration Rate = 0.1000, Train Count = 59200\n",
      "Episode 7891: Reward = 594.00, Steps = 4, Loss = 13.3481, Exploration Rate = 0.1000, Train Count = 59204\n",
      "Episode 7892: Reward = 591.00, Steps = 5, Loss = 11.3594, Exploration Rate = 0.1000, Train Count = 59209\n",
      "Episode 7893: Reward = 582.00, Steps = 8, Loss = 13.6424, Exploration Rate = 0.1000, Train Count = 59217\n",
      "Episode 7894: Reward = 582.00, Steps = 8, Loss = 14.9791, Exploration Rate = 0.1000, Train Count = 59225\n",
      "Episode 7895: Reward = 579.00, Steps = 9, Loss = 11.0966, Exploration Rate = 0.1000, Train Count = 59234\n",
      "Episode 7896: Reward = 582.00, Steps = 8, Loss = 8.4268, Exploration Rate = 0.1000, Train Count = 59242\n",
      "Episode 7897: Reward = 591.00, Steps = 5, Loss = 12.0388, Exploration Rate = 0.1000, Train Count = 59247\n",
      "Episode 7898: Reward = 573.00, Steps = 11, Loss = 8.4083, Exploration Rate = 0.1000, Train Count = 59258\n",
      "Episode 7899: Reward = 600.00, Steps = 2, Loss = 12.1738, Exploration Rate = 0.1000, Train Count = 59260\n",
      "Episode 7900: Reward = 588.00, Steps = 6, Loss = 11.1698, Exploration Rate = 0.1000, Train Count = 59266\n",
      "Episode 7901: Reward = 570.00, Steps = 12, Loss = 8.6012, Exploration Rate = 0.1000, Train Count = 59278\n",
      "Episode 7902: Reward = 597.00, Steps = 3, Loss = 6.3366, Exploration Rate = 0.1000, Train Count = 59281\n",
      "Episode 7903: Reward = 588.00, Steps = 6, Loss = 9.5204, Exploration Rate = 0.1000, Train Count = 59287\n",
      "Episode 7904: Reward = 585.00, Steps = 7, Loss = 8.2970, Exploration Rate = 0.1000, Train Count = 59294\n",
      "Episode 7905: Reward = 585.00, Steps = 7, Loss = 8.5809, Exploration Rate = 0.1000, Train Count = 59301\n",
      "Episode 7906: Reward = 591.00, Steps = 5, Loss = 29.2093, Exploration Rate = 0.1000, Train Count = 59306\n",
      "Episode 7907: Reward = 588.00, Steps = 6, Loss = 22.4106, Exploration Rate = 0.1000, Train Count = 59312\n",
      "Episode 7908: Reward = 591.00, Steps = 5, Loss = 19.9896, Exploration Rate = 0.1000, Train Count = 59317\n",
      "Episode 7909: Reward = 594.00, Steps = 4, Loss = 18.1953, Exploration Rate = 0.1000, Train Count = 59321\n",
      "Episode 7910: Reward = 582.00, Steps = 8, Loss = 16.3953, Exploration Rate = 0.1000, Train Count = 59329\n",
      "Episode 7911: Reward = 591.00, Steps = 5, Loss = 11.9728, Exploration Rate = 0.1000, Train Count = 59334\n",
      "Episode 7912: Reward = 591.00, Steps = 5, Loss = 13.1009, Exploration Rate = 0.1000, Train Count = 59339\n",
      "Episode 7913: Reward = 594.00, Steps = 4, Loss = 10.5335, Exploration Rate = 0.1000, Train Count = 59343\n",
      "Episode 7914: Reward = 591.00, Steps = 5, Loss = 11.2350, Exploration Rate = 0.1000, Train Count = 59348\n",
      "Episode 7915: Reward = 573.00, Steps = 11, Loss = 14.3138, Exploration Rate = 0.1000, Train Count = 59359\n",
      "Episode 7916: Reward = 579.00, Steps = 9, Loss = 11.2999, Exploration Rate = 0.1000, Train Count = 59368\n",
      "Episode 7917: Reward = 588.00, Steps = 6, Loss = 7.8560, Exploration Rate = 0.1000, Train Count = 59374\n",
      "Episode 7918: Reward = 582.00, Steps = 8, Loss = 7.8476, Exploration Rate = 0.1000, Train Count = 59382\n",
      "Episode 7919: Reward = 594.00, Steps = 4, Loss = 7.0226, Exploration Rate = 0.1000, Train Count = 59386\n",
      "Episode 7920: Reward = 567.00, Steps = 13, Loss = 4.7932, Exploration Rate = 0.1000, Train Count = 59399\n",
      "Episode 7921: Reward = 541.00, Steps = 6, Loss = 7.2789, Exploration Rate = 0.1000, Train Count = 59405\n",
      "Episode 7922: Reward = 585.00, Steps = 7, Loss = 6.9372, Exploration Rate = 0.1000, Train Count = 59412\n",
      "Episode 7923: Reward = 594.00, Steps = 4, Loss = 6.6173, Exploration Rate = 0.1000, Train Count = 59416\n",
      "Episode 7924: Reward = 591.00, Steps = 5, Loss = 8.8767, Exploration Rate = 0.1000, Train Count = 59421\n",
      "Episode 7925: Reward = 591.00, Steps = 5, Loss = 4.3706, Exploration Rate = 0.1000, Train Count = 59426\n",
      "Episode 7926: Reward = 514.00, Steps = 15, Loss = 7.2018, Exploration Rate = 0.1000, Train Count = 59441\n",
      "Episode 7927: Reward = 582.00, Steps = 8, Loss = 8.7834, Exploration Rate = 0.1000, Train Count = 59449\n",
      "Episode 7928: Reward = 588.00, Steps = 6, Loss = 7.2061, Exploration Rate = 0.1000, Train Count = 59455\n",
      "Episode 7929: Reward = 573.00, Steps = 11, Loss = 5.9914, Exploration Rate = 0.1000, Train Count = 59466\n",
      "Episode 7930: Reward = 538.00, Steps = 7, Loss = 7.5788, Exploration Rate = 0.1000, Train Count = 59473\n",
      "Episode 7931: Reward = 588.00, Steps = 6, Loss = 8.6792, Exploration Rate = 0.1000, Train Count = 59479\n",
      "Episode 7932: Reward = 588.00, Steps = 6, Loss = 8.5746, Exploration Rate = 0.1000, Train Count = 59485\n",
      "Episode 7933: Reward = 573.00, Steps = 11, Loss = 12.0551, Exploration Rate = 0.1000, Train Count = 59496\n",
      "Episode 7934: Reward = 600.00, Steps = 2, Loss = 11.7458, Exploration Rate = 0.1000, Train Count = 59498\n",
      "Episode 7935: Reward = 594.00, Steps = 4, Loss = 9.7836, Exploration Rate = 0.1000, Train Count = 59502\n",
      "Episode 7936: Reward = 591.00, Steps = 5, Loss = 7.1890, Exploration Rate = 0.1000, Train Count = 59507\n",
      "Episode 7937: Reward = 591.00, Steps = 5, Loss = 7.5255, Exploration Rate = 0.1000, Train Count = 59512\n",
      "Episode 7938: Reward = 585.00, Steps = 7, Loss = 7.5602, Exploration Rate = 0.1000, Train Count = 59519\n",
      "Episode 7939: Reward = 582.00, Steps = 8, Loss = 7.8679, Exploration Rate = 0.1000, Train Count = 59527\n",
      "Episode 7940: Reward = 585.00, Steps = 7, Loss = 7.6917, Exploration Rate = 0.1000, Train Count = 59534\n",
      "Episode 7941: Reward = 597.00, Steps = 3, Loss = 8.7819, Exploration Rate = 0.1000, Train Count = 59537\n",
      "Episode 7942: Reward = 588.00, Steps = 6, Loss = 6.2430, Exploration Rate = 0.1000, Train Count = 59543\n",
      "Episode 7943: Reward = 535.00, Steps = 8, Loss = 11.7872, Exploration Rate = 0.1000, Train Count = 59551\n",
      "Episode 7944: Reward = 585.00, Steps = 7, Loss = 5.2723, Exploration Rate = 0.1000, Train Count = 59558\n",
      "Episode 7945: Reward = 579.00, Steps = 9, Loss = 4.9040, Exploration Rate = 0.1000, Train Count = 59567\n",
      "Episode 7946: Reward = 582.00, Steps = 8, Loss = 6.8595, Exploration Rate = 0.1000, Train Count = 59575\n",
      "Episode 7947: Reward = 597.00, Steps = 3, Loss = 8.6686, Exploration Rate = 0.1000, Train Count = 59578\n",
      "Episode 7948: Reward = 579.00, Steps = 9, Loss = 8.4991, Exploration Rate = 0.1000, Train Count = 59587\n",
      "Episode 7949: Reward = 576.00, Steps = 10, Loss = 7.6218, Exploration Rate = 0.1000, Train Count = 59597\n",
      "Episode 7950: Reward = 576.00, Steps = 10, Loss = 7.7682, Exploration Rate = 0.1000, Train Count = 59607\n",
      "Episode 7951: Reward = 582.00, Steps = 8, Loss = 9.5108, Exploration Rate = 0.1000, Train Count = 59615\n",
      "Episode 7952: Reward = 576.00, Steps = 10, Loss = 12.3151, Exploration Rate = 0.1000, Train Count = 59625\n",
      "Episode 7953: Reward = 585.00, Steps = 7, Loss = 8.5426, Exploration Rate = 0.1000, Train Count = 59632\n",
      "Episode 7954: Reward = 594.00, Steps = 4, Loss = 10.8360, Exploration Rate = 0.1000, Train Count = 59636\n",
      "Episode 7955: Reward = 594.00, Steps = 4, Loss = 6.7913, Exploration Rate = 0.1000, Train Count = 59640\n",
      "Episode 7956: Reward = 591.00, Steps = 5, Loss = 4.9304, Exploration Rate = 0.1000, Train Count = 59645\n",
      "Episode 7957: Reward = 582.00, Steps = 8, Loss = 9.4768, Exploration Rate = 0.1000, Train Count = 59653\n",
      "Episode 7958: Reward = 582.00, Steps = 8, Loss = 7.3178, Exploration Rate = 0.1000, Train Count = 59661\n",
      "Episode 7959: Reward = 570.00, Steps = 12, Loss = 7.2342, Exploration Rate = 0.1000, Train Count = 59673\n",
      "Episode 7960: Reward = 591.00, Steps = 5, Loss = 8.4588, Exploration Rate = 0.1000, Train Count = 59678\n",
      "Episode 7961: Reward = 594.00, Steps = 4, Loss = 2.5313, Exploration Rate = 0.1000, Train Count = 59682\n",
      "Episode 7962: Reward = 591.00, Steps = 5, Loss = 5.2381, Exploration Rate = 0.1000, Train Count = 59687\n",
      "Episode 7963: Reward = 591.00, Steps = 5, Loss = 3.9155, Exploration Rate = 0.1000, Train Count = 59692\n",
      "Episode 7964: Reward = 585.00, Steps = 7, Loss = 5.2073, Exploration Rate = 0.1000, Train Count = 59699\n",
      "Episode 7965: Reward = 585.00, Steps = 7, Loss = 4.0266, Exploration Rate = 0.1000, Train Count = 59706\n",
      "Episode 7966: Reward = 594.00, Steps = 4, Loss = 6.6418, Exploration Rate = 0.1000, Train Count = 59710\n",
      "Episode 7967: Reward = 597.00, Steps = 3, Loss = 1.4695, Exploration Rate = 0.1000, Train Count = 59713\n",
      "Episode 7968: Reward = 591.00, Steps = 5, Loss = 3.5990, Exploration Rate = 0.1000, Train Count = 59718\n",
      "Episode 7969: Reward = 573.00, Steps = 11, Loss = 4.5977, Exploration Rate = 0.1000, Train Count = 59729\n",
      "Episode 7970: Reward = 597.00, Steps = 3, Loss = 1.5561, Exploration Rate = 0.1000, Train Count = 59732\n",
      "Episode 7971: Reward = 576.00, Steps = 10, Loss = 2.6944, Exploration Rate = 0.1000, Train Count = 59742\n",
      "Episode 7972: Reward = 597.00, Steps = 3, Loss = 3.6166, Exploration Rate = 0.1000, Train Count = 59745\n",
      "Episode 7973: Reward = 591.00, Steps = 5, Loss = 4.4805, Exploration Rate = 0.1000, Train Count = 59750\n",
      "Episode 7974: Reward = 585.00, Steps = 7, Loss = 2.2911, Exploration Rate = 0.1000, Train Count = 59757\n",
      "Episode 7975: Reward = 591.00, Steps = 5, Loss = 5.5502, Exploration Rate = 0.1000, Train Count = 59762\n",
      "Episode 7976: Reward = 588.00, Steps = 6, Loss = 5.7819, Exploration Rate = 0.1000, Train Count = 59768\n",
      "Episode 7977: Reward = 579.00, Steps = 9, Loss = 7.0365, Exploration Rate = 0.1000, Train Count = 59777\n",
      "Episode 7978: Reward = 558.00, Steps = 16, Loss = 4.3832, Exploration Rate = 0.1000, Train Count = 59793\n",
      "Episode 7979: Reward = 582.00, Steps = 8, Loss = 7.8137, Exploration Rate = 0.1000, Train Count = 59801\n",
      "Episode 7980: Reward = 585.00, Steps = 7, Loss = 30.7147, Exploration Rate = 0.1000, Train Count = 59808\n",
      "Episode 7981: Reward = 582.00, Steps = 8, Loss = 20.4677, Exploration Rate = 0.1000, Train Count = 59816\n",
      "Episode 7982: Reward = 594.00, Steps = 4, Loss = 17.5649, Exploration Rate = 0.1000, Train Count = 59820\n",
      "Episode 7983: Reward = 585.00, Steps = 7, Loss = 12.9581, Exploration Rate = 0.1000, Train Count = 59827\n",
      "Episode 7984: Reward = 535.00, Steps = 8, Loss = 12.5313, Exploration Rate = 0.1000, Train Count = 59835\n",
      "Episode 7985: Reward = 594.00, Steps = 4, Loss = 16.1251, Exploration Rate = 0.1000, Train Count = 59839\n",
      "Episode 7986: Reward = 591.00, Steps = 5, Loss = 8.0366, Exploration Rate = 0.1000, Train Count = 59844\n",
      "Episode 7987: Reward = 594.00, Steps = 4, Loss = 8.7113, Exploration Rate = 0.1000, Train Count = 59848\n",
      "Episode 7988: Reward = 585.00, Steps = 7, Loss = 9.5803, Exploration Rate = 0.1000, Train Count = 59855\n",
      "Episode 7989: Reward = 594.00, Steps = 4, Loss = 5.2962, Exploration Rate = 0.1000, Train Count = 59859\n",
      "Episode 7990: Reward = 591.00, Steps = 5, Loss = 3.9005, Exploration Rate = 0.1000, Train Count = 59864\n",
      "Episode 7991: Reward = 585.00, Steps = 7, Loss = 4.2875, Exploration Rate = 0.1000, Train Count = 59871\n",
      "Episode 7992: Reward = 597.00, Steps = 3, Loss = 3.3883, Exploration Rate = 0.1000, Train Count = 59874\n",
      "Episode 7993: Reward = 594.00, Steps = 4, Loss = 5.1126, Exploration Rate = 0.1000, Train Count = 59878\n",
      "Episode 7994: Reward = 594.00, Steps = 4, Loss = 4.1246, Exploration Rate = 0.1000, Train Count = 59882\n",
      "Episode 7995: Reward = 538.00, Steps = 7, Loss = 11.2179, Exploration Rate = 0.1000, Train Count = 59889\n",
      "Episode 7996: Reward = 582.00, Steps = 8, Loss = 10.7066, Exploration Rate = 0.1000, Train Count = 59897\n",
      "Episode 7997: Reward = 576.00, Steps = 10, Loss = 5.0033, Exploration Rate = 0.1000, Train Count = 59907\n",
      "Episode 7998: Reward = 579.00, Steps = 9, Loss = 5.7407, Exploration Rate = 0.1000, Train Count = 59916\n",
      "Episode 7999: Reward = 597.00, Steps = 3, Loss = 4.8973, Exploration Rate = 0.1000, Train Count = 59919\n",
      "Episode 8000: Reward = 588.00, Steps = 6, Loss = 8.1284, Exploration Rate = 0.1000, Train Count = 59925\n",
      "Episode 8001: Reward = 591.00, Steps = 5, Loss = 5.5326, Exploration Rate = 0.1000, Train Count = 59930\n",
      "Episode 8002: Reward = 585.00, Steps = 7, Loss = 7.9760, Exploration Rate = 0.1000, Train Count = 59937\n",
      "Episode 8003: Reward = 576.00, Steps = 10, Loss = 6.6229, Exploration Rate = 0.1000, Train Count = 59947\n",
      "Episode 8004: Reward = 594.00, Steps = 4, Loss = 4.8824, Exploration Rate = 0.1000, Train Count = 59951\n",
      "Episode 8005: Reward = 544.00, Steps = 5, Loss = 8.2916, Exploration Rate = 0.1000, Train Count = 59956\n",
      "Episode 8006: Reward = 585.00, Steps = 7, Loss = 12.0430, Exploration Rate = 0.1000, Train Count = 59963\n",
      "Episode 8007: Reward = 591.00, Steps = 5, Loss = 9.0989, Exploration Rate = 0.1000, Train Count = 59968\n",
      "Episode 8008: Reward = 594.00, Steps = 4, Loss = 6.0485, Exploration Rate = 0.1000, Train Count = 59972\n",
      "Episode 8009: Reward = 576.00, Steps = 10, Loss = 9.0349, Exploration Rate = 0.1000, Train Count = 59982\n",
      "Episode 8010: Reward = 594.00, Steps = 4, Loss = 5.5517, Exploration Rate = 0.1000, Train Count = 59986\n",
      "Episode 8011: Reward = 547.00, Steps = 4, Loss = 7.3962, Exploration Rate = 0.1000, Train Count = 59990\n",
      "Episode 8012: Reward = 594.00, Steps = 4, Loss = 7.3974, Exploration Rate = 0.1000, Train Count = 59994\n",
      "Episode 8013: Reward = 579.00, Steps = 9, Loss = 8.4510, Exploration Rate = 0.1000, Train Count = 60003\n",
      "Episode 8014: Reward = 594.00, Steps = 4, Loss = 7.8739, Exploration Rate = 0.1000, Train Count = 60007\n",
      "Episode 8015: Reward = 588.00, Steps = 6, Loss = 8.3886, Exploration Rate = 0.1000, Train Count = 60013\n",
      "Episode 8016: Reward = 591.00, Steps = 5, Loss = 3.5949, Exploration Rate = 0.1000, Train Count = 60018\n",
      "Episode 8017: Reward = 588.00, Steps = 6, Loss = 3.6397, Exploration Rate = 0.1000, Train Count = 60024\n",
      "Episode 8018: Reward = 582.00, Steps = 8, Loss = 4.2549, Exploration Rate = 0.1000, Train Count = 60032\n",
      "Episode 8019: Reward = 588.00, Steps = 6, Loss = 3.8892, Exploration Rate = 0.1000, Train Count = 60038\n",
      "Episode 8020: Reward = 591.00, Steps = 5, Loss = 5.5980, Exploration Rate = 0.1000, Train Count = 60043\n",
      "Episode 8021: Reward = 570.00, Steps = 12, Loss = 4.0714, Exploration Rate = 0.1000, Train Count = 60055\n",
      "Episode 8022: Reward = 597.00, Steps = 3, Loss = 1.3040, Exploration Rate = 0.1000, Train Count = 60058\n",
      "Episode 8023: Reward = 588.00, Steps = 6, Loss = 3.0823, Exploration Rate = 0.1000, Train Count = 60064\n",
      "Episode 8024: Reward = 588.00, Steps = 6, Loss = 3.1110, Exploration Rate = 0.1000, Train Count = 60070\n",
      "Episode 8025: Reward = 535.00, Steps = 8, Loss = 5.5358, Exploration Rate = 0.1000, Train Count = 60078\n",
      "Episode 8026: Reward = 588.00, Steps = 6, Loss = 11.0921, Exploration Rate = 0.1000, Train Count = 60084\n",
      "Episode 8027: Reward = 582.00, Steps = 8, Loss = 8.3257, Exploration Rate = 0.1000, Train Count = 60092\n",
      "Episode 8028: Reward = 591.00, Steps = 5, Loss = 4.7545, Exploration Rate = 0.1000, Train Count = 60097\n",
      "Episode 8029: Reward = 588.00, Steps = 6, Loss = 5.3917, Exploration Rate = 0.1000, Train Count = 60103\n",
      "Episode 8030: Reward = 582.00, Steps = 8, Loss = 5.3207, Exploration Rate = 0.1000, Train Count = 60111\n",
      "Episode 8031: Reward = 591.00, Steps = 5, Loss = 6.0200, Exploration Rate = 0.1000, Train Count = 60116\n",
      "Episode 8032: Reward = 591.00, Steps = 5, Loss = 5.3532, Exploration Rate = 0.1000, Train Count = 60121\n",
      "Episode 8033: Reward = 576.00, Steps = 10, Loss = 2.7094, Exploration Rate = 0.1000, Train Count = 60131\n",
      "Episode 8034: Reward = 594.00, Steps = 4, Loss = 4.8268, Exploration Rate = 0.1000, Train Count = 60135\n",
      "Episode 8035: Reward = 591.00, Steps = 5, Loss = 3.8069, Exploration Rate = 0.1000, Train Count = 60140\n",
      "Episode 8036: Reward = 546.00, Steps = 20, Loss = 4.2680, Exploration Rate = 0.1000, Train Count = 60160\n",
      "Episode 8037: Reward = 585.00, Steps = 7, Loss = 4.8485, Exploration Rate = 0.1000, Train Count = 60167\n",
      "Episode 8038: Reward = 597.00, Steps = 3, Loss = 6.6733, Exploration Rate = 0.1000, Train Count = 60170\n",
      "Episode 8039: Reward = 591.00, Steps = 5, Loss = 4.0809, Exploration Rate = 0.1000, Train Count = 60175\n",
      "Episode 8040: Reward = 594.00, Steps = 4, Loss = 5.2814, Exploration Rate = 0.1000, Train Count = 60179\n",
      "Episode 8041: Reward = 526.00, Steps = 11, Loss = 4.3859, Exploration Rate = 0.1000, Train Count = 60190\n",
      "Episode 8042: Reward = 591.00, Steps = 5, Loss = 5.7508, Exploration Rate = 0.1000, Train Count = 60195\n",
      "Episode 8043: Reward = 585.00, Steps = 7, Loss = 3.8737, Exploration Rate = 0.1000, Train Count = 60202\n",
      "Episode 8044: Reward = 544.00, Steps = 5, Loss = 3.7312, Exploration Rate = 0.1000, Train Count = 60207\n",
      "Episode 8045: Reward = 597.00, Steps = 3, Loss = 3.2298, Exploration Rate = 0.1000, Train Count = 60210\n",
      "Episode 8046: Reward = 597.00, Steps = 3, Loss = 8.3345, Exploration Rate = 0.1000, Train Count = 60213\n",
      "Episode 8047: Reward = 544.00, Steps = 5, Loss = 10.2027, Exploration Rate = 0.1000, Train Count = 60218\n",
      "Episode 8048: Reward = 585.00, Steps = 7, Loss = 14.4888, Exploration Rate = 0.1000, Train Count = 60225\n",
      "Episode 8049: Reward = 585.00, Steps = 7, Loss = 8.6093, Exploration Rate = 0.1000, Train Count = 60232\n",
      "Episode 8050: Reward = 582.00, Steps = 8, Loss = 7.9743, Exploration Rate = 0.1000, Train Count = 60240\n",
      "Episode 8051: Reward = 564.00, Steps = 14, Loss = 7.8025, Exploration Rate = 0.1000, Train Count = 60254\n",
      "Episode 8052: Reward = 591.00, Steps = 5, Loss = 6.7112, Exploration Rate = 0.1000, Train Count = 60259\n",
      "Episode 8053: Reward = 579.00, Steps = 9, Loss = 7.5448, Exploration Rate = 0.1000, Train Count = 60268\n",
      "Episode 8054: Reward = 591.00, Steps = 5, Loss = 8.3172, Exploration Rate = 0.1000, Train Count = 60273\n",
      "Episode 8055: Reward = 591.00, Steps = 5, Loss = 4.9075, Exploration Rate = 0.1000, Train Count = 60278\n",
      "Episode 8056: Reward = 597.00, Steps = 3, Loss = 5.0493, Exploration Rate = 0.1000, Train Count = 60281\n",
      "Episode 8057: Reward = 591.00, Steps = 5, Loss = 3.3080, Exploration Rate = 0.1000, Train Count = 60286\n",
      "Episode 8058: Reward = 594.00, Steps = 4, Loss = 4.7215, Exploration Rate = 0.1000, Train Count = 60290\n",
      "Episode 8059: Reward = 594.00, Steps = 4, Loss = 5.8353, Exploration Rate = 0.1000, Train Count = 60294\n",
      "Episode 8060: Reward = 585.00, Steps = 7, Loss = 7.8261, Exploration Rate = 0.1000, Train Count = 60301\n",
      "Episode 8061: Reward = 588.00, Steps = 6, Loss = 25.8337, Exploration Rate = 0.1000, Train Count = 60307\n",
      "Episode 8062: Reward = 591.00, Steps = 5, Loss = 17.0809, Exploration Rate = 0.1000, Train Count = 60312\n",
      "Episode 8063: Reward = 597.00, Steps = 3, Loss = 14.6041, Exploration Rate = 0.1000, Train Count = 60315\n",
      "Episode 8064: Reward = 588.00, Steps = 6, Loss = 17.0329, Exploration Rate = 0.1000, Train Count = 60321\n",
      "Episode 8065: Reward = 600.00, Steps = 2, Loss = 16.7369, Exploration Rate = 0.1000, Train Count = 60323\n",
      "Episode 8066: Reward = 588.00, Steps = 6, Loss = 15.2820, Exploration Rate = 0.1000, Train Count = 60329\n",
      "Episode 8067: Reward = 597.00, Steps = 3, Loss = 12.6480, Exploration Rate = 0.1000, Train Count = 60332\n",
      "Episode 8068: Reward = 594.00, Steps = 4, Loss = 10.7643, Exploration Rate = 0.1000, Train Count = 60336\n",
      "Episode 8069: Reward = 579.00, Steps = 9, Loss = 9.6187, Exploration Rate = 0.1000, Train Count = 60345\n",
      "Episode 8070: Reward = 591.00, Steps = 5, Loss = 6.1341, Exploration Rate = 0.1000, Train Count = 60350\n",
      "Episode 8071: Reward = 561.00, Steps = 15, Loss = 14.4452, Exploration Rate = 0.1000, Train Count = 60365\n",
      "Episode 8072: Reward = 588.00, Steps = 6, Loss = 15.3484, Exploration Rate = 0.1000, Train Count = 60371\n",
      "Episode 8073: Reward = 588.00, Steps = 6, Loss = 14.8809, Exploration Rate = 0.1000, Train Count = 60377\n",
      "Episode 8074: Reward = 600.00, Steps = 2, Loss = 12.2977, Exploration Rate = 0.1000, Train Count = 60379\n",
      "Episode 8075: Reward = 588.00, Steps = 6, Loss = 8.0908, Exploration Rate = 0.1000, Train Count = 60385\n",
      "Episode 8076: Reward = 591.00, Steps = 5, Loss = 9.1171, Exploration Rate = 0.1000, Train Count = 60390\n",
      "Episode 8077: Reward = 579.00, Steps = 9, Loss = 6.7238, Exploration Rate = 0.1000, Train Count = 60399\n",
      "Episode 8078: Reward = 600.00, Steps = 2, Loss = 5.2617, Exploration Rate = 0.1000, Train Count = 60401\n",
      "Episode 8079: Reward = 585.00, Steps = 7, Loss = 9.2906, Exploration Rate = 0.1000, Train Count = 60408\n",
      "Episode 8080: Reward = 597.00, Steps = 3, Loss = 4.7485, Exploration Rate = 0.1000, Train Count = 60411\n",
      "Episode 8081: Reward = 585.00, Steps = 7, Loss = 8.6404, Exploration Rate = 0.1000, Train Count = 60418\n",
      "Episode 8082: Reward = 597.00, Steps = 3, Loss = 7.6380, Exploration Rate = 0.1000, Train Count = 60421\n",
      "Episode 8083: Reward = 600.00, Steps = 2, Loss = 8.4955, Exploration Rate = 0.1000, Train Count = 60423\n",
      "Episode 8084: Reward = 538.00, Steps = 7, Loss = 4.9149, Exploration Rate = 0.1000, Train Count = 60430\n",
      "Episode 8085: Reward = 591.00, Steps = 5, Loss = 6.1316, Exploration Rate = 0.1000, Train Count = 60435\n",
      "Episode 8086: Reward = 541.00, Steps = 6, Loss = 5.3499, Exploration Rate = 0.1000, Train Count = 60441\n",
      "Episode 8087: Reward = 585.00, Steps = 7, Loss = 12.7227, Exploration Rate = 0.1000, Train Count = 60448\n",
      "Episode 8088: Reward = 585.00, Steps = 7, Loss = 7.8119, Exploration Rate = 0.1000, Train Count = 60455\n",
      "Episode 8089: Reward = 588.00, Steps = 6, Loss = 8.0508, Exploration Rate = 0.1000, Train Count = 60461\n",
      "Episode 8090: Reward = 591.00, Steps = 5, Loss = 6.3419, Exploration Rate = 0.1000, Train Count = 60466\n",
      "Episode 8091: Reward = 588.00, Steps = 6, Loss = 5.6297, Exploration Rate = 0.1000, Train Count = 60472\n",
      "Episode 8092: Reward = 585.00, Steps = 7, Loss = 5.5607, Exploration Rate = 0.1000, Train Count = 60479\n",
      "Episode 8093: Reward = 526.00, Steps = 11, Loss = 6.4733, Exploration Rate = 0.1000, Train Count = 60490\n",
      "Episode 8094: Reward = 591.00, Steps = 5, Loss = 5.0617, Exploration Rate = 0.1000, Train Count = 60495\n",
      "Episode 8095: Reward = 591.00, Steps = 5, Loss = 6.7350, Exploration Rate = 0.1000, Train Count = 60500\n",
      "Episode 8096: Reward = 579.00, Steps = 9, Loss = 7.5716, Exploration Rate = 0.1000, Train Count = 60509\n",
      "Episode 8097: Reward = 600.00, Steps = 2, Loss = 7.1753, Exploration Rate = 0.1000, Train Count = 60511\n",
      "Episode 8098: Reward = 538.00, Steps = 7, Loss = 8.8143, Exploration Rate = 0.1000, Train Count = 60518\n",
      "Episode 8099: Reward = 588.00, Steps = 6, Loss = 5.8318, Exploration Rate = 0.1000, Train Count = 60524\n",
      "Episode 8100: Reward = 585.00, Steps = 7, Loss = 5.9934, Exploration Rate = 0.1000, Train Count = 60531\n",
      "Episode 8101: Reward = 594.00, Steps = 4, Loss = 2.7888, Exploration Rate = 0.1000, Train Count = 60535\n",
      "Episode 8102: Reward = 591.00, Steps = 5, Loss = 6.5465, Exploration Rate = 0.1000, Train Count = 60540\n",
      "Episode 8103: Reward = 588.00, Steps = 6, Loss = 7.8247, Exploration Rate = 0.1000, Train Count = 60546\n",
      "Episode 8104: Reward = 573.00, Steps = 11, Loss = 6.6008, Exploration Rate = 0.1000, Train Count = 60557\n",
      "Episode 8105: Reward = 591.00, Steps = 5, Loss = 4.0716, Exploration Rate = 0.1000, Train Count = 60562\n",
      "Episode 8106: Reward = 585.00, Steps = 7, Loss = 6.8908, Exploration Rate = 0.1000, Train Count = 60569\n",
      "Episode 8107: Reward = 588.00, Steps = 6, Loss = 7.0061, Exploration Rate = 0.1000, Train Count = 60575\n",
      "Episode 8108: Reward = 570.00, Steps = 12, Loss = 6.6752, Exploration Rate = 0.1000, Train Count = 60587\n",
      "Episode 8109: Reward = 594.00, Steps = 4, Loss = 10.1567, Exploration Rate = 0.1000, Train Count = 60591\n",
      "Episode 8110: Reward = 591.00, Steps = 5, Loss = 8.3754, Exploration Rate = 0.1000, Train Count = 60596\n",
      "Episode 8111: Reward = 591.00, Steps = 5, Loss = 6.1061, Exploration Rate = 0.1000, Train Count = 60601\n",
      "Episode 8112: Reward = 582.00, Steps = 8, Loss = 7.4422, Exploration Rate = 0.1000, Train Count = 60609\n",
      "Episode 8113: Reward = 594.00, Steps = 4, Loss = 8.1714, Exploration Rate = 0.1000, Train Count = 60613\n",
      "Episode 8114: Reward = 594.00, Steps = 4, Loss = 5.4604, Exploration Rate = 0.1000, Train Count = 60617\n",
      "Episode 8115: Reward = 479.00, Steps = 11, Loss = 6.0981, Exploration Rate = 0.1000, Train Count = 60628\n",
      "Episode 8116: Reward = 591.00, Steps = 5, Loss = 7.7775, Exploration Rate = 0.1000, Train Count = 60633\n",
      "Episode 8117: Reward = 588.00, Steps = 6, Loss = 10.9601, Exploration Rate = 0.1000, Train Count = 60639\n",
      "Episode 8118: Reward = 585.00, Steps = 7, Loss = 5.0511, Exploration Rate = 0.1000, Train Count = 60646\n",
      "Episode 8119: Reward = 588.00, Steps = 6, Loss = 10.6274, Exploration Rate = 0.1000, Train Count = 60652\n",
      "Episode 8120: Reward = 579.00, Steps = 9, Loss = 7.0905, Exploration Rate = 0.1000, Train Count = 60661\n",
      "Episode 8121: Reward = 585.00, Steps = 7, Loss = 8.2572, Exploration Rate = 0.1000, Train Count = 60668\n",
      "Episode 8122: Reward = 594.00, Steps = 4, Loss = 5.0983, Exploration Rate = 0.1000, Train Count = 60672\n",
      "Episode 8123: Reward = 541.00, Steps = 6, Loss = 7.4021, Exploration Rate = 0.1000, Train Count = 60678\n",
      "Episode 8124: Reward = 594.00, Steps = 4, Loss = 8.1723, Exploration Rate = 0.1000, Train Count = 60682\n",
      "Episode 8125: Reward = 594.00, Steps = 4, Loss = 6.8750, Exploration Rate = 0.1000, Train Count = 60686\n",
      "Episode 8126: Reward = 591.00, Steps = 5, Loss = 7.0559, Exploration Rate = 0.1000, Train Count = 60691\n",
      "Episode 8127: Reward = 582.00, Steps = 8, Loss = 9.1525, Exploration Rate = 0.1000, Train Count = 60699\n",
      "Episode 8128: Reward = 594.00, Steps = 4, Loss = 10.1848, Exploration Rate = 0.1000, Train Count = 60703\n",
      "Episode 8129: Reward = 594.00, Steps = 4, Loss = 5.7328, Exploration Rate = 0.1000, Train Count = 60707\n",
      "Episode 8130: Reward = 597.00, Steps = 3, Loss = 5.0925, Exploration Rate = 0.1000, Train Count = 60710\n",
      "Episode 8131: Reward = 591.00, Steps = 5, Loss = 9.5284, Exploration Rate = 0.1000, Train Count = 60715\n",
      "Episode 8132: Reward = 585.00, Steps = 7, Loss = 7.6456, Exploration Rate = 0.1000, Train Count = 60722\n",
      "Episode 8133: Reward = 588.00, Steps = 6, Loss = 8.5382, Exploration Rate = 0.1000, Train Count = 60728\n",
      "Episode 8134: Reward = 582.00, Steps = 8, Loss = 5.8611, Exploration Rate = 0.1000, Train Count = 60736\n",
      "Episode 8135: Reward = 379.00, Steps = 13, Loss = 22.6736, Exploration Rate = 0.1000, Train Count = 60749\n",
      "Episode 8136: Reward = 582.00, Steps = 8, Loss = 23.6438, Exploration Rate = 0.1000, Train Count = 60757\n",
      "Episode 8137: Reward = 591.00, Steps = 5, Loss = 11.7969, Exploration Rate = 0.1000, Train Count = 60762\n",
      "Episode 8138: Reward = 600.00, Steps = 2, Loss = 13.9979, Exploration Rate = 0.1000, Train Count = 60764\n",
      "Episode 8139: Reward = 594.00, Steps = 4, Loss = 12.2205, Exploration Rate = 0.1000, Train Count = 60768\n",
      "Episode 8140: Reward = 585.00, Steps = 7, Loss = 10.3524, Exploration Rate = 0.1000, Train Count = 60775\n",
      "Episode 8141: Reward = 582.00, Steps = 8, Loss = 9.4238, Exploration Rate = 0.1000, Train Count = 60783\n",
      "Episode 8142: Reward = 594.00, Steps = 4, Loss = 6.9339, Exploration Rate = 0.1000, Train Count = 60787\n",
      "Episode 8143: Reward = 594.00, Steps = 4, Loss = 9.4317, Exploration Rate = 0.1000, Train Count = 60791\n",
      "Episode 8144: Reward = 582.00, Steps = 8, Loss = 6.2259, Exploration Rate = 0.1000, Train Count = 60799\n",
      "Episode 8145: Reward = 597.00, Steps = 3, Loss = 23.4963, Exploration Rate = 0.1000, Train Count = 60802\n",
      "Episode 8146: Reward = 561.00, Steps = 15, Loss = 22.9175, Exploration Rate = 0.1000, Train Count = 60817\n",
      "Episode 8147: Reward = 585.00, Steps = 7, Loss = 18.7712, Exploration Rate = 0.1000, Train Count = 60824\n",
      "Episode 8148: Reward = 594.00, Steps = 4, Loss = 15.0427, Exploration Rate = 0.1000, Train Count = 60828\n",
      "Episode 8149: Reward = 576.00, Steps = 10, Loss = 15.1531, Exploration Rate = 0.1000, Train Count = 60838\n",
      "Episode 8150: Reward = 597.00, Steps = 3, Loss = 13.6472, Exploration Rate = 0.1000, Train Count = 60841\n",
      "Episode 8151: Reward = 591.00, Steps = 5, Loss = 14.1345, Exploration Rate = 0.1000, Train Count = 60846\n",
      "Episode 8152: Reward = 591.00, Steps = 5, Loss = 14.2543, Exploration Rate = 0.1000, Train Count = 60851\n",
      "Episode 8153: Reward = 591.00, Steps = 5, Loss = 13.8566, Exploration Rate = 0.1000, Train Count = 60856\n",
      "Episode 8154: Reward = 526.00, Steps = 11, Loss = 12.7790, Exploration Rate = 0.1000, Train Count = 60867\n",
      "Episode 8155: Reward = 588.00, Steps = 6, Loss = 8.5740, Exploration Rate = 0.1000, Train Count = 60873\n",
      "Episode 8156: Reward = 576.00, Steps = 10, Loss = 10.2649, Exploration Rate = 0.1000, Train Count = 60883\n",
      "Episode 8157: Reward = 532.00, Steps = 9, Loss = 11.3369, Exploration Rate = 0.1000, Train Count = 60892\n",
      "Episode 8158: Reward = 594.00, Steps = 4, Loss = 9.4590, Exploration Rate = 0.1000, Train Count = 60896\n",
      "Episode 8159: Reward = 585.00, Steps = 7, Loss = 10.6869, Exploration Rate = 0.1000, Train Count = 60903\n",
      "Episode 8160: Reward = 585.00, Steps = 7, Loss = 12.7789, Exploration Rate = 0.1000, Train Count = 60910\n",
      "Episode 8161: Reward = 585.00, Steps = 7, Loss = 14.5337, Exploration Rate = 0.1000, Train Count = 60917\n",
      "Episode 8162: Reward = 594.00, Steps = 4, Loss = 10.5386, Exploration Rate = 0.1000, Train Count = 60921\n",
      "Episode 8163: Reward = 591.00, Steps = 5, Loss = 11.3814, Exploration Rate = 0.1000, Train Count = 60926\n",
      "Episode 8164: Reward = 591.00, Steps = 5, Loss = 10.8335, Exploration Rate = 0.1000, Train Count = 60931\n",
      "Episode 8165: Reward = 591.00, Steps = 5, Loss = 8.6503, Exploration Rate = 0.1000, Train Count = 60936\n",
      "Episode 8166: Reward = 588.00, Steps = 6, Loss = 8.5880, Exploration Rate = 0.1000, Train Count = 60942\n",
      "Episode 8167: Reward = 582.00, Steps = 8, Loss = 9.9954, Exploration Rate = 0.1000, Train Count = 60950\n",
      "Episode 8168: Reward = 538.00, Steps = 7, Loss = 10.2005, Exploration Rate = 0.1000, Train Count = 60957\n",
      "Episode 8169: Reward = 594.00, Steps = 4, Loss = 5.0769, Exploration Rate = 0.1000, Train Count = 60961\n",
      "Episode 8170: Reward = 585.00, Steps = 7, Loss = 11.5693, Exploration Rate = 0.1000, Train Count = 60968\n",
      "Episode 8171: Reward = 541.00, Steps = 6, Loss = 11.3908, Exploration Rate = 0.1000, Train Count = 60974\n",
      "Episode 8172: Reward = 591.00, Steps = 5, Loss = 24.9946, Exploration Rate = 0.1000, Train Count = 60979\n",
      "Episode 8173: Reward = 541.00, Steps = 6, Loss = 11.9632, Exploration Rate = 0.1000, Train Count = 60985\n",
      "Episode 8174: Reward = 585.00, Steps = 7, Loss = 14.1753, Exploration Rate = 0.1000, Train Count = 60992\n",
      "Episode 8175: Reward = 591.00, Steps = 5, Loss = 12.9951, Exploration Rate = 0.1000, Train Count = 60997\n",
      "Episode 8176: Reward = 491.00, Steps = 7, Loss = 10.3243, Exploration Rate = 0.1000, Train Count = 61004\n",
      "Episode 8177: Reward = 591.00, Steps = 5, Loss = 10.9245, Exploration Rate = 0.1000, Train Count = 61009\n",
      "Episode 8178: Reward = 582.00, Steps = 8, Loss = 9.3325, Exploration Rate = 0.1000, Train Count = 61017\n",
      "Episode 8179: Reward = 594.00, Steps = 4, Loss = 10.0822, Exploration Rate = 0.1000, Train Count = 61021\n",
      "Episode 8180: Reward = 597.00, Steps = 3, Loss = 13.0713, Exploration Rate = 0.1000, Train Count = 61024\n",
      "Episode 8181: Reward = 582.00, Steps = 8, Loss = 12.2328, Exploration Rate = 0.1000, Train Count = 61032\n",
      "Episode 8182: Reward = 597.00, Steps = 3, Loss = 13.1975, Exploration Rate = 0.1000, Train Count = 61035\n",
      "Episode 8183: Reward = 588.00, Steps = 6, Loss = 11.5779, Exploration Rate = 0.1000, Train Count = 61041\n",
      "Episode 8184: Reward = 588.00, Steps = 6, Loss = 7.5136, Exploration Rate = 0.1000, Train Count = 61047\n",
      "Episode 8185: Reward = 588.00, Steps = 6, Loss = 14.4592, Exploration Rate = 0.1000, Train Count = 61053\n",
      "Episode 8186: Reward = 588.00, Steps = 6, Loss = 9.3651, Exploration Rate = 0.1000, Train Count = 61059\n",
      "Episode 8187: Reward = 597.00, Steps = 3, Loss = 10.8883, Exploration Rate = 0.1000, Train Count = 61062\n",
      "Episode 8188: Reward = 591.00, Steps = 5, Loss = 7.5821, Exploration Rate = 0.1000, Train Count = 61067\n",
      "Episode 8189: Reward = 585.00, Steps = 7, Loss = 11.1514, Exploration Rate = 0.1000, Train Count = 61074\n",
      "Episode 8190: Reward = 597.00, Steps = 3, Loss = 8.2520, Exploration Rate = 0.1000, Train Count = 61077\n",
      "Episode 8191: Reward = 585.00, Steps = 7, Loss = 7.5593, Exploration Rate = 0.1000, Train Count = 61084\n",
      "Episode 8192: Reward = 591.00, Steps = 5, Loss = 12.6510, Exploration Rate = 0.1000, Train Count = 61089\n",
      "Episode 8193: Reward = 585.00, Steps = 7, Loss = 6.9714, Exploration Rate = 0.1000, Train Count = 61096\n",
      "Episode 8194: Reward = 579.00, Steps = 9, Loss = 11.5305, Exploration Rate = 0.1000, Train Count = 61105\n",
      "Episode 8195: Reward = 594.00, Steps = 4, Loss = 8.5871, Exploration Rate = 0.1000, Train Count = 61109\n",
      "Episode 8196: Reward = 588.00, Steps = 6, Loss = 11.4471, Exploration Rate = 0.1000, Train Count = 61115\n",
      "Episode 8197: Reward = 591.00, Steps = 5, Loss = 7.4839, Exploration Rate = 0.1000, Train Count = 61120\n",
      "Episode 8198: Reward = 585.00, Steps = 7, Loss = 11.9829, Exploration Rate = 0.1000, Train Count = 61127\n",
      "Episode 8199: Reward = 600.00, Steps = 2, Loss = 8.1046, Exploration Rate = 0.1000, Train Count = 61129\n",
      "Episode 8200: Reward = 591.00, Steps = 5, Loss = 12.4114, Exploration Rate = 0.1000, Train Count = 61134\n",
      "Episode 8201: Reward = 588.00, Steps = 6, Loss = 8.5597, Exploration Rate = 0.1000, Train Count = 61140\n",
      "Episode 8202: Reward = 591.00, Steps = 5, Loss = 13.0836, Exploration Rate = 0.1000, Train Count = 61145\n",
      "Episode 8203: Reward = 591.00, Steps = 5, Loss = 8.8914, Exploration Rate = 0.1000, Train Count = 61150\n",
      "Episode 8204: Reward = 585.00, Steps = 7, Loss = 11.9770, Exploration Rate = 0.1000, Train Count = 61157\n",
      "Episode 8205: Reward = 585.00, Steps = 7, Loss = 7.5210, Exploration Rate = 0.1000, Train Count = 61164\n",
      "Episode 8206: Reward = 585.00, Steps = 7, Loss = 6.8552, Exploration Rate = 0.1000, Train Count = 61171\n",
      "Episode 8207: Reward = 594.00, Steps = 4, Loss = 6.3383, Exploration Rate = 0.1000, Train Count = 61175\n",
      "Episode 8208: Reward = 585.00, Steps = 7, Loss = 8.5644, Exploration Rate = 0.1000, Train Count = 61182\n",
      "Episode 8209: Reward = 597.00, Steps = 3, Loss = 8.4582, Exploration Rate = 0.1000, Train Count = 61185\n",
      "Episode 8210: Reward = 594.00, Steps = 4, Loss = 7.9586, Exploration Rate = 0.1000, Train Count = 61189\n",
      "Episode 8211: Reward = 594.00, Steps = 4, Loss = 4.7425, Exploration Rate = 0.1000, Train Count = 61193\n",
      "Episode 8212: Reward = 597.00, Steps = 3, Loss = 5.4710, Exploration Rate = 0.1000, Train Count = 61196\n",
      "Episode 8213: Reward = 541.00, Steps = 6, Loss = 5.3800, Exploration Rate = 0.1000, Train Count = 61202\n",
      "Episode 8214: Reward = 591.00, Steps = 5, Loss = 9.3645, Exploration Rate = 0.1000, Train Count = 61207\n",
      "Episode 8215: Reward = 585.00, Steps = 7, Loss = 10.0470, Exploration Rate = 0.1000, Train Count = 61214\n",
      "Episode 8216: Reward = 594.00, Steps = 4, Loss = 18.4364, Exploration Rate = 0.1000, Train Count = 61218\n",
      "Episode 8217: Reward = 582.00, Steps = 8, Loss = 16.5868, Exploration Rate = 0.1000, Train Count = 61226\n",
      "Episode 8218: Reward = 582.00, Steps = 8, Loss = 11.1637, Exploration Rate = 0.1000, Train Count = 61234\n",
      "Episode 8219: Reward = 588.00, Steps = 6, Loss = 11.1300, Exploration Rate = 0.1000, Train Count = 61240\n",
      "Episode 8220: Reward = 594.00, Steps = 4, Loss = 10.0191, Exploration Rate = 0.1000, Train Count = 61244\n",
      "Episode 8221: Reward = 579.00, Steps = 9, Loss = 8.5335, Exploration Rate = 0.1000, Train Count = 61253\n",
      "Episode 8222: Reward = 594.00, Steps = 4, Loss = 5.7437, Exploration Rate = 0.1000, Train Count = 61257\n",
      "Episode 8223: Reward = 582.00, Steps = 8, Loss = 8.2383, Exploration Rate = 0.1000, Train Count = 61265\n",
      "Episode 8224: Reward = 582.00, Steps = 8, Loss = 7.4968, Exploration Rate = 0.1000, Train Count = 61273\n",
      "Episode 8225: Reward = 594.00, Steps = 4, Loss = 6.2286, Exploration Rate = 0.1000, Train Count = 61277\n",
      "Episode 8226: Reward = 582.00, Steps = 8, Loss = 6.1034, Exploration Rate = 0.1000, Train Count = 61285\n",
      "Episode 8227: Reward = 588.00, Steps = 6, Loss = 6.4055, Exploration Rate = 0.1000, Train Count = 61291\n",
      "Episode 8228: Reward = 582.00, Steps = 8, Loss = 7.2923, Exploration Rate = 0.1000, Train Count = 61299\n",
      "Episode 8229: Reward = 588.00, Steps = 6, Loss = 24.9808, Exploration Rate = 0.1000, Train Count = 61305\n",
      "Episode 8230: Reward = 588.00, Steps = 6, Loss = 25.7093, Exploration Rate = 0.1000, Train Count = 61311\n",
      "Episode 8231: Reward = 585.00, Steps = 7, Loss = 24.5021, Exploration Rate = 0.1000, Train Count = 61318\n",
      "Episode 8232: Reward = 597.00, Steps = 3, Loss = 22.8240, Exploration Rate = 0.1000, Train Count = 61321\n",
      "Episode 8233: Reward = 547.00, Steps = 4, Loss = 20.5882, Exploration Rate = 0.1000, Train Count = 61325\n",
      "Episode 8234: Reward = 591.00, Steps = 5, Loss = 17.9981, Exploration Rate = 0.1000, Train Count = 61330\n",
      "Episode 8235: Reward = 532.00, Steps = 9, Loss = 13.6026, Exploration Rate = 0.1000, Train Count = 61339\n",
      "Episode 8236: Reward = 591.00, Steps = 5, Loss = 13.8154, Exploration Rate = 0.1000, Train Count = 61344\n",
      "Episode 8237: Reward = 579.00, Steps = 9, Loss = 10.5359, Exploration Rate = 0.1000, Train Count = 61353\n",
      "Episode 8238: Reward = 591.00, Steps = 5, Loss = 10.9535, Exploration Rate = 0.1000, Train Count = 61358\n",
      "Episode 8239: Reward = 579.00, Steps = 9, Loss = 10.7052, Exploration Rate = 0.1000, Train Count = 61367\n",
      "Episode 8240: Reward = 582.00, Steps = 8, Loss = 8.1921, Exploration Rate = 0.1000, Train Count = 61375\n",
      "Episode 8241: Reward = 594.00, Steps = 4, Loss = 7.2272, Exploration Rate = 0.1000, Train Count = 61379\n",
      "Episode 8242: Reward = 597.00, Steps = 3, Loss = 12.0029, Exploration Rate = 0.1000, Train Count = 61382\n",
      "Episode 8243: Reward = 514.00, Steps = 15, Loss = 10.4041, Exploration Rate = 0.1000, Train Count = 61397\n",
      "Episode 8244: Reward = 600.00, Steps = 2, Loss = 12.7957, Exploration Rate = 0.1000, Train Count = 61399\n",
      "Episode 8245: Reward = 591.00, Steps = 5, Loss = 8.1732, Exploration Rate = 0.1000, Train Count = 61404\n",
      "Episode 8246: Reward = 550.00, Steps = 3, Loss = 7.8816, Exploration Rate = 0.1000, Train Count = 61407\n",
      "Episode 8247: Reward = 582.00, Steps = 8, Loss = 7.8696, Exploration Rate = 0.1000, Train Count = 61415\n",
      "Episode 8248: Reward = 538.00, Steps = 7, Loss = 12.6124, Exploration Rate = 0.1000, Train Count = 61422\n",
      "Episode 8249: Reward = 585.00, Steps = 7, Loss = 8.6411, Exploration Rate = 0.1000, Train Count = 61429\n",
      "Episode 8250: Reward = 573.00, Steps = 11, Loss = 9.4707, Exploration Rate = 0.1000, Train Count = 61440\n",
      "Episode 8251: Reward = 579.00, Steps = 9, Loss = 10.0188, Exploration Rate = 0.1000, Train Count = 61449\n",
      "Episode 8252: Reward = 541.00, Steps = 6, Loss = 9.0563, Exploration Rate = 0.1000, Train Count = 61455\n",
      "Episode 8253: Reward = 594.00, Steps = 4, Loss = 5.0959, Exploration Rate = 0.1000, Train Count = 61459\n",
      "Episode 8254: Reward = 588.00, Steps = 6, Loss = 10.1739, Exploration Rate = 0.1000, Train Count = 61465\n",
      "Episode 8255: Reward = 591.00, Steps = 5, Loss = 14.9640, Exploration Rate = 0.1000, Train Count = 61470\n",
      "Episode 8256: Reward = 597.00, Steps = 3, Loss = 9.4582, Exploration Rate = 0.1000, Train Count = 61473\n",
      "Episode 8257: Reward = 585.00, Steps = 7, Loss = 10.8196, Exploration Rate = 0.1000, Train Count = 61480\n",
      "Episode 8258: Reward = 597.00, Steps = 3, Loss = 7.1407, Exploration Rate = 0.1000, Train Count = 61483\n",
      "Episode 8259: Reward = 588.00, Steps = 6, Loss = 9.4036, Exploration Rate = 0.1000, Train Count = 61489\n",
      "Episode 8260: Reward = 585.00, Steps = 7, Loss = 7.8204, Exploration Rate = 0.1000, Train Count = 61496\n",
      "Episode 8261: Reward = 588.00, Steps = 6, Loss = 9.3168, Exploration Rate = 0.1000, Train Count = 61502\n",
      "Episode 8262: Reward = 594.00, Steps = 4, Loss = 8.4246, Exploration Rate = 0.1000, Train Count = 61506\n",
      "Episode 8263: Reward = 579.00, Steps = 9, Loss = 8.8408, Exploration Rate = 0.1000, Train Count = 61515\n",
      "Episode 8264: Reward = 594.00, Steps = 4, Loss = 6.2130, Exploration Rate = 0.1000, Train Count = 61519\n",
      "Episode 8265: Reward = 588.00, Steps = 6, Loss = 11.2739, Exploration Rate = 0.1000, Train Count = 61525\n",
      "Episode 8266: Reward = 582.00, Steps = 8, Loss = 7.7701, Exploration Rate = 0.1000, Train Count = 61533\n",
      "Episode 8267: Reward = 600.00, Steps = 2, Loss = 2.9696, Exploration Rate = 0.1000, Train Count = 61535\n",
      "Episode 8268: Reward = 579.00, Steps = 9, Loss = 8.2525, Exploration Rate = 0.1000, Train Count = 61544\n",
      "Episode 8269: Reward = 591.00, Steps = 5, Loss = 8.8175, Exploration Rate = 0.1000, Train Count = 61549\n",
      "Episode 8270: Reward = 585.00, Steps = 7, Loss = 7.7872, Exploration Rate = 0.1000, Train Count = 61556\n",
      "Episode 8271: Reward = 582.00, Steps = 8, Loss = 10.3864, Exploration Rate = 0.1000, Train Count = 61564\n",
      "Episode 8272: Reward = 588.00, Steps = 6, Loss = 6.9073, Exploration Rate = 0.1000, Train Count = 61570\n",
      "Episode 8273: Reward = 547.00, Steps = 4, Loss = 8.6654, Exploration Rate = 0.1000, Train Count = 61574\n",
      "Episode 8274: Reward = 579.00, Steps = 9, Loss = 12.3867, Exploration Rate = 0.1000, Train Count = 61583\n",
      "Episode 8275: Reward = 588.00, Steps = 6, Loss = 8.9110, Exploration Rate = 0.1000, Train Count = 61589\n",
      "Episode 8276: Reward = 588.00, Steps = 6, Loss = 12.2000, Exploration Rate = 0.1000, Train Count = 61595\n",
      "Episode 8277: Reward = 588.00, Steps = 6, Loss = 8.5015, Exploration Rate = 0.1000, Train Count = 61601\n",
      "Episode 8278: Reward = 588.00, Steps = 6, Loss = 9.3732, Exploration Rate = 0.1000, Train Count = 61607\n",
      "Episode 8279: Reward = 597.00, Steps = 3, Loss = 7.4602, Exploration Rate = 0.1000, Train Count = 61610\n",
      "Episode 8280: Reward = 597.00, Steps = 3, Loss = 10.1512, Exploration Rate = 0.1000, Train Count = 61613\n",
      "Episode 8281: Reward = 579.00, Steps = 9, Loss = 7.2182, Exploration Rate = 0.1000, Train Count = 61622\n",
      "Episode 8282: Reward = 579.00, Steps = 9, Loss = 11.3040, Exploration Rate = 0.1000, Train Count = 61631\n",
      "Episode 8283: Reward = 591.00, Steps = 5, Loss = 15.8089, Exploration Rate = 0.1000, Train Count = 61636\n",
      "Episode 8284: Reward = 591.00, Steps = 5, Loss = 7.3906, Exploration Rate = 0.1000, Train Count = 61641\n",
      "Episode 8285: Reward = 579.00, Steps = 9, Loss = 6.3290, Exploration Rate = 0.1000, Train Count = 61650\n",
      "Episode 8286: Reward = 585.00, Steps = 7, Loss = 6.8067, Exploration Rate = 0.1000, Train Count = 61657\n",
      "Episode 8287: Reward = 597.00, Steps = 3, Loss = 7.0032, Exploration Rate = 0.1000, Train Count = 61660\n",
      "Episode 8288: Reward = 588.00, Steps = 6, Loss = 10.2731, Exploration Rate = 0.1000, Train Count = 61666\n",
      "Episode 8289: Reward = 585.00, Steps = 7, Loss = 6.6728, Exploration Rate = 0.1000, Train Count = 61673\n",
      "Episode 8290: Reward = 591.00, Steps = 5, Loss = 6.7891, Exploration Rate = 0.1000, Train Count = 61678\n",
      "Episode 8291: Reward = 591.00, Steps = 5, Loss = 4.3059, Exploration Rate = 0.1000, Train Count = 61683\n",
      "Episode 8292: Reward = 594.00, Steps = 4, Loss = 4.2835, Exploration Rate = 0.1000, Train Count = 61687\n",
      "Episode 8293: Reward = 597.00, Steps = 3, Loss = 8.6271, Exploration Rate = 0.1000, Train Count = 61690\n",
      "Episode 8294: Reward = 588.00, Steps = 6, Loss = 6.3689, Exploration Rate = 0.1000, Train Count = 61696\n",
      "Episode 8295: Reward = 579.00, Steps = 9, Loss = 8.6793, Exploration Rate = 0.1000, Train Count = 61705\n",
      "Episode 8296: Reward = 579.00, Steps = 9, Loss = 6.0950, Exploration Rate = 0.1000, Train Count = 61714\n",
      "Episode 8297: Reward = 588.00, Steps = 6, Loss = 3.6801, Exploration Rate = 0.1000, Train Count = 61720\n",
      "Episode 8298: Reward = 591.00, Steps = 5, Loss = 7.0850, Exploration Rate = 0.1000, Train Count = 61725\n",
      "Episode 8299: Reward = 582.00, Steps = 8, Loss = 7.2249, Exploration Rate = 0.1000, Train Count = 61733\n",
      "Episode 8300: Reward = 597.00, Steps = 3, Loss = 5.1203, Exploration Rate = 0.1000, Train Count = 61736\n",
      "Episode 8301: Reward = 585.00, Steps = 7, Loss = 8.2387, Exploration Rate = 0.1000, Train Count = 61743\n",
      "Episode 8302: Reward = 588.00, Steps = 6, Loss = 5.1007, Exploration Rate = 0.1000, Train Count = 61749\n",
      "Episode 8303: Reward = 591.00, Steps = 5, Loss = 6.2652, Exploration Rate = 0.1000, Train Count = 61754\n",
      "Episode 8304: Reward = 594.00, Steps = 4, Loss = 11.1235, Exploration Rate = 0.1000, Train Count = 61758\n",
      "Episode 8305: Reward = 564.00, Steps = 14, Loss = 17.9838, Exploration Rate = 0.1000, Train Count = 61772\n",
      "Episode 8306: Reward = 591.00, Steps = 5, Loss = 5.1031, Exploration Rate = 0.1000, Train Count = 61777\n",
      "Episode 8307: Reward = 594.00, Steps = 4, Loss = 7.8959, Exploration Rate = 0.1000, Train Count = 61781\n",
      "Episode 8308: Reward = 594.00, Steps = 4, Loss = 7.5903, Exploration Rate = 0.1000, Train Count = 61785\n",
      "Episode 8309: Reward = 591.00, Steps = 5, Loss = 7.3692, Exploration Rate = 0.1000, Train Count = 61790\n",
      "Episode 8310: Reward = 573.00, Steps = 11, Loss = 9.5337, Exploration Rate = 0.1000, Train Count = 61801\n",
      "Episode 8311: Reward = 541.00, Steps = 6, Loss = 34.0046, Exploration Rate = 0.1000, Train Count = 61807\n",
      "Episode 8312: Reward = 597.00, Steps = 3, Loss = 24.4309, Exploration Rate = 0.1000, Train Count = 61810\n",
      "Episode 8313: Reward = 582.00, Steps = 8, Loss = 22.1779, Exploration Rate = 0.1000, Train Count = 61818\n",
      "Episode 8314: Reward = 582.00, Steps = 8, Loss = 14.0768, Exploration Rate = 0.1000, Train Count = 61826\n",
      "Episode 8315: Reward = 594.00, Steps = 4, Loss = 14.7227, Exploration Rate = 0.1000, Train Count = 61830\n",
      "Episode 8316: Reward = 594.00, Steps = 4, Loss = 14.4741, Exploration Rate = 0.1000, Train Count = 61834\n",
      "Episode 8317: Reward = 579.00, Steps = 9, Loss = 11.4595, Exploration Rate = 0.1000, Train Count = 61843\n",
      "Episode 8318: Reward = 591.00, Steps = 5, Loss = 21.1856, Exploration Rate = 0.1000, Train Count = 61848\n",
      "Episode 8319: Reward = 591.00, Steps = 5, Loss = 13.0773, Exploration Rate = 0.1000, Train Count = 61853\n",
      "Episode 8320: Reward = 576.00, Steps = 10, Loss = 11.8320, Exploration Rate = 0.1000, Train Count = 61863\n",
      "Episode 8321: Reward = 585.00, Steps = 7, Loss = 7.1655, Exploration Rate = 0.1000, Train Count = 61870\n",
      "Episode 8322: Reward = 597.00, Steps = 3, Loss = 7.8525, Exploration Rate = 0.1000, Train Count = 61873\n",
      "Episode 8323: Reward = 582.00, Steps = 8, Loss = 7.4879, Exploration Rate = 0.1000, Train Count = 61881\n",
      "Episode 8324: Reward = 591.00, Steps = 5, Loss = 5.3710, Exploration Rate = 0.1000, Train Count = 61886\n",
      "Episode 8325: Reward = 585.00, Steps = 7, Loss = 6.4367, Exploration Rate = 0.1000, Train Count = 61893\n",
      "Episode 8326: Reward = 585.00, Steps = 7, Loss = 5.4622, Exploration Rate = 0.1000, Train Count = 61900\n",
      "Episode 8327: Reward = 588.00, Steps = 6, Loss = 3.6015, Exploration Rate = 0.1000, Train Count = 61906\n",
      "Episode 8328: Reward = 600.00, Steps = 2, Loss = 4.7093, Exploration Rate = 0.1000, Train Count = 61908\n",
      "Episode 8329: Reward = 582.00, Steps = 8, Loss = 4.5913, Exploration Rate = 0.1000, Train Count = 61916\n",
      "Episode 8330: Reward = 591.00, Steps = 5, Loss = 5.6309, Exploration Rate = 0.1000, Train Count = 61921\n",
      "Episode 8331: Reward = 588.00, Steps = 6, Loss = 5.9244, Exploration Rate = 0.1000, Train Count = 61927\n",
      "Episode 8332: Reward = 585.00, Steps = 7, Loss = 4.5684, Exploration Rate = 0.1000, Train Count = 61934\n",
      "Episode 8333: Reward = 576.00, Steps = 10, Loss = 5.9720, Exploration Rate = 0.1000, Train Count = 61944\n",
      "Episode 8334: Reward = 579.00, Steps = 9, Loss = 4.9415, Exploration Rate = 0.1000, Train Count = 61953\n",
      "Episode 8335: Reward = 594.00, Steps = 4, Loss = 5.3158, Exploration Rate = 0.1000, Train Count = 61957\n",
      "Episode 8336: Reward = 600.00, Steps = 2, Loss = 5.4402, Exploration Rate = 0.1000, Train Count = 61959\n",
      "Episode 8337: Reward = 588.00, Steps = 6, Loss = 8.1885, Exploration Rate = 0.1000, Train Count = 61965\n",
      "Episode 8338: Reward = 597.00, Steps = 3, Loss = 3.4305, Exploration Rate = 0.1000, Train Count = 61968\n",
      "Episode 8339: Reward = 585.00, Steps = 7, Loss = 3.9605, Exploration Rate = 0.1000, Train Count = 61975\n",
      "Episode 8340: Reward = 585.00, Steps = 7, Loss = 4.0469, Exploration Rate = 0.1000, Train Count = 61982\n",
      "Episode 8341: Reward = 594.00, Steps = 4, Loss = 4.2403, Exploration Rate = 0.1000, Train Count = 61986\n",
      "Episode 8342: Reward = 591.00, Steps = 5, Loss = 4.1202, Exploration Rate = 0.1000, Train Count = 61991\n",
      "Episode 8343: Reward = 588.00, Steps = 6, Loss = 5.1410, Exploration Rate = 0.1000, Train Count = 61997\n",
      "Episode 8344: Reward = 597.00, Steps = 3, Loss = 2.8247, Exploration Rate = 0.1000, Train Count = 62000\n",
      "Episode 8345: Reward = 597.00, Steps = 3, Loss = 2.4133, Exploration Rate = 0.1000, Train Count = 62003\n",
      "Episode 8346: Reward = 588.00, Steps = 6, Loss = 3.3490, Exploration Rate = 0.1000, Train Count = 62009\n",
      "Episode 8347: Reward = 585.00, Steps = 7, Loss = 3.7306, Exploration Rate = 0.1000, Train Count = 62016\n",
      "Episode 8348: Reward = 582.00, Steps = 8, Loss = 2.2131, Exploration Rate = 0.1000, Train Count = 62024\n",
      "Episode 8349: Reward = 594.00, Steps = 4, Loss = 3.5462, Exploration Rate = 0.1000, Train Count = 62028\n",
      "Episode 8350: Reward = 591.00, Steps = 5, Loss = 5.5687, Exploration Rate = 0.1000, Train Count = 62033\n",
      "Episode 8351: Reward = 576.00, Steps = 10, Loss = 4.3758, Exploration Rate = 0.1000, Train Count = 62043\n",
      "Episode 8352: Reward = 582.00, Steps = 8, Loss = 3.8585, Exploration Rate = 0.1000, Train Count = 62051\n",
      "Episode 8353: Reward = 597.00, Steps = 3, Loss = 4.1104, Exploration Rate = 0.1000, Train Count = 62054\n",
      "Episode 8354: Reward = 600.00, Steps = 2, Loss = 7.9777, Exploration Rate = 0.1000, Train Count = 62056\n",
      "Episode 8355: Reward = 573.00, Steps = 11, Loss = 4.3012, Exploration Rate = 0.1000, Train Count = 62067\n",
      "Episode 8356: Reward = 585.00, Steps = 7, Loss = 4.6189, Exploration Rate = 0.1000, Train Count = 62074\n",
      "Episode 8357: Reward = 582.00, Steps = 8, Loss = 4.8598, Exploration Rate = 0.1000, Train Count = 62082\n",
      "Episode 8358: Reward = 579.00, Steps = 9, Loss = 3.5577, Exploration Rate = 0.1000, Train Count = 62091\n",
      "Episode 8359: Reward = 594.00, Steps = 4, Loss = 4.7840, Exploration Rate = 0.1000, Train Count = 62095\n",
      "Episode 8360: Reward = 594.00, Steps = 4, Loss = 4.1218, Exploration Rate = 0.1000, Train Count = 62099\n",
      "Episode 8361: Reward = 591.00, Steps = 5, Loss = 2.3892, Exploration Rate = 0.1000, Train Count = 62104\n",
      "Episode 8362: Reward = 588.00, Steps = 6, Loss = 2.5326, Exploration Rate = 0.1000, Train Count = 62110\n",
      "Episode 8363: Reward = 579.00, Steps = 9, Loss = 3.2477, Exploration Rate = 0.1000, Train Count = 62119\n",
      "Episode 8364: Reward = 585.00, Steps = 7, Loss = 3.1442, Exploration Rate = 0.1000, Train Count = 62126\n",
      "Episode 8365: Reward = 591.00, Steps = 5, Loss = 3.2115, Exploration Rate = 0.1000, Train Count = 62131\n",
      "Episode 8366: Reward = 585.00, Steps = 7, Loss = 3.7524, Exploration Rate = 0.1000, Train Count = 62138\n",
      "Episode 8367: Reward = 591.00, Steps = 5, Loss = 5.7149, Exploration Rate = 0.1000, Train Count = 62143\n",
      "Episode 8368: Reward = 585.00, Steps = 7, Loss = 4.8581, Exploration Rate = 0.1000, Train Count = 62150\n",
      "Episode 8369: Reward = 582.00, Steps = 8, Loss = 3.3815, Exploration Rate = 0.1000, Train Count = 62158\n",
      "Episode 8370: Reward = 585.00, Steps = 7, Loss = 9.1319, Exploration Rate = 0.1000, Train Count = 62165\n",
      "Episode 8371: Reward = 591.00, Steps = 5, Loss = 13.2297, Exploration Rate = 0.1000, Train Count = 62170\n",
      "Episode 8372: Reward = 588.00, Steps = 6, Loss = 5.2697, Exploration Rate = 0.1000, Train Count = 62176\n",
      "Episode 8373: Reward = 588.00, Steps = 6, Loss = 7.6500, Exploration Rate = 0.1000, Train Count = 62182\n",
      "Episode 8374: Reward = 597.00, Steps = 3, Loss = 6.0438, Exploration Rate = 0.1000, Train Count = 62185\n",
      "Episode 8375: Reward = 588.00, Steps = 6, Loss = 6.5244, Exploration Rate = 0.1000, Train Count = 62191\n",
      "Episode 8376: Reward = 576.00, Steps = 10, Loss = 11.5886, Exploration Rate = 0.1000, Train Count = 62201\n",
      "Episode 8377: Reward = 588.00, Steps = 6, Loss = 7.4036, Exploration Rate = 0.1000, Train Count = 62207\n",
      "Episode 8378: Reward = 538.00, Steps = 7, Loss = 5.1292, Exploration Rate = 0.1000, Train Count = 62214\n",
      "Episode 8379: Reward = 579.00, Steps = 9, Loss = 7.5439, Exploration Rate = 0.1000, Train Count = 62223\n",
      "Episode 8380: Reward = 585.00, Steps = 7, Loss = 5.0511, Exploration Rate = 0.1000, Train Count = 62230\n",
      "Episode 8381: Reward = 579.00, Steps = 9, Loss = 3.7857, Exploration Rate = 0.1000, Train Count = 62239\n",
      "Episode 8382: Reward = 591.00, Steps = 5, Loss = 3.5798, Exploration Rate = 0.1000, Train Count = 62244\n",
      "Episode 8383: Reward = 588.00, Steps = 6, Loss = 2.1862, Exploration Rate = 0.1000, Train Count = 62250\n",
      "Episode 8384: Reward = 585.00, Steps = 7, Loss = 2.6236, Exploration Rate = 0.1000, Train Count = 62257\n",
      "Episode 8385: Reward = 591.00, Steps = 5, Loss = 1.7151, Exploration Rate = 0.1000, Train Count = 62262\n",
      "Episode 8386: Reward = 588.00, Steps = 6, Loss = 1.1641, Exploration Rate = 0.1000, Train Count = 62268\n",
      "Episode 8387: Reward = 597.00, Steps = 3, Loss = 2.5911, Exploration Rate = 0.1000, Train Count = 62271\n",
      "Episode 8388: Reward = 538.00, Steps = 7, Loss = 1.8656, Exploration Rate = 0.1000, Train Count = 62278\n",
      "Episode 8389: Reward = 594.00, Steps = 4, Loss = 4.7937, Exploration Rate = 0.1000, Train Count = 62282\n",
      "Episode 8390: Reward = 591.00, Steps = 5, Loss = 1.9005, Exploration Rate = 0.1000, Train Count = 62287\n",
      "Episode 8391: Reward = 594.00, Steps = 4, Loss = 4.7187, Exploration Rate = 0.1000, Train Count = 62291\n",
      "Episode 8392: Reward = 597.00, Steps = 3, Loss = 2.1795, Exploration Rate = 0.1000, Train Count = 62294\n",
      "Episode 8393: Reward = 588.00, Steps = 6, Loss = 4.0268, Exploration Rate = 0.1000, Train Count = 62300\n",
      "Episode 8394: Reward = 535.00, Steps = 8, Loss = 24.8300, Exploration Rate = 0.1000, Train Count = 62308\n",
      "Episode 8395: Reward = 600.00, Steps = 2, Loss = 19.1831, Exploration Rate = 0.1000, Train Count = 62310\n",
      "Episode 8396: Reward = 582.00, Steps = 8, Loss = 14.8288, Exploration Rate = 0.1000, Train Count = 62318\n",
      "Episode 8397: Reward = 597.00, Steps = 3, Loss = 9.9415, Exploration Rate = 0.1000, Train Count = 62321\n",
      "Episode 8398: Reward = 585.00, Steps = 7, Loss = 13.5246, Exploration Rate = 0.1000, Train Count = 62328\n",
      "Episode 8399: Reward = 597.00, Steps = 3, Loss = 9.8587, Exploration Rate = 0.1000, Train Count = 62331\n",
      "Episode 8400: Reward = 591.00, Steps = 5, Loss = 13.1464, Exploration Rate = 0.1000, Train Count = 62336\n",
      "Episode 8401: Reward = 588.00, Steps = 6, Loss = 7.6285, Exploration Rate = 0.1000, Train Count = 62342\n",
      "Episode 8402: Reward = 594.00, Steps = 4, Loss = 9.6359, Exploration Rate = 0.1000, Train Count = 62346\n",
      "Episode 8403: Reward = 585.00, Steps = 7, Loss = 6.5137, Exploration Rate = 0.1000, Train Count = 62353\n",
      "Episode 8404: Reward = 594.00, Steps = 4, Loss = 5.2647, Exploration Rate = 0.1000, Train Count = 62357\n",
      "Episode 8405: Reward = 532.00, Steps = 9, Loss = 5.8982, Exploration Rate = 0.1000, Train Count = 62366\n",
      "Episode 8406: Reward = 585.00, Steps = 7, Loss = 3.9474, Exploration Rate = 0.1000, Train Count = 62373\n",
      "Episode 8407: Reward = 591.00, Steps = 5, Loss = 4.6066, Exploration Rate = 0.1000, Train Count = 62378\n",
      "Episode 8408: Reward = 588.00, Steps = 6, Loss = 2.6866, Exploration Rate = 0.1000, Train Count = 62384\n",
      "Episode 8409: Reward = 594.00, Steps = 4, Loss = 2.4394, Exploration Rate = 0.1000, Train Count = 62388\n",
      "Episode 8410: Reward = 588.00, Steps = 6, Loss = 4.6458, Exploration Rate = 0.1000, Train Count = 62394\n",
      "Episode 8411: Reward = 591.00, Steps = 5, Loss = 2.8884, Exploration Rate = 0.1000, Train Count = 62399\n",
      "Episode 8412: Reward = 588.00, Steps = 6, Loss = 4.8871, Exploration Rate = 0.1000, Train Count = 62405\n",
      "Episode 8413: Reward = 591.00, Steps = 5, Loss = 5.5354, Exploration Rate = 0.1000, Train Count = 62410\n",
      "Episode 8414: Reward = 588.00, Steps = 6, Loss = 3.9920, Exploration Rate = 0.1000, Train Count = 62416\n",
      "Episode 8415: Reward = 600.00, Steps = 2, Loss = 3.9652, Exploration Rate = 0.1000, Train Count = 62418\n",
      "Episode 8416: Reward = 582.00, Steps = 8, Loss = 5.1796, Exploration Rate = 0.1000, Train Count = 62426\n",
      "Episode 8417: Reward = 594.00, Steps = 4, Loss = 5.3216, Exploration Rate = 0.1000, Train Count = 62430\n",
      "Episode 8418: Reward = 579.00, Steps = 9, Loss = 3.4585, Exploration Rate = 0.1000, Train Count = 62439\n",
      "Episode 8419: Reward = 579.00, Steps = 9, Loss = 5.3066, Exploration Rate = 0.1000, Train Count = 62448\n",
      "Episode 8420: Reward = 582.00, Steps = 8, Loss = 6.2945, Exploration Rate = 0.1000, Train Count = 62456\n",
      "Episode 8421: Reward = 588.00, Steps = 6, Loss = 5.5062, Exploration Rate = 0.1000, Train Count = 62462\n",
      "Episode 8422: Reward = 591.00, Steps = 5, Loss = 3.1418, Exploration Rate = 0.1000, Train Count = 62467\n",
      "Episode 8423: Reward = 597.00, Steps = 3, Loss = 2.3748, Exploration Rate = 0.1000, Train Count = 62470\n",
      "Episode 8424: Reward = 591.00, Steps = 5, Loss = 3.1376, Exploration Rate = 0.1000, Train Count = 62475\n",
      "Episode 8425: Reward = 591.00, Steps = 5, Loss = 2.0453, Exploration Rate = 0.1000, Train Count = 62480\n",
      "Episode 8426: Reward = 579.00, Steps = 9, Loss = 2.6449, Exploration Rate = 0.1000, Train Count = 62489\n",
      "Episode 8427: Reward = 588.00, Steps = 6, Loss = 1.9233, Exploration Rate = 0.1000, Train Count = 62495\n",
      "Episode 8428: Reward = 585.00, Steps = 7, Loss = 3.8047, Exploration Rate = 0.1000, Train Count = 62502\n",
      "Episode 8429: Reward = 594.00, Steps = 4, Loss = 4.4251, Exploration Rate = 0.1000, Train Count = 62506\n",
      "Episode 8430: Reward = 591.00, Steps = 5, Loss = 5.4479, Exploration Rate = 0.1000, Train Count = 62511\n",
      "Episode 8431: Reward = 588.00, Steps = 6, Loss = 5.6224, Exploration Rate = 0.1000, Train Count = 62517\n",
      "Episode 8432: Reward = 588.00, Steps = 6, Loss = 4.0666, Exploration Rate = 0.1000, Train Count = 62523\n",
      "Episode 8433: Reward = 588.00, Steps = 6, Loss = 4.8028, Exploration Rate = 0.1000, Train Count = 62529\n",
      "Episode 8434: Reward = 588.00, Steps = 6, Loss = 5.5469, Exploration Rate = 0.1000, Train Count = 62535\n",
      "Episode 8435: Reward = 591.00, Steps = 5, Loss = 4.2853, Exploration Rate = 0.1000, Train Count = 62540\n",
      "Episode 8436: Reward = 594.00, Steps = 4, Loss = 4.8220, Exploration Rate = 0.1000, Train Count = 62544\n",
      "Episode 8437: Reward = 582.00, Steps = 8, Loss = 3.9375, Exploration Rate = 0.1000, Train Count = 62552\n",
      "Episode 8438: Reward = 585.00, Steps = 7, Loss = 4.7454, Exploration Rate = 0.1000, Train Count = 62559\n",
      "Episode 8439: Reward = 585.00, Steps = 7, Loss = 4.6738, Exploration Rate = 0.1000, Train Count = 62566\n",
      "Episode 8440: Reward = 594.00, Steps = 4, Loss = 2.8700, Exploration Rate = 0.1000, Train Count = 62570\n",
      "Episode 8441: Reward = 588.00, Steps = 6, Loss = 4.9625, Exploration Rate = 0.1000, Train Count = 62576\n",
      "Episode 8442: Reward = 597.00, Steps = 3, Loss = 4.2112, Exploration Rate = 0.1000, Train Count = 62579\n",
      "Episode 8443: Reward = 594.00, Steps = 4, Loss = 3.3910, Exploration Rate = 0.1000, Train Count = 62583\n",
      "Episode 8444: Reward = 582.00, Steps = 8, Loss = 2.9641, Exploration Rate = 0.1000, Train Count = 62591\n",
      "Episode 8445: Reward = 585.00, Steps = 7, Loss = 4.5341, Exploration Rate = 0.1000, Train Count = 62598\n",
      "Episode 8446: Reward = 582.00, Steps = 8, Loss = 4.5014, Exploration Rate = 0.1000, Train Count = 62606\n",
      "Episode 8447: Reward = 544.00, Steps = 5, Loss = 4.9801, Exploration Rate = 0.1000, Train Count = 62611\n",
      "Episode 8448: Reward = 591.00, Steps = 5, Loss = 8.3733, Exploration Rate = 0.1000, Train Count = 62616\n",
      "Episode 8449: Reward = 594.00, Steps = 4, Loss = 6.3717, Exploration Rate = 0.1000, Train Count = 62620\n",
      "Episode 8450: Reward = 588.00, Steps = 6, Loss = 5.3747, Exploration Rate = 0.1000, Train Count = 62626\n",
      "Episode 8451: Reward = 538.00, Steps = 7, Loss = 4.0970, Exploration Rate = 0.1000, Train Count = 62633\n",
      "Episode 8452: Reward = 576.00, Steps = 10, Loss = 7.3390, Exploration Rate = 0.1000, Train Count = 62643\n",
      "Episode 8453: Reward = 585.00, Steps = 7, Loss = 5.3448, Exploration Rate = 0.1000, Train Count = 62650\n",
      "Episode 8454: Reward = 594.00, Steps = 4, Loss = 7.4176, Exploration Rate = 0.1000, Train Count = 62654\n",
      "Episode 8455: Reward = 591.00, Steps = 5, Loss = 4.6917, Exploration Rate = 0.1000, Train Count = 62659\n",
      "Episode 8456: Reward = 591.00, Steps = 5, Loss = 6.3012, Exploration Rate = 0.1000, Train Count = 62664\n",
      "Episode 8457: Reward = 594.00, Steps = 4, Loss = 7.5593, Exploration Rate = 0.1000, Train Count = 62668\n",
      "Episode 8458: Reward = 597.00, Steps = 3, Loss = 4.7517, Exploration Rate = 0.1000, Train Count = 62671\n",
      "Episode 8459: Reward = 582.00, Steps = 8, Loss = 5.6139, Exploration Rate = 0.1000, Train Count = 62679\n",
      "Episode 8460: Reward = 591.00, Steps = 5, Loss = 5.0339, Exploration Rate = 0.1000, Train Count = 62684\n",
      "Episode 8461: Reward = 591.00, Steps = 5, Loss = 7.5812, Exploration Rate = 0.1000, Train Count = 62689\n",
      "Episode 8462: Reward = 588.00, Steps = 6, Loss = 3.3505, Exploration Rate = 0.1000, Train Count = 62695\n",
      "Episode 8463: Reward = 591.00, Steps = 5, Loss = 2.4378, Exploration Rate = 0.1000, Train Count = 62700\n",
      "Episode 8464: Reward = 573.00, Steps = 11, Loss = 2.9465, Exploration Rate = 0.1000, Train Count = 62711\n",
      "Episode 8465: Reward = 594.00, Steps = 4, Loss = 5.1484, Exploration Rate = 0.1000, Train Count = 62715\n",
      "Episode 8466: Reward = 585.00, Steps = 7, Loss = 3.3792, Exploration Rate = 0.1000, Train Count = 62722\n",
      "Episode 8467: Reward = 585.00, Steps = 7, Loss = 3.3376, Exploration Rate = 0.1000, Train Count = 62729\n",
      "Episode 8468: Reward = 597.00, Steps = 3, Loss = 2.5753, Exploration Rate = 0.1000, Train Count = 62732\n",
      "Episode 8469: Reward = 591.00, Steps = 5, Loss = 3.3250, Exploration Rate = 0.1000, Train Count = 62737\n",
      "Episode 8470: Reward = 588.00, Steps = 6, Loss = 3.6730, Exploration Rate = 0.1000, Train Count = 62743\n",
      "Episode 8471: Reward = 538.00, Steps = 7, Loss = 8.6450, Exploration Rate = 0.1000, Train Count = 62750\n",
      "Episode 8472: Reward = 582.00, Steps = 8, Loss = 4.6306, Exploration Rate = 0.1000, Train Count = 62758\n",
      "Episode 8473: Reward = 591.00, Steps = 5, Loss = 2.6315, Exploration Rate = 0.1000, Train Count = 62763\n",
      "Episode 8474: Reward = 585.00, Steps = 7, Loss = 4.9859, Exploration Rate = 0.1000, Train Count = 62770\n",
      "Episode 8475: Reward = 579.00, Steps = 9, Loss = 3.6571, Exploration Rate = 0.1000, Train Count = 62779\n",
      "Episode 8476: Reward = 597.00, Steps = 3, Loss = 7.7039, Exploration Rate = 0.1000, Train Count = 62782\n",
      "Episode 8477: Reward = 597.00, Steps = 3, Loss = 2.2295, Exploration Rate = 0.1000, Train Count = 62785\n",
      "Episode 8478: Reward = 579.00, Steps = 9, Loss = 3.0975, Exploration Rate = 0.1000, Train Count = 62794\n",
      "Episode 8479: Reward = 488.00, Steps = 8, Loss = 7.0329, Exploration Rate = 0.1000, Train Count = 62802\n",
      "Episode 8480: Reward = 597.00, Steps = 3, Loss = 30.3258, Exploration Rate = 0.1000, Train Count = 62805\n",
      "Episode 8481: Reward = 591.00, Steps = 5, Loss = 22.3637, Exploration Rate = 0.1000, Train Count = 62810\n",
      "Episode 8482: Reward = 591.00, Steps = 5, Loss = 17.6470, Exploration Rate = 0.1000, Train Count = 62815\n",
      "Episode 8483: Reward = 594.00, Steps = 4, Loss = 14.9054, Exploration Rate = 0.1000, Train Count = 62819\n",
      "Episode 8484: Reward = 582.00, Steps = 8, Loss = 13.3593, Exploration Rate = 0.1000, Train Count = 62827\n",
      "Episode 8485: Reward = 594.00, Steps = 4, Loss = 8.6689, Exploration Rate = 0.1000, Train Count = 62831\n",
      "Episode 8486: Reward = 594.00, Steps = 4, Loss = 7.8958, Exploration Rate = 0.1000, Train Count = 62835\n",
      "Episode 8487: Reward = 597.00, Steps = 3, Loss = 7.6992, Exploration Rate = 0.1000, Train Count = 62838\n",
      "Episode 8488: Reward = 588.00, Steps = 6, Loss = 8.8621, Exploration Rate = 0.1000, Train Count = 62844\n",
      "Episode 8489: Reward = 585.00, Steps = 7, Loss = 11.4789, Exploration Rate = 0.1000, Train Count = 62851\n",
      "Episode 8490: Reward = 594.00, Steps = 4, Loss = 9.0328, Exploration Rate = 0.1000, Train Count = 62855\n",
      "Episode 8491: Reward = 597.00, Steps = 3, Loss = 9.2377, Exploration Rate = 0.1000, Train Count = 62858\n",
      "Episode 8492: Reward = 582.00, Steps = 8, Loss = 10.8003, Exploration Rate = 0.1000, Train Count = 62866\n",
      "Episode 8493: Reward = 594.00, Steps = 4, Loss = 10.5784, Exploration Rate = 0.1000, Train Count = 62870\n",
      "Episode 8494: Reward = 597.00, Steps = 3, Loss = 6.1309, Exploration Rate = 0.1000, Train Count = 62873\n",
      "Episode 8495: Reward = 588.00, Steps = 6, Loss = 6.3157, Exploration Rate = 0.1000, Train Count = 62879\n",
      "Episode 8496: Reward = 591.00, Steps = 5, Loss = 6.9757, Exploration Rate = 0.1000, Train Count = 62884\n",
      "Episode 8497: Reward = 582.00, Steps = 8, Loss = 7.2180, Exploration Rate = 0.1000, Train Count = 62892\n",
      "Episode 8498: Reward = 579.00, Steps = 9, Loss = 10.8730, Exploration Rate = 0.1000, Train Count = 62901\n",
      "Episode 8499: Reward = 585.00, Steps = 7, Loss = 10.0617, Exploration Rate = 0.1000, Train Count = 62908\n",
      "Episode 8500: Reward = 585.00, Steps = 7, Loss = 9.7469, Exploration Rate = 0.1000, Train Count = 62915\n",
      "Episode 8501: Reward = 597.00, Steps = 3, Loss = 7.0152, Exploration Rate = 0.1000, Train Count = 62918\n",
      "Episode 8502: Reward = 600.00, Steps = 2, Loss = 5.2872, Exploration Rate = 0.1000, Train Count = 62920\n",
      "Episode 8503: Reward = 591.00, Steps = 5, Loss = 6.5384, Exploration Rate = 0.1000, Train Count = 62925\n",
      "Episode 8504: Reward = 588.00, Steps = 6, Loss = 5.6796, Exploration Rate = 0.1000, Train Count = 62931\n",
      "Episode 8505: Reward = 594.00, Steps = 4, Loss = 7.7068, Exploration Rate = 0.1000, Train Count = 62935\n",
      "Episode 8506: Reward = 582.00, Steps = 8, Loss = 4.9517, Exploration Rate = 0.1000, Train Count = 62943\n",
      "Episode 8507: Reward = 600.00, Steps = 2, Loss = 4.8362, Exploration Rate = 0.1000, Train Count = 62945\n",
      "Episode 8508: Reward = 585.00, Steps = 7, Loss = 6.0821, Exploration Rate = 0.1000, Train Count = 62952\n",
      "Episode 8509: Reward = 585.00, Steps = 7, Loss = 6.4934, Exploration Rate = 0.1000, Train Count = 62959\n",
      "Episode 8510: Reward = 591.00, Steps = 5, Loss = 7.3496, Exploration Rate = 0.1000, Train Count = 62964\n",
      "Episode 8511: Reward = 588.00, Steps = 6, Loss = 6.8013, Exploration Rate = 0.1000, Train Count = 62970\n",
      "Episode 8512: Reward = 594.00, Steps = 4, Loss = 3.4628, Exploration Rate = 0.1000, Train Count = 62974\n",
      "Episode 8513: Reward = 585.00, Steps = 7, Loss = 5.6261, Exploration Rate = 0.1000, Train Count = 62981\n",
      "Episode 8514: Reward = 579.00, Steps = 9, Loss = 10.0643, Exploration Rate = 0.1000, Train Count = 62990\n",
      "Episode 8515: Reward = 600.00, Steps = 2, Loss = 11.4359, Exploration Rate = 0.1000, Train Count = 62992\n",
      "Episode 8516: Reward = 594.00, Steps = 4, Loss = 4.9626, Exploration Rate = 0.1000, Train Count = 62996\n",
      "Episode 8517: Reward = 591.00, Steps = 5, Loss = 5.5147, Exploration Rate = 0.1000, Train Count = 63001\n",
      "Episode 8518: Reward = 579.00, Steps = 9, Loss = 6.2180, Exploration Rate = 0.1000, Train Count = 63010\n",
      "Episode 8519: Reward = 588.00, Steps = 6, Loss = 8.6895, Exploration Rate = 0.1000, Train Count = 63016\n",
      "Episode 8520: Reward = 576.00, Steps = 10, Loss = 11.4030, Exploration Rate = 0.1000, Train Count = 63026\n",
      "Episode 8521: Reward = 588.00, Steps = 6, Loss = 10.1003, Exploration Rate = 0.1000, Train Count = 63032\n",
      "Episode 8522: Reward = 585.00, Steps = 7, Loss = 7.3153, Exploration Rate = 0.1000, Train Count = 63039\n",
      "Episode 8523: Reward = 594.00, Steps = 4, Loss = 6.7932, Exploration Rate = 0.1000, Train Count = 63043\n",
      "Episode 8524: Reward = 597.00, Steps = 3, Loss = 9.1547, Exploration Rate = 0.1000, Train Count = 63046\n",
      "Episode 8525: Reward = 585.00, Steps = 7, Loss = 4.7705, Exploration Rate = 0.1000, Train Count = 63053\n",
      "Episode 8526: Reward = 594.00, Steps = 4, Loss = 5.8144, Exploration Rate = 0.1000, Train Count = 63057\n",
      "Episode 8527: Reward = 588.00, Steps = 6, Loss = 3.7823, Exploration Rate = 0.1000, Train Count = 63063\n",
      "Episode 8528: Reward = 582.00, Steps = 8, Loss = 4.7175, Exploration Rate = 0.1000, Train Count = 63071\n",
      "Episode 8529: Reward = 579.00, Steps = 9, Loss = 4.0540, Exploration Rate = 0.1000, Train Count = 63080\n",
      "Episode 8530: Reward = 591.00, Steps = 5, Loss = 3.2219, Exploration Rate = 0.1000, Train Count = 63085\n",
      "Episode 8531: Reward = 585.00, Steps = 7, Loss = 4.4498, Exploration Rate = 0.1000, Train Count = 63092\n",
      "Episode 8532: Reward = 485.00, Steps = 9, Loss = 4.8282, Exploration Rate = 0.1000, Train Count = 63101\n",
      "Episode 8533: Reward = 585.00, Steps = 7, Loss = 3.0885, Exploration Rate = 0.1000, Train Count = 63108\n",
      "Episode 8534: Reward = 588.00, Steps = 6, Loss = 3.9503, Exploration Rate = 0.1000, Train Count = 63114\n",
      "Episode 8535: Reward = 582.00, Steps = 8, Loss = 2.4516, Exploration Rate = 0.1000, Train Count = 63122\n",
      "Episode 8536: Reward = 591.00, Steps = 5, Loss = 5.0224, Exploration Rate = 0.1000, Train Count = 63127\n",
      "Episode 8537: Reward = 535.00, Steps = 8, Loss = 4.3069, Exploration Rate = 0.1000, Train Count = 63135\n",
      "Episode 8538: Reward = 579.00, Steps = 9, Loss = 5.9591, Exploration Rate = 0.1000, Train Count = 63144\n",
      "Episode 8539: Reward = 591.00, Steps = 5, Loss = 6.0052, Exploration Rate = 0.1000, Train Count = 63149\n",
      "Episode 8540: Reward = 585.00, Steps = 7, Loss = 4.0121, Exploration Rate = 0.1000, Train Count = 63156\n",
      "Episode 8541: Reward = 579.00, Steps = 9, Loss = 5.4878, Exploration Rate = 0.1000, Train Count = 63165\n",
      "Episode 8542: Reward = 588.00, Steps = 6, Loss = 7.7355, Exploration Rate = 0.1000, Train Count = 63171\n",
      "Episode 8543: Reward = 538.00, Steps = 7, Loss = 5.5805, Exploration Rate = 0.1000, Train Count = 63178\n",
      "Episode 8544: Reward = 582.00, Steps = 8, Loss = 6.7375, Exploration Rate = 0.1000, Train Count = 63186\n",
      "Episode 8545: Reward = 588.00, Steps = 6, Loss = 6.8726, Exploration Rate = 0.1000, Train Count = 63192\n",
      "Episode 8546: Reward = 588.00, Steps = 6, Loss = 4.4898, Exploration Rate = 0.1000, Train Count = 63198\n",
      "Episode 8547: Reward = 594.00, Steps = 4, Loss = 4.9848, Exploration Rate = 0.1000, Train Count = 63202\n",
      "Episode 8548: Reward = 591.00, Steps = 5, Loss = 4.5294, Exploration Rate = 0.1000, Train Count = 63207\n",
      "Episode 8549: Reward = 594.00, Steps = 4, Loss = 5.3186, Exploration Rate = 0.1000, Train Count = 63211\n",
      "Episode 8550: Reward = 582.00, Steps = 8, Loss = 3.4783, Exploration Rate = 0.1000, Train Count = 63219\n",
      "Episode 8551: Reward = 591.00, Steps = 5, Loss = 3.1307, Exploration Rate = 0.1000, Train Count = 63224\n",
      "Episode 8552: Reward = 582.00, Steps = 8, Loss = 4.0153, Exploration Rate = 0.1000, Train Count = 63232\n",
      "Episode 8553: Reward = 576.00, Steps = 10, Loss = 4.8527, Exploration Rate = 0.1000, Train Count = 63242\n",
      "Episode 8554: Reward = 570.00, Steps = 12, Loss = 3.0208, Exploration Rate = 0.1000, Train Count = 63254\n",
      "Episode 8555: Reward = 535.00, Steps = 8, Loss = 6.0447, Exploration Rate = 0.1000, Train Count = 63262\n",
      "Episode 8556: Reward = 591.00, Steps = 5, Loss = 6.9735, Exploration Rate = 0.1000, Train Count = 63267\n",
      "Episode 8557: Reward = 591.00, Steps = 5, Loss = 6.7670, Exploration Rate = 0.1000, Train Count = 63272\n",
      "Episode 8558: Reward = 594.00, Steps = 4, Loss = 8.8774, Exploration Rate = 0.1000, Train Count = 63276\n",
      "Episode 8559: Reward = 573.00, Steps = 11, Loss = 9.8576, Exploration Rate = 0.1000, Train Count = 63287\n",
      "Episode 8560: Reward = 591.00, Steps = 5, Loss = 7.8881, Exploration Rate = 0.1000, Train Count = 63292\n",
      "Episode 8561: Reward = 591.00, Steps = 5, Loss = 7.5932, Exploration Rate = 0.1000, Train Count = 63297\n",
      "Episode 8562: Reward = 591.00, Steps = 5, Loss = 13.4944, Exploration Rate = 0.1000, Train Count = 63302\n",
      "Episode 8563: Reward = 564.00, Steps = 14, Loss = 17.1449, Exploration Rate = 0.1000, Train Count = 63316\n",
      "Episode 8564: Reward = 591.00, Steps = 5, Loss = 9.7408, Exploration Rate = 0.1000, Train Count = 63321\n",
      "Episode 8565: Reward = 579.00, Steps = 9, Loss = 10.1046, Exploration Rate = 0.1000, Train Count = 63330\n",
      "Episode 8566: Reward = 594.00, Steps = 4, Loss = 7.5192, Exploration Rate = 0.1000, Train Count = 63334\n",
      "Episode 8567: Reward = 588.00, Steps = 6, Loss = 8.0389, Exploration Rate = 0.1000, Train Count = 63340\n",
      "Episode 8568: Reward = 579.00, Steps = 9, Loss = 7.2948, Exploration Rate = 0.1000, Train Count = 63349\n",
      "Episode 8569: Reward = 579.00, Steps = 9, Loss = 5.9486, Exploration Rate = 0.1000, Train Count = 63358\n",
      "Episode 8570: Reward = 579.00, Steps = 9, Loss = 4.5154, Exploration Rate = 0.1000, Train Count = 63367\n",
      "Episode 8571: Reward = 585.00, Steps = 7, Loss = 5.9482, Exploration Rate = 0.1000, Train Count = 63374\n",
      "Episode 8572: Reward = 594.00, Steps = 4, Loss = 4.9928, Exploration Rate = 0.1000, Train Count = 63378\n",
      "Episode 8573: Reward = 591.00, Steps = 5, Loss = 4.0912, Exploration Rate = 0.1000, Train Count = 63383\n",
      "Episode 8574: Reward = 585.00, Steps = 7, Loss = 1.9796, Exploration Rate = 0.1000, Train Count = 63390\n",
      "Episode 8575: Reward = 532.00, Steps = 9, Loss = 2.1051, Exploration Rate = 0.1000, Train Count = 63399\n",
      "Episode 8576: Reward = 579.00, Steps = 9, Loss = 2.4935, Exploration Rate = 0.1000, Train Count = 63408\n",
      "Episode 8577: Reward = 573.00, Steps = 11, Loss = 5.0902, Exploration Rate = 0.1000, Train Count = 63419\n",
      "Episode 8578: Reward = 582.00, Steps = 8, Loss = 2.7779, Exploration Rate = 0.1000, Train Count = 63427\n",
      "Episode 8579: Reward = 585.00, Steps = 7, Loss = 3.0186, Exploration Rate = 0.1000, Train Count = 63434\n",
      "Episode 8580: Reward = 588.00, Steps = 6, Loss = 4.2800, Exploration Rate = 0.1000, Train Count = 63440\n",
      "Episode 8581: Reward = 585.00, Steps = 7, Loss = 2.9362, Exploration Rate = 0.1000, Train Count = 63447\n",
      "Episode 8582: Reward = 597.00, Steps = 3, Loss = 1.8305, Exploration Rate = 0.1000, Train Count = 63450\n",
      "Episode 8583: Reward = 535.00, Steps = 8, Loss = 5.6536, Exploration Rate = 0.1000, Train Count = 63458\n",
      "Episode 8584: Reward = 535.00, Steps = 8, Loss = 6.0407, Exploration Rate = 0.1000, Train Count = 63466\n",
      "Episode 8585: Reward = 597.00, Steps = 3, Loss = 6.9759, Exploration Rate = 0.1000, Train Count = 63469\n",
      "Episode 8586: Reward = 585.00, Steps = 7, Loss = 4.5575, Exploration Rate = 0.1000, Train Count = 63476\n",
      "Episode 8587: Reward = 591.00, Steps = 5, Loss = 3.7455, Exploration Rate = 0.1000, Train Count = 63481\n",
      "Episode 8588: Reward = 600.00, Steps = 2, Loss = 6.8873, Exploration Rate = 0.1000, Train Count = 63483\n",
      "Episode 8589: Reward = 585.00, Steps = 7, Loss = 4.6474, Exploration Rate = 0.1000, Train Count = 63490\n",
      "Episode 8590: Reward = 579.00, Steps = 9, Loss = 4.3177, Exploration Rate = 0.1000, Train Count = 63499\n",
      "Episode 8591: Reward = 582.00, Steps = 8, Loss = 5.9410, Exploration Rate = 0.1000, Train Count = 63507\n",
      "Episode 8592: Reward = 544.00, Steps = 5, Loss = 5.5174, Exploration Rate = 0.1000, Train Count = 63512\n",
      "Episode 8593: Reward = 585.00, Steps = 7, Loss = 4.1906, Exploration Rate = 0.1000, Train Count = 63519\n",
      "Episode 8594: Reward = 597.00, Steps = 3, Loss = 5.1255, Exploration Rate = 0.1000, Train Count = 63522\n",
      "Episode 8595: Reward = 570.00, Steps = 12, Loss = 5.6468, Exploration Rate = 0.1000, Train Count = 63534\n",
      "Episode 8596: Reward = 591.00, Steps = 5, Loss = 4.8756, Exploration Rate = 0.1000, Train Count = 63539\n",
      "Episode 8597: Reward = 585.00, Steps = 7, Loss = 4.8905, Exploration Rate = 0.1000, Train Count = 63546\n",
      "Episode 8598: Reward = 594.00, Steps = 4, Loss = 3.5083, Exploration Rate = 0.1000, Train Count = 63550\n",
      "Episode 8599: Reward = 591.00, Steps = 5, Loss = 4.4091, Exploration Rate = 0.1000, Train Count = 63555\n",
      "Episode 8600: Reward = 582.00, Steps = 8, Loss = 3.4532, Exploration Rate = 0.1000, Train Count = 63563\n",
      "Episode 8601: Reward = 573.00, Steps = 11, Loss = 4.1056, Exploration Rate = 0.1000, Train Count = 63574\n",
      "Episode 8602: Reward = 591.00, Steps = 5, Loss = 3.4814, Exploration Rate = 0.1000, Train Count = 63579\n",
      "Episode 8603: Reward = 597.00, Steps = 3, Loss = 6.5474, Exploration Rate = 0.1000, Train Count = 63582\n",
      "Episode 8604: Reward = 597.00, Steps = 3, Loss = 1.8124, Exploration Rate = 0.1000, Train Count = 63585\n",
      "Episode 8605: Reward = 588.00, Steps = 6, Loss = 4.1208, Exploration Rate = 0.1000, Train Count = 63591\n",
      "Episode 8606: Reward = 588.00, Steps = 6, Loss = 3.6514, Exploration Rate = 0.1000, Train Count = 63597\n",
      "Episode 8607: Reward = 594.00, Steps = 4, Loss = 3.5149, Exploration Rate = 0.1000, Train Count = 63601\n",
      "Episode 8608: Reward = 594.00, Steps = 4, Loss = 3.3758, Exploration Rate = 0.1000, Train Count = 63605\n",
      "Episode 8609: Reward = 600.00, Steps = 2, Loss = 1.7107, Exploration Rate = 0.1000, Train Count = 63607\n",
      "Episode 8610: Reward = 591.00, Steps = 5, Loss = 5.4870, Exploration Rate = 0.1000, Train Count = 63612\n",
      "Episode 8611: Reward = 591.00, Steps = 5, Loss = 3.0868, Exploration Rate = 0.1000, Train Count = 63617\n",
      "Episode 8612: Reward = 597.00, Steps = 3, Loss = 4.2580, Exploration Rate = 0.1000, Train Count = 63620\n",
      "Episode 8613: Reward = 538.00, Steps = 7, Loss = 3.7882, Exploration Rate = 0.1000, Train Count = 63627\n",
      "Episode 8614: Reward = 594.00, Steps = 4, Loss = 5.4495, Exploration Rate = 0.1000, Train Count = 63631\n",
      "Episode 8615: Reward = 588.00, Steps = 6, Loss = 8.3218, Exploration Rate = 0.1000, Train Count = 63637\n",
      "Episode 8616: Reward = 588.00, Steps = 6, Loss = 8.3477, Exploration Rate = 0.1000, Train Count = 63643\n",
      "Episode 8617: Reward = 594.00, Steps = 4, Loss = 5.6291, Exploration Rate = 0.1000, Train Count = 63647\n",
      "Episode 8618: Reward = 591.00, Steps = 5, Loss = 6.9127, Exploration Rate = 0.1000, Train Count = 63652\n",
      "Episode 8619: Reward = 591.00, Steps = 5, Loss = 7.1754, Exploration Rate = 0.1000, Train Count = 63657\n",
      "Episode 8620: Reward = 585.00, Steps = 7, Loss = 5.9405, Exploration Rate = 0.1000, Train Count = 63664\n",
      "Episode 8621: Reward = 573.00, Steps = 11, Loss = 4.0527, Exploration Rate = 0.1000, Train Count = 63675\n",
      "Episode 8622: Reward = 585.00, Steps = 7, Loss = 2.4437, Exploration Rate = 0.1000, Train Count = 63682\n",
      "Episode 8623: Reward = 588.00, Steps = 6, Loss = 4.4791, Exploration Rate = 0.1000, Train Count = 63688\n",
      "Episode 8624: Reward = 582.00, Steps = 8, Loss = 4.0542, Exploration Rate = 0.1000, Train Count = 63696\n",
      "Episode 8625: Reward = 585.00, Steps = 7, Loss = 2.8553, Exploration Rate = 0.1000, Train Count = 63703\n",
      "Episode 8626: Reward = 594.00, Steps = 4, Loss = 3.6792, Exploration Rate = 0.1000, Train Count = 63707\n",
      "Episode 8627: Reward = 591.00, Steps = 5, Loss = 4.7695, Exploration Rate = 0.1000, Train Count = 63712\n",
      "Episode 8628: Reward = 591.00, Steps = 5, Loss = 3.2766, Exploration Rate = 0.1000, Train Count = 63717\n",
      "Episode 8629: Reward = 588.00, Steps = 6, Loss = 4.5191, Exploration Rate = 0.1000, Train Count = 63723\n",
      "Episode 8630: Reward = 600.00, Steps = 2, Loss = 4.5746, Exploration Rate = 0.1000, Train Count = 63725\n",
      "Episode 8631: Reward = 588.00, Steps = 6, Loss = 2.9131, Exploration Rate = 0.1000, Train Count = 63731\n",
      "Episode 8632: Reward = 579.00, Steps = 9, Loss = 3.6850, Exploration Rate = 0.1000, Train Count = 63740\n",
      "Episode 8633: Reward = 552.00, Steps = 18, Loss = 6.6479, Exploration Rate = 0.1000, Train Count = 63758\n",
      "Episode 8634: Reward = 588.00, Steps = 6, Loss = 3.8976, Exploration Rate = 0.1000, Train Count = 63764\n",
      "Episode 8635: Reward = 538.00, Steps = 7, Loss = 5.8395, Exploration Rate = 0.1000, Train Count = 63771\n",
      "Episode 8636: Reward = 594.00, Steps = 4, Loss = 3.7948, Exploration Rate = 0.1000, Train Count = 63775\n",
      "Episode 8637: Reward = 591.00, Steps = 5, Loss = 3.8153, Exploration Rate = 0.1000, Train Count = 63780\n",
      "Episode 8638: Reward = 588.00, Steps = 6, Loss = 3.9294, Exploration Rate = 0.1000, Train Count = 63786\n",
      "Episode 8639: Reward = 585.00, Steps = 7, Loss = 5.1409, Exploration Rate = 0.1000, Train Count = 63793\n",
      "Episode 8640: Reward = 585.00, Steps = 7, Loss = 3.0049, Exploration Rate = 0.1000, Train Count = 63800\n",
      "Episode 8641: Reward = 579.00, Steps = 9, Loss = 20.8447, Exploration Rate = 0.1000, Train Count = 63809\n",
      "Episode 8642: Reward = 585.00, Steps = 7, Loss = 14.6478, Exploration Rate = 0.1000, Train Count = 63816\n",
      "Episode 8643: Reward = 582.00, Steps = 8, Loss = 11.3432, Exploration Rate = 0.1000, Train Count = 63824\n",
      "Episode 8644: Reward = 567.00, Steps = 13, Loss = 10.6217, Exploration Rate = 0.1000, Train Count = 63837\n",
      "Episode 8645: Reward = 588.00, Steps = 6, Loss = 12.9164, Exploration Rate = 0.1000, Train Count = 63843\n",
      "Episode 8646: Reward = 591.00, Steps = 5, Loss = 7.2520, Exploration Rate = 0.1000, Train Count = 63848\n",
      "Episode 8647: Reward = 582.00, Steps = 8, Loss = 5.8379, Exploration Rate = 0.1000, Train Count = 63856\n",
      "Episode 8648: Reward = 597.00, Steps = 3, Loss = 6.9818, Exploration Rate = 0.1000, Train Count = 63859\n",
      "Episode 8649: Reward = 594.00, Steps = 4, Loss = 5.7008, Exploration Rate = 0.1000, Train Count = 63863\n",
      "Episode 8650: Reward = 588.00, Steps = 6, Loss = 3.1564, Exploration Rate = 0.1000, Train Count = 63869\n",
      "Episode 8651: Reward = 591.00, Steps = 5, Loss = 4.7502, Exploration Rate = 0.1000, Train Count = 63874\n",
      "Episode 8652: Reward = 588.00, Steps = 6, Loss = 2.8745, Exploration Rate = 0.1000, Train Count = 63880\n",
      "Episode 8653: Reward = 597.00, Steps = 3, Loss = 3.5116, Exploration Rate = 0.1000, Train Count = 63883\n",
      "Episode 8654: Reward = 591.00, Steps = 5, Loss = 2.2701, Exploration Rate = 0.1000, Train Count = 63888\n",
      "Episode 8655: Reward = 579.00, Steps = 9, Loss = 4.8828, Exploration Rate = 0.1000, Train Count = 63897\n",
      "Episode 8656: Reward = 588.00, Steps = 6, Loss = 3.9481, Exploration Rate = 0.1000, Train Count = 63903\n",
      "Episode 8657: Reward = 588.00, Steps = 6, Loss = 3.4667, Exploration Rate = 0.1000, Train Count = 63909\n",
      "Episode 8658: Reward = 576.00, Steps = 10, Loss = 4.5648, Exploration Rate = 0.1000, Train Count = 63919\n",
      "Episode 8659: Reward = 588.00, Steps = 6, Loss = 5.3829, Exploration Rate = 0.1000, Train Count = 63925\n",
      "Episode 8660: Reward = 585.00, Steps = 7, Loss = 3.0839, Exploration Rate = 0.1000, Train Count = 63932\n",
      "Episode 8661: Reward = 588.00, Steps = 6, Loss = 3.6726, Exploration Rate = 0.1000, Train Count = 63938\n",
      "Episode 8662: Reward = 591.00, Steps = 5, Loss = 3.2815, Exploration Rate = 0.1000, Train Count = 63943\n",
      "Episode 8663: Reward = 591.00, Steps = 5, Loss = 2.5703, Exploration Rate = 0.1000, Train Count = 63948\n",
      "Episode 8664: Reward = 544.00, Steps = 5, Loss = 2.4235, Exploration Rate = 0.1000, Train Count = 63953\n",
      "Episode 8665: Reward = 591.00, Steps = 5, Loss = 1.7614, Exploration Rate = 0.1000, Train Count = 63958\n",
      "Episode 8666: Reward = 585.00, Steps = 7, Loss = 5.3751, Exploration Rate = 0.1000, Train Count = 63965\n",
      "Episode 8667: Reward = 594.00, Steps = 4, Loss = 6.7758, Exploration Rate = 0.1000, Train Count = 63969\n",
      "Episode 8668: Reward = 591.00, Steps = 5, Loss = 2.6168, Exploration Rate = 0.1000, Train Count = 63974\n",
      "Episode 8669: Reward = 582.00, Steps = 8, Loss = 4.2414, Exploration Rate = 0.1000, Train Count = 63982\n",
      "Episode 8670: Reward = 588.00, Steps = 6, Loss = 2.1693, Exploration Rate = 0.1000, Train Count = 63988\n",
      "Episode 8671: Reward = 591.00, Steps = 5, Loss = 1.6274, Exploration Rate = 0.1000, Train Count = 63993\n",
      "Episode 8672: Reward = 597.00, Steps = 3, Loss = 3.2433, Exploration Rate = 0.1000, Train Count = 63996\n",
      "Episode 8673: Reward = 585.00, Steps = 7, Loss = 2.7724, Exploration Rate = 0.1000, Train Count = 64003\n",
      "Episode 8674: Reward = 588.00, Steps = 6, Loss = 3.2219, Exploration Rate = 0.1000, Train Count = 64009\n",
      "Episode 8675: Reward = 585.00, Steps = 7, Loss = 4.8907, Exploration Rate = 0.1000, Train Count = 64016\n",
      "Episode 8676: Reward = 594.00, Steps = 4, Loss = 2.9728, Exploration Rate = 0.1000, Train Count = 64020\n",
      "Episode 8677: Reward = 591.00, Steps = 5, Loss = 1.5613, Exploration Rate = 0.1000, Train Count = 64025\n",
      "Episode 8678: Reward = 594.00, Steps = 4, Loss = 2.9854, Exploration Rate = 0.1000, Train Count = 64029\n",
      "Episode 8679: Reward = 585.00, Steps = 7, Loss = 4.0429, Exploration Rate = 0.1000, Train Count = 64036\n",
      "Episode 8680: Reward = 594.00, Steps = 4, Loss = 2.7544, Exploration Rate = 0.1000, Train Count = 64040\n",
      "Episode 8681: Reward = 535.00, Steps = 8, Loss = 6.4356, Exploration Rate = 0.1000, Train Count = 64048\n",
      "Episode 8682: Reward = 600.00, Steps = 2, Loss = 8.3088, Exploration Rate = 0.1000, Train Count = 64050\n",
      "Episode 8683: Reward = 594.00, Steps = 4, Loss = 4.0979, Exploration Rate = 0.1000, Train Count = 64054\n",
      "Episode 8684: Reward = 585.00, Steps = 7, Loss = 7.0573, Exploration Rate = 0.1000, Train Count = 64061\n",
      "Episode 8685: Reward = 588.00, Steps = 6, Loss = 6.2476, Exploration Rate = 0.1000, Train Count = 64067\n",
      "Episode 8686: Reward = 591.00, Steps = 5, Loss = 7.0825, Exploration Rate = 0.1000, Train Count = 64072\n",
      "Episode 8687: Reward = 591.00, Steps = 5, Loss = 4.2064, Exploration Rate = 0.1000, Train Count = 64077\n",
      "Episode 8688: Reward = 588.00, Steps = 6, Loss = 6.2839, Exploration Rate = 0.1000, Train Count = 64083\n",
      "Episode 8689: Reward = 594.00, Steps = 4, Loss = 4.9507, Exploration Rate = 0.1000, Train Count = 64087\n",
      "Episode 8690: Reward = 591.00, Steps = 5, Loss = 6.8523, Exploration Rate = 0.1000, Train Count = 64092\n",
      "Episode 8691: Reward = 585.00, Steps = 7, Loss = 2.4137, Exploration Rate = 0.1000, Train Count = 64099\n",
      "Episode 8692: Reward = 588.00, Steps = 6, Loss = 6.2988, Exploration Rate = 0.1000, Train Count = 64105\n",
      "Episode 8693: Reward = 591.00, Steps = 5, Loss = 4.6677, Exploration Rate = 0.1000, Train Count = 64110\n",
      "Episode 8694: Reward = 591.00, Steps = 5, Loss = 3.8376, Exploration Rate = 0.1000, Train Count = 64115\n",
      "Episode 8695: Reward = 558.00, Steps = 16, Loss = 6.8174, Exploration Rate = 0.1000, Train Count = 64131\n",
      "Episode 8696: Reward = 597.00, Steps = 3, Loss = 5.2297, Exploration Rate = 0.1000, Train Count = 64134\n",
      "Episode 8697: Reward = 535.00, Steps = 8, Loss = 7.5091, Exploration Rate = 0.1000, Train Count = 64142\n",
      "Episode 8698: Reward = 588.00, Steps = 6, Loss = 7.6108, Exploration Rate = 0.1000, Train Count = 64148\n",
      "Episode 8699: Reward = 591.00, Steps = 5, Loss = 7.1606, Exploration Rate = 0.1000, Train Count = 64153\n",
      "Episode 8700: Reward = 600.00, Steps = 2, Loss = 8.4708, Exploration Rate = 0.1000, Train Count = 64155\n",
      "Episode 8701: Reward = 585.00, Steps = 7, Loss = 6.7569, Exploration Rate = 0.1000, Train Count = 64162\n",
      "Episode 8702: Reward = 573.00, Steps = 11, Loss = 3.7699, Exploration Rate = 0.1000, Train Count = 64173\n",
      "Episode 8703: Reward = 591.00, Steps = 5, Loss = 4.5559, Exploration Rate = 0.1000, Train Count = 64178\n",
      "Episode 8704: Reward = 591.00, Steps = 5, Loss = 3.2534, Exploration Rate = 0.1000, Train Count = 64183\n",
      "Episode 8705: Reward = 588.00, Steps = 6, Loss = 5.3474, Exploration Rate = 0.1000, Train Count = 64189\n",
      "Episode 8706: Reward = 600.00, Steps = 2, Loss = 6.6294, Exploration Rate = 0.1000, Train Count = 64191\n",
      "Episode 8707: Reward = 588.00, Steps = 6, Loss = 6.5271, Exploration Rate = 0.1000, Train Count = 64197\n",
      "Episode 8708: Reward = 594.00, Steps = 4, Loss = 11.4530, Exploration Rate = 0.1000, Train Count = 64201\n",
      "Episode 8709: Reward = 535.00, Steps = 8, Loss = 4.8008, Exploration Rate = 0.1000, Train Count = 64209\n",
      "Episode 8710: Reward = 585.00, Steps = 7, Loss = 6.1964, Exploration Rate = 0.1000, Train Count = 64216\n",
      "Episode 8711: Reward = 600.00, Steps = 2, Loss = 5.3641, Exploration Rate = 0.1000, Train Count = 64218\n",
      "Episode 8712: Reward = 573.00, Steps = 11, Loss = 5.8514, Exploration Rate = 0.1000, Train Count = 64229\n",
      "Episode 8713: Reward = 594.00, Steps = 4, Loss = 5.6171, Exploration Rate = 0.1000, Train Count = 64233\n",
      "Episode 8714: Reward = 582.00, Steps = 8, Loss = 4.2772, Exploration Rate = 0.1000, Train Count = 64241\n",
      "Episode 8715: Reward = 591.00, Steps = 5, Loss = 8.1086, Exploration Rate = 0.1000, Train Count = 64246\n",
      "Episode 8716: Reward = 588.00, Steps = 6, Loss = 3.8814, Exploration Rate = 0.1000, Train Count = 64252\n",
      "Episode 8717: Reward = 591.00, Steps = 5, Loss = 4.8201, Exploration Rate = 0.1000, Train Count = 64257\n",
      "Episode 8718: Reward = 594.00, Steps = 4, Loss = 2.9642, Exploration Rate = 0.1000, Train Count = 64261\n",
      "Episode 8719: Reward = 588.00, Steps = 6, Loss = 4.5418, Exploration Rate = 0.1000, Train Count = 64267\n",
      "Episode 8720: Reward = 585.00, Steps = 7, Loss = 3.3132, Exploration Rate = 0.1000, Train Count = 64274\n",
      "Episode 8721: Reward = 576.00, Steps = 10, Loss = 3.2522, Exploration Rate = 0.1000, Train Count = 64284\n",
      "Episode 8722: Reward = 588.00, Steps = 6, Loss = 2.1863, Exploration Rate = 0.1000, Train Count = 64290\n",
      "Episode 8723: Reward = 594.00, Steps = 4, Loss = 1.9842, Exploration Rate = 0.1000, Train Count = 64294\n",
      "Episode 8724: Reward = 585.00, Steps = 7, Loss = 5.5642, Exploration Rate = 0.1000, Train Count = 64301\n",
      "Episode 8725: Reward = 588.00, Steps = 6, Loss = 18.2468, Exploration Rate = 0.1000, Train Count = 64307\n",
      "Episode 8726: Reward = 585.00, Steps = 7, Loss = 16.9146, Exploration Rate = 0.1000, Train Count = 64314\n",
      "Episode 8727: Reward = 588.00, Steps = 6, Loss = 12.5428, Exploration Rate = 0.1000, Train Count = 64320\n",
      "Episode 8728: Reward = 594.00, Steps = 4, Loss = 11.7565, Exploration Rate = 0.1000, Train Count = 64324\n",
      "Episode 8729: Reward = 576.00, Steps = 10, Loss = 9.7529, Exploration Rate = 0.1000, Train Count = 64334\n",
      "Episode 8730: Reward = 597.00, Steps = 3, Loss = 7.6874, Exploration Rate = 0.1000, Train Count = 64337\n",
      "Episode 8731: Reward = 591.00, Steps = 5, Loss = 6.7069, Exploration Rate = 0.1000, Train Count = 64342\n",
      "Episode 8732: Reward = 588.00, Steps = 6, Loss = 7.0016, Exploration Rate = 0.1000, Train Count = 64348\n",
      "Episode 8733: Reward = 597.00, Steps = 3, Loss = 4.8309, Exploration Rate = 0.1000, Train Count = 64351\n",
      "Episode 8734: Reward = 588.00, Steps = 6, Loss = 4.7133, Exploration Rate = 0.1000, Train Count = 64357\n",
      "Episode 8735: Reward = 582.00, Steps = 8, Loss = 3.5833, Exploration Rate = 0.1000, Train Count = 64365\n",
      "Episode 8736: Reward = 538.00, Steps = 7, Loss = 4.0522, Exploration Rate = 0.1000, Train Count = 64372\n",
      "Episode 8737: Reward = 591.00, Steps = 5, Loss = 4.8883, Exploration Rate = 0.1000, Train Count = 64377\n",
      "Episode 8738: Reward = 597.00, Steps = 3, Loss = 2.5041, Exploration Rate = 0.1000, Train Count = 64380\n",
      "Episode 8739: Reward = 591.00, Steps = 5, Loss = 3.3535, Exploration Rate = 0.1000, Train Count = 64385\n",
      "Episode 8740: Reward = 591.00, Steps = 5, Loss = 3.8593, Exploration Rate = 0.1000, Train Count = 64390\n",
      "Episode 8741: Reward = 588.00, Steps = 6, Loss = 6.5336, Exploration Rate = 0.1000, Train Count = 64396\n",
      "Episode 8742: Reward = 585.00, Steps = 7, Loss = 3.6262, Exploration Rate = 0.1000, Train Count = 64403\n",
      "Episode 8743: Reward = 594.00, Steps = 4, Loss = 2.9044, Exploration Rate = 0.1000, Train Count = 64407\n",
      "Episode 8744: Reward = 588.00, Steps = 6, Loss = 4.9588, Exploration Rate = 0.1000, Train Count = 64413\n",
      "Episode 8745: Reward = 585.00, Steps = 7, Loss = 6.6962, Exploration Rate = 0.1000, Train Count = 64420\n",
      "Episode 8746: Reward = 594.00, Steps = 4, Loss = 6.4655, Exploration Rate = 0.1000, Train Count = 64424\n",
      "Episode 8747: Reward = 594.00, Steps = 4, Loss = 4.6255, Exploration Rate = 0.1000, Train Count = 64428\n",
      "Episode 8748: Reward = 582.00, Steps = 8, Loss = 4.8094, Exploration Rate = 0.1000, Train Count = 64436\n",
      "Episode 8749: Reward = 532.00, Steps = 9, Loss = 4.7130, Exploration Rate = 0.1000, Train Count = 64445\n",
      "Episode 8750: Reward = 594.00, Steps = 4, Loss = 5.5282, Exploration Rate = 0.1000, Train Count = 64449\n",
      "Episode 8751: Reward = 597.00, Steps = 3, Loss = 3.4373, Exploration Rate = 0.1000, Train Count = 64452\n",
      "Episode 8752: Reward = 585.00, Steps = 7, Loss = 3.9657, Exploration Rate = 0.1000, Train Count = 64459\n",
      "Episode 8753: Reward = 570.00, Steps = 12, Loss = 5.1452, Exploration Rate = 0.1000, Train Count = 64471\n",
      "Episode 8754: Reward = 585.00, Steps = 7, Loss = 3.5652, Exploration Rate = 0.1000, Train Count = 64478\n",
      "Episode 8755: Reward = 582.00, Steps = 8, Loss = 3.9649, Exploration Rate = 0.1000, Train Count = 64486\n",
      "Episode 8756: Reward = 588.00, Steps = 6, Loss = 1.3602, Exploration Rate = 0.1000, Train Count = 64492\n",
      "Episode 8757: Reward = 582.00, Steps = 8, Loss = 3.0136, Exploration Rate = 0.1000, Train Count = 64500\n",
      "Episode 8758: Reward = 591.00, Steps = 5, Loss = 4.3990, Exploration Rate = 0.1000, Train Count = 64505\n",
      "Episode 8759: Reward = 591.00, Steps = 5, Loss = 2.8278, Exploration Rate = 0.1000, Train Count = 64510\n",
      "Episode 8760: Reward = 585.00, Steps = 7, Loss = 5.2289, Exploration Rate = 0.1000, Train Count = 64517\n",
      "Episode 8761: Reward = 597.00, Steps = 3, Loss = 6.8955, Exploration Rate = 0.1000, Train Count = 64520\n",
      "Episode 8762: Reward = 588.00, Steps = 6, Loss = 4.5785, Exploration Rate = 0.1000, Train Count = 64526\n",
      "Episode 8763: Reward = 585.00, Steps = 7, Loss = 4.0248, Exploration Rate = 0.1000, Train Count = 64533\n",
      "Episode 8764: Reward = 591.00, Steps = 5, Loss = 5.0126, Exploration Rate = 0.1000, Train Count = 64538\n",
      "Episode 8765: Reward = 582.00, Steps = 8, Loss = 3.3223, Exploration Rate = 0.1000, Train Count = 64546\n",
      "Episode 8766: Reward = 591.00, Steps = 5, Loss = 3.4778, Exploration Rate = 0.1000, Train Count = 64551\n",
      "Episode 8767: Reward = 597.00, Steps = 3, Loss = 4.1227, Exploration Rate = 0.1000, Train Count = 64554\n",
      "Episode 8768: Reward = 541.00, Steps = 6, Loss = 2.9604, Exploration Rate = 0.1000, Train Count = 64560\n",
      "Episode 8769: Reward = 597.00, Steps = 3, Loss = 6.6588, Exploration Rate = 0.1000, Train Count = 64563\n",
      "Episode 8770: Reward = 597.00, Steps = 3, Loss = 7.9338, Exploration Rate = 0.1000, Train Count = 64566\n",
      "Episode 8771: Reward = 588.00, Steps = 6, Loss = 4.6072, Exploration Rate = 0.1000, Train Count = 64572\n",
      "Episode 8772: Reward = 591.00, Steps = 5, Loss = 3.5858, Exploration Rate = 0.1000, Train Count = 64577\n",
      "Episode 8773: Reward = 570.00, Steps = 12, Loss = 3.4861, Exploration Rate = 0.1000, Train Count = 64589\n",
      "Episode 8774: Reward = 585.00, Steps = 7, Loss = 5.1469, Exploration Rate = 0.1000, Train Count = 64596\n",
      "Episode 8775: Reward = 591.00, Steps = 5, Loss = 6.6157, Exploration Rate = 0.1000, Train Count = 64601\n",
      "Episode 8776: Reward = 597.00, Steps = 3, Loss = 4.3730, Exploration Rate = 0.1000, Train Count = 64604\n",
      "Episode 8777: Reward = 579.00, Steps = 9, Loss = 4.9019, Exploration Rate = 0.1000, Train Count = 64613\n",
      "Episode 8778: Reward = 585.00, Steps = 7, Loss = 4.1066, Exploration Rate = 0.1000, Train Count = 64620\n",
      "Episode 8779: Reward = 600.00, Steps = 2, Loss = 10.1118, Exploration Rate = 0.1000, Train Count = 64622\n",
      "Episode 8780: Reward = 476.00, Steps = 12, Loss = 7.7963, Exploration Rate = 0.1000, Train Count = 64634\n",
      "Episode 8781: Reward = 591.00, Steps = 5, Loss = 8.0230, Exploration Rate = 0.1000, Train Count = 64639\n",
      "Episode 8782: Reward = 585.00, Steps = 7, Loss = 16.3209, Exploration Rate = 0.1000, Train Count = 64646\n",
      "Episode 8783: Reward = 585.00, Steps = 7, Loss = 8.6956, Exploration Rate = 0.1000, Train Count = 64653\n",
      "Episode 8784: Reward = 591.00, Steps = 5, Loss = 13.5664, Exploration Rate = 0.1000, Train Count = 64658\n",
      "Episode 8785: Reward = 532.00, Steps = 9, Loss = 10.7783, Exploration Rate = 0.1000, Train Count = 64667\n",
      "Episode 8786: Reward = 585.00, Steps = 7, Loss = 17.3058, Exploration Rate = 0.1000, Train Count = 64674\n",
      "Episode 8787: Reward = 564.00, Steps = 14, Loss = 12.2654, Exploration Rate = 0.1000, Train Count = 64688\n",
      "Episode 8788: Reward = 585.00, Steps = 7, Loss = 7.1107, Exploration Rate = 0.1000, Train Count = 64695\n",
      "Episode 8789: Reward = 582.00, Steps = 8, Loss = 9.2377, Exploration Rate = 0.1000, Train Count = 64703\n",
      "Episode 8790: Reward = 591.00, Steps = 5, Loss = 9.3189, Exploration Rate = 0.1000, Train Count = 64708\n",
      "Episode 8791: Reward = 585.00, Steps = 7, Loss = 10.6483, Exploration Rate = 0.1000, Train Count = 64715\n",
      "Episode 8792: Reward = 582.00, Steps = 8, Loss = 11.0861, Exploration Rate = 0.1000, Train Count = 64723\n",
      "Episode 8793: Reward = 591.00, Steps = 5, Loss = 11.1287, Exploration Rate = 0.1000, Train Count = 64728\n",
      "Episode 8794: Reward = 591.00, Steps = 5, Loss = 13.3405, Exploration Rate = 0.1000, Train Count = 64733\n",
      "Episode 8795: Reward = 591.00, Steps = 5, Loss = 6.0512, Exploration Rate = 0.1000, Train Count = 64738\n",
      "Episode 8796: Reward = 582.00, Steps = 8, Loss = 9.4736, Exploration Rate = 0.1000, Train Count = 64746\n",
      "Episode 8797: Reward = 594.00, Steps = 4, Loss = 5.0320, Exploration Rate = 0.1000, Train Count = 64750\n",
      "Episode 8798: Reward = 591.00, Steps = 5, Loss = 6.1958, Exploration Rate = 0.1000, Train Count = 64755\n",
      "Episode 8799: Reward = 582.00, Steps = 8, Loss = 10.6951, Exploration Rate = 0.1000, Train Count = 64763\n",
      "Episode 8800: Reward = 579.00, Steps = 9, Loss = 11.9369, Exploration Rate = 0.1000, Train Count = 64772\n",
      "Episode 8801: Reward = 591.00, Steps = 5, Loss = 9.3186, Exploration Rate = 0.1000, Train Count = 64777\n",
      "Episode 8802: Reward = 594.00, Steps = 4, Loss = 13.4860, Exploration Rate = 0.1000, Train Count = 64781\n",
      "Episode 8803: Reward = 591.00, Steps = 5, Loss = 8.9512, Exploration Rate = 0.1000, Train Count = 64786\n",
      "Episode 8804: Reward = 594.00, Steps = 4, Loss = 8.7258, Exploration Rate = 0.1000, Train Count = 64790\n",
      "Episode 8805: Reward = 594.00, Steps = 4, Loss = 12.2874, Exploration Rate = 0.1000, Train Count = 64794\n",
      "Episode 8806: Reward = 582.00, Steps = 8, Loss = 14.3943, Exploration Rate = 0.1000, Train Count = 64802\n",
      "Episode 8807: Reward = 594.00, Steps = 4, Loss = 24.7282, Exploration Rate = 0.1000, Train Count = 64806\n",
      "Episode 8808: Reward = 579.00, Steps = 9, Loss = 15.9735, Exploration Rate = 0.1000, Train Count = 64815\n",
      "Episode 8809: Reward = 588.00, Steps = 6, Loss = 14.9838, Exploration Rate = 0.1000, Train Count = 64821\n",
      "Episode 8810: Reward = 478.00, Steps = 27, Loss = 16.3117, Exploration Rate = 0.1000, Train Count = 64848\n",
      "Episode 8811: Reward = 591.00, Steps = 5, Loss = 13.9093, Exploration Rate = 0.1000, Train Count = 64853\n",
      "Episode 8812: Reward = 591.00, Steps = 5, Loss = 8.2297, Exploration Rate = 0.1000, Train Count = 64858\n",
      "Episode 8813: Reward = 588.00, Steps = 6, Loss = 10.8302, Exploration Rate = 0.1000, Train Count = 64864\n",
      "Episode 8814: Reward = 588.00, Steps = 6, Loss = 9.9988, Exploration Rate = 0.1000, Train Count = 64870\n",
      "Episode 8815: Reward = 594.00, Steps = 4, Loss = 12.3644, Exploration Rate = 0.1000, Train Count = 64874\n",
      "Episode 8816: Reward = 591.00, Steps = 5, Loss = 10.9638, Exploration Rate = 0.1000, Train Count = 64879\n",
      "Episode 8817: Reward = 579.00, Steps = 9, Loss = 8.5463, Exploration Rate = 0.1000, Train Count = 64888\n",
      "Episode 8818: Reward = 591.00, Steps = 5, Loss = 9.6892, Exploration Rate = 0.1000, Train Count = 64893\n",
      "Episode 8819: Reward = 585.00, Steps = 7, Loss = 4.2931, Exploration Rate = 0.1000, Train Count = 64900\n",
      "Episode 8820: Reward = 594.00, Steps = 4, Loss = 4.4008, Exploration Rate = 0.1000, Train Count = 64904\n",
      "Episode 8821: Reward = 600.00, Steps = 2, Loss = 3.8070, Exploration Rate = 0.1000, Train Count = 64906\n",
      "Episode 8822: Reward = 585.00, Steps = 7, Loss = 4.4076, Exploration Rate = 0.1000, Train Count = 64913\n",
      "Episode 8823: Reward = 594.00, Steps = 4, Loss = 7.3517, Exploration Rate = 0.1000, Train Count = 64917\n",
      "Episode 8824: Reward = 594.00, Steps = 4, Loss = 11.2227, Exploration Rate = 0.1000, Train Count = 64921\n",
      "Episode 8825: Reward = 535.00, Steps = 8, Loss = 10.0319, Exploration Rate = 0.1000, Train Count = 64929\n",
      "Episode 8826: Reward = 597.00, Steps = 3, Loss = 8.0436, Exploration Rate = 0.1000, Train Count = 64932\n",
      "Episode 8827: Reward = 591.00, Steps = 5, Loss = 7.4502, Exploration Rate = 0.1000, Train Count = 64937\n",
      "Episode 8828: Reward = 591.00, Steps = 5, Loss = 6.6015, Exploration Rate = 0.1000, Train Count = 64942\n",
      "Episode 8829: Reward = 585.00, Steps = 7, Loss = 6.8770, Exploration Rate = 0.1000, Train Count = 64949\n",
      "Episode 8830: Reward = 600.00, Steps = 2, Loss = 4.6702, Exploration Rate = 0.1000, Train Count = 64951\n",
      "Episode 8831: Reward = 591.00, Steps = 5, Loss = 7.9729, Exploration Rate = 0.1000, Train Count = 64956\n",
      "Episode 8832: Reward = 591.00, Steps = 5, Loss = 7.6557, Exploration Rate = 0.1000, Train Count = 64961\n",
      "Episode 8833: Reward = 594.00, Steps = 4, Loss = 7.6511, Exploration Rate = 0.1000, Train Count = 64965\n",
      "Episode 8834: Reward = 588.00, Steps = 6, Loss = 7.5494, Exploration Rate = 0.1000, Train Count = 64971\n",
      "Episode 8835: Reward = 588.00, Steps = 6, Loss = 5.0370, Exploration Rate = 0.1000, Train Count = 64977\n",
      "Episode 8836: Reward = 582.00, Steps = 8, Loss = 6.8881, Exploration Rate = 0.1000, Train Count = 64985\n",
      "Episode 8837: Reward = 582.00, Steps = 8, Loss = 6.7332, Exploration Rate = 0.1000, Train Count = 64993\n",
      "Episode 8838: Reward = 597.00, Steps = 3, Loss = 2.7671, Exploration Rate = 0.1000, Train Count = 64996\n",
      "Episode 8839: Reward = 591.00, Steps = 5, Loss = 8.7430, Exploration Rate = 0.1000, Train Count = 65001\n",
      "Episode 8840: Reward = 582.00, Steps = 8, Loss = 8.7086, Exploration Rate = 0.1000, Train Count = 65009\n",
      "Episode 8841: Reward = 582.00, Steps = 8, Loss = 8.8171, Exploration Rate = 0.1000, Train Count = 65017\n",
      "Episode 8842: Reward = 585.00, Steps = 7, Loss = 5.6635, Exploration Rate = 0.1000, Train Count = 65024\n",
      "Episode 8843: Reward = 600.00, Steps = 2, Loss = 2.6261, Exploration Rate = 0.1000, Train Count = 65026\n",
      "Episode 8844: Reward = 591.00, Steps = 5, Loss = 8.4557, Exploration Rate = 0.1000, Train Count = 65031\n",
      "Episode 8845: Reward = 567.00, Steps = 13, Loss = 7.8773, Exploration Rate = 0.1000, Train Count = 65044\n",
      "Episode 8846: Reward = 585.00, Steps = 7, Loss = 8.4034, Exploration Rate = 0.1000, Train Count = 65051\n",
      "Episode 8847: Reward = 600.00, Steps = 2, Loss = 6.1545, Exploration Rate = 0.1000, Train Count = 65053\n",
      "Episode 8848: Reward = 588.00, Steps = 6, Loss = 6.7430, Exploration Rate = 0.1000, Train Count = 65059\n",
      "Episode 8849: Reward = 588.00, Steps = 6, Loss = 4.1256, Exploration Rate = 0.1000, Train Count = 65065\n",
      "Episode 8850: Reward = 591.00, Steps = 5, Loss = 3.1347, Exploration Rate = 0.1000, Train Count = 65070\n",
      "Episode 8851: Reward = 597.00, Steps = 3, Loss = 7.1553, Exploration Rate = 0.1000, Train Count = 65073\n",
      "Episode 8852: Reward = 594.00, Steps = 4, Loss = 7.3922, Exploration Rate = 0.1000, Train Count = 65077\n",
      "Episode 8853: Reward = 597.00, Steps = 3, Loss = 5.2354, Exploration Rate = 0.1000, Train Count = 65080\n",
      "Episode 8854: Reward = 576.00, Steps = 10, Loss = 6.2312, Exploration Rate = 0.1000, Train Count = 65090\n",
      "Episode 8855: Reward = 597.00, Steps = 3, Loss = 10.2629, Exploration Rate = 0.1000, Train Count = 65093\n",
      "Episode 8856: Reward = 591.00, Steps = 5, Loss = 6.9652, Exploration Rate = 0.1000, Train Count = 65098\n",
      "Episode 8857: Reward = 588.00, Steps = 6, Loss = 8.4070, Exploration Rate = 0.1000, Train Count = 65104\n",
      "Episode 8858: Reward = 594.00, Steps = 4, Loss = 9.1411, Exploration Rate = 0.1000, Train Count = 65108\n",
      "Episode 8859: Reward = 588.00, Steps = 6, Loss = 6.4291, Exploration Rate = 0.1000, Train Count = 65114\n",
      "Episode 8860: Reward = 582.00, Steps = 8, Loss = 9.0745, Exploration Rate = 0.1000, Train Count = 65122\n",
      "Episode 8861: Reward = 594.00, Steps = 4, Loss = 7.2845, Exploration Rate = 0.1000, Train Count = 65126\n",
      "Episode 8862: Reward = 585.00, Steps = 7, Loss = 5.9741, Exploration Rate = 0.1000, Train Count = 65133\n",
      "Episode 8863: Reward = 594.00, Steps = 4, Loss = 8.5815, Exploration Rate = 0.1000, Train Count = 65137\n",
      "Episode 8864: Reward = 579.00, Steps = 9, Loss = 6.6171, Exploration Rate = 0.1000, Train Count = 65146\n",
      "Episode 8865: Reward = 591.00, Steps = 5, Loss = 3.4895, Exploration Rate = 0.1000, Train Count = 65151\n",
      "Episode 8866: Reward = 585.00, Steps = 7, Loss = 6.8845, Exploration Rate = 0.1000, Train Count = 65158\n",
      "Episode 8867: Reward = 591.00, Steps = 5, Loss = 4.8224, Exploration Rate = 0.1000, Train Count = 65163\n",
      "Episode 8868: Reward = 591.00, Steps = 5, Loss = 5.1412, Exploration Rate = 0.1000, Train Count = 65168\n",
      "Episode 8869: Reward = 591.00, Steps = 5, Loss = 6.0274, Exploration Rate = 0.1000, Train Count = 65173\n",
      "Episode 8870: Reward = 576.00, Steps = 10, Loss = 8.1781, Exploration Rate = 0.1000, Train Count = 65183\n",
      "Episode 8871: Reward = 582.00, Steps = 8, Loss = 6.9917, Exploration Rate = 0.1000, Train Count = 65191\n",
      "Episode 8872: Reward = 582.00, Steps = 8, Loss = 4.9690, Exploration Rate = 0.1000, Train Count = 65199\n",
      "Episode 8873: Reward = 582.00, Steps = 8, Loss = 6.9668, Exploration Rate = 0.1000, Train Count = 65207\n",
      "Episode 8874: Reward = 520.00, Steps = 13, Loss = 5.3831, Exploration Rate = 0.1000, Train Count = 65220\n",
      "Episode 8875: Reward = 573.00, Steps = 11, Loss = 6.3057, Exploration Rate = 0.1000, Train Count = 65231\n",
      "Episode 8876: Reward = 585.00, Steps = 7, Loss = 5.5945, Exploration Rate = 0.1000, Train Count = 65238\n",
      "Episode 8877: Reward = 585.00, Steps = 7, Loss = 5.3771, Exploration Rate = 0.1000, Train Count = 65245\n",
      "Episode 8878: Reward = 588.00, Steps = 6, Loss = 5.6008, Exploration Rate = 0.1000, Train Count = 65251\n",
      "Episode 8879: Reward = 573.00, Steps = 11, Loss = 6.1372, Exploration Rate = 0.1000, Train Count = 65262\n",
      "Episode 8880: Reward = 588.00, Steps = 6, Loss = 7.0272, Exploration Rate = 0.1000, Train Count = 65268\n",
      "Episode 8881: Reward = 579.00, Steps = 9, Loss = 8.5302, Exploration Rate = 0.1000, Train Count = 65277\n",
      "Episode 8882: Reward = 597.00, Steps = 3, Loss = 5.6237, Exploration Rate = 0.1000, Train Count = 65280\n",
      "Episode 8883: Reward = 591.00, Steps = 5, Loss = 8.4000, Exploration Rate = 0.1000, Train Count = 65285\n",
      "Episode 8884: Reward = 579.00, Steps = 9, Loss = 6.4214, Exploration Rate = 0.1000, Train Count = 65294\n",
      "Episode 8885: Reward = 576.00, Steps = 10, Loss = 13.5091, Exploration Rate = 0.1000, Train Count = 65304\n",
      "Episode 8886: Reward = 591.00, Steps = 5, Loss = 22.8001, Exploration Rate = 0.1000, Train Count = 65309\n",
      "Episode 8887: Reward = 591.00, Steps = 5, Loss = 15.0172, Exploration Rate = 0.1000, Train Count = 65314\n",
      "Episode 8888: Reward = 591.00, Steps = 5, Loss = 19.1227, Exploration Rate = 0.1000, Train Count = 65319\n",
      "Episode 8889: Reward = 588.00, Steps = 6, Loss = 10.5882, Exploration Rate = 0.1000, Train Count = 65325\n",
      "Episode 8890: Reward = 579.00, Steps = 9, Loss = 10.2649, Exploration Rate = 0.1000, Train Count = 65334\n",
      "Episode 8891: Reward = 585.00, Steps = 7, Loss = 10.9405, Exploration Rate = 0.1000, Train Count = 65341\n",
      "Episode 8892: Reward = 588.00, Steps = 6, Loss = 7.9245, Exploration Rate = 0.1000, Train Count = 65347\n",
      "Episode 8893: Reward = 597.00, Steps = 3, Loss = 6.9161, Exploration Rate = 0.1000, Train Count = 65350\n",
      "Episode 8894: Reward = 597.00, Steps = 3, Loss = 8.4918, Exploration Rate = 0.1000, Train Count = 65353\n",
      "Episode 8895: Reward = 597.00, Steps = 3, Loss = 7.4189, Exploration Rate = 0.1000, Train Count = 65356\n",
      "Episode 8896: Reward = 591.00, Steps = 5, Loss = 11.3732, Exploration Rate = 0.1000, Train Count = 65361\n",
      "Episode 8897: Reward = 594.00, Steps = 4, Loss = 7.1865, Exploration Rate = 0.1000, Train Count = 65365\n",
      "Episode 8898: Reward = 588.00, Steps = 6, Loss = 13.3017, Exploration Rate = 0.1000, Train Count = 65371\n",
      "Episode 8899: Reward = 597.00, Steps = 3, Loss = 8.4996, Exploration Rate = 0.1000, Train Count = 65374\n",
      "Episode 8900: Reward = 591.00, Steps = 5, Loss = 11.5342, Exploration Rate = 0.1000, Train Count = 65379\n",
      "Episode 8901: Reward = 564.00, Steps = 14, Loss = 9.2809, Exploration Rate = 0.1000, Train Count = 65393\n",
      "Episode 8902: Reward = 585.00, Steps = 7, Loss = 5.2914, Exploration Rate = 0.1000, Train Count = 65400\n",
      "Episode 8903: Reward = 585.00, Steps = 7, Loss = 7.1957, Exploration Rate = 0.1000, Train Count = 65407\n",
      "Episode 8904: Reward = 585.00, Steps = 7, Loss = 3.9234, Exploration Rate = 0.1000, Train Count = 65414\n",
      "Episode 8905: Reward = 538.00, Steps = 7, Loss = 7.3863, Exploration Rate = 0.1000, Train Count = 65421\n",
      "Episode 8906: Reward = 594.00, Steps = 4, Loss = 10.0435, Exploration Rate = 0.1000, Train Count = 65425\n",
      "Episode 8907: Reward = 591.00, Steps = 5, Loss = 8.1203, Exploration Rate = 0.1000, Train Count = 65430\n",
      "Episode 8908: Reward = 594.00, Steps = 4, Loss = 3.7447, Exploration Rate = 0.1000, Train Count = 65434\n",
      "Episode 8909: Reward = 597.00, Steps = 3, Loss = 5.1374, Exploration Rate = 0.1000, Train Count = 65437\n",
      "Episode 8910: Reward = 585.00, Steps = 7, Loss = 5.2573, Exploration Rate = 0.1000, Train Count = 65444\n",
      "Episode 8911: Reward = 591.00, Steps = 5, Loss = 2.3484, Exploration Rate = 0.1000, Train Count = 65449\n",
      "Episode 8912: Reward = 591.00, Steps = 5, Loss = 2.5624, Exploration Rate = 0.1000, Train Count = 65454\n",
      "Episode 8913: Reward = 579.00, Steps = 9, Loss = 5.1281, Exploration Rate = 0.1000, Train Count = 65463\n",
      "Episode 8914: Reward = 591.00, Steps = 5, Loss = 4.6143, Exploration Rate = 0.1000, Train Count = 65468\n",
      "Episode 8915: Reward = 597.00, Steps = 3, Loss = 6.9744, Exploration Rate = 0.1000, Train Count = 65471\n",
      "Episode 8916: Reward = 591.00, Steps = 5, Loss = 5.2105, Exploration Rate = 0.1000, Train Count = 65476\n",
      "Episode 8917: Reward = 585.00, Steps = 7, Loss = 4.3776, Exploration Rate = 0.1000, Train Count = 65483\n",
      "Episode 8918: Reward = 588.00, Steps = 6, Loss = 4.8929, Exploration Rate = 0.1000, Train Count = 65489\n",
      "Episode 8919: Reward = 591.00, Steps = 5, Loss = 6.6198, Exploration Rate = 0.1000, Train Count = 65494\n",
      "Episode 8920: Reward = 535.00, Steps = 8, Loss = 7.5637, Exploration Rate = 0.1000, Train Count = 65502\n",
      "Episode 8921: Reward = 597.00, Steps = 3, Loss = 6.1145, Exploration Rate = 0.1000, Train Count = 65505\n",
      "Episode 8922: Reward = 576.00, Steps = 10, Loss = 7.5556, Exploration Rate = 0.1000, Train Count = 65515\n",
      "Episode 8923: Reward = 582.00, Steps = 8, Loss = 8.8573, Exploration Rate = 0.1000, Train Count = 65523\n",
      "Episode 8924: Reward = 585.00, Steps = 7, Loss = 5.9938, Exploration Rate = 0.1000, Train Count = 65530\n",
      "Episode 8925: Reward = 588.00, Steps = 6, Loss = 5.7020, Exploration Rate = 0.1000, Train Count = 65536\n",
      "Episode 8926: Reward = 591.00, Steps = 5, Loss = 7.7018, Exploration Rate = 0.1000, Train Count = 65541\n",
      "Episode 8927: Reward = 597.00, Steps = 3, Loss = 3.1131, Exploration Rate = 0.1000, Train Count = 65544\n",
      "Episode 8928: Reward = 600.00, Steps = 2, Loss = 6.5891, Exploration Rate = 0.1000, Train Count = 65546\n",
      "Episode 8929: Reward = 588.00, Steps = 6, Loss = 4.6104, Exploration Rate = 0.1000, Train Count = 65552\n",
      "Episode 8930: Reward = 591.00, Steps = 5, Loss = 6.0350, Exploration Rate = 0.1000, Train Count = 65557\n",
      "Episode 8931: Reward = 588.00, Steps = 6, Loss = 5.7107, Exploration Rate = 0.1000, Train Count = 65563\n",
      "Episode 8932: Reward = 588.00, Steps = 6, Loss = 3.1870, Exploration Rate = 0.1000, Train Count = 65569\n",
      "Episode 8933: Reward = 588.00, Steps = 6, Loss = 2.6955, Exploration Rate = 0.1000, Train Count = 65575\n",
      "Episode 8934: Reward = 523.00, Steps = 12, Loss = 6.5508, Exploration Rate = 0.1000, Train Count = 65587\n",
      "Episode 8935: Reward = 585.00, Steps = 7, Loss = 7.3982, Exploration Rate = 0.1000, Train Count = 65594\n",
      "Episode 8936: Reward = 394.00, Steps = 8, Loss = 18.2824, Exploration Rate = 0.1000, Train Count = 65602\n",
      "Episode 8937: Reward = 591.00, Steps = 5, Loss = 14.6531, Exploration Rate = 0.1000, Train Count = 65607\n",
      "Episode 8938: Reward = 588.00, Steps = 6, Loss = 9.6434, Exploration Rate = 0.1000, Train Count = 65613\n",
      "Episode 8939: Reward = 529.00, Steps = 10, Loss = 5.9808, Exploration Rate = 0.1000, Train Count = 65623\n",
      "Episode 8940: Reward = 582.00, Steps = 8, Loss = 5.6244, Exploration Rate = 0.1000, Train Count = 65631\n",
      "Episode 8941: Reward = 582.00, Steps = 8, Loss = 3.8628, Exploration Rate = 0.1000, Train Count = 65639\n",
      "Episode 8942: Reward = 591.00, Steps = 5, Loss = 4.6724, Exploration Rate = 0.1000, Train Count = 65644\n",
      "Episode 8943: Reward = 582.00, Steps = 8, Loss = 2.9852, Exploration Rate = 0.1000, Train Count = 65652\n",
      "Episode 8944: Reward = 591.00, Steps = 5, Loss = 3.6353, Exploration Rate = 0.1000, Train Count = 65657\n",
      "Episode 8945: Reward = 585.00, Steps = 7, Loss = 2.2423, Exploration Rate = 0.1000, Train Count = 65664\n",
      "Episode 8946: Reward = 585.00, Steps = 7, Loss = 2.5257, Exploration Rate = 0.1000, Train Count = 65671\n",
      "Episode 8947: Reward = 600.00, Steps = 2, Loss = 2.4410, Exploration Rate = 0.1000, Train Count = 65673\n",
      "Episode 8948: Reward = 588.00, Steps = 6, Loss = 2.4369, Exploration Rate = 0.1000, Train Count = 65679\n",
      "Episode 8949: Reward = 594.00, Steps = 4, Loss = 2.0716, Exploration Rate = 0.1000, Train Count = 65683\n",
      "Episode 8950: Reward = 594.00, Steps = 4, Loss = 1.5237, Exploration Rate = 0.1000, Train Count = 65687\n",
      "Episode 8951: Reward = 576.00, Steps = 10, Loss = 1.9939, Exploration Rate = 0.1000, Train Count = 65697\n",
      "Episode 8952: Reward = 579.00, Steps = 9, Loss = 1.3350, Exploration Rate = 0.1000, Train Count = 65706\n",
      "Episode 8953: Reward = 597.00, Steps = 3, Loss = 1.0283, Exploration Rate = 0.1000, Train Count = 65709\n",
      "Episode 8954: Reward = 594.00, Steps = 4, Loss = 1.4854, Exploration Rate = 0.1000, Train Count = 65713\n",
      "Episode 8955: Reward = 597.00, Steps = 3, Loss = 1.0664, Exploration Rate = 0.1000, Train Count = 65716\n",
      "Episode 8956: Reward = 570.00, Steps = 12, Loss = 8.5058, Exploration Rate = 0.1000, Train Count = 65728\n",
      "Episode 8957: Reward = 579.00, Steps = 9, Loss = 3.6320, Exploration Rate = 0.1000, Train Count = 65737\n",
      "Episode 8958: Reward = 585.00, Steps = 7, Loss = 3.3526, Exploration Rate = 0.1000, Train Count = 65744\n",
      "Episode 8959: Reward = 597.00, Steps = 3, Loss = 2.0780, Exploration Rate = 0.1000, Train Count = 65747\n",
      "Episode 8960: Reward = 576.00, Steps = 10, Loss = 2.1270, Exploration Rate = 0.1000, Train Count = 65757\n",
      "Episode 8961: Reward = 576.00, Steps = 10, Loss = 1.9582, Exploration Rate = 0.1000, Train Count = 65767\n",
      "Episode 8962: Reward = 550.00, Steps = 3, Loss = 1.3986, Exploration Rate = 0.1000, Train Count = 65770\n",
      "Episode 8963: Reward = 597.00, Steps = 3, Loss = 6.3052, Exploration Rate = 0.1000, Train Count = 65773\n",
      "Episode 8964: Reward = 600.00, Steps = 2, Loss = 4.1684, Exploration Rate = 0.1000, Train Count = 65775\n",
      "Episode 8965: Reward = 588.00, Steps = 6, Loss = 1.8758, Exploration Rate = 0.1000, Train Count = 65781\n",
      "Episode 8966: Reward = 591.00, Steps = 5, Loss = 1.4049, Exploration Rate = 0.1000, Train Count = 65786\n",
      "Episode 8967: Reward = 588.00, Steps = 6, Loss = 1.1293, Exploration Rate = 0.1000, Train Count = 65792\n",
      "Episode 8968: Reward = 585.00, Steps = 7, Loss = 0.8949, Exploration Rate = 0.1000, Train Count = 65799\n",
      "Episode 8969: Reward = 570.00, Steps = 12, Loss = 15.3097, Exploration Rate = 0.1000, Train Count = 65811\n",
      "Episode 8970: Reward = 591.00, Steps = 5, Loss = 10.6753, Exploration Rate = 0.1000, Train Count = 65816\n",
      "Episode 8971: Reward = 591.00, Steps = 5, Loss = 8.6746, Exploration Rate = 0.1000, Train Count = 65821\n",
      "Episode 8972: Reward = 588.00, Steps = 6, Loss = 7.0179, Exploration Rate = 0.1000, Train Count = 65827\n",
      "Episode 8973: Reward = 588.00, Steps = 6, Loss = 5.4620, Exploration Rate = 0.1000, Train Count = 65833\n",
      "Episode 8974: Reward = 594.00, Steps = 4, Loss = 4.9347, Exploration Rate = 0.1000, Train Count = 65837\n",
      "Episode 8975: Reward = 579.00, Steps = 9, Loss = 4.9048, Exploration Rate = 0.1000, Train Count = 65846\n",
      "Episode 8976: Reward = 588.00, Steps = 6, Loss = 5.5481, Exploration Rate = 0.1000, Train Count = 65852\n",
      "Episode 8977: Reward = 576.00, Steps = 10, Loss = 3.6681, Exploration Rate = 0.1000, Train Count = 65862\n",
      "Episode 8978: Reward = 591.00, Steps = 5, Loss = 6.1582, Exploration Rate = 0.1000, Train Count = 65867\n",
      "Episode 8979: Reward = 591.00, Steps = 5, Loss = 2.5593, Exploration Rate = 0.1000, Train Count = 65872\n",
      "Episode 8980: Reward = 597.00, Steps = 3, Loss = 3.6145, Exploration Rate = 0.1000, Train Count = 65875\n",
      "Episode 8981: Reward = 591.00, Steps = 5, Loss = 2.4553, Exploration Rate = 0.1000, Train Count = 65880\n",
      "Episode 8982: Reward = 573.00, Steps = 11, Loss = 1.9690, Exploration Rate = 0.1000, Train Count = 65891\n",
      "Episode 8983: Reward = 588.00, Steps = 6, Loss = 2.2166, Exploration Rate = 0.1000, Train Count = 65897\n",
      "Episode 8984: Reward = 591.00, Steps = 5, Loss = 1.9867, Exploration Rate = 0.1000, Train Count = 65902\n",
      "Episode 8985: Reward = 582.00, Steps = 8, Loss = 2.7400, Exploration Rate = 0.1000, Train Count = 65910\n",
      "Episode 8986: Reward = 597.00, Steps = 3, Loss = 1.6819, Exploration Rate = 0.1000, Train Count = 65913\n",
      "Episode 8987: Reward = 585.00, Steps = 7, Loss = 1.5859, Exploration Rate = 0.1000, Train Count = 65920\n",
      "Episode 8988: Reward = 591.00, Steps = 5, Loss = 2.7294, Exploration Rate = 0.1000, Train Count = 65925\n",
      "Episode 8989: Reward = 582.00, Steps = 8, Loss = 1.0576, Exploration Rate = 0.1000, Train Count = 65933\n",
      "Episode 8990: Reward = 594.00, Steps = 4, Loss = 1.1835, Exploration Rate = 0.1000, Train Count = 65937\n",
      "Episode 8991: Reward = 588.00, Steps = 6, Loss = 1.0436, Exploration Rate = 0.1000, Train Count = 65943\n",
      "Episode 8992: Reward = 594.00, Steps = 4, Loss = 1.7586, Exploration Rate = 0.1000, Train Count = 65947\n",
      "Episode 8993: Reward = 570.00, Steps = 12, Loss = 3.5248, Exploration Rate = 0.1000, Train Count = 65959\n",
      "Episode 8994: Reward = 591.00, Steps = 5, Loss = 5.2268, Exploration Rate = 0.1000, Train Count = 65964\n",
      "Episode 8995: Reward = 585.00, Steps = 7, Loss = 4.3317, Exploration Rate = 0.1000, Train Count = 65971\n",
      "Episode 8996: Reward = 591.00, Steps = 5, Loss = 6.3527, Exploration Rate = 0.1000, Train Count = 65976\n",
      "Episode 8997: Reward = 591.00, Steps = 5, Loss = 4.6907, Exploration Rate = 0.1000, Train Count = 65981\n",
      "Episode 8998: Reward = 591.00, Steps = 5, Loss = 2.1874, Exploration Rate = 0.1000, Train Count = 65986\n",
      "Episode 8999: Reward = 591.00, Steps = 5, Loss = 1.8403, Exploration Rate = 0.1000, Train Count = 65991\n",
      "Episode 9000: Reward = 594.00, Steps = 4, Loss = 2.1474, Exploration Rate = 0.1000, Train Count = 65995\n",
      "Episode 9001: Reward = 597.00, Steps = 3, Loss = 4.3443, Exploration Rate = 0.1000, Train Count = 65998\n",
      "Episode 9002: Reward = 585.00, Steps = 7, Loss = 2.1768, Exploration Rate = 0.1000, Train Count = 66005\n",
      "Episode 9003: Reward = 582.00, Steps = 8, Loss = 2.1919, Exploration Rate = 0.1000, Train Count = 66013\n",
      "Episode 9004: Reward = 579.00, Steps = 9, Loss = 2.6691, Exploration Rate = 0.1000, Train Count = 66022\n",
      "Episode 9005: Reward = 576.00, Steps = 10, Loss = 1.9890, Exploration Rate = 0.1000, Train Count = 66032\n",
      "Episode 9006: Reward = 594.00, Steps = 4, Loss = 1.4314, Exploration Rate = 0.1000, Train Count = 66036\n",
      "Episode 9007: Reward = 573.00, Steps = 11, Loss = 2.4510, Exploration Rate = 0.1000, Train Count = 66047\n",
      "Episode 9008: Reward = 585.00, Steps = 7, Loss = 2.4219, Exploration Rate = 0.1000, Train Count = 66054\n",
      "Episode 9009: Reward = 591.00, Steps = 5, Loss = 2.7729, Exploration Rate = 0.1000, Train Count = 66059\n",
      "Episode 9010: Reward = 588.00, Steps = 6, Loss = 1.4998, Exploration Rate = 0.1000, Train Count = 66065\n",
      "Episode 9011: Reward = 591.00, Steps = 5, Loss = 0.9604, Exploration Rate = 0.1000, Train Count = 66070\n",
      "Episode 9012: Reward = 579.00, Steps = 9, Loss = 1.9990, Exploration Rate = 0.1000, Train Count = 66079\n",
      "Episode 9013: Reward = 591.00, Steps = 5, Loss = 2.8289, Exploration Rate = 0.1000, Train Count = 66084\n",
      "Episode 9014: Reward = 591.00, Steps = 5, Loss = 3.6274, Exploration Rate = 0.1000, Train Count = 66089\n",
      "Episode 9015: Reward = 588.00, Steps = 6, Loss = 1.4047, Exploration Rate = 0.1000, Train Count = 66095\n",
      "Episode 9016: Reward = 588.00, Steps = 6, Loss = 1.2745, Exploration Rate = 0.1000, Train Count = 66101\n",
      "Episode 9017: Reward = 588.00, Steps = 6, Loss = 1.3761, Exploration Rate = 0.1000, Train Count = 66107\n",
      "Episode 9018: Reward = 585.00, Steps = 7, Loss = 1.1342, Exploration Rate = 0.1000, Train Count = 66114\n",
      "Episode 9019: Reward = 591.00, Steps = 5, Loss = 0.9932, Exploration Rate = 0.1000, Train Count = 66119\n",
      "Episode 9020: Reward = 585.00, Steps = 7, Loss = 2.2980, Exploration Rate = 0.1000, Train Count = 66126\n",
      "Episode 9021: Reward = 591.00, Steps = 5, Loss = 2.3150, Exploration Rate = 0.1000, Train Count = 66131\n",
      "Episode 9022: Reward = 594.00, Steps = 4, Loss = 2.0144, Exploration Rate = 0.1000, Train Count = 66135\n",
      "Episode 9023: Reward = 585.00, Steps = 7, Loss = 3.2104, Exploration Rate = 0.1000, Train Count = 66142\n",
      "Episode 9024: Reward = 597.00, Steps = 3, Loss = 0.9236, Exploration Rate = 0.1000, Train Count = 66145\n",
      "Episode 9025: Reward = 591.00, Steps = 5, Loss = 3.2214, Exploration Rate = 0.1000, Train Count = 66150\n",
      "Episode 9026: Reward = 597.00, Steps = 3, Loss = 1.9991, Exploration Rate = 0.1000, Train Count = 66153\n",
      "Episode 9027: Reward = 582.00, Steps = 8, Loss = 2.6030, Exploration Rate = 0.1000, Train Count = 66161\n",
      "Episode 9028: Reward = 591.00, Steps = 5, Loss = 2.2713, Exploration Rate = 0.1000, Train Count = 66166\n",
      "Episode 9029: Reward = 591.00, Steps = 5, Loss = 1.4362, Exploration Rate = 0.1000, Train Count = 66171\n",
      "Episode 9030: Reward = 594.00, Steps = 4, Loss = 1.3982, Exploration Rate = 0.1000, Train Count = 66175\n",
      "Episode 9031: Reward = 529.00, Steps = 10, Loss = 0.9660, Exploration Rate = 0.1000, Train Count = 66185\n",
      "Episode 9032: Reward = 591.00, Steps = 5, Loss = 4.1217, Exploration Rate = 0.1000, Train Count = 66190\n",
      "Episode 9033: Reward = 594.00, Steps = 4, Loss = 4.4094, Exploration Rate = 0.1000, Train Count = 66194\n",
      "Episode 9034: Reward = 585.00, Steps = 7, Loss = 4.6286, Exploration Rate = 0.1000, Train Count = 66201\n",
      "Episode 9035: Reward = 597.00, Steps = 3, Loss = 1.9863, Exploration Rate = 0.1000, Train Count = 66204\n",
      "Episode 9036: Reward = 591.00, Steps = 5, Loss = 4.2449, Exploration Rate = 0.1000, Train Count = 66209\n",
      "Episode 9037: Reward = 588.00, Steps = 6, Loss = 2.9202, Exploration Rate = 0.1000, Train Count = 66215\n",
      "Episode 9038: Reward = 576.00, Steps = 10, Loss = 2.7458, Exploration Rate = 0.1000, Train Count = 66225\n",
      "Episode 9039: Reward = 594.00, Steps = 4, Loss = 1.3342, Exploration Rate = 0.1000, Train Count = 66229\n",
      "Episode 9040: Reward = 597.00, Steps = 3, Loss = 6.6127, Exploration Rate = 0.1000, Train Count = 66232\n",
      "Episode 9041: Reward = 597.00, Steps = 3, Loss = 0.9889, Exploration Rate = 0.1000, Train Count = 66235\n",
      "Episode 9042: Reward = 544.00, Steps = 5, Loss = 6.2906, Exploration Rate = 0.1000, Train Count = 66240\n",
      "Episode 9043: Reward = 588.00, Steps = 6, Loss = 4.1027, Exploration Rate = 0.1000, Train Count = 66246\n",
      "Episode 9044: Reward = 588.00, Steps = 6, Loss = 5.4561, Exploration Rate = 0.1000, Train Count = 66252\n",
      "Episode 9045: Reward = 576.00, Steps = 10, Loss = 6.5995, Exploration Rate = 0.1000, Train Count = 66262\n",
      "Episode 9046: Reward = 591.00, Steps = 5, Loss = 4.9340, Exploration Rate = 0.1000, Train Count = 66267\n",
      "Episode 9047: Reward = 594.00, Steps = 4, Loss = 4.3962, Exploration Rate = 0.1000, Train Count = 66271\n",
      "Episode 9048: Reward = 591.00, Steps = 5, Loss = 3.9875, Exploration Rate = 0.1000, Train Count = 66276\n",
      "Episode 9049: Reward = 576.00, Steps = 10, Loss = 6.6745, Exploration Rate = 0.1000, Train Count = 66286\n",
      "Episode 9050: Reward = 588.00, Steps = 6, Loss = 6.3905, Exploration Rate = 0.1000, Train Count = 66292\n",
      "Episode 9051: Reward = 594.00, Steps = 4, Loss = 5.1317, Exploration Rate = 0.1000, Train Count = 66296\n",
      "Episode 9052: Reward = 585.00, Steps = 7, Loss = 10.2288, Exploration Rate = 0.1000, Train Count = 66303\n",
      "Episode 9053: Reward = 591.00, Steps = 5, Loss = 15.1033, Exploration Rate = 0.1000, Train Count = 66308\n",
      "Episode 9054: Reward = 585.00, Steps = 7, Loss = 14.8149, Exploration Rate = 0.1000, Train Count = 66315\n",
      "Episode 9055: Reward = 579.00, Steps = 9, Loss = 13.5510, Exploration Rate = 0.1000, Train Count = 66324\n",
      "Episode 9056: Reward = 591.00, Steps = 5, Loss = 13.2589, Exploration Rate = 0.1000, Train Count = 66329\n",
      "Episode 9057: Reward = 591.00, Steps = 5, Loss = 11.3003, Exploration Rate = 0.1000, Train Count = 66334\n",
      "Episode 9058: Reward = 591.00, Steps = 5, Loss = 6.1796, Exploration Rate = 0.1000, Train Count = 66339\n",
      "Episode 9059: Reward = 585.00, Steps = 7, Loss = 9.2197, Exploration Rate = 0.1000, Train Count = 66346\n",
      "Episode 9060: Reward = 591.00, Steps = 5, Loss = 5.6618, Exploration Rate = 0.1000, Train Count = 66351\n",
      "Episode 9061: Reward = 591.00, Steps = 5, Loss = 5.4895, Exploration Rate = 0.1000, Train Count = 66356\n",
      "Episode 9062: Reward = 579.00, Steps = 9, Loss = 6.9431, Exploration Rate = 0.1000, Train Count = 66365\n",
      "Episode 9063: Reward = 591.00, Steps = 5, Loss = 7.7480, Exploration Rate = 0.1000, Train Count = 66370\n",
      "Episode 9064: Reward = 594.00, Steps = 4, Loss = 5.1255, Exploration Rate = 0.1000, Train Count = 66374\n",
      "Episode 9065: Reward = 597.00, Steps = 3, Loss = 1.8426, Exploration Rate = 0.1000, Train Count = 66377\n",
      "Episode 9066: Reward = 585.00, Steps = 7, Loss = 6.9698, Exploration Rate = 0.1000, Train Count = 66384\n",
      "Episode 9067: Reward = 526.00, Steps = 11, Loss = 5.7694, Exploration Rate = 0.1000, Train Count = 66395\n",
      "Episode 9068: Reward = 588.00, Steps = 6, Loss = 6.8657, Exploration Rate = 0.1000, Train Count = 66401\n",
      "Episode 9069: Reward = 579.00, Steps = 9, Loss = 7.6562, Exploration Rate = 0.1000, Train Count = 66410\n",
      "Episode 9070: Reward = 591.00, Steps = 5, Loss = 6.8237, Exploration Rate = 0.1000, Train Count = 66415\n",
      "Episode 9071: Reward = 600.00, Steps = 2, Loss = 9.8627, Exploration Rate = 0.1000, Train Count = 66417\n",
      "Episode 9072: Reward = 585.00, Steps = 7, Loss = 8.8640, Exploration Rate = 0.1000, Train Count = 66424\n",
      "Episode 9073: Reward = 591.00, Steps = 5, Loss = 9.8618, Exploration Rate = 0.1000, Train Count = 66429\n",
      "Episode 9074: Reward = 591.00, Steps = 5, Loss = 5.7135, Exploration Rate = 0.1000, Train Count = 66434\n",
      "Episode 9075: Reward = 588.00, Steps = 6, Loss = 4.4226, Exploration Rate = 0.1000, Train Count = 66440\n",
      "Episode 9076: Reward = 579.00, Steps = 9, Loss = 4.2637, Exploration Rate = 0.1000, Train Count = 66449\n",
      "Episode 9077: Reward = 597.00, Steps = 3, Loss = 3.0725, Exploration Rate = 0.1000, Train Count = 66452\n",
      "Episode 9078: Reward = 594.00, Steps = 4, Loss = 3.8089, Exploration Rate = 0.1000, Train Count = 66456\n",
      "Episode 9079: Reward = 585.00, Steps = 7, Loss = 3.5245, Exploration Rate = 0.1000, Train Count = 66463\n",
      "Episode 9080: Reward = 591.00, Steps = 5, Loss = 5.2564, Exploration Rate = 0.1000, Train Count = 66468\n",
      "Episode 9081: Reward = 597.00, Steps = 3, Loss = 4.3935, Exploration Rate = 0.1000, Train Count = 66471\n",
      "Episode 9082: Reward = 588.00, Steps = 6, Loss = 4.4319, Exploration Rate = 0.1000, Train Count = 66477\n",
      "Episode 9083: Reward = 594.00, Steps = 4, Loss = 5.8632, Exploration Rate = 0.1000, Train Count = 66481\n",
      "Episode 9084: Reward = 594.00, Steps = 4, Loss = 8.4336, Exploration Rate = 0.1000, Train Count = 66485\n",
      "Episode 9085: Reward = 597.00, Steps = 3, Loss = 7.3448, Exploration Rate = 0.1000, Train Count = 66488\n",
      "Episode 9086: Reward = 535.00, Steps = 8, Loss = 7.6178, Exploration Rate = 0.1000, Train Count = 66496\n",
      "Episode 9087: Reward = 585.00, Steps = 7, Loss = 6.4686, Exploration Rate = 0.1000, Train Count = 66503\n",
      "Episode 9088: Reward = 585.00, Steps = 7, Loss = 7.1139, Exploration Rate = 0.1000, Train Count = 66510\n",
      "Episode 9089: Reward = 591.00, Steps = 5, Loss = 8.3393, Exploration Rate = 0.1000, Train Count = 66515\n",
      "Episode 9090: Reward = 594.00, Steps = 4, Loss = 5.0991, Exploration Rate = 0.1000, Train Count = 66519\n",
      "Episode 9091: Reward = 591.00, Steps = 5, Loss = 3.8106, Exploration Rate = 0.1000, Train Count = 66524\n",
      "Episode 9092: Reward = 594.00, Steps = 4, Loss = 7.8842, Exploration Rate = 0.1000, Train Count = 66528\n",
      "Episode 9093: Reward = 591.00, Steps = 5, Loss = 4.7763, Exploration Rate = 0.1000, Train Count = 66533\n",
      "Episode 9094: Reward = 597.00, Steps = 3, Loss = 3.4662, Exploration Rate = 0.1000, Train Count = 66536\n",
      "Episode 9095: Reward = 594.00, Steps = 4, Loss = 6.0062, Exploration Rate = 0.1000, Train Count = 66540\n",
      "Episode 9096: Reward = 585.00, Steps = 7, Loss = 4.2713, Exploration Rate = 0.1000, Train Count = 66547\n",
      "Episode 9097: Reward = 588.00, Steps = 6, Loss = 5.1288, Exploration Rate = 0.1000, Train Count = 66553\n",
      "Episode 9098: Reward = 585.00, Steps = 7, Loss = 3.2965, Exploration Rate = 0.1000, Train Count = 66560\n",
      "Episode 9099: Reward = 582.00, Steps = 8, Loss = 2.4818, Exploration Rate = 0.1000, Train Count = 66568\n",
      "Episode 9100: Reward = 582.00, Steps = 8, Loss = 1.9454, Exploration Rate = 0.1000, Train Count = 66576\n",
      "Episode 9101: Reward = 579.00, Steps = 9, Loss = 5.6894, Exploration Rate = 0.1000, Train Count = 66585\n",
      "Episode 9102: Reward = 594.00, Steps = 4, Loss = 3.4861, Exploration Rate = 0.1000, Train Count = 66589\n",
      "Episode 9103: Reward = 582.00, Steps = 8, Loss = 2.6625, Exploration Rate = 0.1000, Train Count = 66597\n",
      "Episode 9104: Reward = 567.00, Steps = 13, Loss = 3.2920, Exploration Rate = 0.1000, Train Count = 66610\n",
      "Episode 9105: Reward = 591.00, Steps = 5, Loss = 4.6671, Exploration Rate = 0.1000, Train Count = 66615\n",
      "Episode 9106: Reward = 591.00, Steps = 5, Loss = 4.1976, Exploration Rate = 0.1000, Train Count = 66620\n",
      "Episode 9107: Reward = 579.00, Steps = 9, Loss = 5.1527, Exploration Rate = 0.1000, Train Count = 66629\n",
      "Episode 9108: Reward = 597.00, Steps = 3, Loss = 1.0744, Exploration Rate = 0.1000, Train Count = 66632\n",
      "Episode 9109: Reward = 585.00, Steps = 7, Loss = 2.9809, Exploration Rate = 0.1000, Train Count = 66639\n",
      "Episode 9110: Reward = 582.00, Steps = 8, Loss = 3.6190, Exploration Rate = 0.1000, Train Count = 66647\n",
      "Episode 9111: Reward = 582.00, Steps = 8, Loss = 5.6975, Exploration Rate = 0.1000, Train Count = 66655\n",
      "Episode 9112: Reward = 579.00, Steps = 9, Loss = 2.5996, Exploration Rate = 0.1000, Train Count = 66664\n",
      "Episode 9113: Reward = 579.00, Steps = 9, Loss = 5.7481, Exploration Rate = 0.1000, Train Count = 66673\n",
      "Episode 9114: Reward = 594.00, Steps = 4, Loss = 5.6644, Exploration Rate = 0.1000, Train Count = 66677\n",
      "Episode 9115: Reward = 600.00, Steps = 2, Loss = 4.1672, Exploration Rate = 0.1000, Train Count = 66679\n",
      "Episode 9116: Reward = 585.00, Steps = 7, Loss = 6.0201, Exploration Rate = 0.1000, Train Count = 66686\n",
      "Episode 9117: Reward = 582.00, Steps = 8, Loss = 3.4107, Exploration Rate = 0.1000, Train Count = 66694\n",
      "Episode 9118: Reward = 582.00, Steps = 8, Loss = 4.6287, Exploration Rate = 0.1000, Train Count = 66702\n",
      "Episode 9119: Reward = 576.00, Steps = 10, Loss = 7.1974, Exploration Rate = 0.1000, Train Count = 66712\n",
      "Episode 9120: Reward = 591.00, Steps = 5, Loss = 5.9373, Exploration Rate = 0.1000, Train Count = 66717\n",
      "Episode 9121: Reward = 597.00, Steps = 3, Loss = 3.4536, Exploration Rate = 0.1000, Train Count = 66720\n",
      "Episode 9122: Reward = 591.00, Steps = 5, Loss = 4.2815, Exploration Rate = 0.1000, Train Count = 66725\n",
      "Episode 9123: Reward = 555.00, Steps = 17, Loss = 5.3303, Exploration Rate = 0.1000, Train Count = 66742\n",
      "Episode 9124: Reward = 588.00, Steps = 6, Loss = 7.2875, Exploration Rate = 0.1000, Train Count = 66748\n",
      "Episode 9125: Reward = 588.00, Steps = 6, Loss = 6.2423, Exploration Rate = 0.1000, Train Count = 66754\n",
      "Episode 9126: Reward = 588.00, Steps = 6, Loss = 4.4075, Exploration Rate = 0.1000, Train Count = 66760\n",
      "Episode 9127: Reward = 532.00, Steps = 9, Loss = 8.9776, Exploration Rate = 0.1000, Train Count = 66769\n",
      "Episode 9128: Reward = 588.00, Steps = 6, Loss = 10.2504, Exploration Rate = 0.1000, Train Count = 66775\n",
      "Episode 9129: Reward = 585.00, Steps = 7, Loss = 6.4720, Exploration Rate = 0.1000, Train Count = 66782\n",
      "Episode 9130: Reward = 594.00, Steps = 4, Loss = 8.2198, Exploration Rate = 0.1000, Train Count = 66786\n",
      "Episode 9131: Reward = 579.00, Steps = 9, Loss = 5.9654, Exploration Rate = 0.1000, Train Count = 66795\n",
      "Episode 9132: Reward = 591.00, Steps = 5, Loss = 5.2453, Exploration Rate = 0.1000, Train Count = 66800\n",
      "Episode 9133: Reward = 570.00, Steps = 12, Loss = 19.8715, Exploration Rate = 0.1000, Train Count = 66812\n",
      "Episode 9134: Reward = 594.00, Steps = 4, Loss = 12.2425, Exploration Rate = 0.1000, Train Count = 66816\n",
      "Episode 9135: Reward = 585.00, Steps = 7, Loss = 12.1826, Exploration Rate = 0.1000, Train Count = 66823\n",
      "Episode 9136: Reward = 591.00, Steps = 5, Loss = 8.1259, Exploration Rate = 0.1000, Train Count = 66828\n",
      "Episode 9137: Reward = 585.00, Steps = 7, Loss = 7.7054, Exploration Rate = 0.1000, Train Count = 66835\n",
      "Episode 9138: Reward = 523.00, Steps = 12, Loss = 8.0421, Exploration Rate = 0.1000, Train Count = 66847\n",
      "Episode 9139: Reward = 585.00, Steps = 7, Loss = 5.2508, Exploration Rate = 0.1000, Train Count = 66854\n",
      "Episode 9140: Reward = 547.00, Steps = 4, Loss = 6.6000, Exploration Rate = 0.1000, Train Count = 66858\n",
      "Episode 9141: Reward = 579.00, Steps = 9, Loss = 5.9387, Exploration Rate = 0.1000, Train Count = 66867\n",
      "Episode 9142: Reward = 597.00, Steps = 3, Loss = 5.8469, Exploration Rate = 0.1000, Train Count = 66870\n",
      "Episode 9143: Reward = 573.00, Steps = 11, Loss = 5.3838, Exploration Rate = 0.1000, Train Count = 66881\n",
      "Episode 9144: Reward = 594.00, Steps = 4, Loss = 4.5575, Exploration Rate = 0.1000, Train Count = 66885\n",
      "Episode 9145: Reward = 541.00, Steps = 6, Loss = 4.3247, Exploration Rate = 0.1000, Train Count = 66891\n",
      "Episode 9146: Reward = 567.00, Steps = 13, Loss = 3.9808, Exploration Rate = 0.1000, Train Count = 66904\n",
      "Episode 9147: Reward = 591.00, Steps = 5, Loss = 3.3243, Exploration Rate = 0.1000, Train Count = 66909\n",
      "Episode 9148: Reward = 591.00, Steps = 5, Loss = 3.1724, Exploration Rate = 0.1000, Train Count = 66914\n",
      "Episode 9149: Reward = 594.00, Steps = 4, Loss = 3.1607, Exploration Rate = 0.1000, Train Count = 66918\n",
      "Episode 9150: Reward = 585.00, Steps = 7, Loss = 3.8757, Exploration Rate = 0.1000, Train Count = 66925\n",
      "Episode 9151: Reward = 588.00, Steps = 6, Loss = 3.0611, Exploration Rate = 0.1000, Train Count = 66931\n",
      "Episode 9152: Reward = 564.00, Steps = 14, Loss = 3.5271, Exploration Rate = 0.1000, Train Count = 66945\n",
      "Episode 9153: Reward = 588.00, Steps = 6, Loss = 2.2720, Exploration Rate = 0.1000, Train Count = 66951\n",
      "Episode 9154: Reward = 582.00, Steps = 8, Loss = 7.1225, Exploration Rate = 0.1000, Train Count = 66959\n",
      "Episode 9155: Reward = 485.00, Steps = 9, Loss = 12.7919, Exploration Rate = 0.1000, Train Count = 66968\n",
      "Episode 9156: Reward = 594.00, Steps = 4, Loss = 17.3034, Exploration Rate = 0.1000, Train Count = 66972\n",
      "Episode 9157: Reward = 591.00, Steps = 5, Loss = 9.2166, Exploration Rate = 0.1000, Train Count = 66977\n",
      "Episode 9158: Reward = 588.00, Steps = 6, Loss = 4.9235, Exploration Rate = 0.1000, Train Count = 66983\n",
      "Episode 9159: Reward = 585.00, Steps = 7, Loss = 4.3898, Exploration Rate = 0.1000, Train Count = 66990\n",
      "Episode 9160: Reward = 588.00, Steps = 6, Loss = 3.6781, Exploration Rate = 0.1000, Train Count = 66996\n",
      "Episode 9161: Reward = 588.00, Steps = 6, Loss = 4.8438, Exploration Rate = 0.1000, Train Count = 67002\n",
      "Episode 9162: Reward = 585.00, Steps = 7, Loss = 3.6830, Exploration Rate = 0.1000, Train Count = 67009\n",
      "Episode 9163: Reward = 591.00, Steps = 5, Loss = 1.4619, Exploration Rate = 0.1000, Train Count = 67014\n",
      "Episode 9164: Reward = 591.00, Steps = 5, Loss = 2.7557, Exploration Rate = 0.1000, Train Count = 67019\n",
      "Episode 9165: Reward = 573.00, Steps = 11, Loss = 2.6582, Exploration Rate = 0.1000, Train Count = 67030\n",
      "Episode 9166: Reward = 585.00, Steps = 7, Loss = 1.6567, Exploration Rate = 0.1000, Train Count = 67037\n",
      "Episode 9167: Reward = 585.00, Steps = 7, Loss = 6.1904, Exploration Rate = 0.1000, Train Count = 67044\n",
      "Episode 9168: Reward = 591.00, Steps = 5, Loss = 3.4789, Exploration Rate = 0.1000, Train Count = 67049\n",
      "Episode 9169: Reward = 594.00, Steps = 4, Loss = 7.9455, Exploration Rate = 0.1000, Train Count = 67053\n",
      "Episode 9170: Reward = 591.00, Steps = 5, Loss = 3.5289, Exploration Rate = 0.1000, Train Count = 67058\n",
      "Episode 9171: Reward = 594.00, Steps = 4, Loss = 2.3794, Exploration Rate = 0.1000, Train Count = 67062\n",
      "Episode 9172: Reward = 588.00, Steps = 6, Loss = 2.6552, Exploration Rate = 0.1000, Train Count = 67068\n",
      "Episode 9173: Reward = 591.00, Steps = 5, Loss = 3.1061, Exploration Rate = 0.1000, Train Count = 67073\n",
      "Episode 9174: Reward = 588.00, Steps = 6, Loss = 1.6013, Exploration Rate = 0.1000, Train Count = 67079\n",
      "Episode 9175: Reward = 588.00, Steps = 6, Loss = 2.0643, Exploration Rate = 0.1000, Train Count = 67085\n",
      "Episode 9176: Reward = 591.00, Steps = 5, Loss = 2.1581, Exploration Rate = 0.1000, Train Count = 67090\n",
      "Episode 9177: Reward = 594.00, Steps = 4, Loss = 3.3547, Exploration Rate = 0.1000, Train Count = 67094\n",
      "Episode 9178: Reward = 594.00, Steps = 4, Loss = 3.0127, Exploration Rate = 0.1000, Train Count = 67098\n",
      "Episode 9179: Reward = 582.00, Steps = 8, Loss = 2.1284, Exploration Rate = 0.1000, Train Count = 67106\n",
      "Episode 9180: Reward = 591.00, Steps = 5, Loss = 1.5655, Exploration Rate = 0.1000, Train Count = 67111\n",
      "Episode 9181: Reward = 585.00, Steps = 7, Loss = 1.6521, Exploration Rate = 0.1000, Train Count = 67118\n",
      "Episode 9182: Reward = 535.00, Steps = 8, Loss = 2.1344, Exploration Rate = 0.1000, Train Count = 67126\n",
      "Episode 9183: Reward = 585.00, Steps = 7, Loss = 3.3859, Exploration Rate = 0.1000, Train Count = 67133\n",
      "Episode 9184: Reward = 576.00, Steps = 10, Loss = 4.3686, Exploration Rate = 0.1000, Train Count = 67143\n",
      "Episode 9185: Reward = 594.00, Steps = 4, Loss = 3.9789, Exploration Rate = 0.1000, Train Count = 67147\n",
      "Episode 9186: Reward = 597.00, Steps = 3, Loss = 3.3463, Exploration Rate = 0.1000, Train Count = 67150\n",
      "Episode 9187: Reward = 600.00, Steps = 2, Loss = 1.7325, Exploration Rate = 0.1000, Train Count = 67152\n",
      "Episode 9188: Reward = 597.00, Steps = 3, Loss = 2.3503, Exploration Rate = 0.1000, Train Count = 67155\n",
      "Episode 9189: Reward = 597.00, Steps = 3, Loss = 3.2677, Exploration Rate = 0.1000, Train Count = 67158\n",
      "Episode 9190: Reward = 594.00, Steps = 4, Loss = 2.8799, Exploration Rate = 0.1000, Train Count = 67162\n",
      "Episode 9191: Reward = 594.00, Steps = 4, Loss = 2.7376, Exploration Rate = 0.1000, Train Count = 67166\n",
      "Episode 9192: Reward = 597.00, Steps = 3, Loss = 1.8954, Exploration Rate = 0.1000, Train Count = 67169\n",
      "Episode 9193: Reward = 582.00, Steps = 8, Loss = 4.4053, Exploration Rate = 0.1000, Train Count = 67177\n",
      "Episode 9194: Reward = 585.00, Steps = 7, Loss = 3.1754, Exploration Rate = 0.1000, Train Count = 67184\n",
      "Episode 9195: Reward = 594.00, Steps = 4, Loss = 3.6705, Exploration Rate = 0.1000, Train Count = 67188\n",
      "Episode 9196: Reward = 600.00, Steps = 2, Loss = 2.3624, Exploration Rate = 0.1000, Train Count = 67190\n",
      "Episode 9197: Reward = 585.00, Steps = 7, Loss = 4.8884, Exploration Rate = 0.1000, Train Count = 67197\n",
      "Episode 9198: Reward = 570.00, Steps = 12, Loss = 3.1489, Exploration Rate = 0.1000, Train Count = 67209\n",
      "Episode 9199: Reward = 600.00, Steps = 2, Loss = 2.8014, Exploration Rate = 0.1000, Train Count = 67211\n",
      "Episode 9200: Reward = 588.00, Steps = 6, Loss = 3.2384, Exploration Rate = 0.1000, Train Count = 67217\n",
      "Episode 9201: Reward = 591.00, Steps = 5, Loss = 1.9209, Exploration Rate = 0.1000, Train Count = 67222\n",
      "Episode 9202: Reward = 585.00, Steps = 7, Loss = 5.3987, Exploration Rate = 0.1000, Train Count = 67229\n",
      "Episode 9203: Reward = 600.00, Steps = 2, Loss = 5.2096, Exploration Rate = 0.1000, Train Count = 67231\n",
      "Episode 9204: Reward = 594.00, Steps = 4, Loss = 4.0909, Exploration Rate = 0.1000, Train Count = 67235\n",
      "Episode 9205: Reward = 591.00, Steps = 5, Loss = 5.0799, Exploration Rate = 0.1000, Train Count = 67240\n",
      "Episode 9206: Reward = 597.00, Steps = 3, Loss = 2.5432, Exploration Rate = 0.1000, Train Count = 67243\n",
      "Episode 9207: Reward = 588.00, Steps = 6, Loss = 4.6728, Exploration Rate = 0.1000, Train Count = 67249\n",
      "Episode 9208: Reward = 588.00, Steps = 6, Loss = 2.1514, Exploration Rate = 0.1000, Train Count = 67255\n",
      "Episode 9209: Reward = 597.00, Steps = 3, Loss = 2.0955, Exploration Rate = 0.1000, Train Count = 67258\n",
      "Episode 9210: Reward = 591.00, Steps = 5, Loss = 1.7260, Exploration Rate = 0.1000, Train Count = 67263\n",
      "Episode 9211: Reward = 585.00, Steps = 7, Loss = 2.9472, Exploration Rate = 0.1000, Train Count = 67270\n",
      "Episode 9212: Reward = 585.00, Steps = 7, Loss = 1.5485, Exploration Rate = 0.1000, Train Count = 67277\n",
      "Episode 9213: Reward = 582.00, Steps = 8, Loss = 1.1037, Exploration Rate = 0.1000, Train Count = 67285\n",
      "Episode 9214: Reward = 576.00, Steps = 10, Loss = 1.4882, Exploration Rate = 0.1000, Train Count = 67295\n",
      "Episode 9215: Reward = 591.00, Steps = 5, Loss = 0.9493, Exploration Rate = 0.1000, Train Count = 67300\n",
      "Episode 9216: Reward = 591.00, Steps = 5, Loss = 14.7247, Exploration Rate = 0.1000, Train Count = 67305\n",
      "Episode 9217: Reward = 588.00, Steps = 6, Loss = 12.7211, Exploration Rate = 0.1000, Train Count = 67311\n",
      "Episode 9218: Reward = 585.00, Steps = 7, Loss = 8.7447, Exploration Rate = 0.1000, Train Count = 67318\n",
      "Episode 9219: Reward = 591.00, Steps = 5, Loss = 12.2034, Exploration Rate = 0.1000, Train Count = 67323\n",
      "Episode 9220: Reward = 597.00, Steps = 3, Loss = 9.4292, Exploration Rate = 0.1000, Train Count = 67326\n",
      "Episode 9221: Reward = 591.00, Steps = 5, Loss = 6.6930, Exploration Rate = 0.1000, Train Count = 67331\n",
      "Episode 9222: Reward = 597.00, Steps = 3, Loss = 5.6534, Exploration Rate = 0.1000, Train Count = 67334\n",
      "Episode 9223: Reward = 588.00, Steps = 6, Loss = 4.9292, Exploration Rate = 0.1000, Train Count = 67340\n",
      "Episode 9224: Reward = 588.00, Steps = 6, Loss = 5.3979, Exploration Rate = 0.1000, Train Count = 67346\n",
      "Episode 9225: Reward = 588.00, Steps = 6, Loss = 3.8759, Exploration Rate = 0.1000, Train Count = 67352\n",
      "Episode 9226: Reward = 582.00, Steps = 8, Loss = 3.2854, Exploration Rate = 0.1000, Train Count = 67360\n",
      "Episode 9227: Reward = 591.00, Steps = 5, Loss = 2.3851, Exploration Rate = 0.1000, Train Count = 67365\n",
      "Episode 9228: Reward = 594.00, Steps = 4, Loss = 1.8611, Exploration Rate = 0.1000, Train Count = 67369\n",
      "Episode 9229: Reward = 594.00, Steps = 4, Loss = 1.8473, Exploration Rate = 0.1000, Train Count = 67373\n",
      "Episode 9230: Reward = 594.00, Steps = 4, Loss = 1.8896, Exploration Rate = 0.1000, Train Count = 67377\n",
      "Episode 9231: Reward = 591.00, Steps = 5, Loss = 1.3959, Exploration Rate = 0.1000, Train Count = 67382\n",
      "Episode 9232: Reward = 597.00, Steps = 3, Loss = 1.5024, Exploration Rate = 0.1000, Train Count = 67385\n",
      "Episode 9233: Reward = 594.00, Steps = 4, Loss = 1.5164, Exploration Rate = 0.1000, Train Count = 67389\n",
      "Episode 9234: Reward = 588.00, Steps = 6, Loss = 1.1826, Exploration Rate = 0.1000, Train Count = 67395\n",
      "Episode 9235: Reward = 594.00, Steps = 4, Loss = 3.3628, Exploration Rate = 0.1000, Train Count = 67399\n",
      "Episode 9236: Reward = 588.00, Steps = 6, Loss = 1.3689, Exploration Rate = 0.1000, Train Count = 67405\n",
      "Episode 9237: Reward = 591.00, Steps = 5, Loss = 0.7136, Exploration Rate = 0.1000, Train Count = 67410\n",
      "Episode 9238: Reward = 600.00, Steps = 2, Loss = 1.3755, Exploration Rate = 0.1000, Train Count = 67412\n",
      "Episode 9239: Reward = 588.00, Steps = 6, Loss = 1.7313, Exploration Rate = 0.1000, Train Count = 67418\n",
      "Episode 9240: Reward = 585.00, Steps = 7, Loss = 1.7901, Exploration Rate = 0.1000, Train Count = 67425\n",
      "Episode 9241: Reward = 591.00, Steps = 5, Loss = 1.7926, Exploration Rate = 0.1000, Train Count = 67430\n",
      "Episode 9242: Reward = 591.00, Steps = 5, Loss = 0.7427, Exploration Rate = 0.1000, Train Count = 67435\n",
      "Episode 9243: Reward = 591.00, Steps = 5, Loss = 1.8260, Exploration Rate = 0.1000, Train Count = 67440\n",
      "Episode 9244: Reward = 585.00, Steps = 7, Loss = 1.7782, Exploration Rate = 0.1000, Train Count = 67447\n",
      "Episode 9245: Reward = 588.00, Steps = 6, Loss = 1.6839, Exploration Rate = 0.1000, Train Count = 67453\n",
      "Episode 9246: Reward = 594.00, Steps = 4, Loss = 2.0783, Exploration Rate = 0.1000, Train Count = 67457\n",
      "Episode 9247: Reward = 585.00, Steps = 7, Loss = 1.3367, Exploration Rate = 0.1000, Train Count = 67464\n",
      "Episode 9248: Reward = 576.00, Steps = 10, Loss = 1.8669, Exploration Rate = 0.1000, Train Count = 67474\n",
      "Episode 9249: Reward = 591.00, Steps = 5, Loss = 1.2326, Exploration Rate = 0.1000, Train Count = 67479\n",
      "Episode 9250: Reward = 594.00, Steps = 4, Loss = 1.9202, Exploration Rate = 0.1000, Train Count = 67483\n",
      "Episode 9251: Reward = 594.00, Steps = 4, Loss = 2.0830, Exploration Rate = 0.1000, Train Count = 67487\n",
      "Episode 9252: Reward = 588.00, Steps = 6, Loss = 2.8319, Exploration Rate = 0.1000, Train Count = 67493\n",
      "Episode 9253: Reward = 582.00, Steps = 8, Loss = 2.0593, Exploration Rate = 0.1000, Train Count = 67501\n",
      "Episode 9254: Reward = 591.00, Steps = 5, Loss = 2.1153, Exploration Rate = 0.1000, Train Count = 67506\n",
      "Episode 9255: Reward = 594.00, Steps = 4, Loss = 2.3819, Exploration Rate = 0.1000, Train Count = 67510\n",
      "Episode 9256: Reward = 597.00, Steps = 3, Loss = 3.8166, Exploration Rate = 0.1000, Train Count = 67513\n",
      "Episode 9257: Reward = 585.00, Steps = 7, Loss = 2.1717, Exploration Rate = 0.1000, Train Count = 67520\n",
      "Episode 9258: Reward = 594.00, Steps = 4, Loss = 1.8612, Exploration Rate = 0.1000, Train Count = 67524\n",
      "Episode 9259: Reward = 576.00, Steps = 10, Loss = 1.3732, Exploration Rate = 0.1000, Train Count = 67534\n",
      "Episode 9260: Reward = 573.00, Steps = 11, Loss = 1.3194, Exploration Rate = 0.1000, Train Count = 67545\n",
      "Episode 9261: Reward = 591.00, Steps = 5, Loss = 0.9807, Exploration Rate = 0.1000, Train Count = 67550\n",
      "Episode 9262: Reward = 579.00, Steps = 9, Loss = 1.1130, Exploration Rate = 0.1000, Train Count = 67559\n",
      "Episode 9263: Reward = 582.00, Steps = 8, Loss = 1.9370, Exploration Rate = 0.1000, Train Count = 67567\n",
      "Episode 9264: Reward = 585.00, Steps = 7, Loss = 1.2779, Exploration Rate = 0.1000, Train Count = 67574\n",
      "Episode 9265: Reward = 588.00, Steps = 6, Loss = 0.8348, Exploration Rate = 0.1000, Train Count = 67580\n",
      "Episode 9266: Reward = 579.00, Steps = 9, Loss = 5.5447, Exploration Rate = 0.1000, Train Count = 67589\n",
      "Episode 9267: Reward = 582.00, Steps = 8, Loss = 3.5797, Exploration Rate = 0.1000, Train Count = 67597\n",
      "Episode 9268: Reward = 594.00, Steps = 4, Loss = 1.9790, Exploration Rate = 0.1000, Train Count = 67601\n",
      "Episode 9269: Reward = 594.00, Steps = 4, Loss = 1.3973, Exploration Rate = 0.1000, Train Count = 67605\n",
      "Episode 9270: Reward = 597.00, Steps = 3, Loss = 2.3615, Exploration Rate = 0.1000, Train Count = 67608\n",
      "Episode 9271: Reward = 594.00, Steps = 4, Loss = 1.7809, Exploration Rate = 0.1000, Train Count = 67612\n",
      "Episode 9272: Reward = 594.00, Steps = 4, Loss = 1.5670, Exploration Rate = 0.1000, Train Count = 67616\n",
      "Episode 9273: Reward = 591.00, Steps = 5, Loss = 0.9741, Exploration Rate = 0.1000, Train Count = 67621\n",
      "Episode 9274: Reward = 585.00, Steps = 7, Loss = 1.4111, Exploration Rate = 0.1000, Train Count = 67628\n",
      "Episode 9275: Reward = 597.00, Steps = 3, Loss = 1.1841, Exploration Rate = 0.1000, Train Count = 67631\n",
      "Episode 9276: Reward = 576.00, Steps = 10, Loss = 2.0853, Exploration Rate = 0.1000, Train Count = 67641\n",
      "Episode 9277: Reward = 585.00, Steps = 7, Loss = 2.1849, Exploration Rate = 0.1000, Train Count = 67648\n",
      "Episode 9278: Reward = 582.00, Steps = 8, Loss = 1.2248, Exploration Rate = 0.1000, Train Count = 67656\n",
      "Episode 9279: Reward = 594.00, Steps = 4, Loss = 0.9589, Exploration Rate = 0.1000, Train Count = 67660\n",
      "Episode 9280: Reward = 594.00, Steps = 4, Loss = 1.2659, Exploration Rate = 0.1000, Train Count = 67664\n",
      "Episode 9281: Reward = 582.00, Steps = 8, Loss = 1.9060, Exploration Rate = 0.1000, Train Count = 67672\n",
      "Episode 9282: Reward = 594.00, Steps = 4, Loss = 1.1831, Exploration Rate = 0.1000, Train Count = 67676\n",
      "Episode 9283: Reward = 591.00, Steps = 5, Loss = 1.3560, Exploration Rate = 0.1000, Train Count = 67681\n",
      "Episode 9284: Reward = 594.00, Steps = 4, Loss = 1.1359, Exploration Rate = 0.1000, Train Count = 67685\n",
      "Episode 9285: Reward = 585.00, Steps = 7, Loss = 1.2356, Exploration Rate = 0.1000, Train Count = 67692\n",
      "Episode 9286: Reward = 579.00, Steps = 9, Loss = 0.9783, Exploration Rate = 0.1000, Train Count = 67701\n",
      "Episode 9287: Reward = 597.00, Steps = 3, Loss = 0.6757, Exploration Rate = 0.1000, Train Count = 67704\n",
      "Episode 9288: Reward = 591.00, Steps = 5, Loss = 1.4374, Exploration Rate = 0.1000, Train Count = 67709\n",
      "Episode 9289: Reward = 591.00, Steps = 5, Loss = 2.0112, Exploration Rate = 0.1000, Train Count = 67714\n",
      "Episode 9290: Reward = 585.00, Steps = 7, Loss = 1.3830, Exploration Rate = 0.1000, Train Count = 67721\n",
      "Episode 9291: Reward = 591.00, Steps = 5, Loss = 0.8582, Exploration Rate = 0.1000, Train Count = 67726\n",
      "Episode 9292: Reward = 591.00, Steps = 5, Loss = 1.0316, Exploration Rate = 0.1000, Train Count = 67731\n",
      "Episode 9293: Reward = 594.00, Steps = 4, Loss = 1.1647, Exploration Rate = 0.1000, Train Count = 67735\n",
      "Episode 9294: Reward = 579.00, Steps = 9, Loss = 0.9722, Exploration Rate = 0.1000, Train Count = 67744\n",
      "Episode 9295: Reward = 594.00, Steps = 4, Loss = 1.0249, Exploration Rate = 0.1000, Train Count = 67748\n",
      "Episode 9296: Reward = 585.00, Steps = 7, Loss = 0.8394, Exploration Rate = 0.1000, Train Count = 67755\n",
      "Episode 9297: Reward = 594.00, Steps = 4, Loss = 0.5811, Exploration Rate = 0.1000, Train Count = 67759\n",
      "Episode 9298: Reward = 594.00, Steps = 4, Loss = 0.7912, Exploration Rate = 0.1000, Train Count = 67763\n",
      "Episode 9299: Reward = 594.00, Steps = 4, Loss = 0.9957, Exploration Rate = 0.1000, Train Count = 67767\n",
      "Episode 9300: Reward = 594.00, Steps = 4, Loss = 0.6044, Exploration Rate = 0.1000, Train Count = 67771\n",
      "Episode 9301: Reward = 594.00, Steps = 4, Loss = 0.9504, Exploration Rate = 0.1000, Train Count = 67775\n",
      "Episode 9302: Reward = 591.00, Steps = 5, Loss = 1.1641, Exploration Rate = 0.1000, Train Count = 67780\n",
      "Episode 9303: Reward = 570.00, Steps = 12, Loss = 4.4997, Exploration Rate = 0.1000, Train Count = 67792\n",
      "Episode 9304: Reward = 582.00, Steps = 8, Loss = 2.4258, Exploration Rate = 0.1000, Train Count = 67800\n",
      "Episode 9305: Reward = 600.00, Steps = 2, Loss = 12.5210, Exploration Rate = 0.1000, Train Count = 67802\n",
      "Episode 9306: Reward = 541.00, Steps = 6, Loss = 15.4976, Exploration Rate = 0.1000, Train Count = 67808\n",
      "Episode 9307: Reward = 579.00, Steps = 9, Loss = 11.2234, Exploration Rate = 0.1000, Train Count = 67817\n",
      "Episode 9308: Reward = 582.00, Steps = 8, Loss = 9.7879, Exploration Rate = 0.1000, Train Count = 67825\n",
      "Episode 9309: Reward = 582.00, Steps = 8, Loss = 7.1681, Exploration Rate = 0.1000, Train Count = 67833\n",
      "Episode 9310: Reward = 585.00, Steps = 7, Loss = 4.8629, Exploration Rate = 0.1000, Train Count = 67840\n",
      "Episode 9311: Reward = 591.00, Steps = 5, Loss = 4.9056, Exploration Rate = 0.1000, Train Count = 67845\n",
      "Episode 9312: Reward = 588.00, Steps = 6, Loss = 3.2340, Exploration Rate = 0.1000, Train Count = 67851\n",
      "Episode 9313: Reward = 600.00, Steps = 2, Loss = 4.6584, Exploration Rate = 0.1000, Train Count = 67853\n",
      "Episode 9314: Reward = 591.00, Steps = 5, Loss = 3.1982, Exploration Rate = 0.1000, Train Count = 67858\n",
      "Episode 9315: Reward = 582.00, Steps = 8, Loss = 2.5606, Exploration Rate = 0.1000, Train Count = 67866\n",
      "Episode 9316: Reward = 591.00, Steps = 5, Loss = 1.9447, Exploration Rate = 0.1000, Train Count = 67871\n",
      "Episode 9317: Reward = 535.00, Steps = 8, Loss = 2.8246, Exploration Rate = 0.1000, Train Count = 67879\n",
      "Episode 9318: Reward = 594.00, Steps = 4, Loss = 5.9316, Exploration Rate = 0.1000, Train Count = 67883\n",
      "Episode 9319: Reward = 579.00, Steps = 9, Loss = 2.6382, Exploration Rate = 0.1000, Train Count = 67892\n",
      "Episode 9320: Reward = 594.00, Steps = 4, Loss = 3.2861, Exploration Rate = 0.1000, Train Count = 67896\n",
      "Episode 9321: Reward = 588.00, Steps = 6, Loss = 7.6478, Exploration Rate = 0.1000, Train Count = 67902\n",
      "Episode 9322: Reward = 579.00, Steps = 9, Loss = 6.0707, Exploration Rate = 0.1000, Train Count = 67911\n",
      "Episode 9323: Reward = 594.00, Steps = 4, Loss = 5.9846, Exploration Rate = 0.1000, Train Count = 67915\n",
      "Episode 9324: Reward = 594.00, Steps = 4, Loss = 3.5949, Exploration Rate = 0.1000, Train Count = 67919\n",
      "Episode 9325: Reward = 597.00, Steps = 3, Loss = 4.9360, Exploration Rate = 0.1000, Train Count = 67922\n",
      "Episode 9326: Reward = 594.00, Steps = 4, Loss = 3.5502, Exploration Rate = 0.1000, Train Count = 67926\n",
      "Episode 9327: Reward = 591.00, Steps = 5, Loss = 3.2900, Exploration Rate = 0.1000, Train Count = 67931\n",
      "Episode 9328: Reward = 585.00, Steps = 7, Loss = 7.0541, Exploration Rate = 0.1000, Train Count = 67938\n",
      "Episode 9329: Reward = 594.00, Steps = 4, Loss = 3.3980, Exploration Rate = 0.1000, Train Count = 67942\n",
      "Episode 9330: Reward = 591.00, Steps = 5, Loss = 2.3189, Exploration Rate = 0.1000, Train Count = 67947\n",
      "Episode 9331: Reward = 600.00, Steps = 2, Loss = 3.5612, Exploration Rate = 0.1000, Train Count = 67949\n",
      "Episode 9332: Reward = 591.00, Steps = 5, Loss = 2.2857, Exploration Rate = 0.1000, Train Count = 67954\n",
      "Episode 9333: Reward = 591.00, Steps = 5, Loss = 2.0419, Exploration Rate = 0.1000, Train Count = 67959\n",
      "Episode 9334: Reward = 573.00, Steps = 11, Loss = 3.3819, Exploration Rate = 0.1000, Train Count = 67970\n",
      "Episode 9335: Reward = 597.00, Steps = 3, Loss = 2.6801, Exploration Rate = 0.1000, Train Count = 67973\n",
      "Episode 9336: Reward = 597.00, Steps = 3, Loss = 4.5169, Exploration Rate = 0.1000, Train Count = 67976\n",
      "Episode 9337: Reward = 600.00, Steps = 2, Loss = 1.9643, Exploration Rate = 0.1000, Train Count = 67978\n",
      "Episode 9338: Reward = 594.00, Steps = 4, Loss = 5.6373, Exploration Rate = 0.1000, Train Count = 67982\n",
      "Episode 9339: Reward = 588.00, Steps = 6, Loss = 3.3500, Exploration Rate = 0.1000, Train Count = 67988\n",
      "Episode 9340: Reward = 585.00, Steps = 7, Loss = 5.1862, Exploration Rate = 0.1000, Train Count = 67995\n",
      "Episode 9341: Reward = 541.00, Steps = 6, Loss = 4.9298, Exploration Rate = 0.1000, Train Count = 68001\n",
      "Episode 9342: Reward = 582.00, Steps = 8, Loss = 3.1573, Exploration Rate = 0.1000, Train Count = 68009\n",
      "Episode 9343: Reward = 588.00, Steps = 6, Loss = 2.2591, Exploration Rate = 0.1000, Train Count = 68015\n",
      "Episode 9344: Reward = 594.00, Steps = 4, Loss = 4.0542, Exploration Rate = 0.1000, Train Count = 68019\n",
      "Episode 9345: Reward = 535.00, Steps = 8, Loss = 4.6998, Exploration Rate = 0.1000, Train Count = 68027\n",
      "Episode 9346: Reward = 600.00, Steps = 2, Loss = 6.8174, Exploration Rate = 0.1000, Train Count = 68029\n",
      "Episode 9347: Reward = 582.00, Steps = 8, Loss = 5.6653, Exploration Rate = 0.1000, Train Count = 68037\n",
      "Episode 9348: Reward = 594.00, Steps = 4, Loss = 4.1564, Exploration Rate = 0.1000, Train Count = 68041\n",
      "Episode 9349: Reward = 538.00, Steps = 7, Loss = 3.3324, Exploration Rate = 0.1000, Train Count = 68048\n",
      "Episode 9350: Reward = 576.00, Steps = 10, Loss = 3.0579, Exploration Rate = 0.1000, Train Count = 68058\n",
      "Episode 9351: Reward = 582.00, Steps = 8, Loss = 4.2404, Exploration Rate = 0.1000, Train Count = 68066\n",
      "Episode 9352: Reward = 597.00, Steps = 3, Loss = 16.5677, Exploration Rate = 0.1000, Train Count = 68069\n",
      "Episode 9353: Reward = 588.00, Steps = 6, Loss = 6.4662, Exploration Rate = 0.1000, Train Count = 68075\n",
      "Episode 9354: Reward = 594.00, Steps = 4, Loss = 4.8416, Exploration Rate = 0.1000, Train Count = 68079\n",
      "Episode 9355: Reward = 594.00, Steps = 4, Loss = 3.4498, Exploration Rate = 0.1000, Train Count = 68083\n",
      "Episode 9356: Reward = 591.00, Steps = 5, Loss = 4.5682, Exploration Rate = 0.1000, Train Count = 68088\n",
      "Episode 9357: Reward = 600.00, Steps = 2, Loss = 7.2708, Exploration Rate = 0.1000, Train Count = 68090\n",
      "Episode 9358: Reward = 588.00, Steps = 6, Loss = 3.5337, Exploration Rate = 0.1000, Train Count = 68096\n",
      "Episode 9359: Reward = 591.00, Steps = 5, Loss = 3.3124, Exploration Rate = 0.1000, Train Count = 68101\n",
      "Episode 9360: Reward = 597.00, Steps = 3, Loss = 4.3911, Exploration Rate = 0.1000, Train Count = 68104\n",
      "Episode 9361: Reward = 582.00, Steps = 8, Loss = 3.4590, Exploration Rate = 0.1000, Train Count = 68112\n",
      "Episode 9362: Reward = 570.00, Steps = 12, Loss = 4.5458, Exploration Rate = 0.1000, Train Count = 68124\n",
      "Episode 9363: Reward = 585.00, Steps = 7, Loss = 3.7278, Exploration Rate = 0.1000, Train Count = 68131\n",
      "Episode 9364: Reward = 591.00, Steps = 5, Loss = 3.2003, Exploration Rate = 0.1000, Train Count = 68136\n",
      "Episode 9365: Reward = 591.00, Steps = 5, Loss = 2.4733, Exploration Rate = 0.1000, Train Count = 68141\n",
      "Episode 9366: Reward = 585.00, Steps = 7, Loss = 2.1720, Exploration Rate = 0.1000, Train Count = 68148\n",
      "Episode 9367: Reward = 591.00, Steps = 5, Loss = 1.8440, Exploration Rate = 0.1000, Train Count = 68153\n",
      "Episode 9368: Reward = 585.00, Steps = 7, Loss = 5.3470, Exploration Rate = 0.1000, Train Count = 68160\n",
      "Episode 9369: Reward = 588.00, Steps = 6, Loss = 3.5797, Exploration Rate = 0.1000, Train Count = 68166\n",
      "Episode 9370: Reward = 591.00, Steps = 5, Loss = 4.0965, Exploration Rate = 0.1000, Train Count = 68171\n",
      "Episode 9371: Reward = 597.00, Steps = 3, Loss = 2.9161, Exploration Rate = 0.1000, Train Count = 68174\n",
      "Episode 9372: Reward = 585.00, Steps = 7, Loss = 5.5899, Exploration Rate = 0.1000, Train Count = 68181\n",
      "Episode 9373: Reward = 594.00, Steps = 4, Loss = 1.7316, Exploration Rate = 0.1000, Train Count = 68185\n",
      "Episode 9374: Reward = 591.00, Steps = 5, Loss = 3.1873, Exploration Rate = 0.1000, Train Count = 68190\n",
      "Episode 9375: Reward = 594.00, Steps = 4, Loss = 1.2840, Exploration Rate = 0.1000, Train Count = 68194\n",
      "Episode 9376: Reward = 579.00, Steps = 9, Loss = 3.4818, Exploration Rate = 0.1000, Train Count = 68203\n",
      "Episode 9377: Reward = 588.00, Steps = 6, Loss = 3.1965, Exploration Rate = 0.1000, Train Count = 68209\n",
      "Episode 9378: Reward = 579.00, Steps = 9, Loss = 3.3829, Exploration Rate = 0.1000, Train Count = 68218\n",
      "Episode 9379: Reward = 579.00, Steps = 9, Loss = 3.9304, Exploration Rate = 0.1000, Train Count = 68227\n",
      "Episode 9380: Reward = 576.00, Steps = 10, Loss = 2.7084, Exploration Rate = 0.1000, Train Count = 68237\n",
      "Episode 9381: Reward = 538.00, Steps = 7, Loss = 2.5744, Exploration Rate = 0.1000, Train Count = 68244\n",
      "Episode 9382: Reward = 585.00, Steps = 7, Loss = 3.5440, Exploration Rate = 0.1000, Train Count = 68251\n",
      "Episode 9383: Reward = 588.00, Steps = 6, Loss = 3.0486, Exploration Rate = 0.1000, Train Count = 68257\n",
      "Episode 9384: Reward = 585.00, Steps = 7, Loss = 3.7168, Exploration Rate = 0.1000, Train Count = 68264\n",
      "Episode 9385: Reward = 585.00, Steps = 7, Loss = 4.1934, Exploration Rate = 0.1000, Train Count = 68271\n",
      "Episode 9386: Reward = 579.00, Steps = 9, Loss = 3.2306, Exploration Rate = 0.1000, Train Count = 68280\n",
      "Episode 9387: Reward = 597.00, Steps = 3, Loss = 2.7429, Exploration Rate = 0.1000, Train Count = 68283\n",
      "Episode 9388: Reward = 588.00, Steps = 6, Loss = 2.2349, Exploration Rate = 0.1000, Train Count = 68289\n",
      "Episode 9389: Reward = 585.00, Steps = 7, Loss = 3.2250, Exploration Rate = 0.1000, Train Count = 68296\n",
      "Episode 9390: Reward = 588.00, Steps = 6, Loss = 7.4330, Exploration Rate = 0.1000, Train Count = 68302\n",
      "Episode 9391: Reward = 594.00, Steps = 4, Loss = 18.8947, Exploration Rate = 0.1000, Train Count = 68306\n",
      "Episode 9392: Reward = 600.00, Steps = 2, Loss = 15.7320, Exploration Rate = 0.1000, Train Count = 68308\n",
      "Episode 9393: Reward = 600.00, Steps = 2, Loss = 14.6116, Exploration Rate = 0.1000, Train Count = 68310\n",
      "Episode 9394: Reward = 585.00, Steps = 7, Loss = 11.3662, Exploration Rate = 0.1000, Train Count = 68317\n",
      "Episode 9395: Reward = 594.00, Steps = 4, Loss = 13.2060, Exploration Rate = 0.1000, Train Count = 68321\n",
      "Episode 9396: Reward = 588.00, Steps = 6, Loss = 8.9113, Exploration Rate = 0.1000, Train Count = 68327\n",
      "Episode 9397: Reward = 541.00, Steps = 6, Loss = 9.2764, Exploration Rate = 0.1000, Train Count = 68333\n",
      "Episode 9398: Reward = 588.00, Steps = 6, Loss = 11.8586, Exploration Rate = 0.1000, Train Count = 68339\n",
      "Episode 9399: Reward = 585.00, Steps = 7, Loss = 6.6405, Exploration Rate = 0.1000, Train Count = 68346\n",
      "Episode 9400: Reward = 585.00, Steps = 7, Loss = 8.6839, Exploration Rate = 0.1000, Train Count = 68353\n",
      "Episode 9401: Reward = 591.00, Steps = 5, Loss = 9.0666, Exploration Rate = 0.1000, Train Count = 68358\n",
      "Episode 9402: Reward = 588.00, Steps = 6, Loss = 5.1037, Exploration Rate = 0.1000, Train Count = 68364\n",
      "Episode 9403: Reward = 582.00, Steps = 8, Loss = 4.9430, Exploration Rate = 0.1000, Train Count = 68372\n",
      "Episode 9404: Reward = 582.00, Steps = 8, Loss = 6.9643, Exploration Rate = 0.1000, Train Count = 68380\n",
      "Episode 9405: Reward = 582.00, Steps = 8, Loss = 5.8824, Exploration Rate = 0.1000, Train Count = 68388\n",
      "Episode 9406: Reward = 597.00, Steps = 3, Loss = 3.6574, Exploration Rate = 0.1000, Train Count = 68391\n",
      "Episode 9407: Reward = 588.00, Steps = 6, Loss = 5.6446, Exploration Rate = 0.1000, Train Count = 68397\n",
      "Episode 9408: Reward = 570.00, Steps = 12, Loss = 5.8768, Exploration Rate = 0.1000, Train Count = 68409\n",
      "Episode 9409: Reward = 576.00, Steps = 10, Loss = 6.2400, Exploration Rate = 0.1000, Train Count = 68419\n",
      "Episode 9410: Reward = 591.00, Steps = 5, Loss = 5.1826, Exploration Rate = 0.1000, Train Count = 68424\n",
      "Episode 9411: Reward = 573.00, Steps = 11, Loss = 4.8997, Exploration Rate = 0.1000, Train Count = 68435\n",
      "Episode 9412: Reward = 591.00, Steps = 5, Loss = 5.5831, Exploration Rate = 0.1000, Train Count = 68440\n",
      "Episode 9413: Reward = 582.00, Steps = 8, Loss = 7.6551, Exploration Rate = 0.1000, Train Count = 68448\n",
      "Episode 9414: Reward = 573.00, Steps = 11, Loss = 10.2030, Exploration Rate = 0.1000, Train Count = 68459\n",
      "Episode 9415: Reward = 591.00, Steps = 5, Loss = 7.8330, Exploration Rate = 0.1000, Train Count = 68464\n",
      "Episode 9416: Reward = 594.00, Steps = 4, Loss = 6.1301, Exploration Rate = 0.1000, Train Count = 68468\n",
      "Episode 9417: Reward = 594.00, Steps = 4, Loss = 4.4251, Exploration Rate = 0.1000, Train Count = 68472\n",
      "Episode 9418: Reward = 588.00, Steps = 6, Loss = 4.6317, Exploration Rate = 0.1000, Train Count = 68478\n",
      "Episode 9419: Reward = 579.00, Steps = 9, Loss = 6.4817, Exploration Rate = 0.1000, Train Count = 68487\n",
      "Episode 9420: Reward = 585.00, Steps = 7, Loss = 4.5750, Exploration Rate = 0.1000, Train Count = 68494\n",
      "Episode 9421: Reward = 597.00, Steps = 3, Loss = 4.1262, Exploration Rate = 0.1000, Train Count = 68497\n",
      "Episode 9422: Reward = 541.00, Steps = 6, Loss = 8.5080, Exploration Rate = 0.1000, Train Count = 68503\n",
      "Episode 9423: Reward = 591.00, Steps = 5, Loss = 8.1018, Exploration Rate = 0.1000, Train Count = 68508\n",
      "Episode 9424: Reward = 544.00, Steps = 5, Loss = 7.1120, Exploration Rate = 0.1000, Train Count = 68513\n",
      "Episode 9425: Reward = 538.00, Steps = 7, Loss = 7.4350, Exploration Rate = 0.1000, Train Count = 68520\n",
      "Episode 9426: Reward = 597.00, Steps = 3, Loss = 3.8738, Exploration Rate = 0.1000, Train Count = 68523\n",
      "Episode 9427: Reward = 594.00, Steps = 4, Loss = 9.0730, Exploration Rate = 0.1000, Train Count = 68527\n",
      "Episode 9428: Reward = 585.00, Steps = 7, Loss = 8.4298, Exploration Rate = 0.1000, Train Count = 68534\n",
      "Episode 9429: Reward = 588.00, Steps = 6, Loss = 4.8965, Exploration Rate = 0.1000, Train Count = 68540\n",
      "Episode 9430: Reward = 594.00, Steps = 4, Loss = 15.4336, Exploration Rate = 0.1000, Train Count = 68544\n",
      "Episode 9431: Reward = 594.00, Steps = 4, Loss = 4.9294, Exploration Rate = 0.1000, Train Count = 68548\n",
      "Episode 9432: Reward = 582.00, Steps = 8, Loss = 7.8638, Exploration Rate = 0.1000, Train Count = 68556\n",
      "Episode 9433: Reward = 594.00, Steps = 4, Loss = 9.0183, Exploration Rate = 0.1000, Train Count = 68560\n",
      "Episode 9434: Reward = 585.00, Steps = 7, Loss = 7.4671, Exploration Rate = 0.1000, Train Count = 68567\n",
      "Episode 9435: Reward = 591.00, Steps = 5, Loss = 7.2095, Exploration Rate = 0.1000, Train Count = 68572\n",
      "Episode 9436: Reward = 591.00, Steps = 5, Loss = 8.0361, Exploration Rate = 0.1000, Train Count = 68577\n",
      "Episode 9437: Reward = 529.00, Steps = 10, Loss = 10.3599, Exploration Rate = 0.1000, Train Count = 68587\n",
      "Episode 9438: Reward = 591.00, Steps = 5, Loss = 10.5168, Exploration Rate = 0.1000, Train Count = 68592\n",
      "Episode 9439: Reward = 576.00, Steps = 10, Loss = 6.1972, Exploration Rate = 0.1000, Train Count = 68602\n",
      "Episode 9440: Reward = 594.00, Steps = 4, Loss = 15.0368, Exploration Rate = 0.1000, Train Count = 68606\n",
      "Episode 9441: Reward = 588.00, Steps = 6, Loss = 6.9152, Exploration Rate = 0.1000, Train Count = 68612\n",
      "Episode 9442: Reward = 582.00, Steps = 8, Loss = 6.6707, Exploration Rate = 0.1000, Train Count = 68620\n",
      "Episode 9443: Reward = 538.00, Steps = 7, Loss = 7.4089, Exploration Rate = 0.1000, Train Count = 68627\n",
      "Episode 9444: Reward = 588.00, Steps = 6, Loss = 9.6800, Exploration Rate = 0.1000, Train Count = 68633\n",
      "Episode 9445: Reward = 594.00, Steps = 4, Loss = 4.7921, Exploration Rate = 0.1000, Train Count = 68637\n",
      "Episode 9446: Reward = 576.00, Steps = 10, Loss = 8.8002, Exploration Rate = 0.1000, Train Count = 68647\n",
      "Episode 9447: Reward = 594.00, Steps = 4, Loss = 6.9717, Exploration Rate = 0.1000, Train Count = 68651\n",
      "Episode 9448: Reward = 594.00, Steps = 4, Loss = 7.7498, Exploration Rate = 0.1000, Train Count = 68655\n",
      "Episode 9449: Reward = 582.00, Steps = 8, Loss = 6.4059, Exploration Rate = 0.1000, Train Count = 68663\n",
      "Episode 9450: Reward = 597.00, Steps = 3, Loss = 6.0282, Exploration Rate = 0.1000, Train Count = 68666\n",
      "Episode 9451: Reward = 585.00, Steps = 7, Loss = 7.6176, Exploration Rate = 0.1000, Train Count = 68673\n",
      "Episode 9452: Reward = 544.00, Steps = 5, Loss = 8.4593, Exploration Rate = 0.1000, Train Count = 68678\n",
      "Episode 9453: Reward = 588.00, Steps = 6, Loss = 11.2151, Exploration Rate = 0.1000, Train Count = 68684\n",
      "Episode 9454: Reward = 585.00, Steps = 7, Loss = 7.6839, Exploration Rate = 0.1000, Train Count = 68691\n",
      "Episode 9455: Reward = 591.00, Steps = 5, Loss = 8.7945, Exploration Rate = 0.1000, Train Count = 68696\n",
      "Episode 9456: Reward = 597.00, Steps = 3, Loss = 7.7559, Exploration Rate = 0.1000, Train Count = 68699\n",
      "Episode 9457: Reward = 594.00, Steps = 4, Loss = 7.9440, Exploration Rate = 0.1000, Train Count = 68703\n",
      "Episode 9458: Reward = 597.00, Steps = 3, Loss = 2.3992, Exploration Rate = 0.1000, Train Count = 68706\n",
      "Episode 9459: Reward = 585.00, Steps = 7, Loss = 7.2189, Exploration Rate = 0.1000, Train Count = 68713\n",
      "Episode 9460: Reward = 576.00, Steps = 10, Loss = 7.5582, Exploration Rate = 0.1000, Train Count = 68723\n",
      "Episode 9461: Reward = 591.00, Steps = 5, Loss = 12.4980, Exploration Rate = 0.1000, Train Count = 68728\n",
      "Episode 9462: Reward = 597.00, Steps = 3, Loss = 4.9346, Exploration Rate = 0.1000, Train Count = 68731\n",
      "Episode 9463: Reward = 591.00, Steps = 5, Loss = 9.9931, Exploration Rate = 0.1000, Train Count = 68736\n",
      "Episode 9464: Reward = 591.00, Steps = 5, Loss = 6.4925, Exploration Rate = 0.1000, Train Count = 68741\n",
      "Episode 9465: Reward = 597.00, Steps = 3, Loss = 6.6496, Exploration Rate = 0.1000, Train Count = 68744\n",
      "Episode 9466: Reward = 588.00, Steps = 6, Loss = 6.6912, Exploration Rate = 0.1000, Train Count = 68750\n",
      "Episode 9467: Reward = 588.00, Steps = 6, Loss = 8.3200, Exploration Rate = 0.1000, Train Count = 68756\n",
      "Episode 9468: Reward = 594.00, Steps = 4, Loss = 4.6894, Exploration Rate = 0.1000, Train Count = 68760\n",
      "Episode 9469: Reward = 597.00, Steps = 3, Loss = 5.0260, Exploration Rate = 0.1000, Train Count = 68763\n",
      "Episode 9470: Reward = 591.00, Steps = 5, Loss = 4.2241, Exploration Rate = 0.1000, Train Count = 68768\n",
      "Episode 9471: Reward = 570.00, Steps = 12, Loss = 9.8892, Exploration Rate = 0.1000, Train Count = 68780\n",
      "Episode 9472: Reward = 573.00, Steps = 11, Loss = 8.8897, Exploration Rate = 0.1000, Train Count = 68791\n",
      "Episode 9473: Reward = 594.00, Steps = 4, Loss = 5.0593, Exploration Rate = 0.1000, Train Count = 68795\n",
      "Episode 9474: Reward = 594.00, Steps = 4, Loss = 9.1171, Exploration Rate = 0.1000, Train Count = 68799\n",
      "Episode 9475: Reward = 570.00, Steps = 12, Loss = 20.6718, Exploration Rate = 0.1000, Train Count = 68811\n",
      "Episode 9476: Reward = 579.00, Steps = 9, Loss = 19.2704, Exploration Rate = 0.1000, Train Count = 68820\n",
      "Episode 9477: Reward = 591.00, Steps = 5, Loss = 13.5666, Exploration Rate = 0.1000, Train Count = 68825\n",
      "Episode 9478: Reward = 594.00, Steps = 4, Loss = 11.9117, Exploration Rate = 0.1000, Train Count = 68829\n",
      "Episode 9479: Reward = 585.00, Steps = 7, Loss = 15.8650, Exploration Rate = 0.1000, Train Count = 68836\n",
      "Episode 9480: Reward = 591.00, Steps = 5, Loss = 7.4393, Exploration Rate = 0.1000, Train Count = 68841\n",
      "Episode 9481: Reward = 588.00, Steps = 6, Loss = 9.9014, Exploration Rate = 0.1000, Train Count = 68847\n",
      "Episode 9482: Reward = 582.00, Steps = 8, Loss = 9.8029, Exploration Rate = 0.1000, Train Count = 68855\n",
      "Episode 9483: Reward = 600.00, Steps = 2, Loss = 7.5723, Exploration Rate = 0.1000, Train Count = 68857\n",
      "Episode 9484: Reward = 582.00, Steps = 8, Loss = 5.4809, Exploration Rate = 0.1000, Train Count = 68865\n",
      "Episode 9485: Reward = 594.00, Steps = 4, Loss = 9.9082, Exploration Rate = 0.1000, Train Count = 68869\n",
      "Episode 9486: Reward = 591.00, Steps = 5, Loss = 8.8499, Exploration Rate = 0.1000, Train Count = 68874\n",
      "Episode 9487: Reward = 597.00, Steps = 3, Loss = 3.5615, Exploration Rate = 0.1000, Train Count = 68877\n",
      "Episode 9488: Reward = 585.00, Steps = 7, Loss = 5.6502, Exploration Rate = 0.1000, Train Count = 68884\n",
      "Episode 9489: Reward = 579.00, Steps = 9, Loss = 5.2074, Exploration Rate = 0.1000, Train Count = 68893\n",
      "Episode 9490: Reward = 582.00, Steps = 8, Loss = 4.3780, Exploration Rate = 0.1000, Train Count = 68901\n",
      "Episode 9491: Reward = 570.00, Steps = 12, Loss = 4.7638, Exploration Rate = 0.1000, Train Count = 68913\n",
      "Episode 9492: Reward = 594.00, Steps = 4, Loss = 3.3774, Exploration Rate = 0.1000, Train Count = 68917\n",
      "Episode 9493: Reward = 594.00, Steps = 4, Loss = 3.6546, Exploration Rate = 0.1000, Train Count = 68921\n",
      "Episode 9494: Reward = 585.00, Steps = 7, Loss = 2.5559, Exploration Rate = 0.1000, Train Count = 68928\n",
      "Episode 9495: Reward = 546.00, Steps = 20, Loss = 6.3729, Exploration Rate = 0.1000, Train Count = 68948\n",
      "Episode 9496: Reward = 579.00, Steps = 9, Loss = 4.9353, Exploration Rate = 0.1000, Train Count = 68957\n",
      "Episode 9497: Reward = 597.00, Steps = 3, Loss = 4.1922, Exploration Rate = 0.1000, Train Count = 68960\n",
      "Episode 9498: Reward = 594.00, Steps = 4, Loss = 6.3841, Exploration Rate = 0.1000, Train Count = 68964\n",
      "Episode 9499: Reward = 591.00, Steps = 5, Loss = 5.9087, Exploration Rate = 0.1000, Train Count = 68969\n",
      "Episode 9500: Reward = 585.00, Steps = 7, Loss = 3.9006, Exploration Rate = 0.1000, Train Count = 68976\n",
      "Episode 9501: Reward = 597.00, Steps = 3, Loss = 1.5815, Exploration Rate = 0.1000, Train Count = 68979\n",
      "Episode 9502: Reward = 582.00, Steps = 8, Loss = 2.1776, Exploration Rate = 0.1000, Train Count = 68987\n",
      "Episode 9503: Reward = 585.00, Steps = 7, Loss = 2.5931, Exploration Rate = 0.1000, Train Count = 68994\n",
      "Episode 9504: Reward = 588.00, Steps = 6, Loss = 3.7640, Exploration Rate = 0.1000, Train Count = 69000\n",
      "Episode 9505: Reward = 588.00, Steps = 6, Loss = 2.2685, Exploration Rate = 0.1000, Train Count = 69006\n",
      "Episode 9506: Reward = 600.00, Steps = 2, Loss = 3.6154, Exploration Rate = 0.1000, Train Count = 69008\n",
      "Episode 9507: Reward = 591.00, Steps = 5, Loss = 4.2149, Exploration Rate = 0.1000, Train Count = 69013\n",
      "Episode 9508: Reward = 591.00, Steps = 5, Loss = 2.2467, Exploration Rate = 0.1000, Train Count = 69018\n",
      "Episode 9509: Reward = 588.00, Steps = 6, Loss = 3.9198, Exploration Rate = 0.1000, Train Count = 69024\n",
      "Episode 9510: Reward = 582.00, Steps = 8, Loss = 2.0485, Exploration Rate = 0.1000, Train Count = 69032\n",
      "Episode 9511: Reward = 579.00, Steps = 9, Loss = 2.7260, Exploration Rate = 0.1000, Train Count = 69041\n",
      "Episode 9512: Reward = 594.00, Steps = 4, Loss = 2.3705, Exploration Rate = 0.1000, Train Count = 69045\n",
      "Episode 9513: Reward = 585.00, Steps = 7, Loss = 4.9199, Exploration Rate = 0.1000, Train Count = 69052\n",
      "Episode 9514: Reward = 597.00, Steps = 3, Loss = 4.9501, Exploration Rate = 0.1000, Train Count = 69055\n",
      "Episode 9515: Reward = 582.00, Steps = 8, Loss = 4.1925, Exploration Rate = 0.1000, Train Count = 69063\n",
      "Episode 9516: Reward = 594.00, Steps = 4, Loss = 4.7068, Exploration Rate = 0.1000, Train Count = 69067\n",
      "Episode 9517: Reward = 573.00, Steps = 11, Loss = 9.4828, Exploration Rate = 0.1000, Train Count = 69078\n",
      "Episode 9518: Reward = 582.00, Steps = 8, Loss = 4.1703, Exploration Rate = 0.1000, Train Count = 69086\n",
      "Episode 9519: Reward = 591.00, Steps = 5, Loss = 5.1909, Exploration Rate = 0.1000, Train Count = 69091\n",
      "Episode 9520: Reward = 594.00, Steps = 4, Loss = 3.2663, Exploration Rate = 0.1000, Train Count = 69095\n",
      "Episode 9521: Reward = 582.00, Steps = 8, Loss = 4.9060, Exploration Rate = 0.1000, Train Count = 69103\n",
      "Episode 9522: Reward = 594.00, Steps = 4, Loss = 2.5162, Exploration Rate = 0.1000, Train Count = 69107\n",
      "Episode 9523: Reward = 591.00, Steps = 5, Loss = 5.2733, Exploration Rate = 0.1000, Train Count = 69112\n",
      "Episode 9524: Reward = 591.00, Steps = 5, Loss = 2.9918, Exploration Rate = 0.1000, Train Count = 69117\n",
      "Episode 9525: Reward = 579.00, Steps = 9, Loss = 4.4288, Exploration Rate = 0.1000, Train Count = 69126\n",
      "Episode 9526: Reward = 591.00, Steps = 5, Loss = 3.7785, Exploration Rate = 0.1000, Train Count = 69131\n",
      "Episode 9527: Reward = 594.00, Steps = 4, Loss = 3.0341, Exploration Rate = 0.1000, Train Count = 69135\n",
      "Episode 9528: Reward = 579.00, Steps = 9, Loss = 2.9706, Exploration Rate = 0.1000, Train Count = 69144\n",
      "Episode 9529: Reward = 597.00, Steps = 3, Loss = 3.7213, Exploration Rate = 0.1000, Train Count = 69147\n",
      "Episode 9530: Reward = 582.00, Steps = 8, Loss = 4.1124, Exploration Rate = 0.1000, Train Count = 69155\n",
      "Episode 9531: Reward = 585.00, Steps = 7, Loss = 5.9856, Exploration Rate = 0.1000, Train Count = 69162\n",
      "Episode 9532: Reward = 588.00, Steps = 6, Loss = 4.4832, Exploration Rate = 0.1000, Train Count = 69168\n",
      "Episode 9533: Reward = 588.00, Steps = 6, Loss = 4.2185, Exploration Rate = 0.1000, Train Count = 69174\n",
      "Episode 9534: Reward = 585.00, Steps = 7, Loss = 1.9817, Exploration Rate = 0.1000, Train Count = 69181\n",
      "Episode 9535: Reward = 544.00, Steps = 5, Loss = 4.8584, Exploration Rate = 0.1000, Train Count = 69186\n",
      "Episode 9536: Reward = 591.00, Steps = 5, Loss = 3.6086, Exploration Rate = 0.1000, Train Count = 69191\n",
      "Episode 9537: Reward = 576.00, Steps = 10, Loss = 4.0626, Exploration Rate = 0.1000, Train Count = 69201\n",
      "Episode 9538: Reward = 588.00, Steps = 6, Loss = 5.4183, Exploration Rate = 0.1000, Train Count = 69207\n",
      "Episode 9539: Reward = 588.00, Steps = 6, Loss = 4.8078, Exploration Rate = 0.1000, Train Count = 69213\n",
      "Episode 9540: Reward = 576.00, Steps = 10, Loss = 4.1003, Exploration Rate = 0.1000, Train Count = 69223\n",
      "Episode 9541: Reward = 588.00, Steps = 6, Loss = 4.6760, Exploration Rate = 0.1000, Train Count = 69229\n",
      "Episode 9542: Reward = 591.00, Steps = 5, Loss = 5.1559, Exploration Rate = 0.1000, Train Count = 69234\n",
      "Episode 9543: Reward = 591.00, Steps = 5, Loss = 2.1785, Exploration Rate = 0.1000, Train Count = 69239\n",
      "Episode 9544: Reward = 585.00, Steps = 7, Loss = 1.6975, Exploration Rate = 0.1000, Train Count = 69246\n",
      "Episode 9545: Reward = 597.00, Steps = 3, Loss = 5.0434, Exploration Rate = 0.1000, Train Count = 69249\n",
      "Episode 9546: Reward = 597.00, Steps = 3, Loss = 6.1241, Exploration Rate = 0.1000, Train Count = 69252\n",
      "Episode 9547: Reward = 582.00, Steps = 8, Loss = 6.4491, Exploration Rate = 0.1000, Train Count = 69260\n",
      "Episode 9548: Reward = 532.00, Steps = 9, Loss = 7.7349, Exploration Rate = 0.1000, Train Count = 69269\n",
      "Episode 9549: Reward = 594.00, Steps = 4, Loss = 9.0603, Exploration Rate = 0.1000, Train Count = 69273\n",
      "Episode 9550: Reward = 597.00, Steps = 3, Loss = 4.0274, Exploration Rate = 0.1000, Train Count = 69276\n",
      "Episode 9551: Reward = 591.00, Steps = 5, Loss = 5.0426, Exploration Rate = 0.1000, Train Count = 69281\n",
      "Episode 9552: Reward = 588.00, Steps = 6, Loss = 5.6027, Exploration Rate = 0.1000, Train Count = 69287\n",
      "Episode 9553: Reward = 588.00, Steps = 6, Loss = 3.9546, Exploration Rate = 0.1000, Train Count = 69293\n",
      "Episode 9554: Reward = 588.00, Steps = 6, Loss = 1.8699, Exploration Rate = 0.1000, Train Count = 69299\n",
      "Episode 9555: Reward = 585.00, Steps = 7, Loss = 17.7065, Exploration Rate = 0.1000, Train Count = 69306\n",
      "Episode 9556: Reward = 591.00, Steps = 5, Loss = 16.4041, Exploration Rate = 0.1000, Train Count = 69311\n",
      "Episode 9557: Reward = 585.00, Steps = 7, Loss = 11.5034, Exploration Rate = 0.1000, Train Count = 69318\n",
      "Episode 9558: Reward = 576.00, Steps = 10, Loss = 10.0929, Exploration Rate = 0.1000, Train Count = 69328\n",
      "Episode 9559: Reward = 582.00, Steps = 8, Loss = 9.3088, Exploration Rate = 0.1000, Train Count = 69336\n",
      "Episode 9560: Reward = 588.00, Steps = 6, Loss = 7.7911, Exploration Rate = 0.1000, Train Count = 69342\n",
      "Episode 9561: Reward = 582.00, Steps = 8, Loss = 7.5974, Exploration Rate = 0.1000, Train Count = 69350\n",
      "Episode 9562: Reward = 585.00, Steps = 7, Loss = 6.1202, Exploration Rate = 0.1000, Train Count = 69357\n",
      "Episode 9563: Reward = 585.00, Steps = 7, Loss = 5.4945, Exploration Rate = 0.1000, Train Count = 69364\n",
      "Episode 9564: Reward = 585.00, Steps = 7, Loss = 5.1190, Exploration Rate = 0.1000, Train Count = 69371\n",
      "Episode 9565: Reward = 588.00, Steps = 6, Loss = 3.3630, Exploration Rate = 0.1000, Train Count = 69377\n",
      "Episode 9566: Reward = 585.00, Steps = 7, Loss = 3.8416, Exploration Rate = 0.1000, Train Count = 69384\n",
      "Episode 9567: Reward = 591.00, Steps = 5, Loss = 5.7840, Exploration Rate = 0.1000, Train Count = 69389\n",
      "Episode 9568: Reward = 591.00, Steps = 5, Loss = 5.8204, Exploration Rate = 0.1000, Train Count = 69394\n",
      "Episode 9569: Reward = 544.00, Steps = 5, Loss = 4.6822, Exploration Rate = 0.1000, Train Count = 69399\n",
      "Episode 9570: Reward = 532.00, Steps = 9, Loss = 7.0641, Exploration Rate = 0.1000, Train Count = 69408\n",
      "Episode 9571: Reward = 591.00, Steps = 5, Loss = 8.9404, Exploration Rate = 0.1000, Train Count = 69413\n",
      "Episode 9572: Reward = 594.00, Steps = 4, Loss = 7.5790, Exploration Rate = 0.1000, Train Count = 69417\n",
      "Episode 9573: Reward = 579.00, Steps = 9, Loss = 4.6280, Exploration Rate = 0.1000, Train Count = 69426\n",
      "Episode 9574: Reward = 597.00, Steps = 3, Loss = 6.5881, Exploration Rate = 0.1000, Train Count = 69429\n",
      "Episode 9575: Reward = 585.00, Steps = 7, Loss = 6.7851, Exploration Rate = 0.1000, Train Count = 69436\n",
      "Episode 9576: Reward = 594.00, Steps = 4, Loss = 4.4211, Exploration Rate = 0.1000, Train Count = 69440\n",
      "Episode 9577: Reward = 591.00, Steps = 5, Loss = 5.7871, Exploration Rate = 0.1000, Train Count = 69445\n",
      "Episode 9578: Reward = 591.00, Steps = 5, Loss = 4.6796, Exploration Rate = 0.1000, Train Count = 69450\n",
      "Episode 9579: Reward = 588.00, Steps = 6, Loss = 3.4453, Exploration Rate = 0.1000, Train Count = 69456\n",
      "Episode 9580: Reward = 585.00, Steps = 7, Loss = 4.2107, Exploration Rate = 0.1000, Train Count = 69463\n",
      "Episode 9581: Reward = 600.00, Steps = 2, Loss = 2.2006, Exploration Rate = 0.1000, Train Count = 69465\n",
      "Episode 9582: Reward = 597.00, Steps = 3, Loss = 3.7117, Exploration Rate = 0.1000, Train Count = 69468\n",
      "Episode 9583: Reward = 541.00, Steps = 6, Loss = 4.9069, Exploration Rate = 0.1000, Train Count = 69474\n",
      "Episode 9584: Reward = 594.00, Steps = 4, Loss = 3.1110, Exploration Rate = 0.1000, Train Count = 69478\n",
      "Episode 9585: Reward = 535.00, Steps = 8, Loss = 5.1245, Exploration Rate = 0.1000, Train Count = 69486\n",
      "Episode 9586: Reward = 594.00, Steps = 4, Loss = 8.6275, Exploration Rate = 0.1000, Train Count = 69490\n",
      "Episode 9587: Reward = 582.00, Steps = 8, Loss = 5.4118, Exploration Rate = 0.1000, Train Count = 69498\n",
      "Episode 9588: Reward = 594.00, Steps = 4, Loss = 4.0708, Exploration Rate = 0.1000, Train Count = 69502\n",
      "Episode 9589: Reward = 588.00, Steps = 6, Loss = 5.9643, Exploration Rate = 0.1000, Train Count = 69508\n",
      "Episode 9590: Reward = 579.00, Steps = 9, Loss = 4.8217, Exploration Rate = 0.1000, Train Count = 69517\n",
      "Episode 9591: Reward = 597.00, Steps = 3, Loss = 1.6410, Exploration Rate = 0.1000, Train Count = 69520\n",
      "Episode 9592: Reward = 541.00, Steps = 6, Loss = 4.1013, Exploration Rate = 0.1000, Train Count = 69526\n",
      "Episode 9593: Reward = 594.00, Steps = 4, Loss = 3.6658, Exploration Rate = 0.1000, Train Count = 69530\n",
      "Episode 9594: Reward = 567.00, Steps = 13, Loss = 6.3850, Exploration Rate = 0.1000, Train Count = 69543\n",
      "Episode 9595: Reward = 591.00, Steps = 5, Loss = 4.5050, Exploration Rate = 0.1000, Train Count = 69548\n",
      "Episode 9596: Reward = 597.00, Steps = 3, Loss = 4.1602, Exploration Rate = 0.1000, Train Count = 69551\n",
      "Episode 9597: Reward = 582.00, Steps = 8, Loss = 2.3526, Exploration Rate = 0.1000, Train Count = 69559\n",
      "Episode 9598: Reward = 532.00, Steps = 9, Loss = 4.4963, Exploration Rate = 0.1000, Train Count = 69568\n",
      "Episode 9599: Reward = 555.00, Steps = 17, Loss = 12.2855, Exploration Rate = 0.1000, Train Count = 69585\n",
      "Episode 9600: Reward = 591.00, Steps = 5, Loss = 4.8794, Exploration Rate = 0.1000, Train Count = 69590\n",
      "Episode 9601: Reward = 591.00, Steps = 5, Loss = 6.6922, Exploration Rate = 0.1000, Train Count = 69595\n",
      "Episode 9602: Reward = 594.00, Steps = 4, Loss = 7.1452, Exploration Rate = 0.1000, Train Count = 69599\n",
      "Episode 9603: Reward = 585.00, Steps = 7, Loss = 3.9823, Exploration Rate = 0.1000, Train Count = 69606\n",
      "Episode 9604: Reward = 594.00, Steps = 4, Loss = 3.4909, Exploration Rate = 0.1000, Train Count = 69610\n",
      "Episode 9605: Reward = 594.00, Steps = 4, Loss = 4.9202, Exploration Rate = 0.1000, Train Count = 69614\n",
      "Episode 9606: Reward = 582.00, Steps = 8, Loss = 5.5053, Exploration Rate = 0.1000, Train Count = 69622\n",
      "Episode 9607: Reward = 588.00, Steps = 6, Loss = 5.3220, Exploration Rate = 0.1000, Train Count = 69628\n",
      "Episode 9608: Reward = 591.00, Steps = 5, Loss = 3.2632, Exploration Rate = 0.1000, Train Count = 69633\n",
      "Episode 9609: Reward = 582.00, Steps = 8, Loss = 3.2337, Exploration Rate = 0.1000, Train Count = 69641\n",
      "Episode 9610: Reward = 594.00, Steps = 4, Loss = 5.8217, Exploration Rate = 0.1000, Train Count = 69645\n",
      "Episode 9611: Reward = 594.00, Steps = 4, Loss = 7.9144, Exploration Rate = 0.1000, Train Count = 69649\n",
      "Episode 9612: Reward = 585.00, Steps = 7, Loss = 5.1429, Exploration Rate = 0.1000, Train Count = 69656\n",
      "Episode 9613: Reward = 588.00, Steps = 6, Loss = 5.8782, Exploration Rate = 0.1000, Train Count = 69662\n",
      "Episode 9614: Reward = 538.00, Steps = 7, Loss = 3.0869, Exploration Rate = 0.1000, Train Count = 69669\n",
      "Episode 9615: Reward = 473.00, Steps = 13, Loss = 4.1328, Exploration Rate = 0.1000, Train Count = 69682\n",
      "Episode 9616: Reward = 600.00, Steps = 2, Loss = 8.5812, Exploration Rate = 0.1000, Train Count = 69684\n",
      "Episode 9617: Reward = 594.00, Steps = 4, Loss = 7.3247, Exploration Rate = 0.1000, Train Count = 69688\n",
      "Episode 9618: Reward = 600.00, Steps = 2, Loss = 8.8589, Exploration Rate = 0.1000, Train Count = 69690\n",
      "Episode 9619: Reward = 579.00, Steps = 9, Loss = 8.6536, Exploration Rate = 0.1000, Train Count = 69699\n",
      "Episode 9620: Reward = 591.00, Steps = 5, Loss = 5.5018, Exploration Rate = 0.1000, Train Count = 69704\n",
      "Episode 9621: Reward = 588.00, Steps = 6, Loss = 3.2419, Exploration Rate = 0.1000, Train Count = 69710\n",
      "Episode 9622: Reward = 535.00, Steps = 8, Loss = 3.3469, Exploration Rate = 0.1000, Train Count = 69718\n",
      "Episode 9623: Reward = 591.00, Steps = 5, Loss = 5.9222, Exploration Rate = 0.1000, Train Count = 69723\n",
      "Episode 9624: Reward = 582.00, Steps = 8, Loss = 3.6148, Exploration Rate = 0.1000, Train Count = 69731\n",
      "Episode 9625: Reward = 591.00, Steps = 5, Loss = 4.1103, Exploration Rate = 0.1000, Train Count = 69736\n",
      "Episode 9626: Reward = 579.00, Steps = 9, Loss = 4.9971, Exploration Rate = 0.1000, Train Count = 69745\n",
      "Episode 9627: Reward = 591.00, Steps = 5, Loss = 4.4619, Exploration Rate = 0.1000, Train Count = 69750\n",
      "Episode 9628: Reward = 588.00, Steps = 6, Loss = 5.1801, Exploration Rate = 0.1000, Train Count = 69756\n",
      "Episode 9629: Reward = 579.00, Steps = 9, Loss = 11.1641, Exploration Rate = 0.1000, Train Count = 69765\n",
      "Episode 9630: Reward = 588.00, Steps = 6, Loss = 9.7736, Exploration Rate = 0.1000, Train Count = 69771\n",
      "Episode 9631: Reward = 579.00, Steps = 9, Loss = 10.3149, Exploration Rate = 0.1000, Train Count = 69780\n",
      "Episode 9632: Reward = 579.00, Steps = 9, Loss = 8.2622, Exploration Rate = 0.1000, Train Count = 69789\n",
      "Episode 9633: Reward = 591.00, Steps = 5, Loss = 10.5214, Exploration Rate = 0.1000, Train Count = 69794\n",
      "Episode 9634: Reward = 585.00, Steps = 7, Loss = 10.4564, Exploration Rate = 0.1000, Train Count = 69801\n",
      "Episode 9635: Reward = 591.00, Steps = 5, Loss = 28.0611, Exploration Rate = 0.1000, Train Count = 69806\n",
      "Episode 9636: Reward = 538.00, Steps = 7, Loss = 17.9055, Exploration Rate = 0.1000, Train Count = 69813\n",
      "Episode 9637: Reward = 591.00, Steps = 5, Loss = 15.2948, Exploration Rate = 0.1000, Train Count = 69818\n",
      "Episode 9638: Reward = 582.00, Steps = 8, Loss = 11.8489, Exploration Rate = 0.1000, Train Count = 69826\n",
      "Episode 9639: Reward = 585.00, Steps = 7, Loss = 11.1095, Exploration Rate = 0.1000, Train Count = 69833\n",
      "Episode 9640: Reward = 594.00, Steps = 4, Loss = 11.0021, Exploration Rate = 0.1000, Train Count = 69837\n",
      "Episode 9641: Reward = 594.00, Steps = 4, Loss = 7.9582, Exploration Rate = 0.1000, Train Count = 69841\n",
      "Episode 9642: Reward = 582.00, Steps = 8, Loss = 8.4902, Exploration Rate = 0.1000, Train Count = 69849\n",
      "Episode 9643: Reward = 591.00, Steps = 5, Loss = 8.6987, Exploration Rate = 0.1000, Train Count = 69854\n",
      "Episode 9644: Reward = 591.00, Steps = 5, Loss = 7.3611, Exploration Rate = 0.1000, Train Count = 69859\n",
      "Episode 9645: Reward = 594.00, Steps = 4, Loss = 7.8987, Exploration Rate = 0.1000, Train Count = 69863\n",
      "Episode 9646: Reward = 594.00, Steps = 4, Loss = 10.7554, Exploration Rate = 0.1000, Train Count = 69867\n",
      "Episode 9647: Reward = 585.00, Steps = 7, Loss = 8.1637, Exploration Rate = 0.1000, Train Count = 69874\n",
      "Episode 9648: Reward = 535.00, Steps = 8, Loss = 10.3552, Exploration Rate = 0.1000, Train Count = 69882\n",
      "Episode 9649: Reward = 588.00, Steps = 6, Loss = 5.1206, Exploration Rate = 0.1000, Train Count = 69888\n",
      "Episode 9650: Reward = 588.00, Steps = 6, Loss = 7.0881, Exploration Rate = 0.1000, Train Count = 69894\n",
      "Episode 9651: Reward = 585.00, Steps = 7, Loss = 5.4439, Exploration Rate = 0.1000, Train Count = 69901\n",
      "Episode 9652: Reward = 594.00, Steps = 4, Loss = 5.9010, Exploration Rate = 0.1000, Train Count = 69905\n",
      "Episode 9653: Reward = 582.00, Steps = 8, Loss = 6.9658, Exploration Rate = 0.1000, Train Count = 69913\n",
      "Episode 9654: Reward = 594.00, Steps = 4, Loss = 7.4912, Exploration Rate = 0.1000, Train Count = 69917\n",
      "Episode 9655: Reward = 538.00, Steps = 7, Loss = 9.7354, Exploration Rate = 0.1000, Train Count = 69924\n",
      "Episode 9656: Reward = 588.00, Steps = 6, Loss = 7.5292, Exploration Rate = 0.1000, Train Count = 69930\n",
      "Episode 9657: Reward = 588.00, Steps = 6, Loss = 12.4234, Exploration Rate = 0.1000, Train Count = 69936\n",
      "Episode 9658: Reward = 591.00, Steps = 5, Loss = 10.6486, Exploration Rate = 0.1000, Train Count = 69941\n",
      "Episode 9659: Reward = 594.00, Steps = 4, Loss = 9.6455, Exploration Rate = 0.1000, Train Count = 69945\n",
      "Episode 9660: Reward = 594.00, Steps = 4, Loss = 9.7617, Exploration Rate = 0.1000, Train Count = 69949\n",
      "Episode 9661: Reward = 594.00, Steps = 4, Loss = 12.3980, Exploration Rate = 0.1000, Train Count = 69953\n",
      "Episode 9662: Reward = 582.00, Steps = 8, Loss = 8.9711, Exploration Rate = 0.1000, Train Count = 69961\n",
      "Episode 9663: Reward = 594.00, Steps = 4, Loss = 5.1740, Exploration Rate = 0.1000, Train Count = 69965\n",
      "Episode 9664: Reward = 600.00, Steps = 2, Loss = 3.2506, Exploration Rate = 0.1000, Train Count = 69967\n",
      "Episode 9665: Reward = 526.00, Steps = 11, Loss = 7.0814, Exploration Rate = 0.1000, Train Count = 69978\n",
      "Episode 9666: Reward = 588.00, Steps = 6, Loss = 10.3098, Exploration Rate = 0.1000, Train Count = 69984\n",
      "Episode 9667: Reward = 594.00, Steps = 4, Loss = 10.6641, Exploration Rate = 0.1000, Train Count = 69988\n",
      "Episode 9668: Reward = 591.00, Steps = 5, Loss = 9.1374, Exploration Rate = 0.1000, Train Count = 69993\n",
      "Episode 9669: Reward = 579.00, Steps = 9, Loss = 6.5014, Exploration Rate = 0.1000, Train Count = 70002\n",
      "Episode 9670: Reward = 594.00, Steps = 4, Loss = 7.7514, Exploration Rate = 0.1000, Train Count = 70006\n",
      "Episode 9671: Reward = 588.00, Steps = 6, Loss = 7.4129, Exploration Rate = 0.1000, Train Count = 70012\n",
      "Episode 9672: Reward = 597.00, Steps = 3, Loss = 6.8986, Exploration Rate = 0.1000, Train Count = 70015\n",
      "Episode 9673: Reward = 567.00, Steps = 13, Loss = 8.6562, Exploration Rate = 0.1000, Train Count = 70028\n",
      "Episode 9674: Reward = 594.00, Steps = 4, Loss = 10.6181, Exploration Rate = 0.1000, Train Count = 70032\n",
      "Episode 9675: Reward = 576.00, Steps = 10, Loss = 11.8508, Exploration Rate = 0.1000, Train Count = 70042\n",
      "Episode 9676: Reward = 570.00, Steps = 12, Loss = 10.4876, Exploration Rate = 0.1000, Train Count = 70054\n",
      "Episode 9677: Reward = 582.00, Steps = 8, Loss = 11.4705, Exploration Rate = 0.1000, Train Count = 70062\n",
      "Episode 9678: Reward = 588.00, Steps = 6, Loss = 10.1436, Exploration Rate = 0.1000, Train Count = 70068\n",
      "Episode 9679: Reward = 591.00, Steps = 5, Loss = 8.1789, Exploration Rate = 0.1000, Train Count = 70073\n",
      "Episode 9680: Reward = 585.00, Steps = 7, Loss = 10.8641, Exploration Rate = 0.1000, Train Count = 70080\n",
      "Episode 9681: Reward = 588.00, Steps = 6, Loss = 5.5827, Exploration Rate = 0.1000, Train Count = 70086\n",
      "Episode 9682: Reward = 591.00, Steps = 5, Loss = 4.1639, Exploration Rate = 0.1000, Train Count = 70091\n",
      "Episode 9683: Reward = 582.00, Steps = 8, Loss = 10.2268, Exploration Rate = 0.1000, Train Count = 70099\n",
      "Episode 9684: Reward = 597.00, Steps = 3, Loss = 10.4934, Exploration Rate = 0.1000, Train Count = 70102\n",
      "Episode 9685: Reward = 585.00, Steps = 7, Loss = 9.8342, Exploration Rate = 0.1000, Train Count = 70109\n",
      "Episode 9686: Reward = 588.00, Steps = 6, Loss = 6.0987, Exploration Rate = 0.1000, Train Count = 70115\n",
      "Episode 9687: Reward = 588.00, Steps = 6, Loss = 12.0760, Exploration Rate = 0.1000, Train Count = 70121\n",
      "Episode 9688: Reward = 591.00, Steps = 5, Loss = 8.6353, Exploration Rate = 0.1000, Train Count = 70126\n",
      "Episode 9689: Reward = 594.00, Steps = 4, Loss = 8.9247, Exploration Rate = 0.1000, Train Count = 70130\n",
      "Episode 9690: Reward = 547.00, Steps = 4, Loss = 10.0889, Exploration Rate = 0.1000, Train Count = 70134\n",
      "Episode 9691: Reward = 582.00, Steps = 8, Loss = 10.9060, Exploration Rate = 0.1000, Train Count = 70142\n",
      "Episode 9692: Reward = 570.00, Steps = 12, Loss = 11.1357, Exploration Rate = 0.1000, Train Count = 70154\n",
      "Episode 9693: Reward = 588.00, Steps = 6, Loss = 12.7225, Exploration Rate = 0.1000, Train Count = 70160\n",
      "Episode 9694: Reward = 588.00, Steps = 6, Loss = 7.1457, Exploration Rate = 0.1000, Train Count = 70166\n",
      "Episode 9695: Reward = 594.00, Steps = 4, Loss = 18.5143, Exploration Rate = 0.1000, Train Count = 70170\n",
      "Episode 9696: Reward = 482.00, Steps = 10, Loss = 13.3823, Exploration Rate = 0.1000, Train Count = 70180\n",
      "Episode 9697: Reward = 573.00, Steps = 11, Loss = 6.6199, Exploration Rate = 0.1000, Train Count = 70191\n",
      "Episode 9698: Reward = 576.00, Steps = 10, Loss = 11.0413, Exploration Rate = 0.1000, Train Count = 70201\n",
      "Episode 9699: Reward = 591.00, Steps = 5, Loss = 7.9283, Exploration Rate = 0.1000, Train Count = 70206\n",
      "Episode 9700: Reward = 582.00, Steps = 8, Loss = 7.8473, Exploration Rate = 0.1000, Train Count = 70214\n",
      "Episode 9701: Reward = 585.00, Steps = 7, Loss = 9.0606, Exploration Rate = 0.1000, Train Count = 70221\n",
      "Episode 9702: Reward = 588.00, Steps = 6, Loss = 6.3382, Exploration Rate = 0.1000, Train Count = 70227\n",
      "Episode 9703: Reward = 576.00, Steps = 10, Loss = 5.5817, Exploration Rate = 0.1000, Train Count = 70237\n",
      "Episode 9704: Reward = 588.00, Steps = 6, Loss = 9.0391, Exploration Rate = 0.1000, Train Count = 70243\n",
      "Episode 9705: Reward = 588.00, Steps = 6, Loss = 5.9585, Exploration Rate = 0.1000, Train Count = 70249\n",
      "Episode 9706: Reward = 585.00, Steps = 7, Loss = 7.0101, Exploration Rate = 0.1000, Train Count = 70256\n",
      "Episode 9707: Reward = 597.00, Steps = 3, Loss = 8.6534, Exploration Rate = 0.1000, Train Count = 70259\n",
      "Episode 9708: Reward = 597.00, Steps = 3, Loss = 2.9637, Exploration Rate = 0.1000, Train Count = 70262\n",
      "Episode 9709: Reward = 588.00, Steps = 6, Loss = 8.2980, Exploration Rate = 0.1000, Train Count = 70268\n",
      "Episode 9710: Reward = 588.00, Steps = 6, Loss = 7.6629, Exploration Rate = 0.1000, Train Count = 70274\n",
      "Episode 9711: Reward = 582.00, Steps = 8, Loss = 7.2592, Exploration Rate = 0.1000, Train Count = 70282\n",
      "Episode 9712: Reward = 594.00, Steps = 4, Loss = 3.8950, Exploration Rate = 0.1000, Train Count = 70286\n",
      "Episode 9713: Reward = 594.00, Steps = 4, Loss = 6.7166, Exploration Rate = 0.1000, Train Count = 70290\n",
      "Episode 9714: Reward = 585.00, Steps = 7, Loss = 5.0033, Exploration Rate = 0.1000, Train Count = 70297\n",
      "Episode 9715: Reward = 588.00, Steps = 6, Loss = 16.2887, Exploration Rate = 0.1000, Train Count = 70303\n",
      "Episode 9716: Reward = 573.00, Steps = 11, Loss = 20.1750, Exploration Rate = 0.1000, Train Count = 70314\n",
      "Episode 9717: Reward = 594.00, Steps = 4, Loss = 12.1525, Exploration Rate = 0.1000, Train Count = 70318\n",
      "Episode 9718: Reward = 588.00, Steps = 6, Loss = 14.6490, Exploration Rate = 0.1000, Train Count = 70324\n",
      "Episode 9719: Reward = 591.00, Steps = 5, Loss = 12.6047, Exploration Rate = 0.1000, Train Count = 70329\n",
      "Episode 9720: Reward = 576.00, Steps = 10, Loss = 10.3560, Exploration Rate = 0.1000, Train Count = 70339\n",
      "Episode 9721: Reward = 588.00, Steps = 6, Loss = 8.7908, Exploration Rate = 0.1000, Train Count = 70345\n",
      "Episode 9722: Reward = 594.00, Steps = 4, Loss = 7.5273, Exploration Rate = 0.1000, Train Count = 70349\n",
      "Episode 9723: Reward = 585.00, Steps = 7, Loss = 7.5957, Exploration Rate = 0.1000, Train Count = 70356\n",
      "Episode 9724: Reward = 591.00, Steps = 5, Loss = 5.2238, Exploration Rate = 0.1000, Train Count = 70361\n",
      "Episode 9725: Reward = 594.00, Steps = 4, Loss = 6.1927, Exploration Rate = 0.1000, Train Count = 70365\n",
      "Episode 9726: Reward = 597.00, Steps = 3, Loss = 8.1627, Exploration Rate = 0.1000, Train Count = 70368\n",
      "Episode 9727: Reward = 588.00, Steps = 6, Loss = 7.0619, Exploration Rate = 0.1000, Train Count = 70374\n",
      "Episode 9728: Reward = 588.00, Steps = 6, Loss = 6.6172, Exploration Rate = 0.1000, Train Count = 70380\n",
      "Episode 9729: Reward = 600.00, Steps = 2, Loss = 4.4628, Exploration Rate = 0.1000, Train Count = 70382\n",
      "Episode 9730: Reward = 594.00, Steps = 4, Loss = 8.7738, Exploration Rate = 0.1000, Train Count = 70386\n",
      "Episode 9731: Reward = 585.00, Steps = 7, Loss = 11.5958, Exploration Rate = 0.1000, Train Count = 70393\n",
      "Episode 9732: Reward = 573.00, Steps = 11, Loss = 7.1917, Exploration Rate = 0.1000, Train Count = 70404\n",
      "Episode 9733: Reward = 585.00, Steps = 7, Loss = 5.4158, Exploration Rate = 0.1000, Train Count = 70411\n",
      "Episode 9734: Reward = 588.00, Steps = 6, Loss = 5.9895, Exploration Rate = 0.1000, Train Count = 70417\n",
      "Episode 9735: Reward = 597.00, Steps = 3, Loss = 6.6160, Exploration Rate = 0.1000, Train Count = 70420\n",
      "Episode 9736: Reward = 591.00, Steps = 5, Loss = 7.2703, Exploration Rate = 0.1000, Train Count = 70425\n",
      "Episode 9737: Reward = 588.00, Steps = 6, Loss = 6.4332, Exploration Rate = 0.1000, Train Count = 70431\n",
      "Episode 9738: Reward = 567.00, Steps = 13, Loss = 6.7389, Exploration Rate = 0.1000, Train Count = 70444\n",
      "Episode 9739: Reward = 552.00, Steps = 18, Loss = 5.5697, Exploration Rate = 0.1000, Train Count = 70462\n",
      "Episode 9740: Reward = 600.00, Steps = 2, Loss = 6.5344, Exploration Rate = 0.1000, Train Count = 70464\n",
      "Episode 9741: Reward = 588.00, Steps = 6, Loss = 3.4070, Exploration Rate = 0.1000, Train Count = 70470\n",
      "Episode 9742: Reward = 588.00, Steps = 6, Loss = 4.5548, Exploration Rate = 0.1000, Train Count = 70476\n",
      "Episode 9743: Reward = 594.00, Steps = 4, Loss = 2.8314, Exploration Rate = 0.1000, Train Count = 70480\n",
      "Episode 9744: Reward = 588.00, Steps = 6, Loss = 2.9226, Exploration Rate = 0.1000, Train Count = 70486\n",
      "Episode 9745: Reward = 594.00, Steps = 4, Loss = 3.2816, Exploration Rate = 0.1000, Train Count = 70490\n",
      "Episode 9746: Reward = 594.00, Steps = 4, Loss = 2.4107, Exploration Rate = 0.1000, Train Count = 70494\n",
      "Episode 9747: Reward = 591.00, Steps = 5, Loss = 4.5519, Exploration Rate = 0.1000, Train Count = 70499\n",
      "Episode 9748: Reward = 591.00, Steps = 5, Loss = 1.6698, Exploration Rate = 0.1000, Train Count = 70504\n",
      "Episode 9749: Reward = 579.00, Steps = 9, Loss = 2.7609, Exploration Rate = 0.1000, Train Count = 70513\n",
      "Episode 9750: Reward = 591.00, Steps = 5, Loss = 1.8393, Exploration Rate = 0.1000, Train Count = 70518\n",
      "Episode 9751: Reward = 541.00, Steps = 6, Loss = 4.4916, Exploration Rate = 0.1000, Train Count = 70524\n",
      "Episode 9752: Reward = 591.00, Steps = 5, Loss = 4.5359, Exploration Rate = 0.1000, Train Count = 70529\n",
      "Episode 9753: Reward = 591.00, Steps = 5, Loss = 4.6216, Exploration Rate = 0.1000, Train Count = 70534\n",
      "Episode 9754: Reward = 582.00, Steps = 8, Loss = 3.2567, Exploration Rate = 0.1000, Train Count = 70542\n",
      "Episode 9755: Reward = 591.00, Steps = 5, Loss = 4.8482, Exploration Rate = 0.1000, Train Count = 70547\n",
      "Episode 9756: Reward = 594.00, Steps = 4, Loss = 7.1275, Exploration Rate = 0.1000, Train Count = 70551\n",
      "Episode 9757: Reward = 591.00, Steps = 5, Loss = 4.0235, Exploration Rate = 0.1000, Train Count = 70556\n",
      "Episode 9758: Reward = 585.00, Steps = 7, Loss = 4.7360, Exploration Rate = 0.1000, Train Count = 70563\n",
      "Episode 9759: Reward = 597.00, Steps = 3, Loss = 1.9891, Exploration Rate = 0.1000, Train Count = 70566\n",
      "Episode 9760: Reward = 594.00, Steps = 4, Loss = 6.9814, Exploration Rate = 0.1000, Train Count = 70570\n",
      "Episode 9761: Reward = 579.00, Steps = 9, Loss = 5.1801, Exploration Rate = 0.1000, Train Count = 70579\n",
      "Episode 9762: Reward = 591.00, Steps = 5, Loss = 3.3324, Exploration Rate = 0.1000, Train Count = 70584\n",
      "Episode 9763: Reward = 594.00, Steps = 4, Loss = 3.2237, Exploration Rate = 0.1000, Train Count = 70588\n",
      "Episode 9764: Reward = 594.00, Steps = 4, Loss = 3.4455, Exploration Rate = 0.1000, Train Count = 70592\n",
      "Episode 9765: Reward = 585.00, Steps = 7, Loss = 4.2574, Exploration Rate = 0.1000, Train Count = 70599\n",
      "Episode 9766: Reward = 591.00, Steps = 5, Loss = 4.1345, Exploration Rate = 0.1000, Train Count = 70604\n",
      "Episode 9767: Reward = 588.00, Steps = 6, Loss = 5.6310, Exploration Rate = 0.1000, Train Count = 70610\n",
      "Episode 9768: Reward = 591.00, Steps = 5, Loss = 5.4739, Exploration Rate = 0.1000, Train Count = 70615\n",
      "Episode 9769: Reward = 591.00, Steps = 5, Loss = 5.1157, Exploration Rate = 0.1000, Train Count = 70620\n",
      "Episode 9770: Reward = 573.00, Steps = 11, Loss = 5.7756, Exploration Rate = 0.1000, Train Count = 70631\n",
      "Episode 9771: Reward = 591.00, Steps = 5, Loss = 5.8877, Exploration Rate = 0.1000, Train Count = 70636\n",
      "Episode 9772: Reward = 576.00, Steps = 10, Loss = 6.6395, Exploration Rate = 0.1000, Train Count = 70646\n",
      "Episode 9773: Reward = 588.00, Steps = 6, Loss = 5.0818, Exploration Rate = 0.1000, Train Count = 70652\n",
      "Episode 9774: Reward = 588.00, Steps = 6, Loss = 4.5864, Exploration Rate = 0.1000, Train Count = 70658\n",
      "Episode 9775: Reward = 597.00, Steps = 3, Loss = 3.9685, Exploration Rate = 0.1000, Train Count = 70661\n",
      "Episode 9776: Reward = 588.00, Steps = 6, Loss = 8.9343, Exploration Rate = 0.1000, Train Count = 70667\n",
      "Episode 9777: Reward = 588.00, Steps = 6, Loss = 8.4291, Exploration Rate = 0.1000, Train Count = 70673\n",
      "Episode 9778: Reward = 594.00, Steps = 4, Loss = 5.1113, Exploration Rate = 0.1000, Train Count = 70677\n",
      "Episode 9779: Reward = 597.00, Steps = 3, Loss = 8.1114, Exploration Rate = 0.1000, Train Count = 70680\n",
      "Episode 9780: Reward = 579.00, Steps = 9, Loss = 6.4410, Exploration Rate = 0.1000, Train Count = 70689\n",
      "Episode 9781: Reward = 591.00, Steps = 5, Loss = 4.5724, Exploration Rate = 0.1000, Train Count = 70694\n",
      "Episode 9782: Reward = 573.00, Steps = 11, Loss = 6.7563, Exploration Rate = 0.1000, Train Count = 70705\n",
      "Episode 9783: Reward = 588.00, Steps = 6, Loss = 7.7926, Exploration Rate = 0.1000, Train Count = 70711\n",
      "Episode 9784: Reward = 585.00, Steps = 7, Loss = 7.5800, Exploration Rate = 0.1000, Train Count = 70718\n",
      "Episode 9785: Reward = 585.00, Steps = 7, Loss = 6.7004, Exploration Rate = 0.1000, Train Count = 70725\n",
      "Episode 9786: Reward = 544.00, Steps = 5, Loss = 5.6832, Exploration Rate = 0.1000, Train Count = 70730\n",
      "Episode 9787: Reward = 585.00, Steps = 7, Loss = 7.4672, Exploration Rate = 0.1000, Train Count = 70737\n",
      "Episode 9788: Reward = 588.00, Steps = 6, Loss = 4.7023, Exploration Rate = 0.1000, Train Count = 70743\n",
      "Episode 9789: Reward = 585.00, Steps = 7, Loss = 8.1424, Exploration Rate = 0.1000, Train Count = 70750\n",
      "Episode 9790: Reward = 576.00, Steps = 10, Loss = 5.0399, Exploration Rate = 0.1000, Train Count = 70760\n",
      "Episode 9791: Reward = 588.00, Steps = 6, Loss = 6.3986, Exploration Rate = 0.1000, Train Count = 70766\n",
      "Episode 9792: Reward = 576.00, Steps = 10, Loss = 9.2713, Exploration Rate = 0.1000, Train Count = 70776\n",
      "Episode 9793: Reward = 591.00, Steps = 5, Loss = 4.9023, Exploration Rate = 0.1000, Train Count = 70781\n",
      "Episode 9794: Reward = 591.00, Steps = 5, Loss = 9.6975, Exploration Rate = 0.1000, Train Count = 70786\n",
      "Episode 9795: Reward = 597.00, Steps = 3, Loss = 4.4364, Exploration Rate = 0.1000, Train Count = 70789\n",
      "Episode 9796: Reward = 591.00, Steps = 5, Loss = 4.3482, Exploration Rate = 0.1000, Train Count = 70794\n",
      "Episode 9797: Reward = 535.00, Steps = 8, Loss = 10.4101, Exploration Rate = 0.1000, Train Count = 70802\n",
      "Episode 9798: Reward = 594.00, Steps = 4, Loss = 22.1899, Exploration Rate = 0.1000, Train Count = 70806\n",
      "Episode 9799: Reward = 588.00, Steps = 6, Loss = 19.8628, Exploration Rate = 0.1000, Train Count = 70812\n",
      "Episode 9800: Reward = 597.00, Steps = 3, Loss = 16.8299, Exploration Rate = 0.1000, Train Count = 70815\n",
      "Episode 9801: Reward = 588.00, Steps = 6, Loss = 16.1963, Exploration Rate = 0.1000, Train Count = 70821\n",
      "Episode 9802: Reward = 579.00, Steps = 9, Loss = 13.6895, Exploration Rate = 0.1000, Train Count = 70830\n",
      "Episode 9803: Reward = 588.00, Steps = 6, Loss = 7.4324, Exploration Rate = 0.1000, Train Count = 70836\n",
      "Episode 9804: Reward = 594.00, Steps = 4, Loss = 7.9183, Exploration Rate = 0.1000, Train Count = 70840\n",
      "Episode 9805: Reward = 544.00, Steps = 5, Loss = 9.2167, Exploration Rate = 0.1000, Train Count = 70845\n",
      "Episode 9806: Reward = 594.00, Steps = 4, Loss = 22.3291, Exploration Rate = 0.1000, Train Count = 70849\n",
      "Episode 9807: Reward = 594.00, Steps = 4, Loss = 10.4776, Exploration Rate = 0.1000, Train Count = 70853\n",
      "Episode 9808: Reward = 597.00, Steps = 3, Loss = 16.8040, Exploration Rate = 0.1000, Train Count = 70856\n",
      "Episode 9809: Reward = 535.00, Steps = 8, Loss = 12.1944, Exploration Rate = 0.1000, Train Count = 70864\n",
      "Episode 9810: Reward = 591.00, Steps = 5, Loss = 9.0194, Exploration Rate = 0.1000, Train Count = 70869\n",
      "Episode 9811: Reward = 597.00, Steps = 3, Loss = 9.4739, Exploration Rate = 0.1000, Train Count = 70872\n",
      "Episode 9812: Reward = 591.00, Steps = 5, Loss = 7.4102, Exploration Rate = 0.1000, Train Count = 70877\n",
      "Episode 9813: Reward = 594.00, Steps = 4, Loss = 5.9423, Exploration Rate = 0.1000, Train Count = 70881\n",
      "Episode 9814: Reward = 585.00, Steps = 7, Loss = 5.3285, Exploration Rate = 0.1000, Train Count = 70888\n",
      "Episode 9815: Reward = 585.00, Steps = 7, Loss = 7.0437, Exploration Rate = 0.1000, Train Count = 70895\n",
      "Episode 9816: Reward = 594.00, Steps = 4, Loss = 5.6618, Exploration Rate = 0.1000, Train Count = 70899\n",
      "Episode 9817: Reward = 585.00, Steps = 7, Loss = 6.6737, Exploration Rate = 0.1000, Train Count = 70906\n",
      "Episode 9818: Reward = 579.00, Steps = 9, Loss = 6.7122, Exploration Rate = 0.1000, Train Count = 70915\n",
      "Episode 9819: Reward = 588.00, Steps = 6, Loss = 6.9282, Exploration Rate = 0.1000, Train Count = 70921\n",
      "Episode 9820: Reward = 585.00, Steps = 7, Loss = 5.7079, Exploration Rate = 0.1000, Train Count = 70928\n",
      "Episode 9821: Reward = 585.00, Steps = 7, Loss = 4.6321, Exploration Rate = 0.1000, Train Count = 70935\n",
      "Episode 9822: Reward = 588.00, Steps = 6, Loss = 3.7789, Exploration Rate = 0.1000, Train Count = 70941\n",
      "Episode 9823: Reward = 585.00, Steps = 7, Loss = 4.3927, Exploration Rate = 0.1000, Train Count = 70948\n",
      "Episode 9824: Reward = 588.00, Steps = 6, Loss = 3.9665, Exploration Rate = 0.1000, Train Count = 70954\n",
      "Episode 9825: Reward = 588.00, Steps = 6, Loss = 4.9946, Exploration Rate = 0.1000, Train Count = 70960\n",
      "Episode 9826: Reward = 579.00, Steps = 9, Loss = 2.8854, Exploration Rate = 0.1000, Train Count = 70969\n",
      "Episode 9827: Reward = 588.00, Steps = 6, Loss = 2.3914, Exploration Rate = 0.1000, Train Count = 70975\n",
      "Episode 9828: Reward = 526.00, Steps = 11, Loss = 4.0454, Exploration Rate = 0.1000, Train Count = 70986\n",
      "Episode 9829: Reward = 594.00, Steps = 4, Loss = 3.5000, Exploration Rate = 0.1000, Train Count = 70990\n",
      "Episode 9830: Reward = 594.00, Steps = 4, Loss = 3.0658, Exploration Rate = 0.1000, Train Count = 70994\n",
      "Episode 9831: Reward = 573.00, Steps = 11, Loss = 4.5873, Exploration Rate = 0.1000, Train Count = 71005\n",
      "Episode 9832: Reward = 588.00, Steps = 6, Loss = 10.1850, Exploration Rate = 0.1000, Train Count = 71011\n",
      "Episode 9833: Reward = 582.00, Steps = 8, Loss = 6.1750, Exploration Rate = 0.1000, Train Count = 71019\n",
      "Episode 9834: Reward = 594.00, Steps = 4, Loss = 3.8674, Exploration Rate = 0.1000, Train Count = 71023\n",
      "Episode 9835: Reward = 585.00, Steps = 7, Loss = 5.4948, Exploration Rate = 0.1000, Train Count = 71030\n",
      "Episode 9836: Reward = 591.00, Steps = 5, Loss = 4.5420, Exploration Rate = 0.1000, Train Count = 71035\n",
      "Episode 9837: Reward = 591.00, Steps = 5, Loss = 5.7494, Exploration Rate = 0.1000, Train Count = 71040\n",
      "Episode 9838: Reward = 597.00, Steps = 3, Loss = 5.7953, Exploration Rate = 0.1000, Train Count = 71043\n",
      "Episode 9839: Reward = 591.00, Steps = 5, Loss = 7.3729, Exploration Rate = 0.1000, Train Count = 71048\n",
      "Episode 9840: Reward = 591.00, Steps = 5, Loss = 3.9997, Exploration Rate = 0.1000, Train Count = 71053\n",
      "Episode 9841: Reward = 594.00, Steps = 4, Loss = 3.9368, Exploration Rate = 0.1000, Train Count = 71057\n",
      "Episode 9842: Reward = 573.00, Steps = 11, Loss = 4.6111, Exploration Rate = 0.1000, Train Count = 71068\n",
      "Episode 9843: Reward = 585.00, Steps = 7, Loss = 3.6363, Exploration Rate = 0.1000, Train Count = 71075\n",
      "Episode 9844: Reward = 520.00, Steps = 13, Loss = 3.0675, Exploration Rate = 0.1000, Train Count = 71088\n",
      "Episode 9845: Reward = 591.00, Steps = 5, Loss = 6.9986, Exploration Rate = 0.1000, Train Count = 71093\n",
      "Episode 9846: Reward = 570.00, Steps = 12, Loss = 6.4294, Exploration Rate = 0.1000, Train Count = 71105\n",
      "Episode 9847: Reward = 594.00, Steps = 4, Loss = 5.4974, Exploration Rate = 0.1000, Train Count = 71109\n",
      "Episode 9848: Reward = 597.00, Steps = 3, Loss = 3.0082, Exploration Rate = 0.1000, Train Count = 71112\n",
      "Episode 9849: Reward = 591.00, Steps = 5, Loss = 3.9979, Exploration Rate = 0.1000, Train Count = 71117\n",
      "Episode 9850: Reward = 579.00, Steps = 9, Loss = 4.8228, Exploration Rate = 0.1000, Train Count = 71126\n",
      "Episode 9851: Reward = 588.00, Steps = 6, Loss = 6.3793, Exploration Rate = 0.1000, Train Count = 71132\n",
      "Episode 9852: Reward = 594.00, Steps = 4, Loss = 6.6540, Exploration Rate = 0.1000, Train Count = 71136\n",
      "Episode 9853: Reward = 591.00, Steps = 5, Loss = 3.0900, Exploration Rate = 0.1000, Train Count = 71141\n",
      "Episode 9854: Reward = 594.00, Steps = 4, Loss = 5.2862, Exploration Rate = 0.1000, Train Count = 71145\n",
      "Episode 9855: Reward = 570.00, Steps = 12, Loss = 4.1619, Exploration Rate = 0.1000, Train Count = 71157\n",
      "Episode 9856: Reward = 582.00, Steps = 8, Loss = 2.3778, Exploration Rate = 0.1000, Train Count = 71165\n",
      "Episode 9857: Reward = 594.00, Steps = 4, Loss = 5.2318, Exploration Rate = 0.1000, Train Count = 71169\n",
      "Episode 9858: Reward = 591.00, Steps = 5, Loss = 4.8406, Exploration Rate = 0.1000, Train Count = 71174\n",
      "Episode 9859: Reward = 588.00, Steps = 6, Loss = 3.9276, Exploration Rate = 0.1000, Train Count = 71180\n",
      "Episode 9860: Reward = 594.00, Steps = 4, Loss = 6.0635, Exploration Rate = 0.1000, Train Count = 71184\n",
      "Episode 9861: Reward = 594.00, Steps = 4, Loss = 8.2502, Exploration Rate = 0.1000, Train Count = 71188\n",
      "Episode 9862: Reward = 594.00, Steps = 4, Loss = 4.8223, Exploration Rate = 0.1000, Train Count = 71192\n",
      "Episode 9863: Reward = 573.00, Steps = 11, Loss = 6.5386, Exploration Rate = 0.1000, Train Count = 71203\n",
      "Episode 9864: Reward = 594.00, Steps = 4, Loss = 11.2059, Exploration Rate = 0.1000, Train Count = 71207\n",
      "Episode 9865: Reward = 573.00, Steps = 11, Loss = 4.5554, Exploration Rate = 0.1000, Train Count = 71218\n",
      "Episode 9866: Reward = 585.00, Steps = 7, Loss = 5.8263, Exploration Rate = 0.1000, Train Count = 71225\n",
      "Episode 9867: Reward = 597.00, Steps = 3, Loss = 2.2349, Exploration Rate = 0.1000, Train Count = 71228\n",
      "Episode 9868: Reward = 588.00, Steps = 6, Loss = 4.8218, Exploration Rate = 0.1000, Train Count = 71234\n",
      "Episode 9869: Reward = 582.00, Steps = 8, Loss = 4.8843, Exploration Rate = 0.1000, Train Count = 71242\n",
      "Episode 9870: Reward = 591.00, Steps = 5, Loss = 5.8266, Exploration Rate = 0.1000, Train Count = 71247\n",
      "Episode 9871: Reward = 594.00, Steps = 4, Loss = 3.5008, Exploration Rate = 0.1000, Train Count = 71251\n",
      "Episode 9872: Reward = 585.00, Steps = 7, Loss = 4.6029, Exploration Rate = 0.1000, Train Count = 71258\n",
      "Episode 9873: Reward = 582.00, Steps = 8, Loss = 8.0533, Exploration Rate = 0.1000, Train Count = 71266\n",
      "Episode 9874: Reward = 591.00, Steps = 5, Loss = 6.1805, Exploration Rate = 0.1000, Train Count = 71271\n",
      "Episode 9875: Reward = 588.00, Steps = 6, Loss = 3.7372, Exploration Rate = 0.1000, Train Count = 71277\n",
      "Episode 9876: Reward = 591.00, Steps = 5, Loss = 6.6976, Exploration Rate = 0.1000, Train Count = 71282\n",
      "Episode 9877: Reward = 520.00, Steps = 13, Loss = 6.9786, Exploration Rate = 0.1000, Train Count = 71295\n",
      "Episode 9878: Reward = 591.00, Steps = 5, Loss = 3.6831, Exploration Rate = 0.1000, Train Count = 71300\n",
      "Episode 9879: Reward = 597.00, Steps = 3, Loss = 27.3104, Exploration Rate = 0.1000, Train Count = 71303\n",
      "Episode 9880: Reward = 588.00, Steps = 6, Loss = 24.2318, Exploration Rate = 0.1000, Train Count = 71309\n",
      "Episode 9881: Reward = 588.00, Steps = 6, Loss = 14.0338, Exploration Rate = 0.1000, Train Count = 71315\n",
      "Episode 9882: Reward = 591.00, Steps = 5, Loss = 14.7183, Exploration Rate = 0.1000, Train Count = 71320\n",
      "Episode 9883: Reward = 588.00, Steps = 6, Loss = 12.5989, Exploration Rate = 0.1000, Train Count = 71326\n",
      "Episode 9884: Reward = 600.00, Steps = 2, Loss = 10.6801, Exploration Rate = 0.1000, Train Count = 71328\n",
      "Episode 9885: Reward = 594.00, Steps = 4, Loss = 11.4083, Exploration Rate = 0.1000, Train Count = 71332\n",
      "Episode 9886: Reward = 576.00, Steps = 10, Loss = 9.1778, Exploration Rate = 0.1000, Train Count = 71342\n",
      "Episode 9887: Reward = 585.00, Steps = 7, Loss = 9.5463, Exploration Rate = 0.1000, Train Count = 71349\n",
      "Episode 9888: Reward = 588.00, Steps = 6, Loss = 7.3893, Exploration Rate = 0.1000, Train Count = 71355\n",
      "Episode 9889: Reward = 591.00, Steps = 5, Loss = 5.4132, Exploration Rate = 0.1000, Train Count = 71360\n",
      "Episode 9890: Reward = 591.00, Steps = 5, Loss = 5.7411, Exploration Rate = 0.1000, Train Count = 71365\n",
      "Episode 9891: Reward = 532.00, Steps = 9, Loss = 8.1581, Exploration Rate = 0.1000, Train Count = 71374\n",
      "Episode 9892: Reward = 570.00, Steps = 12, Loss = 7.6531, Exploration Rate = 0.1000, Train Count = 71386\n",
      "Episode 9893: Reward = 585.00, Steps = 7, Loss = 5.7790, Exploration Rate = 0.1000, Train Count = 71393\n",
      "Episode 9894: Reward = 588.00, Steps = 6, Loss = 4.9057, Exploration Rate = 0.1000, Train Count = 71399\n",
      "Episode 9895: Reward = 573.00, Steps = 11, Loss = 7.2826, Exploration Rate = 0.1000, Train Count = 71410\n",
      "Episode 9896: Reward = 579.00, Steps = 9, Loss = 9.0324, Exploration Rate = 0.1000, Train Count = 71419\n",
      "Episode 9897: Reward = 591.00, Steps = 5, Loss = 6.6416, Exploration Rate = 0.1000, Train Count = 71424\n",
      "Episode 9898: Reward = 597.00, Steps = 3, Loss = 6.9739, Exploration Rate = 0.1000, Train Count = 71427\n",
      "Episode 9899: Reward = 585.00, Steps = 7, Loss = 4.8723, Exploration Rate = 0.1000, Train Count = 71434\n",
      "Episode 9900: Reward = 594.00, Steps = 4, Loss = 3.0733, Exploration Rate = 0.1000, Train Count = 71438\n",
      "Episode 9901: Reward = 594.00, Steps = 4, Loss = 5.7456, Exploration Rate = 0.1000, Train Count = 71442\n",
      "Episode 9902: Reward = 594.00, Steps = 4, Loss = 7.0065, Exploration Rate = 0.1000, Train Count = 71446\n",
      "Episode 9903: Reward = 579.00, Steps = 9, Loss = 4.7710, Exploration Rate = 0.1000, Train Count = 71455\n",
      "Episode 9904: Reward = 585.00, Steps = 7, Loss = 3.7870, Exploration Rate = 0.1000, Train Count = 71462\n",
      "Episode 9905: Reward = 588.00, Steps = 6, Loss = 3.0132, Exploration Rate = 0.1000, Train Count = 71468\n",
      "Episode 9906: Reward = 591.00, Steps = 5, Loss = 2.8150, Exploration Rate = 0.1000, Train Count = 71473\n",
      "Episode 9907: Reward = 597.00, Steps = 3, Loss = 1.8542, Exploration Rate = 0.1000, Train Count = 71476\n",
      "Episode 9908: Reward = 594.00, Steps = 4, Loss = 1.9879, Exploration Rate = 0.1000, Train Count = 71480\n",
      "Episode 9909: Reward = 576.00, Steps = 10, Loss = 4.6927, Exploration Rate = 0.1000, Train Count = 71490\n",
      "Episode 9910: Reward = 591.00, Steps = 5, Loss = 2.0502, Exploration Rate = 0.1000, Train Count = 71495\n",
      "Episode 9911: Reward = 594.00, Steps = 4, Loss = 1.9985, Exploration Rate = 0.1000, Train Count = 71499\n",
      "Episode 9912: Reward = 541.00, Steps = 6, Loss = 3.8831, Exploration Rate = 0.1000, Train Count = 71505\n",
      "Episode 9913: Reward = 588.00, Steps = 6, Loss = 7.6349, Exploration Rate = 0.1000, Train Count = 71511\n",
      "Episode 9914: Reward = 594.00, Steps = 4, Loss = 4.5254, Exploration Rate = 0.1000, Train Count = 71515\n",
      "Episode 9915: Reward = 594.00, Steps = 4, Loss = 3.5285, Exploration Rate = 0.1000, Train Count = 71519\n",
      "Episode 9916: Reward = 597.00, Steps = 3, Loss = 2.9300, Exploration Rate = 0.1000, Train Count = 71522\n",
      "Episode 9917: Reward = 544.00, Steps = 5, Loss = 8.6730, Exploration Rate = 0.1000, Train Count = 71527\n",
      "Episode 9918: Reward = 588.00, Steps = 6, Loss = 6.8584, Exploration Rate = 0.1000, Train Count = 71533\n",
      "Episode 9919: Reward = 585.00, Steps = 7, Loss = 6.3227, Exploration Rate = 0.1000, Train Count = 71540\n",
      "Episode 9920: Reward = 579.00, Steps = 9, Loss = 4.1552, Exploration Rate = 0.1000, Train Count = 71549\n",
      "Episode 9921: Reward = 594.00, Steps = 4, Loss = 5.5537, Exploration Rate = 0.1000, Train Count = 71553\n",
      "Episode 9922: Reward = 585.00, Steps = 7, Loss = 8.1283, Exploration Rate = 0.1000, Train Count = 71560\n",
      "Episode 9923: Reward = 594.00, Steps = 4, Loss = 2.0009, Exploration Rate = 0.1000, Train Count = 71564\n",
      "Episode 9924: Reward = 588.00, Steps = 6, Loss = 5.0108, Exploration Rate = 0.1000, Train Count = 71570\n",
      "Episode 9925: Reward = 594.00, Steps = 4, Loss = 5.1334, Exploration Rate = 0.1000, Train Count = 71574\n",
      "Episode 9926: Reward = 594.00, Steps = 4, Loss = 4.6391, Exploration Rate = 0.1000, Train Count = 71578\n",
      "Episode 9927: Reward = 585.00, Steps = 7, Loss = 6.5738, Exploration Rate = 0.1000, Train Count = 71585\n",
      "Episode 9928: Reward = 585.00, Steps = 7, Loss = 5.5268, Exploration Rate = 0.1000, Train Count = 71592\n",
      "Episode 9929: Reward = 600.00, Steps = 2, Loss = 3.4667, Exploration Rate = 0.1000, Train Count = 71594\n",
      "Episode 9930: Reward = 591.00, Steps = 5, Loss = 3.9118, Exploration Rate = 0.1000, Train Count = 71599\n",
      "Episode 9931: Reward = 588.00, Steps = 6, Loss = 3.1343, Exploration Rate = 0.1000, Train Count = 71605\n",
      "Episode 9932: Reward = 585.00, Steps = 7, Loss = 6.1634, Exploration Rate = 0.1000, Train Count = 71612\n",
      "Episode 9933: Reward = 597.00, Steps = 3, Loss = 3.8619, Exploration Rate = 0.1000, Train Count = 71615\n",
      "Episode 9934: Reward = 597.00, Steps = 3, Loss = 6.5064, Exploration Rate = 0.1000, Train Count = 71618\n",
      "Episode 9935: Reward = 591.00, Steps = 5, Loss = 7.3358, Exploration Rate = 0.1000, Train Count = 71623\n",
      "Episode 9936: Reward = 579.00, Steps = 9, Loss = 3.9900, Exploration Rate = 0.1000, Train Count = 71632\n",
      "Episode 9937: Reward = 579.00, Steps = 9, Loss = 7.8505, Exploration Rate = 0.1000, Train Count = 71641\n",
      "Episode 9938: Reward = 591.00, Steps = 5, Loss = 7.3432, Exploration Rate = 0.1000, Train Count = 71646\n",
      "Episode 9939: Reward = 594.00, Steps = 4, Loss = 6.5385, Exploration Rate = 0.1000, Train Count = 71650\n",
      "Episode 9940: Reward = 532.00, Steps = 9, Loss = 5.6713, Exploration Rate = 0.1000, Train Count = 71659\n",
      "Episode 9941: Reward = 597.00, Steps = 3, Loss = 6.2917, Exploration Rate = 0.1000, Train Count = 71662\n",
      "Episode 9942: Reward = 588.00, Steps = 6, Loss = 6.2820, Exploration Rate = 0.1000, Train Count = 71668\n",
      "Episode 9943: Reward = 570.00, Steps = 12, Loss = 5.6545, Exploration Rate = 0.1000, Train Count = 71680\n",
      "Episode 9944: Reward = 594.00, Steps = 4, Loss = 3.0988, Exploration Rate = 0.1000, Train Count = 71684\n",
      "Episode 9945: Reward = 591.00, Steps = 5, Loss = 6.3448, Exploration Rate = 0.1000, Train Count = 71689\n",
      "Episode 9946: Reward = 582.00, Steps = 8, Loss = 4.9625, Exploration Rate = 0.1000, Train Count = 71697\n",
      "Episode 9947: Reward = 594.00, Steps = 4, Loss = 3.0545, Exploration Rate = 0.1000, Train Count = 71701\n",
      "Episode 9948: Reward = 600.00, Steps = 2, Loss = 5.9861, Exploration Rate = 0.1000, Train Count = 71703\n",
      "Episode 9949: Reward = 588.00, Steps = 6, Loss = 6.0712, Exploration Rate = 0.1000, Train Count = 71709\n",
      "Episode 9950: Reward = 582.00, Steps = 8, Loss = 4.2539, Exploration Rate = 0.1000, Train Count = 71717\n",
      "Episode 9951: Reward = 529.00, Steps = 10, Loss = 7.3484, Exploration Rate = 0.1000, Train Count = 71727\n",
      "Episode 9952: Reward = 591.00, Steps = 5, Loss = 6.0580, Exploration Rate = 0.1000, Train Count = 71732\n",
      "Episode 9953: Reward = 591.00, Steps = 5, Loss = 3.2554, Exploration Rate = 0.1000, Train Count = 71737\n",
      "Episode 9954: Reward = 579.00, Steps = 9, Loss = 6.5154, Exploration Rate = 0.1000, Train Count = 71746\n",
      "Episode 9955: Reward = 588.00, Steps = 6, Loss = 5.4742, Exploration Rate = 0.1000, Train Count = 71752\n",
      "Episode 9956: Reward = 594.00, Steps = 4, Loss = 4.4030, Exploration Rate = 0.1000, Train Count = 71756\n",
      "Episode 9957: Reward = 588.00, Steps = 6, Loss = 6.0045, Exploration Rate = 0.1000, Train Count = 71762\n",
      "Episode 9958: Reward = 597.00, Steps = 3, Loss = 2.1149, Exploration Rate = 0.1000, Train Count = 71765\n",
      "Episode 9959: Reward = 597.00, Steps = 3, Loss = 2.9704, Exploration Rate = 0.1000, Train Count = 71768\n",
      "Episode 9960: Reward = 579.00, Steps = 9, Loss = 7.6491, Exploration Rate = 0.1000, Train Count = 71777\n",
      "Episode 9961: Reward = 594.00, Steps = 4, Loss = 5.3803, Exploration Rate = 0.1000, Train Count = 71781\n",
      "Episode 9962: Reward = 582.00, Steps = 8, Loss = 5.3964, Exploration Rate = 0.1000, Train Count = 71789\n",
      "Episode 9963: Reward = 570.00, Steps = 12, Loss = 6.7976, Exploration Rate = 0.1000, Train Count = 71801\n",
      "Episode 9964: Reward = 588.00, Steps = 6, Loss = 25.6973, Exploration Rate = 0.1000, Train Count = 71807\n",
      "Episode 9965: Reward = 594.00, Steps = 4, Loss = 22.1706, Exploration Rate = 0.1000, Train Count = 71811\n",
      "Episode 9966: Reward = 582.00, Steps = 8, Loss = 15.8311, Exploration Rate = 0.1000, Train Count = 71819\n",
      "Episode 9967: Reward = 588.00, Steps = 6, Loss = 14.7939, Exploration Rate = 0.1000, Train Count = 71825\n",
      "Episode 9968: Reward = 582.00, Steps = 8, Loss = 11.7084, Exploration Rate = 0.1000, Train Count = 71833\n",
      "Episode 9969: Reward = 594.00, Steps = 4, Loss = 8.6348, Exploration Rate = 0.1000, Train Count = 71837\n",
      "Episode 9970: Reward = 594.00, Steps = 4, Loss = 6.6413, Exploration Rate = 0.1000, Train Count = 71841\n",
      "Episode 9971: Reward = 594.00, Steps = 4, Loss = 9.2276, Exploration Rate = 0.1000, Train Count = 71845\n",
      "Episode 9972: Reward = 538.00, Steps = 7, Loss = 10.1057, Exploration Rate = 0.1000, Train Count = 71852\n",
      "Episode 9973: Reward = 585.00, Steps = 7, Loss = 12.3913, Exploration Rate = 0.1000, Train Count = 71859\n",
      "Episode 9974: Reward = 597.00, Steps = 3, Loss = 8.6832, Exploration Rate = 0.1000, Train Count = 71862\n",
      "Episode 9975: Reward = 582.00, Steps = 8, Loss = 9.3675, Exploration Rate = 0.1000, Train Count = 71870\n",
      "Episode 9976: Reward = 594.00, Steps = 4, Loss = 8.9208, Exploration Rate = 0.1000, Train Count = 71874\n",
      "Episode 9977: Reward = 579.00, Steps = 9, Loss = 8.9918, Exploration Rate = 0.1000, Train Count = 71883\n",
      "Episode 9978: Reward = 591.00, Steps = 5, Loss = 7.3428, Exploration Rate = 0.1000, Train Count = 71888\n",
      "Episode 9979: Reward = 585.00, Steps = 7, Loss = 9.7387, Exploration Rate = 0.1000, Train Count = 71895\n",
      "Episode 9980: Reward = 588.00, Steps = 6, Loss = 9.9173, Exploration Rate = 0.1000, Train Count = 71901\n",
      "Episode 9981: Reward = 585.00, Steps = 7, Loss = 8.4645, Exploration Rate = 0.1000, Train Count = 71908\n",
      "Episode 9982: Reward = 591.00, Steps = 5, Loss = 7.0873, Exploration Rate = 0.1000, Train Count = 71913\n",
      "Episode 9983: Reward = 588.00, Steps = 6, Loss = 6.9407, Exploration Rate = 0.1000, Train Count = 71919\n",
      "Episode 9984: Reward = 585.00, Steps = 7, Loss = 9.4698, Exploration Rate = 0.1000, Train Count = 71926\n",
      "Episode 9985: Reward = 585.00, Steps = 7, Loss = 6.0980, Exploration Rate = 0.1000, Train Count = 71933\n",
      "Episode 9986: Reward = 594.00, Steps = 4, Loss = 3.9533, Exploration Rate = 0.1000, Train Count = 71937\n",
      "Episode 9987: Reward = 591.00, Steps = 5, Loss = 4.5062, Exploration Rate = 0.1000, Train Count = 71942\n",
      "Episode 9988: Reward = 594.00, Steps = 4, Loss = 8.7364, Exploration Rate = 0.1000, Train Count = 71946\n",
      "Episode 9989: Reward = 588.00, Steps = 6, Loss = 6.3785, Exploration Rate = 0.1000, Train Count = 71952\n",
      "Episode 9990: Reward = 585.00, Steps = 7, Loss = 7.3912, Exploration Rate = 0.1000, Train Count = 71959\n",
      "Episode 9991: Reward = 585.00, Steps = 7, Loss = 7.7909, Exploration Rate = 0.1000, Train Count = 71966\n",
      "Episode 9992: Reward = 594.00, Steps = 4, Loss = 6.1738, Exploration Rate = 0.1000, Train Count = 71970\n",
      "Episode 9993: Reward = 597.00, Steps = 3, Loss = 7.1456, Exploration Rate = 0.1000, Train Count = 71973\n",
      "Episode 9994: Reward = 594.00, Steps = 4, Loss = 7.3362, Exploration Rate = 0.1000, Train Count = 71977\n",
      "Episode 9995: Reward = 600.00, Steps = 2, Loss = 6.9340, Exploration Rate = 0.1000, Train Count = 71979\n",
      "Episode 9996: Reward = 541.00, Steps = 6, Loss = 8.3274, Exploration Rate = 0.1000, Train Count = 71985\n",
      "Episode 9997: Reward = 591.00, Steps = 5, Loss = 9.7207, Exploration Rate = 0.1000, Train Count = 71990\n",
      "Episode 9998: Reward = 576.00, Steps = 10, Loss = 12.1882, Exploration Rate = 0.1000, Train Count = 72000\n",
      "Episode 9999: Reward = 597.00, Steps = 3, Loss = 9.7720, Exploration Rate = 0.1000, Train Count = 72003\n",
      "Episode 10000: Reward = 591.00, Steps = 5, Loss = 7.7376, Exploration Rate = 0.1000, Train Count = 72008\n"
     ]
    }
   ],
   "source": [
    "env = Environment(size = grid_size)\n",
    "# used pervious parameter to train the agent\n",
    "intelligent_agent = DeepQLearningAgent_A2(\n",
    "    possible_moves         = env.possible_moves,\n",
    "    learning_rate  = learning_rate,\n",
    "    future_reward_discount = future_reward_discount,\n",
    "    initial_exploration_rate = initial_exploration_rate,\n",
    "    min_exploration_rate   = min_exploration_rate,\n",
    "    exploration_rate_decay = exploration_rate_decay,\n",
    "    replay_buffer_size = replay_buffer_size,\n",
    "    batch_size = batch_size,\n",
    "    copy_frequency = copy_frequency\n",
    ")\n",
    "trained_agent = train_intelligent_agent_A2(env, intelligent_agent, num_training_episodes, max_step_limit = max_step_limit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn5N7IklC_q3"
   },
   "source": [
    "### Metrics evaluation and Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aHw3jlKZDHBN",
    "outputId": "1a25d552-d368-43ae-e8cc-6413171e9294"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_results(agent):\n",
    "    rewards = agent.performance_history['rewards']\n",
    "    best_rewards = agent.performance_history['best_rewards']\n",
    "    steps = agent.performance_history['steps']\n",
    "    best_steps = agent.performance_history['best_steps']\n",
    "    exploration_rates = agent.performance_history['exploration_rate']\n",
    "    episodes = range(len(rewards))\n",
    "\n",
    "    _, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot average reward\n",
    "    axs[0].plot(episodes, rewards, label='Actual Reward')\n",
    "    axs[0].plot(episodes, best_rewards, label='Best Reward')\n",
    "    axs[0].set_title('Reward per Episode')\n",
    "    axs[0].set_xlabel('Training Episode')\n",
    "    axs[0].set_ylabel('Reward')\n",
    "    axs[0].legend()\n",
    "\n",
    "\n",
    "    # Plot steps per episode\n",
    "    axs[1].plot(episodes, steps, label='Actual Steps')\n",
    "    axs[1].plot(episodes, best_steps, label='Best Steps')\n",
    "    axs[1].set_title('Steps per Training Episode')\n",
    "    axs[1].set_xlabel('Training Episode')\n",
    "    axs[1].set_ylabel('Steps')\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Plot exploration rate decay\n",
    "    axs[2].plot(episodes, exploration_rates)\n",
    "    axs[2].set_title('Exploration Rate Decay')\n",
    "    axs[2].set_xlabel('Training Episode')\n",
    "    axs[2].set_ylabel('Exploration Rate')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training_results(trained_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilc0NUbDRuWV"
   },
   "outputs": [],
   "source": [
    "def test_intelligent_agent_A2(environment, agent, num_test_episodes, max_step_limit):\n",
    "    agent.test_history = {'rewards': [], 'best_rewards': [], 'steps': [], 'best_steps': []}\n",
    "    for episode in range(num_test_episodes):\n",
    "        state = environment.reset_environment()\n",
    "        best_steps = environment.cal_best_performance()\n",
    "        episode_best_reward = environment.cal_best_reward()\n",
    "        episode_reward = 0\n",
    "        steps_taken = 0\n",
    "\n",
    "        for _ in range(max_step_limit):\n",
    "            action = agent.choose_action_test(state)\n",
    "            next_state, reward, done, _ = environment.take_action(action)\n",
    "            steps_taken += 1\n",
    "            state = next_state\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        agent.record_performance_test(episode_reward, episode_best_reward, steps_taken, best_steps)\n",
    "\n",
    "        print(f\"Episode {episode + 1}: Reward = {episode_reward}, Best Rewards = {episode_best_reward}, Steps = {steps_taken}, Best Steps = {best_steps}\")\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pp_5fxK4RuWV",
    "outputId": "b33627b9-f9c5-4f68-9f66-f4285f04db9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 2: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 3: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 4: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 5: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 6: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 7: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 8: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 9: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 10: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 11: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 12: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 13: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 14: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 15: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 16: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 17: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 18: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 19: Reward = 576, Best Rewards = 576, Steps = 10, Best Steps = 10\n",
      "Episode 20: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 21: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 22: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 23: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 24: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 25: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 26: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 27: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 28: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 29: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 30: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 31: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 32: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 33: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 34: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 35: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 36: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 37: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 38: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 39: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 40: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 41: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 42: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 43: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 44: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 45: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 46: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 47: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 48: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 49: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 50: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 51: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 52: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 53: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 54: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 55: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 56: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 57: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 58: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 59: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 60: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 61: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 62: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 63: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 64: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 65: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 66: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 67: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 68: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 69: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 70: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 71: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 72: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 73: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 74: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 75: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 76: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 77: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 78: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 79: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 80: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 81: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 82: Reward = 579, Best Rewards = 579, Steps = 9, Best Steps = 9\n",
      "Episode 83: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 84: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 85: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 86: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 87: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 88: Reward = 582, Best Rewards = 582, Steps = 8, Best Steps = 8\n",
      "Episode 89: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 90: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 91: Reward = 588, Best Rewards = 588, Steps = 6, Best Steps = 6\n",
      "Episode 92: Reward = 597, Best Rewards = 597, Steps = 3, Best Steps = 3\n",
      "Episode 93: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 94: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 95: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n",
      "Episode 96: Reward = 591, Best Rewards = 591, Steps = 5, Best Steps = 5\n",
      "Episode 97: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 98: Reward = 594, Best Rewards = 594, Steps = 4, Best Steps = 4\n",
      "Episode 99: Reward = 585, Best Rewards = 585, Steps = 7, Best Steps = 7\n",
      "Episode 100: Reward = 600, Best Rewards = 600, Steps = 2, Best Steps = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_test_results(agent):\n",
    "    rewards = agent.test_history['rewards']\n",
    "    best_rewards = agent.test_history['best_rewards']\n",
    "    steps = agent.test_history['steps']\n",
    "    best_steps = agent.test_history['best_steps']\n",
    "    episodes = range(len(rewards))\n",
    "\n",
    "    _, axs = plt.subplots(1, 2)\n",
    "\n",
    "    # Plot average reward\n",
    "    axs[0].plot(episodes, rewards, label='Actual Reward')\n",
    "    axs[0].plot(episodes, best_rewards, label='Best Reward', linestyle='--')\n",
    "    axs[0].set_title('Reward per Episode')\n",
    "    axs[0].set_xlabel('Test Episode')\n",
    "    axs[0].set_ylabel('Reward')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot steps per episode\n",
    "    axs[1].plot(episodes, steps, label='Actual Steps')\n",
    "    axs[1].plot(episodes, best_steps, label='Best Steps', linestyle='--')\n",
    "    axs[1].set_title('Steps per Test Episode')\n",
    "    axs[1].set_xlabel('Test Episode')\n",
    "    axs[1].set_ylabel('Steps')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "num_test_episods = 100\n",
    "plot_test_results(test_intelligent_agent_A2(env, trained_agent, num_test_episods, max_step_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHzOsYfoDNg3",
    "outputId": "898c3f0a-b68a-459f-84a8-72c22d470e85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\"\n",
       "href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css\">\n",
       "<script language=\"javascript\">\n",
       "  function isInternetExplorer() {\n",
       "    ua = navigator.userAgent;\n",
       "    /* MSIE used to detect old browsers and Trident used to newer ones*/\n",
       "    return ua.indexOf(\"MSIE \") > -1 || ua.indexOf(\"Trident/\") > -1;\n",
       "  }\n",
       "\n",
       "  /* Define the Animation class */\n",
       "  function Animation(frames, img_id, slider_id, interval, loop_select_id){\n",
       "    this.img_id = img_id;\n",
       "    this.slider_id = slider_id;\n",
       "    this.loop_select_id = loop_select_id;\n",
       "    this.interval = interval;\n",
       "    this.current_frame = 0;\n",
       "    this.direction = 0;\n",
       "    this.timer = null;\n",
       "    this.frames = new Array(frames.length);\n",
       "\n",
       "    for (var i=0; i<frames.length; i++)\n",
       "    {\n",
       "     this.frames[i] = new Image();\n",
       "     this.frames[i].src = frames[i];\n",
       "    }\n",
       "    var slider = document.getElementById(this.slider_id);\n",
       "    slider.max = this.frames.length - 1;\n",
       "    if (isInternetExplorer()) {\n",
       "        // switch from oninput to onchange because IE <= 11 does not conform\n",
       "        // with W3C specification. It ignores oninput and onchange behaves\n",
       "        // like oninput. In contrast, Microsoft Edge behaves correctly.\n",
       "        slider.setAttribute('onchange', slider.getAttribute('oninput'));\n",
       "        slider.setAttribute('oninput', null);\n",
       "    }\n",
       "    this.set_frame(this.current_frame);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.get_loop_state = function(){\n",
       "    var button_group = document[this.loop_select_id].state;\n",
       "    for (var i = 0; i < button_group.length; i++) {\n",
       "        var button = button_group[i];\n",
       "        if (button.checked) {\n",
       "            return button.value;\n",
       "        }\n",
       "    }\n",
       "    return undefined;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.set_frame = function(frame){\n",
       "    this.current_frame = frame;\n",
       "    document.getElementById(this.img_id).src =\n",
       "            this.frames[this.current_frame].src;\n",
       "    document.getElementById(this.slider_id).value = this.current_frame;\n",
       "  }\n",
       "\n",
       "  Animation.prototype.next_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.previous_frame = function()\n",
       "  {\n",
       "    this.set_frame(Math.max(0, this.current_frame - 1));\n",
       "  }\n",
       "\n",
       "  Animation.prototype.first_frame = function()\n",
       "  {\n",
       "    this.set_frame(0);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.last_frame = function()\n",
       "  {\n",
       "    this.set_frame(this.frames.length - 1);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.slower = function()\n",
       "  {\n",
       "    this.interval /= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.faster = function()\n",
       "  {\n",
       "    this.interval *= 0.7;\n",
       "    if(this.direction > 0){this.play_animation();}\n",
       "    else if(this.direction < 0){this.reverse_animation();}\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_forward = function()\n",
       "  {\n",
       "    this.current_frame += 1;\n",
       "    if(this.current_frame < this.frames.length){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.first_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.last_frame();\n",
       "        this.reverse_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.last_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.anim_step_reverse = function()\n",
       "  {\n",
       "    this.current_frame -= 1;\n",
       "    if(this.current_frame >= 0){\n",
       "      this.set_frame(this.current_frame);\n",
       "    }else{\n",
       "      var loop_state = this.get_loop_state();\n",
       "      if(loop_state == \"loop\"){\n",
       "        this.last_frame();\n",
       "      }else if(loop_state == \"reflect\"){\n",
       "        this.first_frame();\n",
       "        this.play_animation();\n",
       "      }else{\n",
       "        this.pause_animation();\n",
       "        this.first_frame();\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.pause_animation = function()\n",
       "  {\n",
       "    this.direction = 0;\n",
       "    if (this.timer){\n",
       "      clearInterval(this.timer);\n",
       "      this.timer = null;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  Animation.prototype.play_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = 1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function() {\n",
       "        t.anim_step_forward();\n",
       "    }, this.interval);\n",
       "  }\n",
       "\n",
       "  Animation.prototype.reverse_animation = function()\n",
       "  {\n",
       "    this.pause_animation();\n",
       "    this.direction = -1;\n",
       "    var t = this;\n",
       "    if (!this.timer) this.timer = setInterval(function() {\n",
       "        t.anim_step_reverse();\n",
       "    }, this.interval);\n",
       "  }\n",
       "</script>\n",
       "\n",
       "<style>\n",
       ".animation {\n",
       "    display: inline-block;\n",
       "    text-align: center;\n",
       "}\n",
       "input[type=range].anim-slider {\n",
       "    width: 374px;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "}\n",
       ".anim-buttons {\n",
       "    margin: 8px 0px;\n",
       "}\n",
       ".anim-buttons button {\n",
       "    padding: 0;\n",
       "    width: 36px;\n",
       "}\n",
       ".anim-state label {\n",
       "    margin-right: 8px;\n",
       "}\n",
       ".anim-state input {\n",
       "    margin: 0;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div class=\"animation\">\n",
       "  <img id=\"_anim_img3f18c438281c410480afbcba3a6ea51d\">\n",
       "  <div class=\"anim-controls\">\n",
       "    <input id=\"_anim_slider3f18c438281c410480afbcba3a6ea51d\" type=\"range\" class=\"anim-slider\"\n",
       "           name=\"points\" min=\"0\" max=\"1\" step=\"1\" value=\"0\"\n",
       "           oninput=\"anim3f18c438281c410480afbcba3a6ea51d.set_frame(parseInt(this.value));\">\n",
       "    <div class=\"anim-buttons\">\n",
       "      <button title=\"Decrease speed\" aria-label=\"Decrease speed\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.slower()\">\n",
       "          <i class=\"fa fa-minus\"></i></button>\n",
       "      <button title=\"First frame\" aria-label=\"First frame\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.first_frame()\">\n",
       "        <i class=\"fa fa-fast-backward\"></i></button>\n",
       "      <button title=\"Previous frame\" aria-label=\"Previous frame\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.previous_frame()\">\n",
       "          <i class=\"fa fa-step-backward\"></i></button>\n",
       "      <button title=\"Play backwards\" aria-label=\"Play backwards\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.reverse_animation()\">\n",
       "          <i class=\"fa fa-play fa-flip-horizontal\"></i></button>\n",
       "      <button title=\"Pause\" aria-label=\"Pause\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.pause_animation()\">\n",
       "          <i class=\"fa fa-pause\"></i></button>\n",
       "      <button title=\"Play\" aria-label=\"Play\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.play_animation()\">\n",
       "          <i class=\"fa fa-play\"></i></button>\n",
       "      <button title=\"Next frame\" aria-label=\"Next frame\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.next_frame()\">\n",
       "          <i class=\"fa fa-step-forward\"></i></button>\n",
       "      <button title=\"Last frame\" aria-label=\"Last frame\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.last_frame()\">\n",
       "          <i class=\"fa fa-fast-forward\"></i></button>\n",
       "      <button title=\"Increase speed\" aria-label=\"Increase speed\" onclick=\"anim3f18c438281c410480afbcba3a6ea51d.faster()\">\n",
       "          <i class=\"fa fa-plus\"></i></button>\n",
       "    </div>\n",
       "    <form title=\"Repetition mode\" aria-label=\"Repetition mode\" action=\"#n\" name=\"_anim_loop_select3f18c438281c410480afbcba3a6ea51d\"\n",
       "          class=\"anim-state\">\n",
       "      <input type=\"radio\" name=\"state\" value=\"once\" id=\"_anim_radio1_3f18c438281c410480afbcba3a6ea51d\"\n",
       "             >\n",
       "      <label for=\"_anim_radio1_3f18c438281c410480afbcba3a6ea51d\">Once</label>\n",
       "      <input type=\"radio\" name=\"state\" value=\"loop\" id=\"_anim_radio2_3f18c438281c410480afbcba3a6ea51d\"\n",
       "             checked>\n",
       "      <label for=\"_anim_radio2_3f18c438281c410480afbcba3a6ea51d\">Loop</label>\n",
       "      <input type=\"radio\" name=\"state\" value=\"reflect\" id=\"_anim_radio3_3f18c438281c410480afbcba3a6ea51d\"\n",
       "             >\n",
       "      <label for=\"_anim_radio3_3f18c438281c410480afbcba3a6ea51d\">Reflect</label>\n",
       "    </form>\n",
       "  </div>\n",
       "</div>\n",
       "\n",
       "\n",
       "<script language=\"javascript\">\n",
       "  /* Instantiate the Animation class. */\n",
       "  /* The IDs given should match those used in the template above. */\n",
       "  (function() {\n",
       "    var img_id = \"_anim_img3f18c438281c410480afbcba3a6ea51d\";\n",
       "    var slider_id = \"_anim_slider3f18c438281c410480afbcba3a6ea51d\";\n",
       "    var loop_select_id = \"_anim_loop_select3f18c438281c410480afbcba3a6ea51d\";\n",
       "    var frames = new Array(4);\n",
       "    \n",
       "  frames[0] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+gAAAPoCAYAAABNo9TkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAA3vklEQVR4nO3de5SWdb3//9cI4wAKqIMKKiSlYGYqZK6iVYLnzDIPeSQl1Dxk\\\n",
       "Hra1ra+akKmVlZa7tFae2upWMksrwExRK13bQ55+atouidoNykHwgPIdmPv3h4v5NoGJJ+Yt83is\\\n",
       "xdL7uq77/nzuYa41POc63E2NRqMRAAAAoFut0d0TAAAAAAQ6AAAAlCDQAQAAoACBDgAAAAUIdAAA\\\n",
       "AChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMA\\\n",
       "AEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0A\\\n",
       "AAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgA\\\n",
       "AABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAH\\\n",
       "AACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6\\\n",
       "AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQ\\\n",
       "AQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACB\\\n",
       "DgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUI\\\n",
       "dAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChA\\\n",
       "oAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEAB\\\n",
       "Ah0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDkA5TU1NK/Xn1ltvfV3jTJo0KU1NTW/M\\\n",
       "pF+lmTNnpqmpKZdddlm3jP9G+973vveq3svzzz+fr33ta9lmm20yYMCA9O/fP+94xzuy//7757bb\\\n",
       "buvc7pFHHsmkSZMyc+bMN37Sr9Nvf/vbHHHEEXnPe96TlpaWNDU1lZwnAG8dvbt7AgDwz+68884u\\\n",
       "j88888zMmDEjt9xyS5flW2655esa54gjjsjuu+/+ul6Dl3zve9/LoEGDMmHChFfcdunSpdl1113z\\\n",
       "0EMP5fOf/3y23377JMkf//jH/PznP89vfvOb7LDDDkleCvTJkydn7Nix2XTTTd/Ed/Dq3Xzzzfn1\\\n",
       "r3+dUaNGZcCAAa/7F0YAINABKOd973tfl8frr79+1lhjjeWW/7NFixalX79+Kz3OJptskk022eQ1\\\n",
       "zZHX7vbbb88dd9yRSy65JJ/61Kc6l++222457rjj0tHR0Y2zW3mnn356zjjjjCTJN77xDYEOwOvm\\\n",
       "FHcA3pLGjh2brbbaKrfffnvGjBmTfv36ZeLEiUmSa665JrvuumuGDBmSvn375p3vfGe+8IUv5Pnn\\\n",
       "n+/yGis6xX3TTTfNnnvumenTp2f06NHp27dvtthii1xyySXLzWH27Nk56qijsskmm2TNNdfM8OHD\\\n",
       "M3ny5CxZsqTLdn//+9+z//77p3///hk4cGAOOOCAzJ49e6Xe55w5c3Lsscdmyy23zNprr50NNtgg\\\n",
       "O+64Y37zm98st+3f/va37Lfffunfv3/WWWedHHLIIbn77rtXeCr9Pffck4997GNZb7310qdPn4wa\\\n",
       "NSpTpkzpss1ll12WpqamzJgxI8ccc0wGDRqU1tbW7LPPPvn73//e5Wv28MMP57bbbuu8/OBfHe2e\\\n",
       "N29ekmTIkCErXL/GGmt0jv+JT3wiSTJu3LjO1/7H9/LrX/86O+20UwYMGJB+/frlAx/4QG6++eYu\\\n",
       "r7fs7/m+++7LPvvskwEDBmTgwIEZP3585syZ87LzfCXL5gkAbxQ/WQB4y2pra8v48eNz8MEHZ+rU\\\n",
       "qTn22GOTvHSq9B577JGLL74406dPz4knnpgpU6bkox/96Eq97gMPPJCTTz45J510Uq6//vpsvfXW\\\n",
       "Ofzww3P77bd3bjN79uxsv/32ufHGG/OlL30p06ZNy+GHH55zzjknRx55ZOd2L7zwQnbeeef86le/\\\n",
       "yjnnnJMf//jHGTx4cA444ICVmsv8+fOTJGeccUZ++ctf5tJLL83b3/72jB07tssR2+effz7jxo3L\\\n",
       "jBkz8rWvfS1TpkzJhhtuuMJxZsyYkQ984ANZsGBBLrroolx//fXZdtttc8ABB6zwOvIjjjgizc3N\\\n",
       "ueqqq/L1r389t956a8aPH9+5/qc//Wne/va3Z9SoUbnzzjtz55135qc//enLvqftttsuzc3NOeGE\\\n",
       "E3LllVemra1thdt95CMfydlnn50k+e53v9v52h/5yEeSJFdccUV23XXXDBgwIJdffnmmTJmS9dZb\\\n",
       "L7vttttykZ4ke++9dzbbbLNce+21mTRpUn72s59lt912S3t7e+c2y34psbrcGwCAt5gGABR32GGH\\\n",
       "NdZaa60uy3bYYYdGksbNN9/8L5/b0dHRaG9vb9x2222NJI0HHnigc90ZZ5zR+OcfhW9729saffr0\\\n",
       "afzlL3/pXPbCCy801ltvvcZRRx3Vueyoo45qrL322l22azQajW984xuNJI2HH3640Wg0GhdeeGEj\\\n",
       "SeP666/vst2RRx7ZSNK49NJLX/kL8A+WLFnSaG9vb+y0006Nvffeu3P5d7/73UaSxrRp07psf9RR\\\n",
       "Ry03zhZbbNEYNWpUo729vcu2e+65Z2PIkCGNpUuXNhqNRuPSSy9tJGkce+yxXbb7+te/3kjSaGtr\\\n",
       "61z2rne9q7HDDjus9Pu4+OKLG2uvvXYjSSNJY8iQIY1DDz20cfvtt3fZ7sc//nEjSWPGjBldlj//\\\n",
       "/PON9dZbr/HRj360y/KlS5c2ttlmm8b222/fuWzZ3/NJJ53UZdsrr7yykaRxxRVXdC67/PLLG716\\\n",
       "9WpcfvnlK/1eGo1G49xzz20kaTzxxBOv6nkA8I8cQQfgLWvdddfNjjvuuNzyP//5zzn44IMzePDg\\\n",
       "9OrVK83NzZ03HXv00Udf8XW33XbbDBs2rPNxnz59MmLEiPzlL3/pXPaLX/wi48aNy0YbbZQlS5Z0\\\n",
       "/vnwhz+cJJ13Ip8xY0b69++fj33sY13GOPjgg1f6fV500UUZPXp0+vTpk969e6e5uTk333xzl/dy\\\n",
       "2223pX///svd9O6ggw7q8vh//ud/8oc//CGHHHJIknSZ+x577JG2trY89thjXZ7zz3Pfeuutk6TL\\\n",
       "1+PVmjhxYv72t7/lqquuyvHHH5+hQ4fmiiuuyA477JBzzz33FZ9/xx13ZP78+TnssMO6vIeOjo7s\\\n",
       "vvvuufvuu5e7pGHZe15m//33T+/evTNjxozOZYceemiWLFmSQw899DW/NwB4rdwkDoC3rBVdw/zc\\\n",
       "c8/lgx/8YPr06ZOvfOUrGTFiRPr165e//vWv2WefffLCCy+84uu2trYut6ylpaXLc5988sn8/Oc/\\\n",
       "T3Nz8wpfY+7cuUleut56ww03XG794MGDX3EeSfKtb30rJ598co4++uiceeaZGTRoUHr16pXTTz+9\\\n",
       "S6C/3Dj/vOzJJ59Mknzuc5/L5z73uX8592X++evR0tKSJCv1tfxXBg4cmIMOOqjzlwgPP/xwdt55\\\n",
       "55x66qk58sgjs84667zsc5e9j/322+9lt5k/f37WWmutzsf//DXv3bt3WltbO6+JB4DuJtABeMta\\\n",
       "0WeY33LLLfn73/+eW2+9tfOoeZIsWLDgDR170KBB2XrrrXPWWWetcP1GG22U5KW4veuuu5Zbv7I3\\\n",
       "ibviiisyduzYXHjhhV2WP/vss10er+w4gwYNSpJ88YtfzD777LPCMUeOHLlSc3ujvetd78qBBx6Y\\\n",
       "888/P48//njnx6+tyLL3ccEFF7zs3f3/+ZcTs2fPzsYbb9z5eMmSJZk3b94KfyEDAN1BoAOwWlkW\\\n",
       "7cuO8i7z/e9//w0dZ88998zUqVPzjne8I+uuu+7Lbjdu3LhMmTIlN9xwQ5dTxa+66qqVGqepqWm5\\\n",
       "9/Lggw/mzjvvzNChQzuX7bDDDpkyZUqmTZvWeZp9klx99dVdnjty5MhsvvnmeeCBBzpvwPZG+Ocz\\\n",
       "DP6VefPmpX///llzzTWXW/eHP/whyf/7BcfLHa3/wAc+kHXWWSePPPJIjjvuuJUa98orr8x73vOe\\\n",
       "zsdTpkzJkiVLMnbs2JV6PgC82QQ6AKuVMWPGZN11183RRx+dM844I83NzbnyyivzwAMPvKHjfPnL\\\n",
       "X85NN92UMWPG5Pjjj8/IkSPz4osvZubMmZk6dWouuuiibLLJJjn00ENz3nnn5dBDD81ZZ52VzTff\\\n",
       "PFOnTs2NN964UuPsueeeOfPMM3PGGWdkhx12yGOPPZYvf/nLGT58eJePczvssMNy3nnnZfz48fnK\\\n",
       "V76SzTbbLNOmTesc5x8/Euz73/9+PvzhD2e33XbLhAkTsvHGG2f+/Pl59NFH8/vf/z4//vGPX/XX\\\n",
       "493vfneuvvrqXHPNNXn729+ePn365N3vfvcKt50xY0ZOOOGEHHLIIRkzZkxaW1vz1FNP5b/+678y\\\n",
       "ffr0HHrooZ2fT7/VVlslSX7wgx+kf//+6dOnT4YPH57W1tZccMEFOeywwzJ//vzst99+2WCDDTJn\\\n",
       "zpw88MADmTNnznJnHVx33XXp3bt3dtlllzz88MM5/fTTs80222T//ffv3OZHP/pRJk6cmEsuueQV\\\n",
       "r0OfM2dO570GHnrooSTJtGnTsv7662f99dfvcgYHAKwMgQ7AaqW1tTW//OUvc/LJJ2f8+PFZa621\\\n",
       "stdee+Waa67J6NGj37BxhgwZknvuuSdnnnlmzj333Pztb39L//79M3z48Oy+++6dR9X79euXW265\\\n",
       "JSeccEK+8IUvpKmpKbvuumuuvvrqjBkz5hXHOfXUU7No0aJcfPHF+frXv54tt9wyF110UX760592\\\n",
       "+Zi1tdZaK7fccktOPPHE/Pu//3vnON/73veyxx57dLmee9y4cbnrrrty1lln5cQTT8zTTz+d1tbW\\\n",
       "bLnlll1i9dWYPHly2tracuSRR+bZZ5/N2972tsycOXOF277vfe/LxIkTM2PGjPznf/5n5s6dm759\\\n",
       "+2bLLbfMBRdckGOOOaZz2+HDh+f888/Pt7/97YwdOzZLly7NpZdemgkTJmT8+PEZNmxYvv71r+eo\\\n",
       "o47Ks88+mw022CDbbrttJkyYsNy41113XSZNmpQLL7wwTU1N+ehHP5rzzz+/y5H8jo6OLF26NB0d\\\n",
       "Ha/4nh9++OHOz2lfZtlH/e2www5d/n4AYGU0NRqNRndPAgB4c5x99tk57bTTMmvWrM6j0j3NpEmT\\\n",
       "Mnny5MyZM6fz2nUAqMgRdABYTfzHf/xHkmSLLbZIe3t7brnllnznO9/J+PHje2ycA8BbiUAHgNVE\\\n",
       "v379ct5552XmzJlZvHhxhg0bllNOOSWnnXZad08NAFgJTnEHAACAAtZ45U0AAACAN5tABwAAgAIE\\\n",
       "OgAAABTgJnGrucWLF2fx4sWdjzs6OjJ//vy0tramqampG2cGAAB0p0ajkWeffTYbbbRR1ljDsdsK\\\n",
       "BPpq7pxzzsnkyZO7exoAAEBRf/3rX30cZxHu4r6a++cj6AsXLsywYcPy+OOPZ7311uvGmUH3aW9v\\\n",
       "z4wZMzJu3Lg0Nzd393SgWzzwQHuefHJGPvOZcXnhBfsBPU/fvu357ndnZMMNx2WbbewD9Ezz58/P\\\n",
       "iBEjsmDBggwcOLC7p0McQV/ttbS0pKWlZbnl6623XlpbW7thRtD92tvb069fv7S2tgp0eqwBA9rz\\\n",
       "7LP98uKLrXnxRfsBPU9T00s/CwYMaE1rq32Ans2lr3W40AAAAAAKEOgAAABQgEAHAACAAlyDDgAA\\\n",
       "wMtaunRp2tvbu3saPYJABwAAYDmNRiOzZ8/OggULunsqPYZABwAAYDnL4nyDDTZIv3793O19FRDo\\\n",
       "AAAAdLF06dLOOPfxzKuOm8QBAADQxbJrzvv169fNM+lZBDoAAAAr5LT2VUugAwAAQAGuQQcAAGCl\\\n",
       "zZqVzJ27asYaNCgZNmzVjFWBQAcAAGClzJqVjByZvPjiqhmvT5/kscdWPtInTJiQBQsW5Gc/+1mS\\\n",
       "ZOzYsdl2221z/vnnv2lz/Fde7fhOcQcAAGClzJ276uI8eWmsVXW0vgKBDgAAwGpnwoQJue222/Lt\\\n",
       "b387TU1NaWpqysyZM5MkjzzySPbYY4+svfba2XDDDfPJT34yc//hNwFjx47NZz/72Zx44olZd911\\\n",
       "s+GGG+YHP/hBnn/++XzqU59K//798453vCPTpk17XXP8yU9+kne9611paWnJpptuKtABAABY/Xz7\\\n",
       "29/O+9///hx55JFpa2tLW1tbhg4dmra2tuywww7Zdtttc88992T69Ol58skns//++3d5/uWXX55B\\\n",
       "gwblrrvuymc/+9kcc8wx+cQnPpExY8bk97//fXbbbbd88pOfzKJFi17T/O69997sv//+OfDAA/PQ\\\n",
       "Qw9l0qRJrkEHAABg9TNw4MCsueaa6devXwYPHty5/MILL8zo0aNz9tlndy675JJLMnTo0Dz++OMZ\\\n",
       "MWJEkmSbbbbJaaedliT54he/mK9+9asZNGhQjjzyyCTJl770pVx44YV58MEH8773ve9Vz+9b3/pW\\\n",
       "dtppp5x++ulJkhEjRgh0AAAAeo577703M2bMyNprr73cuj/96U+dgb711lt3Lu/Vq1daW1vz7ne/\\\n",
       "u3PZhhtumCR56qmnXtM8Hn300ey1115dlgl0AAAAeoyOjo589KMfzde+9rXl1g0ZMqTz/5ubm7us\\\n",
       "a2pq6rKsqamp8/Vei0aj0fkaywh0AAAAVktrrrlmli5d2mXZ6NGj85Of/CSbbrppevfuviTecsst\\\n",
       "89vf/rbLMjeJAwAAYLW06aab5r//+78zc+bMzJ07Nx0dHfnMZz6T+fPn56CDDspdd92VP//5z/nV\\\n",
       "r36ViRMnLhfzb4Q5c+bk/vvv7/Jn9uzZOfnkk3PzzTfnzDPPzOOPP57LL79coAMAALB6+tznPpde\\\n",
       "vXplyy23zPrrr59Zs2Zlo402yu9+97ssXbo0u+22W7baaquccMIJGThwYNZY441P5KuuuiqjRo3q\\\n",
       "8ueiiy7K6NGjM2XKlFx99dXZaqut8qUvfckp7gAAAKycQYOSPn2SF19cNeP16fPSmCvrsssu6/J4\\\n",
       "xIgRufPOO5fbbvPNN8911133sq9z6623Lrds2Weo/6NGo/Ev57Oi1/lH++67b/bdd9/OxwIdAACA\\\n",
       "lTJsWPLYY8ncuatmvEGDXhqzpxDoAAAArLRhw3pWNK9KrkEHAACAAgQ6AAAAFCDQAQAAoACBDgAA\\\n",
       "AAUIdAAAAChAoAMAAEABAh0AAADeAJtuumnOP//81/x8n4MOAADASpu1cFbmLpq7SsYa1G9Qhg18\\\n",
       "dR+6PmHChFx++eVJkt69e2e99dbL1ltvnYMOOigTJkzIGmu8/uPUl112WU488cQsWLCgy/K77747\\\n",
       "a6211mt+XYEOAADASpm1cFZG/sfIvLjkxVUyXp/effLYcY+96kjffffdc+mll2bp0qV58sknM336\\\n",
       "9Jxwwgm59tprc8MNN6R37zcnhddff/3X9XynuAMAALBS5i6au8riPEleXPLiazpa39LSksGDB2fj\\\n",
       "jTfO6NGj83/+z//J9ddfn2nTpuWyyy5LkixcuDCf/vSns8EGG2TAgAHZcccd88ADD3S+xgMPPJBx\\\n",
       "48alf//+GTBgQN7znvfknnvuya233ppPfepTWbhwYZqamtLU1JRJkyYlWf4U96ampvzwhz/M3nvv\\\n",
       "nX79+mXzzTfPDTfc0Ll+6dKlOfzwwzN8+PD07dtXoAMAALD623HHHbPNNtvkuuuuS6PRyEc+8pHM\\\n",
       "nj07U6dOzb333pvRo0dnp512yvz585MkhxxySDbZZJPcfffduffee/OFL3whzc3NGTNmTM4///wM\\\n",
       "GDAgbW1taWtry+c+97mXHXfy5MnZf//98+CDD2aPPfbIIYcc0jlGR0dHNtlkk0yZMiWPPPKIU9wB\\\n",
       "AADoGbbYYos8+OCDmTFjRh566KE89dRTaWlpSZJ84xvfyM9+9rNce+21+fSnP51Zs2bl85//fLbY\\\n",
       "Yoskyeabb975OgMHDkxTU1MGDx78imNOmDAhBx10UJLk7LPPzgUXXJC77roru+++e5qbmzN58uTO\\\n",
       "bR1BBwAAoEdoNBppamrKvffem+eeey6tra1Ze+21O/888cQT+dOf/pQk+bd/+7ccccQR2XnnnfPV\\\n",
       "r361c/mrtfXWW3f+/1prrZX+/fvnqaee6lx20UUXZbvttsv666/vCDoAAAA9w6OPPprhw4eno6Mj\\\n",
       "Q4YMya233rrcNuuss06SZNKkSTn44IPzy1/+MtOmTcsZZ5yRq6++OnvvvferGrO5ubnL46ampnR0\\\n",
       "dCRJpkyZkpNOOinf/OY38/73v1+gAwAAsPq75ZZb8tBDD+Wkk07KJptsktmzZ6d3797ZdNNNX/Y5\\\n",
       "I0aMyIgRI3LSSSfloIMOyqWXXpq99947a665ZpYuXfq65/Sb3/wmY8aMybHHHpvEKe4AAACsZhYv\\\n",
       "XpzZs2fnf//3f/P73/8+Z599dvbaa6/sueeeOfTQQ7Pzzjvn/e9/fz7+8Y/nxhtvzMyZM3PHHXfk\\\n",
       "tNNOyz333JMXXnghxx13XG699db85S9/ye9+97vcfffdeec735nkpbu1P/fcc7n55pszd+7cLFq0\\\n",
       "6DXNc7PNNss999yTG2+8MY8//rgj6AAAAKxepk+fniFDhqR3795Zd911s8022+Q73/lODjvssKyx\\\n",
       "xkvHqadOnZpTTz01EydOzJw5czJ48OB86EMfyoYbbphevXpl3rx5OfTQQ/Pkk09m0KBB2WeffTpv\\\n",
       "6DZmzJgcffTROeCAAzJv3rycccYZnR+19mocffTRuf/++3PAAQe89JFtjUaj8UZ+IajtmWeeycCB\\\n",
       "AzN37ty0trZ293SgW7S3t2fq1KnZY489lrsmCHqKe+5pz//+79QcdNAeeeEF+wE9T9++7fmv/5qa\\\n",
       "jTfeI9ttZx+gZ5o3b14GDRqUhQsXZsCAAV3Wvfjii3niiScyfPjw9OnTp3P5rIWzMvI/Rq6yz0Lv\\\n",
       "07tPHjvusQwbOGyVjNfdHEEHAABgpQwbOCyPHfdY5i6au0rGG9RvUI+J80SgAwAA8CoMGzisR0Xz\\\n",
       "quQmcQAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAro3d0T\\\n",
       "AAAA4C1k1qxk7txVM9agQcmwYa/6aXfccUc++MEPZpdddsn06dPfhIn9azNnzszw4cNz3333Zdtt\\\n",
       "t13p5wl0AAAAVs6sWcnIkcmLL66a8fr0SR577FVH+iWXXJLPfvaz+eEPf5hZs2Zl2GuI/O7gFHcA\\\n",
       "AABWzty5qy7Ok5fGepVH659//vlMmTIlxxxzTPbcc89cdtllXdbfcMMN2XzzzdO3b9+MGzcul19+\\\n",
       "eZqamrJgwYLObe6444586EMfSt++fTN06NAcf/zxef755zvXb7rppjn77LMzceLE9O/fP8OGDcsP\\\n",
       "fvCDzvXDhw9PkowaNSpNTU0ZO3bsSs1doAMAALDauOaaazJy5MiMHDky48ePz6WXXppGo5HkpVPP\\\n",
       "99tvv3z84x/P/fffn6OOOiqnnnpql+c/9NBD2W233bLPPvvkwQcfzDXXXJPf/va3Oe6447ps981v\\\n",
       "fjPbbbdd7rvvvhx77LE55phj8oc//CFJctdddyVJfv3rX6etrS3XXXfdSs1doAMAALDauPjiizN+\\\n",
       "/Pgkye67757nnnsuN998c5LkoosuysiRI3Puuedm5MiROfDAAzNhwoQuzz/33HNz8MEH58QTT8zm\\\n",
       "m2+eMWPG5Dvf+U5+9KMf5cV/OHtgjz32yLHHHpvNNtssp5xySgYNGpRbb701SbL++usnSVpbWzN4\\\n",
       "8OCst956KzV3gQ4AAMBq4bHHHstdd92VAw88MEnSu3fvHHDAAbnkkks617/3ve/t8pztt9++y+N7\\\n",
       "7703l112WdZee+3OP7vttls6OjryxBNPdG639dZbd/5/U1NTBg8enKeeeup1zd9N4gAAAFgtXHzx\\\n",
       "xVmyZEk23njjzmWNRiPNzc15+umn02g00tTU1OU5y05/X6ajoyNHHXVUjj/++OVe/x9vNtfc3Nxl\\\n",
       "XVNTUzo6Ol7X/AU6AAAAb3lLlizJj370o3zzm9/Mrrvu2mXdvvvumyuvvDJbbLFFpk6d2mXdPffc\\\n",
       "0+Xx6NGj8/DDD2ezzTZ7zXNZc801kyRLly59Vc8T6AAAALzl/eIXv8jTTz+dww8/PAMHDuyybr/9\\\n",
       "9svFF1+c6667Lt/61rdyyimn5PDDD8/999/feZf3ZUfWTznllLzvfe/LZz7zmRx55JFZa6218uij\\\n",
       "j+amm27KBRdcsFJz2WCDDdK3b99Mnz49m2yySfr06bPcnFbENegAAAC85V188cXZeeedVxjC++67\\\n",
       "b+6///48/fTTufbaa3Pddddl6623zoUXXth5F/eWlpYkL11bftttt+WPf/xjPvjBD2bUqFE5/fTT\\\n",
       "M2TIkJWeS+/evfOd73wn3//+97PRRhtlr732WrnnrfQIAAAA9GyDBiV9+qy6z0Lv0+elMVfCz3/+\\\n",
       "85ddN3r06M5rzUePHp2PfexjnevOOuuszqPcy7z3ve/Nr371q5d9vZkzZy637P777+/y+IgjjsgR\\\n",
       "RxyxUnNfRqADAACwcoYNSx57LJk7d9WMN2jQS2O+gb73ve/lve99b1pbW/O73/0u55577nKfcd5d\\\n",
       "BDoAAAArb9iwNzyaV6U//vGP+cpXvpL58+dn2LBhOfnkk/PFL36xu6eVRKADAADQg5x33nk577zz\\\n",
       "unsaK+QmcQAAAFCAQAcAAIACBDoAAAArtOzO56waAh0AAIAumpubkySLFi3q5pn0LG4SBwAAQBe9\\\n",
       "evXKOuusk6eeeipJ0q9fvzQ1NXXzrFZ/Ah0AAIDlDB48OEk6I503n0AHAABgOU1NTRkyZEg22GCD\\\n",
       "tLe3d/d0egSBDgAAwMvq1atXevXq1d3T6BHcJA4AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAA\\\n",
       "oACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAA\\\n",
       "AAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAA\\\n",
       "AChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMA\\\n",
       "AEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0A\\\n",
       "AAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgA\\\n",
       "AABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAH\\\n",
       "AACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6\\\n",
       "AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQ\\\n",
       "AQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACB\\\n",
       "DgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUI\\\n",
       "dAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChA\\\n",
       "oAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEAB\\\n",
       "Ah0AAAAKEOgAAABQgEAHAACAAnp39wR4cy1evDiLFy/ufPzMM88kSdrb29Pe3t5d04Jutex7/76/\\\n",
       "35c1evk9JT3TYws6snaS7frel//r9/X0QGv27UiSdHS0xz+J6Kn0QD1NjUaj0d2T4M0zadKkTJ48\\\n",
       "ebnlV111Vfr169cNMwIAACpYtGhRDj744CxcuDADBgzo7ukQgb7aW9ER9KFDh6atrS2tra3dODPo\\\n",
       "Pvf9/b603d+Wif/fxLzQ8UJ3Twe6xXZz+ubknS7JLhMnpvkF+wE9T3vfvrnpkkuyy5AhaR41qrun\\\n",
       "A91i3rx5GTJkiEAvxCnuq7mWlpa0tLQst7y5uTnNzc3dMCPofstOa3+h4wWBTo/1f5e+9N/mF14Q\\\n",
       "6PRozWus4d9E9Fi+9+tx0RkAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAA\\\n",
       "AFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcA\\\n",
       "AIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoA\\\n",
       "AAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINAB\\\n",
       "AACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEO\\\n",
       "AAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0\\\n",
       "AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECg\\\n",
       "AwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAEC\\\n",
       "HQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ\\\n",
       "6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCA\\\n",
       "QAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIAC\\\n",
       "BDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAU\\\n",
       "INABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACg\\\n",
       "AIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAA\\\n",
       "BQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAA\\\n",
       "KECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAA\\\n",
       "QAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAA\\\n",
       "AAoQ6AAAAFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAA\\\n",
       "AFCAQAcAAIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcA\\\n",
       "AIACBDoAAAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoA\\\n",
       "AAAUINABAACgAIEOAAAABQh0AAAAKECgAwAAQAECHQAAAAoQ6AAAAFCAQAcAAIACBDoAAAAUINAB\\\n",
       "AACgAIEOAAAABQh0AAAAKKB3d0+AN9fixYuzePHizsfPPPNMkqS9vT3t7e3dNS3oVh1LO5Ikfdfo\\\n",
       "280zge6zZq+Xvv/b+9oP6JmWfe+3d3Qk/k1ED6UH6mlqNBqN7p4Eb55JkyZl8uTJyy2/6qqr0q9f\\\n",
       "v26YEQAAUMGiRYty8MEHZ+HChRkwYEB3T4cI9NXeio6gDx06NG1tbWltbe3GmUH3aW9vz0033ZQh\\\n",
       "2w7JGr1c6UPP1LG0I233t2WXIUPSvIb9gJ6nvaMjN7W1ZZdddklzc3N3Twe6xbx58zJkyBCBXohT\\\n",
       "3FdzLS0taWlpWW55c3OzH0b0eKM2GmU/oMdqb29P2/1taR5lP6CHam9P2tr8m4gezfd+PX5lDgAA\\\n",
       "AAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAA\\\n",
       "AChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMA\\\n",
       "AEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0A\\\n",
       "AAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgA\\\n",
       "AABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAH\\\n",
       "AACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6\\\n",
       "AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQ\\\n",
       "AQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACB\\\n",
       "DgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUI\\\n",
       "dAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChA\\\n",
       "oAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEAB\\\n",
       "Ah0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAK\\\n",
       "EOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQ\\\n",
       "gEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACA\\\n",
       "AgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAA\\\n",
       "FCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAA\\\n",
       "oACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAA\\\n",
       "AAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAA\\\n",
       "AChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMA\\\n",
       "AEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0A\\\n",
       "AAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgA\\\n",
       "AABQQO/ungBvrsWLF2fx4sWdj5955pkkSXt7e9rb27trWtCtln3v2wfoyewH9HT2AfD9X1FTo9Fo\\\n",
       "dPckePNMmjQpkydPXm75VVddlX79+nXDjAAAgAoWLVqUgw8+OAsXLsyAAQO6ezpEoK/2VnQEfejQ\\\n",
       "oWlra0tra2s3zgy6T3t7e2666abssssuaW5u7u7pQLewH9DT2QcgmTdvXoYMGSLQC3GK+2qupaUl\\\n",
       "LS0tyy1vbm72w4gez34A9gOwD9CT+d6vx03iAAAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAK\\\n",
       "EOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQ\\\n",
       "gEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACA\\\n",
       "AgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAA\\\n",
       "FCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAA\\\n",
       "oACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAA\\\n",
       "AAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAA\\\n",
       "AChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMA\\\n",
       "AEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0A\\\n",
       "AAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgA\\\n",
       "AABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAH\\\n",
       "AACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6\\\n",
       "AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQ\\\n",
       "AQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACB\\\n",
       "DgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUI\\\n",
       "dAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChA\\\n",
       "oAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEAB\\\n",
       "Ah0AAAAKEOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAK\\\n",
       "EOgAAABQgEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQ\\\n",
       "gEAHAACAAgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACA\\\n",
       "AgQ6AAAAFCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABAh0AAAAKEOgAAABQgEAHAACAAgQ6AAAA\\\n",
       "FCDQAQAAoACBDgAAAAUIdAAAAChAoAMAAEABvbt7Ary5Fi9enMWLF3c+XrhwYZJk/vz53TUl6Hbt\\\n",
       "7e1ZtGhR5s2bl+bm5u6eDnQL+wE9nX0A/l8TNBqNbp4Jywj01dw555yTyZMnL7d8xIgR3TAbAACg\\\n",
       "mnnz5mXgwIHdPQ2SNDX8umS19s9H0BcsWJC3ve1tmTVrlp2QHuuZZ57J0KFD89e//jUDBgzo7ulA\\\n",
       "t7Af0NPZB+Cls2uHDRuWp59+Ouuss053T4c4gr7aa2lpSUtLy3LLBw4c6IcRPd6AAQPsB/R49gN6\\\n",
       "OvsAJGus4dZkVfibAAAAgAIEOgAAABQg0HuYlpaWnHHGGSs87R16CvsB2A/APgD2g4rcJA4AAAAK\\\n",
       "cAQdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAA\\\n",
       "ChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAA\\\n",
       "UIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAA\\\n",
       "gAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAA\\\n",
       "ABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEA\\\n",
       "AKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4A\\\n",
       "AAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQA\\\n",
       "AAAoQKADAABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKAD\\\n",
       "AABAAQIdAAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQId\\\n",
       "AAAAChDoAAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDo\\\n",
       "AAAAUIBABwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAoQKADAABAAQIdAAAAChDoAAAAUIBA\\\n",
       "BwAAgAIEOgAAABQg0AEAAKAAgQ4AAAAFCHQAAAAo4P8Hnc7RPCWzUPkAAAAASUVORK5CYII=\\\n",
       "\"\n",
       "  frames[1] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+gAAAPoCAYAAABNo9TkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAArOklEQVR4nO3df5BVhX338e8C68IiC7L4Yw1gUKMGf2IdJ4PTARIRYzSZOEYr\\\n",
       "MmCJlsQnE82YtukkKRA1Tkwm2lp/JDNqbJUqtrHWRk2trJqZ2ImOSvOoSdonIdG6WgKCRsj2wt7n\\\n",
       "jwzbrqCi0dyP7Os1wzD37Nl7vvdyz1zee86529ZsNpsFAAAAtNSIVg8AAAAACHQAAACIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHIE5bW9tO/bn//vt/q+0sW7as2tra3pqh\\\n",
       "36A1a9ZUW1tbfetb32rJ9t9qV1999Rt6LC+//HJ95StfqSOPPLK6urpq3LhxdcABB9Tpp59eDzzw\\\n",
       "wOB6Tz75ZC1btqzWrFnz1g/9W9i6dWt9/etfrxNPPLEmT55cnZ2d9d73vrc+97nP1YYNG1o9HgDv\\\n",
       "UKNaPQAAvNJDDz005PZFF11Uvb29tWrVqiHLp0+f/ltt55xzzqkTTzzxt7oPfuPqq6+uSZMm1dln\\\n",
       "n/26627durVOOOGE+uEPf1h//Md/XMcee2xVVf37v/973XnnnfW9732vZs2aVVW/CfTly5fX7Nmz\\\n",
       "693vfvfb+AjemM2bN9eyZcvqzDPPrHPOOacmTZpUjz76aF188cV155131iOPPFJjxoxp9ZgAvMMI\\\n",
       "dADivO997xtye88996wRI0Zst/yVNm3aVJ2dnTu9ncmTJ9fkyZPf1Iy8eQ8++GB9//vfr+uvv77+\\\n",
       "8A//cHD5vHnz6lOf+lQNDAy0cLqdM2bMmPrZz35W3d3dg8tmz55dU6dOrY997GP193//97VgwYIW\\\n",
       "TgjAO5FT3AF4R5o9e3Yddthh9eCDD9bMmTOrs7OzFi9eXFVVt956a51wwgnV09NTY8aMGTz1+OWX\\\n",
       "Xx5yHzs6xf3d7353nXzyyXXPPffU0UcfXWPGjKlDDjmkrr/++u1meO6552rJkiU1efLk2m233Wra\\\n",
       "tGm1fPny2rJly5D1nn322Tr99NNr3LhxNX78+DrjjDPqueee26nHuXbt2jrvvPNq+vTptfvuu9de\\\n",
       "e+1V73//++t73/vedus+88wzddppp9W4ceNqwoQJddZZZ9XDDz+8w1PpH3nkkfrwhz9cEydOrNGj\\\n",
       "R9eMGTNq5cqVQ9b51re+VW1tbdXb21uf/OQna9KkSdXd3V2nnnpqPfvss0OesyeeeKIeeOCBwcsP\\\n",
       "Xuto97p166qqqqenZ4dfHzFixOD2P/axj1VV1Zw5cwbv+38/ln/5l3+pD3zgA9XV1VWdnZ113HHH\\\n",
       "1X333Tfk/rb9Oz/22GN16qmnVldXV40fP74WLFhQa9eufdU5X8vIkSOHxPk2284GePrpp9/U/QIw\\\n",
       "vAl0AN6x+vr6asGCBTV//vy666676rzzzquq35wqfdJJJ9V1111X99xzT11wwQW1cuXKOuWUU3bq\\\n",
       "flevXl0XXnhhfeYzn6k77rijjjjiiPr4xz9eDz744OA6zz33XB177LH13e9+t/78z/+87r777vr4\\\n",
       "xz9el156aZ177rmD623evLmOP/74+ud//ue69NJL67bbbqt99tmnzjjjjJ2aZf369VVVtXTp0vrO\\\n",
       "d75TN9xwQ+2///41e/bsIdfgv/zyyzVnzpzq7e2tr3zlK7Vy5crae++9d7id3t7eOu6442rDhg11\\\n",
       "7bXX1h133FFHHXVUnXHGGTu8jvycc86p9vb2WrFiRV122WV1//33Dzk6fPvtt9f+++9fM2bMqIce\\\n",
       "eqgeeuihuv3221/1MR1zzDHV3t5e559/ft18883V19e3w/U+9KEP1Ze//OWqqrrqqqsG7/tDH/pQ\\\n",
       "VVXddNNNdcIJJ1RXV1fdeOONtXLlypo4cWLNmzdvu0ivqvroRz9aBx54YP3d3/1dLVu2rP7hH/6h\\\n",
       "5s2bV41GY3CdbT+UeLOfDbDtMoxDDz30TX0/AMNcEwDCLVq0qDl27Nghy2bNmtWsquZ99933mt87\\\n",
       "MDDQbDQazQceeKBZVc3Vq1cPfm3p0qXNV74V7rfffs3Ro0c3f/7znw8u27x5c3PixInNJUuWDC5b\\\n",
       "smRJc/fddx+yXrPZbH7ta19rVlXziSeeaDabzeY111zTrKrmHXfcMWS9c889t1lVzRtuuOH1n4D/\\\n",
       "ZcuWLc1Go9H8wAc+0PzoRz86uPyqq65qVlXz7rvvHrL+kiVLttvOIYcc0pwxY0az0WgMWffkk09u\\\n",
       "9vT0NLdu3dpsNpvNG264oVlVzfPOO2/Iepdddlmzqpp9fX2Dyw499NDmrFmzdvpxXHfddc3dd9+9\\\n",
       "WVXNqmr29PQ0Fy5c2HzwwQeHrHfbbbc1q6rZ29s7ZPnLL7/cnDhxYvOUU04Zsnzr1q3NI488snns\\\n",
       "sccOLtv27/yZz3xmyLo333xzs6qaN9100+CyG2+8sTly5MjmjTfeuNOPZZtnnnmmuffeezePOeaY\\\n",
       "wecQAN4IR9ABeMfaY4896v3vf/92y3/605/W/Pnza5999qmRI0dWe3v74IeOPfXUU697v0cddVRN\\\n",
       "nTp18Pbo0aProIMOqp///OeDy/7pn/6p5syZU/vuu29t2bJl8M8HP/jBqqrBTyLv7e2tcePG1Yc/\\\n",
       "/OEh25g/f/5OP85rr722jj766Bo9enSNGjWq2tvb67777hvyWB544IEaN27cdh96d+aZZw65/R//\\\n",
       "8R/1ox/9qM4666yqqiGzn3TSSdXX11c//vGPh3zPK2c/4ogjqqqGPB9v1OLFi+uZZ56pFStW1Kc/\\\n",
       "/emaMmVK3XTTTTVr1qz66le/+rrf//3vf7/Wr19fixYtGvIYBgYG6sQTT6yHH354u0satj3mbU4/\\\n",
       "/fQaNWpU9fb2Di5buHBhbdmypRYuXPiGHs/69evrpJNOqmazWbfeeuvgafoA8Eb4kDgA3rF2dA3z\\\n",
       "r371q/r93//9Gj16dF188cV10EEHVWdnZz399NN16qmn1ubNm1/3fnd0bXFHR8eQ733++efrzjvv\\\n",
       "rPb29h3exy9/+cuq+s311nvvvfd2X99nn31ed46qqq9//et14YUX1ic+8Ym66KKLatKkSTVy5Mj6\\\n",
       "4he/OCTQX207r1z2/PPPV1XVZz/72frsZz/7mrNv88rno6Ojo6pqp57L1zJ+/Pg688wzB3+I8MQT\\\n",
       "T9Txxx9fn//85+vcc8+tCRMmvOr3bnscp5122quus379+ho7duzg7Vc+56NGjaru7u7Ba+LfrBde\\\n",
       "eKHmzp1b//mf/1mrVq2q/fff/7e6PwCGL4EOwDvWjn6H+apVq+rZZ5+t+++/f/CoeVW95b+betKk\\\n",
       "SXXEEUfUJZdcssOv77vvvlX1m7j9wQ9+sN3Xd/ZD4m666aaaPXt2XXPNNUOWv/TSS0Nu7+x2Jk2a\\\n",
       "VFVVf/Znf1annnrqDrd58MEH79Rsb7VDDz20/uAP/qCuuOKK+slPfjL4gWs7su1xXHnlla/66f6v\\\n",
       "/OHEc889V+9617sGb2/ZsqXWrVu3wx/I7KwXXnihjj/++PrZz35W99133+DZBQDwZgh0AHYp26J9\\\n",
       "21Hebb7xjW+8pds5+eST66677qoDDjig9thjj1ddb86cObVy5cr6x3/8xyGniq9YsWKnttPW1rbd\\\n",
       "Y/m3f/u3euihh2rKlCmDy2bNmlUrV66su+++e/A0+6qqW265Zcj3HnzwwfWe97ynVq9ePfgBbG+F\\\n",
       "V55h8FrWrVtX48aNq9122227r/3oRz+qqv/5AcerHa0/7rjjasKECfXkk0/Wpz71qZ3a7s0331y/\\\n",
       "93u/N3h75cqVtWXLlpo9e/ZOff8rbYvzn/70p3XvvffWjBkz3tT9AMA2Ah2AXcrMmTNrjz32qE98\\\n",
       "4hO1dOnSam9vr5tvvrlWr179lm7nS1/6Ut177701c+bM+vSnP10HH3xw/frXv641a9bUXXfdVdde\\\n",
       "e21Nnjy5Fi5cWJdffnktXLiwLrnkknrPe95Td911V333u9/dqe2cfPLJddFFF9XSpUtr1qxZ9eMf\\\n",
       "/7i+9KUv1bRp04b8OrdFixbV5ZdfXgsWLKiLL764DjzwwLr77rsHt/O/r4n+xje+UR/84Adr3rx5\\\n",
       "dfbZZ9e73vWuWr9+fT311FP16KOP1m233faGn4/DDz+8brnllrr11ltr//33r9GjR9fhhx++w3V7\\\n",
       "e3vr/PPPr7POOqtmzpxZ3d3d9V//9V/1t3/7t3XPPffUwoULB38//WGHHVZVVd/85jdr3LhxNXr0\\\n",
       "6Jo2bVp1d3fXlVdeWYsWLar169fXaaedVnvttVetXbu2Vq9eXWvXrt3urINvf/vbNWrUqJo7d249\\\n",
       "8cQT9cUvfrGOPPLIOv300wfX+eu//utavHhxXX/99a95HfrmzZtr3rx59dhjj9UVV1xRW7ZsqX/9\\\n",
       "138d/Pqee+5ZBxxwwBt+HgEY3gQ6ALuU7u7u+s53vlMXXnhhLViwoMaOHVsf+chH6tZbb62jjz76\\\n",
       "LdtOT09PPfLII3XRRRfVV7/61XrmmWdq3LhxNW3atDrxxBMHj6p3dnbWqlWr6vzzz6/Pfe5z1dbW\\\n",
       "VieccELdcsstNXPmzNfdzuc///natGlTXXfddXXZZZfV9OnT69prr63bb799yK9ZGzt2bK1ataou\\\n",
       "uOCC+pM/+ZPB7Vx99dV10kknDbmee86cOfWDH/ygLrnkkrrgggvqhRdeqO7u7po+ffqQWH0jli9f\\\n",
       "Xn19fXXuuefWSy+9VPvtt1+tWbNmh+u+733vq8WLF1dvb2/9zd/8Tf3yl7+sMWPG1PTp0+vKK6+s\\\n",
       "T37yk4PrTps2ra644or6i7/4i5o9e3Zt3bq1brjhhjr77LNrwYIFNXXq1LrssstqyZIl9dJLL9Ve\\\n",
       "e+1VRx11VJ199tnbbffb3/52LVu2rK655ppqa2urU045pa644oohR/IHBgZq69atNTAw8JqP9/nn\\\n",
       "n6+HH364qqrOP//87b6+aNGiN/2r2gAYvtqazWaz1UMAAG+PL3/5y/WFL3yhfvGLXwwelR5uli1b\\\n",
       "VsuXL6+1a9cOXrsOAIkcQQeAXcRf/dVfVVXVIYccUo1Go1atWlV/+Zd/WQsWLBi2cQ4A7yQCHQB2\\\n",
       "EZ2dnXX55ZfXmjVrqr+/v6ZOnVp/+qd/Wl/4whdaPRoAsBOc4g4AAAABRrz+KgAAAMDbTaADAABA\\\n",
       "AIEOAAAAAXxI3C6uv7+/+vv7B28PDAzU+vXrq7u7u9ra2lo4GQAA0ErNZrNeeuml2nfffWvECMdu\\\n",
       "Ewj0Xdyll15ay5cvb/UYAABAqKefftqv4wzhU9x3ca88gr5x48aaOnVq/eQnP6mJEye2cDJonUaj\\\n",
       "Ub29vTVnzpxqb29v9TjQEn2r++qHz/+wnvw/T9bA5oFWjwO/cyPGjKjpV02vw/c+vHqO7Gn1ONAS\\\n",
       "69evr4MOOqg2bNhQ48ePb/U4lCPou7yOjo7q6OjYbvnEiROru7u7BRNB6zUajers7Kzu7m6BzrC1\\\n",
       "uWtzdb7UWbv9erca+LVAZ/gZ0TaiOjs7a0LXBP8nYthz6WsOFxoAAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBgVKsHAAAYbo6e80jtNvq/\\\n",
       "679/vVs92ntMq8cBIIRABwD4Hdtt9H9Xx5j+Vo8BQBinuAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQY\\\n",
       "1eoBeHv19/dXf3//4O0XX3yxqqoajUY1Go1WjQUtte21/9izj9WIkX5OyfC0Ye2GqqoaMcY+0Apt\\\n",
       "7W2/+bOlzb9Bi2x73rcObPV/IoYtr/08bc1ms9nqIXj7LFu2rJYvX77d8hUrVlRnZ2cLJgIADmjc\\\n",
       "UaOam2pLW2f9v/aPtHocYJjatGlTzZ8/vzZu3FhdXV2tHocS6Lu8HR1BnzJlSvX19VV3d3cLJ4PW\\\n",
       "eezZx6rv8b5a/H8X1+aBza0eB1pizIgxdf1h19fY3cbWIXse0upxhp3dX/hmjdj6qxoYuXv9ao8/\\\n",
       "avU4w9LWga31eN/jNXfu3Gpvb2/1ONAS69atq56eHoEexCnuu7iOjo7q6OjYbnl7e7s3I4atbae1\\\n",
       "bx7YLNAZ9iYcPqEmT57c6jGGn6cmVDVGVLV31YT3ev5bodFo1ON9j/s/EcOa134eFz0BAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAA\\\n",
       "AQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAE\\\n",
       "EOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgA\\\n",
       "AAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMA\\\n",
       "AEAAgQ4AAAABRrV6AACAYad996F/A0AJdACA370D/6jVEwAQyCnuAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEGNXqAXh79ff3V39//+Dt\\\n",
       "F198saqqGo1GNRqNVo0FLTWwdaCqqsaMGNPiSaB1tr3+B7YOeD9gWNr2uvf6Zzjz+s/T1mw2m60e\\\n",
       "grfPsmXLavny5dstX7FiRXV2drZgIgAAIMGmTZtq/vz5tXHjxurq6mr1OJRA3+Xt6Aj6lClTqq+v\\\n",
       "r7q7u1s4GbROo9Goe++9t3qO6qkRI13pw/A0sHWg+h7vq7lz51Z7e3urx4HfuW3vBfYBhrN169ZV\\\n",
       "T0+PQA/iFPddXEdHR3V0dGy3vL293ZsRw96MfWfYDxi2Go1G9T3e5/2AYc8+wHDmtZ/HoSMAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCA\\\n",
       "QAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgwqtUD8Pbq7++v/v7+wdsvvvhiVVU1\\\n",
       "Go1qNBqtGgtaattr3z7AcGY/YLizD4DXf6K2ZrPZbPUQvH2WLVtWy5cv3275ihUrqrOzswUTAQAA\\\n",
       "CTZt2lTz58+vjRs3VldXV6vHoQT6Lm9HR9CnTJlSfX191d3d3cLJoHUajUbde++9NXfu3Gpvb2/1\\\n",
       "ONAS9gOGO/sAVK1bt656enoEehCnuO/iOjo6qqOjY7vl7e3t3owY9uwHYD8A+wDDmdd+Hh8SBwAA\\\n",
       "AAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAA\\\n",
       "BBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAA\\\n",
       "AQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAE\\\n",
       "EOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAgFGtHoC3V39/f/X39w/e3rhxY1VVrV+/vlUj\\\n",
       "Qcs1Go3atGlTrVu3rtrb21s9DrSE/YDhzj4A/9MEzWazxZOwjUDfxV166aW1fPny7ZYfdNBBLZgG\\\n",
       "AABIs27duho/fnyrx6Cq2pp+XLJLe+UR9A0bNtR+++1Xv/jFL+yEDFsvvvhiTZkypZ5++unq6upq\\\n",
       "9TjQEvYDhjv7APzm7NqpU6fWCy+8UBMmTGj1OJQj6Lu8jo6O6ujo2G75+PHjvRkx7HV1ddkPGPbs\\\n",
       "Bwx39gGoGjHCR5Ol8C8BAAAAAQQ6AAAABBDow0xHR0ctXbp0h6e9w3BhPwD7AdgHwH6QyIfEAQAA\\\n",
       "QABH0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQA\\\n",
       "AAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEA\\\n",
       "ACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAA\\\n",
       "gAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAA\\\n",
       "Agh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAvx/jPHoddWneeAAAAAASUVORK5CYII=\\\n",
       "\"\n",
       "  frames[2] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+gAAAPoCAYAAABNo9TkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAArK0lEQVR4nO3dfZBVhX3/8e8Cm4XVXZQlRohgMIqWGEHbsQ5Of4DGx6idOFYT\\\n",
       "ZNASHRInE82YtmmTFFZjSEynmtiozYwaW6CKrdakUVMrq2ZGZvJQpQlGbSdD1GFNEQJYIduFvf3D\\\n",
       "H5uuoKLR3o/s6zXjyD177j3fc7ln2Pc996Gl0Wg0CgAAAGiqEc0eAAAAABDoAAAAEEGgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgA\\\n",
       "AAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMA\\\n",
       "AEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAA\\\n",
       "AAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAA\\\n",
       "BBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDkCclpaWPfrvwQcf/I22s3jx4mppaXlzhn6d\\\n",
       "1q5dWy0tLfXNb36zKdt/s11//fWva19efPHF+vKXv1zTp0+vzs7O6ujoqPe+97117rnn1kMPPTS4\\\n",
       "3uOPP16LFy+utWvXvvlD/4a+9rWv1XHHHVfjx4+vtra2mjx5cn34wx+uNWvWNHs0AN6mRjV7AAB4\\\n",
       "uVWrVg25fOWVV1ZPT0+tXLlyyPJp06b9Rtu56KKL6tRTT/2NboOXXH/99TV+/Pi68MILX3PdHTt2\\\n",
       "1Mknn1w//vGP64/+6I/q2GOPraqqf//3f69vf/vb9b3vfa9mzZpVVS8Fend3d82ePbve8573vIV7\\\n",
       "8Ppt2LChTjvttJo+fXrtv//+9bOf/ay+9KUv1e/+7u/Wj370ozr88MObPSIAbzMCHYA4xx133JDL\\\n",
       "73znO2vEiBG7LH+5rVu3Vnt7+x5v56CDDqqDDjroDc3IG/fwww/XI488UjfffHP94R/+4eDyU045\\\n",
       "pT7xiU/UwMBAE6fbc93d3UMuz5o1q4477riaNm1aLVu2rK644oomTQbA25WXuAPwtjR79uw68sgj\\\n",
       "6+GHH66ZM2dWe3t7LViwoKqqbr/99jr55JNrwoQJNWbMmPqt3/qt+sxnPlMvvvjikNvY3Uvc3/Oe\\\n",
       "99QZZ5xR9913Xx1zzDE1ZsyYOuKII+rmm2/eZYbnnnuuFi5cWAcddFC94x3vqClTplR3d3dt3759\\\n",
       "yHrr1q2rc889tzo6Omrs2LF13nnn1XPPPbdH+7l+/fq65JJLatq0abXvvvvWAQccUCeccEJ973vf\\\n",
       "22XdZ599ts4555zq6Oio/fbbr84///z6wQ9+sNuX0v/whz+ss846q8aNG1ejR4+uo48+ulasWDFk\\\n",
       "nW9+85vV0tJSPT099fGPf7zGjx9fXV1ddfbZZ9e6deuG3Gdr1qyphx56aPDtB692tnvDhg1VVTVh\\\n",
       "woTd/nzEiBGD2/+DP/iDqqqaM2fO4G3/7335l3/5lzrxxBOrs7Oz2tvb6/jjj68HHnhgyO3t/Ht+\\\n",
       "9NFH6+yzz67Ozs4aO3ZszZs3r9avX/+Kc74R73znO6uqatQo50AAeP0EOgBvW729vTVv3ryaO3du\\\n",
       "3XPPPXXJJZdU1UsvlT799NPrpptuqvvuu68uu+yyWrFiRZ155pl7dLurV6+uyy+/vD71qU/V3Xff\\\n",
       "XUcddVR99KMfrYcffnhwneeee66OPfbY+u53v1t//ud/Xvfee2999KMfrSVLltTFF188uN62bdvq\\\n",
       "Ax/4QP3zP/9zLVmypO6444468MAD67zzztujWTZu3FhVVYsWLarvfOc7dcstt9QhhxxSs2fPHvIe\\\n",
       "/BdffLHmzJlTPT099eUvf7lWrFhR73rXu3a7nZ6enjr++ONr06ZNdeONN9bdd99dM2bMqPPOO2+3\\\n",
       "7yO/6KKLqrW1tZYvX15XX311PfjggzVv3rzBn9911111yCGH1NFHH12rVq2qVatW1V133fWK+/Q7\\\n",
       "v/M71draWpdeemktW7asent7d7veBz/4wfriF79YVVVf//rXB2/7gx/8YFVVLV26tE4++eTq7Oys\\\n",
       "W2+9tVasWFHjxo2rU045ZZdIr6r60Ic+VIceemj9/d//fS1evLj+8R//sU455ZTq7+8fXGfnkxKv\\\n",
       "5/30O3bsqL6+vnriiSfqoosuqgMOOGDIKwMAYI81ACDcBRdc0Nhnn32GLJs1a1ajqhoPPPDAq153\\\n",
       "YGCg0d/f33jooYcaVdVYvXr14M8WLVrUePk/hQcffHBj9OjRjZ///OeDy7Zt29YYN25cY+HChYPL\\\n",
       "Fi5c2Nh3332HrNdoNBp/8Rd/0aiqxpo1axqNRqNxww03NKqqcffddw9Z7+KLL25UVeOWW2557Tvg\\\n",
       "f9m+fXujv7+/ceKJJzY+9KEPDS7/+te/3qiqxr333jtk/YULF+6ynSOOOKJx9NFHN/r7+4ese8YZ\\\n",
       "ZzQmTJjQ2LFjR6PRaDRuueWWRlU1LrnkkiHrXX311Y2qavT29g4ue9/73teYNWvWHu/HTTfd1Nh3\\\n",
       "330bVdWoqsaECRMa8+fPbzz88MND1rvjjjsaVdXo6ekZsvzFF19sjBs3rnHmmWcOWb5jx47G9OnT\\\n",
       "G8cee+zgsp1/z5/61KeGrLts2bJGVTWWLl06uOzWW29tjBw5snHrrbfu8b60tbUN7sfUqVMbjz/+\\\n",
       "+B5fFwD+N2fQAXjb2n///euEE07YZfnPfvazmjt3bh144IE1cuTIam1tHfzQsZ/+9KevebszZsyo\\\n",
       "yZMnD14ePXp0TZ06tX7+858PLvunf/qnmjNnTk2cOLG2b98++N9pp51WVTX4SeQ9PT3V0dFRZ511\\\n",
       "1pBtzJ07d4/388Ybb6xjjjmmRo8eXaNGjarW1tZ64IEHhuzLQw89VB0dHbt86N1HPvKRIZf/4z/+\\\n",
       "o5544ok6//zzq6qGzH766adXb29vPfnkk0Ou8/LZjzrqqKqqIffH67VgwYJ69tlna/ny5fXJT36y\\\n",
       "Jk2aVEuXLq1Zs2bVV77ylde8/iOPPFIbN26sCy64YMg+DAwM1Kmnnlo/+MEPdnlLw8593uncc8+t\\\n",
       "UaNGVU9Pz+Cy+fPn1/bt22v+/Pl7vC+PPPJIrVq1qpYuXVodHR01Z84cn+QOwBviDVIAvG3t7j3M\\\n",
       "//Vf/1W/93u/V6NHj64vfOELNXXq1Gpvb69nnnmmzj777Nq2bdtr3m5XV9cuy9ra2oZc9xe/+EV9\\\n",
       "+9vfrtbW1t3exvPPP19VL73f+l3vetcuPz/wwANfc46qqr/8y7+syy+/vD72sY/VlVdeWePHj6+R\\\n",
       "I0fW5z//+SGB/krbefmyX/ziF1VV9elPf7o+/elPv+rsO738/mhra6uq2qP78tWMHTu2PvKRjww+\\\n",
       "ibBmzZr6wAc+UJ/97Gfr4osvrv322+8Vr7tzP84555xXXGfjxo21zz77DF5++X0+atSo6urqGnxP\\\n",
       "/Bt1zDHHVNVLH2541lln1aGHHlp/9md/VnffffdvdLsADD8CHYC3rd19h/nKlStr3bp19eCDDw6e\\\n",
       "Na+q2rRp05u67fHjx9dRRx1VV1111W5/PnHixKp6KW6///3v7/LzPf2QuKVLl9bs2bPrhhtuGLL8\\\n",
       "hRdeGHJ5T7czfvz4qqr60z/90zr77LN3u81mfT3Y+973vvrwhz9c1157bT311FODX7+2Ozv347rr\\\n",
       "rnvFT/d/+ZMTzz33XL373e8evLx9+/basGHDbp+QeaM6OjrqiCOOqKeeeupNu00Ahg+BDsBeZWe0\\\n",
       "7zzLu9Nf//Vfv6nbOeOMM+qee+6p9773vbX//vu/4npz5sypFStW1Le+9a0hLxVfvnz5Hm2npaVl\\\n",
       "l335t3/7t1q1alVNmjRpcNmsWbNqxYoVde+99w6+zL6q6rbbbhty3cMPP7wOO+ywWr169eAHsL0Z\\\n",
       "Xv4Kg1ezYcOG6ujoqHe84x27/OyJJ56oql8/wfFKZ+uPP/742m+//erxxx+vT3ziE3u03WXLltVv\\\n",
       "//ZvD15esWJFbd++vWbPnr1H198Tzz//fP34xz+u448//k27TQCGD4EOwF5l5syZtf/++9fHPvax\\\n",
       "WrRoUbW2ttayZctq9erVb+p2rrjiirr//vtr5syZ9clPfrIOP/zw+tWvflVr166te+65p2688cY6\\\n",
       "6KCDav78+XXNNdfU/Pnz66qrrqrDDjus7rnnnvrud7+7R9s544wz6sorr6xFixbVrFmz6sknn6wr\\\n",
       "rriipkyZMuTr3C644IK65pprat68efWFL3yhDj300Lr33nsHt7Pzq8uqXnqy4rTTTqtTTjmlLrzw\\\n",
       "wnr3u99dGzdurJ/+9Kf1r//6r3XHHXe87vvj/e9/f9122211++231yGHHFKjR4+u97///btdt6en\\\n",
       "py699NI6//zza+bMmdXV1VX/+Z//WX/3d39X9913X82fP3/w++mPPPLIqqr6xje+UR0dHTV69Oia\\\n",
       "MmVKdXV11XXXXVcXXHBBbdy4sc4555w64IADav369bV69epav379Lq86uPPOO2vUqFF10kkn1Zo1\\\n",
       "a+rzn/98TZ8+vc4999zBdf7mb/6mFixYUDfffPOrvg998+bNddJJJ9XcuXPrsMMOqzFjxtRTTz1V\\\n",
       "X/3qV6uvr68WLVr0uu9DABDoAOxVurq66jvf+U5dfvnlNW/evNpnn33q93//9+v2228ffK/wm2HC\\\n",
       "hAn1wx/+sK688sr6yle+Us8++2x1dHTUlClT6tRTTx08q97e3l4rV66sSy+9tD7zmc9US0tLnXzy\\\n",
       "yXXbbbfVzJkzX3M7n/3sZ2vr1q1100031dVXX13Tpk2rG2+8se66664hX7O2zz771MqVK+uyyy6r\\\n",
       "P/7jPx7czvXXX1+nn376kPdzz5kzp77//e/XVVddVZdddln98pe/rK6urpo2bdqQWH09uru7q7e3\\\n",
       "ty6++OJ64YUX6uCDD661a9fudt3jjjuuFixYUD09PfW3f/u39fzzz9eYMWNq2rRpdd1119XHP/7x\\\n",
       "wXWnTJlS1157bX31q1+t2bNn144dO+qWW26pCy+8sObNm1eTJ0+uq6++uhYuXFgvvPBCHXDAATVj\\\n",
       "xoy68MILd9nunXfeWYsXL64bbrihWlpa6swzz6xrr712yJn8gYGB2rFjRw0MDLzq/o4ePbqmT59e\\\n",
       "3/jGN+qZZ56pX/3qV3XggQfW7Nmz6x/+4R9q2rRpb+h+BGB4a2k0Go1mDwEAvDW++MUv1uc+97l6\\\n",
       "+umnB89KDzeLFy+u7u7uWr9+/eB71wEgkTPoALCX+Ku/+quqqjriiCOqv7+/Vq5cWV/72tdq3rx5\\\n",
       "wzbOAeDtRKADwF6ivb29rrnmmlq7dm319fXV5MmT60/+5E/qc5/7XLNHAwD2gJe4AwAAQIARr70K\\\n",
       "AAAA8FYT6AAAABBAoAMAAEAAHxK3l+vr66u+vr7BywMDA7Vx48bq6uqqlpaWJk4GAAA0U6PRqBde\\\n",
       "eKEmTpxYI0Y4d5tAoO/llixZUt3d3c0eAwAACPXMM8/4Os4QPsV9L/fyM+ibN2+uyZMn11NPPVXj\\\n",
       "xo1r4mTQPP39/dXT01Nz5syp1tbWZo8DTeE4YLhzDEDVxo0ba+rUqbVp06YaO3Zss8ehnEHf67W1\\\n",
       "tVVbW9suy8eNG1ddXV1NmAiar7+/v9rb26urq8svZQxbjgOGO8cA/Jq3vubwRgMAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAKMavYAAADD\\\n",
       "ztN3VG1aU7XfkVWTz2n2NACEcAYdAOD/2qY1////P2nuHABEEegAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgA\\\n",
       "AAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMA\\\n",
       "AEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAA\\\n",
       "AAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAA\\\n",
       "BBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABRjV7AN5afX191dfXN3h5y5YtVVXV399f/f39zRoLmmrnY//RdY/WiJGep2R4GtgxUFVV6x5d\\\n",
       "VyNHjGzyNMNP5/NbBv+85b+fbeIkw9eOgR1VVX4fYljz+M8j0PdyS5Ysqe7u7l2W9/T0VHt7exMm\\\n",
       "ghy9j/U2ewRousd6H2v2CMPS4f+9bvDPT/b9qImTcP/99zd7BGiarVu3NnsEXqal0Wg0mj0Eb53d\\\n",
       "nUGfNGlS9fb2VldXVxMng+Z5dN2j1ftYby34yYLaNrCt2eNAUxy8/uD60olfqp8s+EkNbBto9jjD\\\n",
       "zv87a+Xgnx/+1glNnGT4GjFmRB1585E1Y8KMmnj0xGaPA02xYcOGmjBhQm3evLk6OzubPQ7lDPpe\\\n",
       "r62trdra2nZZ3traWq2trU2YCJpv58vatw1sE+gMW307XnrydmDbgEBvgkb/r8+PuP+ba+SIkX4n\\\n",
       "Ytjy2M/jzZcAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAA\\\n",
       "AQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAE\\\n",
       "EOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABRjV7AACA4eahO+c0ewQAAjmDDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAgFHNHoC3\\\n",
       "Vl9fX/X19Q1e3rJlS1VV9ff3V39/f7PGgqYa2DFQVVVjRoxp8iTQPG0j26qqasQYz9UzPO187O8Y\\\n",
       "2OF3IoYtj/08LY1Go9HsIXjrLF68uLq7u3dZvnz58mpvb2/CRAAAQIKtW7fW3Llza/PmzdXZ2dns\\\n",
       "cSiBvtfb3Rn0SZMmVW9vb3V1dTVxMmie/v7+uv/++2vCjAk1YqSzhwxPAzsGqvex3poxYUaNHDGy\\\n",
       "2ePA/7kdAzvqsd7H6qSTTqrW1tZmjwNNsWHDhpowYYJAD+Il7nu5tra2amtr22V5a2urf4wY9o6e\\\n",
       "eLTjgGGrv7+/eh/rrYlHT3QcMCz19/fXY72P+Z2IYc1jP49TRwAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAA\\\n",
       "AQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAE\\\n",
       "EOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgA\\\n",
       "AAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMA\\\n",
       "AEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAA\\\n",
       "AAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAA\\\n",
       "BBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEGBUswfgrdXX11d9fX2Dl7ds2VJVVf39/dXf39+ssaCpdj72HQMM\\\n",
       "Z44DhjvHAHj8J2ppNBqNZg/BW2fx4sXV3d29y/Lly5dXe3t7EyYCAAASbN26tebOnVubN2+uzs7O\\\n",
       "Zo9DCfS93u7OoE+aNKl6e3urq6uriZNB8/T399f9999fJ510UrW2tjZ7HGgKxwHDnWMAqjZs2FAT\\\n",
       "JkwQ6EG8xH0v19bWVm1tbbssb21t9Y8Rw57jABwH4BhgOPPYz+ND4gAAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQA\\\n",
       "AAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEA\\\n",
       "ACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAA\\\n",
       "gAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAA\\\n",
       "Agh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCA\\\n",
       "QAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACDCq2QPw1urr66u+vr7By5s3b66qqo0bNzZrJGi6/v7+2rp1a23YsKFa\\\n",
       "W1ubPQ40heOA4c4xAL9ugkaj0eRJ2Emg7+WWLFlS3d3duyyfOnVqE6YBAADSbNiwocaOHdvsMaiq\\\n",
       "loanS/ZqLz+DvmnTpjr44IPr6aefdhAybG3ZsqUmTZpUzzzzTHV2djZ7HGgKxwHDnWMAXnp17eTJ\\\n",
       "k+uXv/xl7bfffs0eh3IGfa/X1tZWbW1tuywfO3asf4wY9jo7Ox0HDHuOA4Y7xwBUjRjho8lS+JsA\\\n",
       "AACAAAIdAAAAAgj0Yaatra0WLVq025e9w3DhOADHATgGwHGQyIfEAQAAQABn0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAvwPCrve7OqwRi4AAAAASUVORK5CYII=\\\n",
       "\"\n",
       "  frames[3] = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+gAAAPoCAYAAABNo9TkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\\\n",
       "bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9h\\\n",
       "AAAPYQGoP6dpAAAq+ElEQVR4nO3df5BdBX3///eGLBs2ZAPZFAmQQFABA/KrDuOEaZMIAUSwwlCo\\\n",
       "IRPSKA1SRnCwrY4/kgUxI3YKLQpYC4iFFIIjpdaAjWQJdmQGGTtpjYg6/YQfQ7AxMYEmuNwk5/sH\\\n",
       "32y7JEBQ6H2RfTxmGPaePfee9717z9w877k/OpqmaQoAAABoqxHtHgAAAAAQ6AAAABBBoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4A\\\n",
       "AAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAA\\\n",
       "AAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAA\\\n",
       "EECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABA\\\n",
       "AIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAAB\\\n",
       "BDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ\\\n",
       "6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ5AnI6Ojl3674EHHvittrNw4cLq6Oh4fYZ+\\\n",
       "jVavXl0dHR31ta99rS3bf71df/31r+m6bNq0qb7whS/UMcccUz09PTVmzJh661vfWueee26tWLFi\\\n",
       "cL0f//jHtXDhwlq9evXrP/TrqGma+v3f//3q6OioSy65pN3jAPAmNbLdAwDASz300ENDTl955ZXV\\\n",
       "399fy5cvH7J8ypQpv9V2PvzhD9dpp532W10GL7r++utr/PjxNXfu3Fddd+vWrXXKKafUf/zHf9Sf\\\n",
       "/dmf1QknnFBVVT/72c/qW9/6Vn3ve9+radOmVdWLgd7X11fTp0+vQw455A28Br+dL3/5y/Xzn/+8\\\n",
       "3WMA8CYn0AGI8+53v3vI6d/5nd+pESNG7LD8pTZv3lzd3d27vJ2DDjqoDjrooN9oRn5zDz74YH3/\\\n",
       "+9+vm2++uf74j/94cPmpp55al1xySW3btq2N0712q1evrk9+8pP19a9/vc4+++x2jwPAm5iXuAPw\\\n",
       "pjR9+vQ66qij6sEHH6ypU6dWd3d3zZs3r6qq7rzzzjrllFNqwoQJtddee9U73vGO+sQnPlGbNm0a\\\n",
       "chk7e4n7IYccUmeccUbdd999dfzxx9dee+1VRxxxRN188807zPDMM8/U/Pnz66CDDqo999yzJk+e\\\n",
       "XH19fbVly5Yh6z399NN17rnn1pgxY2rs2LF13nnn1TPPPLNL13Pt2rV18cUX15QpU2rvvfeu/fbb\\\n",
       "r97znvfU9773vR3Wfeqpp+qcc86pMWPG1D777FPnn39+/eAHP9jpS+kfeeSRev/731/jxo2rUaNG\\\n",
       "1XHHHVdLliwZss7Xvva16ujoqP7+/vrIRz5S48ePr97e3jr77LPr6aefHnKbrVq1qlasWDH49oNX\\\n",
       "Otq9bt26qqqaMGHCTn8/YsSIwe3/4R/+YVVVzZgxY/Cy//d1+e53v1snnXRS9fT0VHd3d5144ol1\\\n",
       "//33D7m87X/nf/u3f6uzzz67enp6auzYsTV79uxau3bty865q/7kT/6kZs6cWWedddZvfVkADG8C\\\n",
       "HYA3rTVr1tTs2bNr1qxZtXTp0rr44our6sWXSp9++ul100031X333VeXXXZZLVmypM4888xdutyV\\\n",
       "K1fW5ZdfXh/72MfqnnvuqaOPPro+9KEP1YMPPji4zjPPPFMnnHBCfec736nPfvazde+999aHPvSh\\\n",
       "WrRoUV144YWD6z3//PN18skn17/8y7/UokWL6q677qr999+/zjvvvF2aZf369VVVtWDBgvr2t79d\\\n",
       "t9xySx166KE1ffr0Ie/B37RpU82YMaP6+/vrC1/4Qi1ZsqTe8pa37HQ7/f39deKJJ9aGDRvqxhtv\\\n",
       "rHvuuaeOPfbYOu+883b6PvIPf/jD1dnZWYsXL66rr766HnjggZo9e/bg7+++++469NBD67jjjquH\\\n",
       "HnqoHnroobr77rtf9jq9613vqs7Ozrr00kvr9ttvrzVr1ux0vfe97331+c9/vqpefAn59st+3/ve\\\n",
       "V1VVt912W51yyinV09NTt956ay1ZsqTGjRtXp5566g6RXlV11lln1dve9rb6xje+UQsXLqx//Md/\\\n",
       "rFNPPbVardbgOtuflNjV99P/3d/9XT388MP1pS99aZfWB4BX1ABAuAsuuKAZPXr0kGXTpk1rqqq5\\\n",
       "//77X/G827Zta1qtVrNixYqmqpqVK1cO/m7BggXNSx8KDz744GbUqFHN448/Prjs+eefb8aNG9fM\\\n",
       "nz9/cNn8+fObvffee8h6TdM0f/mXf9lUVbNq1aqmaZrmhhtuaKqqueeee4asd+GFFzZV1dxyyy2v\\\n",
       "fgP8L1u2bGlarVZz0kknNWedddbg8i9/+ctNVTX33nvvkPXnz5+/w3aOOOKI5rjjjmtardaQdc84\\\n",
       "44xmwoQJzdatW5umaZpbbrmlqarm4osvHrLe1Vdf3VRVs2bNmsFlRx55ZDNt2rRdvh433XRTs/fe\\\n",
       "ezdV1VRVM2HChGbOnDnNgw8+OGS9u+66q6mqpr+/f8jyTZs2NePGjWvOPPPMIcu3bt3aHHPMMc0J\\\n",
       "J5wwuGz73/ljH/vYkHVvv/32pqqa2267bXDZrbfe2uyxxx7Nrbfe+qrX4amnnmrGjh3bfOUrXxlc\\\n",
       "VlXNn/7pn77qeQFgZxxBB+BNa9999633vOc9Oyz/z//8z5o1a1btv//+tccee1RnZ+fgh449+uij\\\n",
       "r3q5xx57bE2aNGnw9KhRo+qwww6rxx9/fHDZP//zP9eMGTPqgAMOqC1btgz+9973vreqavCTyPv7\\\n",
       "+2vMmDH1/ve/f8g2Zs2atcvX88Ybb6zjjz++Ro0aVSNHjqzOzs66//77h1yXFStW1JgxY3b40LsP\\\n",
       "fvCDQ07//Oc/r5/85Cd1/vnnV1UNmf3000+vNWvW1GOPPTbkPC+d/eijj66qGnJ7vFbz5s2rp556\\\n",
       "qhYvXlwf/ehHa+LEiXXbbbfVtGnT6otf/OKrnv/73/9+rV+/vi644IIh12Hbtm112mmn1Q9+8IMd\\\n",
       "3tKw/Tpvd+6559bIkSOrv79/cNmcOXNqy5YtNWfOnFed4aKLLqpjjjlmyCsmAOC34UPiAHjT2tl7\\\n",
       "mP/7v/+7fu/3fq9GjRpVn/vc5+qwww6r7u7uevLJJ+vss8+u559//lUvt7e3d4dlXV1dQ877i1/8\\\n",
       "or71rW9VZ2fnTi/jl7/8ZVW9+H7rt7zlLTv8fv/993/VOaqq/uqv/qouv/zyuuiii+rKK6+s8ePH\\\n",
       "1x577FGf+cxnhgT6y23npct+8YtfVFXVxz/+8fr4xz/+irNv99Lbo6urq6pql27LVzJ27Nj64Ac/\\\n",
       "OPgkwqpVq+rkk0+uT33qU3XhhRfWPvvs87Ln3X49zjnnnJddZ/369TV69OjB0y+9zUeOHFm9vb2D\\\n",
       "74l/Lb7xjW/UfffdV//6r/9aGzduHPK7F154oTZs2FCjR49+2fsHAOyMQAfgTWtn32G+fPnyevrp\\\n",
       "p+uBBx4YPGpeVbVhw4bXddvjx4+vo48+uq666qqd/v6AAw6oqhfj9uGHH97h97v6IXG33XZbTZ8+\\\n",
       "vW644YYhy5977rkhp3d1O+PHj6+qqk9+8pMv+4njhx9++C7N9no78sgj64/+6I/q2muvrZ/+9KeD\\\n",
       "X7+2M9uvx3XXXfeyn+7/0icnnnnmmTrwwAMHT2/ZsqXWrVu30ydkXs2PfvSj2rJly063/dWvfrW+\\\n",
       "+tWv1t13310f+MAHXvNlAzB8CXQAdivbo337Ud7tvvKVr7yu2znjjDNq6dKl9da3vrX23Xffl11v\\\n",
       "xowZtWTJkvqnf/qnIS8VX7x48S5tp6OjY4fr8u///u/10EMP1cSJEweXTZs2rZYsWVL33nvv4Mvs\\\n",
       "q6ruuOOOIec9/PDD6+1vf3utXLly8APYXg8vfYXBK1m3bl2NGTOm9txzzx1+95Of/KSq/ucJjpc7\\\n",
       "Wn/iiSfWPvvsUz/+8Y/rkksu2aXt3n777fW7v/u7g6eXLFlSW7ZsqenTp+/S+f+3uXPn7vR8M2bM\\\n",
       "qA984AN16aWX1lFHHfWaLxeA4U2gA7BbmTp1au2777510UUX1YIFC6qzs7Nuv/32Wrly5eu6nSuu\\\n",
       "uKKWLVtWU6dOrY9+9KN1+OGH169//etavXp1LV26tG688cY66KCDas6cOXXNNdfUnDlz6qqrrqq3\\\n",
       "v/3ttXTp0vrOd76zS9s544wz6sorr6wFCxbUtGnT6rHHHqsrrriiJk+ePOTr3C644IK65ppravbs\\\n",
       "2fW5z32u3va2t9W99947uJ3tX11W9eKTFe9973vr1FNPrblz59aBBx5Y69evr0cffbR++MMf1l13\\\n",
       "3fWab493vvOddccdd9Sdd95Zhx56aI0aNare+c537nTd/v7+uvTSS+v888+vqVOnVm9vb/3Xf/1X\\\n",
       "/cM//EPdd999NWfOnMHvp98euX/7t39bY8aMqVGjRtXkyZOrt7e3rrvuurrgggtq/fr1dc4559R+\\\n",
       "++1Xa9eurZUrV9batWt3eNXBN7/5zRo5cmTNnDmzVq1aVZ/5zGfqmGOOqXPPPXdwna9//es1b968\\\n",
       "uvnmm1/xfeiHHHLIy36V3IEHHvgbRT8ACHQAdiu9vb317W9/uy6//PKaPXt2jR49uv7gD/6g7rzz\\\n",
       "zjr++ONft+1MmDChHnnkkbryyivri1/8Yj311FM1ZsyYmjx5cp122mmDR9W7u7tr+fLldemll9Yn\\\n",
       "PvGJ6ujoqFNOOaXuuOOOmjp16qtu51Of+lRt3ry5brrpprr66qtrypQpdeONN9bdd9895GvWRo8e\\\n",
       "XcuXL6/LLrus/vzP/3xwO9dff32dfvrpQ97PPWPGjHr44Yfrqquuqssuu6x+9atfVW9vb02ZMmVI\\\n",
       "rL4WfX19tWbNmrrwwgvrueeeq4MPPrhWr16903Xf/e5317x586q/v7/+/u//vn75y1/WXnvtVVOm\\\n",
       "TKnrrruuPvKRjwyuO3ny5Lr22mvrr//6r2v69Om1devWuuWWW2ru3Lk1e/bsmjRpUl199dU1f/78\\\n",
       "eu6552q//farY489tubOnbvDdr/5zW/WwoUL64YbbqiOjo4688wz69prrx1yJH/btm21devW2rZt\\\n",
       "2290OwDAb6OjaZqm3UMAAG+Mz3/+8/XpT3+6nnjiicGj0sPNwoULq6+vr9auXTv43nUASOQIOgDs\\\n",
       "Jr70pS9VVdURRxxRrVarli9fXn/zN39Ts2fPHrZxDgBvJgIdAHYT3d3ddc0119Tq1atrYGCgJk2a\\\n",
       "VH/xF39Rn/70p9s9GgCwC7zEHQAAAAKMePVVAAAAgDeaQAcAAIAAAh0AAAAC+JC43dzAwEANDAwM\\\n",
       "nt62bVutX7++ent7q6Ojo42TAQAA7dQ0TT333HN1wAEH1IgRjt0mEOi7uUWLFlVfX1+7xwAAAEI9\\\n",
       "+eSTvo4zhE9x38299Aj6xo0ba9KkSfXTn/60xo0b18bJoH1arVb19/fXjBkzqrOzs93jQFvYDxju\\\n",
       "7ANQtX79+jrssMNqw4YNNXbs2HaPQzmCvtvr6uqqrq6uHZaPGzeuent72zARtF+r1aru7u7q7e31\\\n",
       "jzKGLfsBw519AP6Ht77m8EYDAAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACjGz3AAAAw84Td1VtWFW1z1FVk85p9zQAhHAEHQDg/9qGVf//\\\n",
       "/3/U3jkAiCLQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCA\\\n",
       "QAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAoxs9wC8sQYGBmpgYGDw9LPPPltVVa1Wq1qt\\\n",
       "VrvGgrbaft9f8d0V1dHR0eZpoD2apqmq8ljQJiO2bR38eZu/QVtsv+/bBxjO3P/zCPTd3KJFi6qv\\\n",
       "r2+H5f39/dXd3d2GiSDHphc2tXsEaLtly5a1e4Rh6fAXfjb482OPL23jJNgHGM42b97c7hF4iY5m\\\n",
       "+1Po7JZ2dgR94sSJtWbNmurt7W3jZNA+K767oja9sKl+NO9Hte35be0eB9pixF4j6qibj6rRe46u\\\n",
       "aSdPa/c4w86IVVcM/rztyM+2cZLhq9Vq1bJly2rmzJnV2dnZ7nGgLdatW1cTJkyojRs3Vk9PT7vH\\\n",
       "oRxB3+11dXVVV1fXDss7Ozs9GDFsbX9Z+7bntwl0hr2Ojg6PB+0wYo/BH/dw+7eVfxMxnLnv5/Eh\\\n",
       "cQAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECg\\\n",
       "AwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEO\\\n",
       "AAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoA\\\n",
       "AAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAA\\\n",
       "ABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAA\\\n",
       "QACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAA\\\n",
       "AQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAE\\\n",
       "EOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBjZ7gEAGH6On/FI7TnqhXaPMax1dHbUAa3/V3tu66p6dGW7xwEASqAD0AZ7jnqhuvYaaPcY\\\n",
       "w1pHZ0eNbDbXyGZLVevZdo8DAJRAB6ANXvj1nu0eYdjr2NJRWzq6a0RHV1VnT7vHGX48KQLATgh0\\\n",
       "AP7P/bD/Xe0eYdgbsdeIOnre0bV319512DtOavc4AED5kDgAAACIINABAAAggEAHAACAAAIdAAAA\\\n",
       "Agh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCA\\\n",
       "QAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAKMbPcAvLEGBgZqYGBg8PSzzz5b\\\n",
       "VVWtVqtarVa7xoK2apqmqqpG7OU5Soav7ff/pmk8HjAsbb/fu/8znLn/5+lotv9Lld3SwoULq6+v\\\n",
       "b4flixcvru7u7jZMBAAAJNi8eXPNmjWrNm7cWD09Pe0ehxLou72dHUGfOHFirVmzpnp7e9s4GbRP\\\n",
       "q9WqZcuW1eg9R1dHR0e7x4G2aJqmNr2wqWbOnFmdnZ3tHgf+z21/LLAPMJytW7euJkyYINCDeIn7\\\n",
       "bq6rq6u6urp2WN7Z2enBiGFv2snT7AcMW61Wq5YuXerxgGHPPsBw5r6fxxswAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0A\\\n",
       "AAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAA\\\n",
       "AAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAA\\\n",
       "IIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACA\\\n",
       "AAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQA\\\n",
       "AAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEA\\\n",
       "ACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAgwMh2D8Aba2BgoAYGBgZPP/vss1VV1Wq1qtVqtWss\\\n",
       "aKvt9337AMOZ/YDhzj4A7v+JOpqmado9BG+chQsXVl9f3w7LFy9eXN3d3W2YCAAASLB58+aaNWtW\\\n",
       "bdy4sXp6eto9DiXQd3s7O4I+ceLEWrNmTfX29rZxMmifVqtVy5Ytq5kzZ1ZnZ2e7x4G2sB8w3NkH\\\n",
       "oGrdunU1YcIEgR7ES9x3c11dXdXV1bXD8s7OTg9GDHv2A7AfgH2A4cx9P48PiQMAAIAAAh0AAAAC\\\n",
       "CHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg\\\n",
       "0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBA\\\n",
       "BwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAId\\\n",
       "AAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQA\\\n",
       "AAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEA\\\n",
       "ACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAA\\\n",
       "gAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAA\\\n",
       "Agh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAI\\\n",
       "INABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCA\\\n",
       "QAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAAC\\\n",
       "HQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0\\\n",
       "AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINAB\\\n",
       "AAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcA\\\n",
       "AIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAA\\\n",
       "AAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAA\\\n",
       "CCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAg\\\n",
       "gEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAA\\\n",
       "Ah0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQAQAAIIBABwAAgAACHQAAAAII\\\n",
       "dAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAHAACAAAIdAAAAAgh0AAAACCDQ\\\n",
       "AQAAIIBABwAAgAACHQAAAAIIdAAAAAgg0AEAACCAQAcAAIAAAh0AAAACCHQAAAAIINABAAAggEAH\\\n",
       "AACAAAIdAAAAAgh0AAAACCDQAQAAIMDIdg/AG2tgYKAGBgYGT2/cuLGqqtavX9+ukaDtWq1Wbd68\\\n",
       "udatW1ednZ3tHgfawn7AcGcfgP9pgqZp2jwJ2wn03dyiRYuqr69vh+WHHXZYG6YBAADSrFu3rsaO\\\n",
       "HdvuMaiqjsbTJbu1lx5B37BhQx188MH1xBNP2AkZtp599tmaOHFiPfnkk9XT09PucaAt7AcMd/YB\\\n",
       "ePHVtZMmTapf/epXtc8++7R7HMoR9N1eV1dXdXV17bB87NixHowY9np6euwHDHv2A4Y7+wBUjRjh\\\n",
       "o8lS+EsAAABAAIEOAAAAAQT6MNPV1VULFizY6cveYbiwH4D9AOwDYD9I5EPiAAAAIIAj6AAAABBA\\\n",
       "oAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACB\\\n",
       "DgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6\\\n",
       "AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgA\\\n",
       "AAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMA\\\n",
       "AEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAA\\\n",
       "AAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAA\\\n",
       "BBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQ\\\n",
       "QKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAA\\\n",
       "gQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDoAAAAEECgAwAAQACBDgAAAAEE\\\n",
       "OgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKADAABAAIEOAAAAAQQ6AAAABBDo\\\n",
       "AAAAEECgAwAAQACBDgAAAAEEOgAAAAQQ6AAAABBAoAMAAEAAgQ4AAAABBDoAAAAEEOgAAAAQQKAD\\\n",
       "AABAAIEOAAAAAf4/tPjQQyueRaIAAAAASUVORK5CYII=\\\n",
       "\"\n",
       "\n",
       "\n",
       "    /* set a timeout to make sure all the above elements are created before\n",
       "       the object is initialized. */\n",
       "    setTimeout(function() {\n",
       "        anim3f18c438281c410480afbcba3a6ea51d = new Animation(frames, img_id, slider_id, 500.0,\n",
       "                                 loop_select_id);\n",
       "    }, 0);\n",
       "  })()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_result_animation(env, intelligent_agent):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "\n",
    "    #reset environment(location of agent,item and drop off point),initial path, item carry status,and task\n",
    "    state = env.reset_environment()\n",
    "    path = [env.agent_location]\n",
    "    item_status = [env.item_carried]\n",
    "    task_complete = False\n",
    "\n",
    "    #train agent until complete which is let agent pick up item and get to the drop off point then one task is completed\n",
    "    while not task_complete:\n",
    "        action = intelligent_agent.choose_action(state)\n",
    "        state, reward, task_complete, _ = env.take_action(action)\n",
    "        path.append(env.agent_location)\n",
    "        item_status.append(env.item_carried)\n",
    "\n",
    "    def animate(frame):\n",
    "      # clear the graph\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, env.dimensions)\n",
    "        ax.set_ylim(0, env.dimensions)\n",
    "        ax.set_xticks(range(env.dimensions + 1))\n",
    "        ax.set_yticks(range(env.dimensions + 1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(True)\n",
    "\n",
    "        # Draw item location when item is not pick up\n",
    "        if not item_status[frame]:\n",
    "            ax.add_patch(patches.Rectangle((env.item_location[1], env.dimensions - env.item_location[0] - 1),1, 1, fill=True, color=\"blue\", label=\"Item Location\"))\n",
    "\n",
    "        # Draw destination\n",
    "        ax.add_patch(patches.Rectangle((env.destination[1], env.dimensions - env.destination[0] - 1),1, 1, fill=True, color=\"green\", label=\"Destination\"))\n",
    "\n",
    "        # Draw agent\n",
    "        current_pos = path[frame]\n",
    "        agent_color = \"red\" if not item_status[frame] else \"purple\"\n",
    "        agent_label = \"Agent\" if frame == 0 else None  # Only label the agent in the first frame\n",
    "        ax.add_patch(patches.Rectangle((current_pos[1], env.dimensions - current_pos[0] - 1), 1, 1, fill=True, color=agent_color, label=agent_label))\n",
    "\n",
    "        # Draw path\n",
    "        path_x = [pos[1] + 0.5 for pos in path[:frame+1]]\n",
    "        path_y = [env.dimensions - pos[0] - 0.5 for pos in path[:frame+1]]\n",
    "        ax.plot(path_x, path_y, color='orange', linewidth=2, alpha=0.5)\n",
    "\n",
    "        ax.set_title(f\"{'Trained agent'} Step: {frame + 1}\")\n",
    "\n",
    "        if frame == 0:\n",
    "          ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        return ax.patches + ax.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(path), interval=500, blit=False, repeat=True)\n",
    "    return anim\n",
    "\n",
    "result_animation = create_result_animation(env, trained_agent)\n",
    "display(HTML(result_animation.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiU86Z6MDQUL",
    "outputId": "fa5a6d5f-9cc5-4306-934f-f861827b875e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Environment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 64\u001b[0m\n\u001b[0;32m     60\u001b[0m     anim \u001b[38;5;241m=\u001b[39m animation\u001b[38;5;241m.\u001b[39mFuncAnimation(fig, animate, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(path), interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, blit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m anim\n\u001b[1;32m---> 64\u001b[0m new_env \u001b[38;5;241m=\u001b[39m \u001b[43mEnvironment\u001b[49m(size\u001b[38;5;241m=\u001b[39m grid_size)\n\u001b[0;32m     67\u001b[0m untrained_agent \u001b[38;5;241m=\u001b[39m untrainedAgent(possible_moves\u001b[38;5;241m=\u001b[39mnew_env\u001b[38;5;241m.\u001b[39mpossible_moves)\n\u001b[0;32m     70\u001b[0m untrained_animation \u001b[38;5;241m=\u001b[39m create_untrained_movement_animation(new_env, untrained_agent, is_trained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Environment' is not defined"
     ]
    }
   ],
   "source": [
    "# fmpl.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "class untrainedAgent:\n",
    "    def __init__(self, possible_moves):\n",
    "        self.possible_moves = possible_moves\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        return random.choice(self.possible_moves)\n",
    "\n",
    "def create_untrained_movement_animation(env, agent, is_trained=True):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    state = env.reset_environment()\n",
    "    path = [env.agent_location]\n",
    "    item_status = [env.item_carried]\n",
    "    task_complete = False\n",
    "\n",
    "    while not task_complete and len(path) < 100:\n",
    "        action = agent.choose_action(state)\n",
    "        state, reward, task_complete, _ = env.take_action(action)\n",
    "        path.append(env.agent_location)\n",
    "        item_status.append(env.item_carried)\n",
    "\n",
    "    def animate(frame):\n",
    "      # clear the graph\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, env.dimensions)\n",
    "        ax.set_ylim(0, env.dimensions)\n",
    "        ax.set_xticks(range(env.dimensions + 1))\n",
    "        ax.set_yticks(range(env.dimensions + 1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.grid(True)\n",
    "\n",
    "        if not item_status[frame]:\n",
    "          # Draw item location when item is not pick up\n",
    "          ax.add_patch(patches.Rectangle((env.item_location[1], env.dimensions - env.item_location[0] - 1),1, 1, fill=True, color=\"blue\", label=\"Item Location\"))\n",
    "\n",
    "          # Draw destination\n",
    "          ax.add_patch(patches.Rectangle((env.destination[1], env.dimensions - env.destination[0] - 1),1, 1, fill=True, color=\"green\", label=\"Destination\"))\n",
    "\n",
    "          #draw agent\n",
    "          current_pos = path[frame]\n",
    "          agent_color = \"red\" if not item_status[frame] else \"purple\"\n",
    "          agent_label = \"Agent\" if frame == 0 else None\n",
    "          ax.add_patch(patches.Rectangle((current_pos[1], env.dimensions - current_pos[0] - 1),1, 1, fill=True, color=agent_color, label=agent_label))\n",
    "\n",
    "          # Draw path\n",
    "          path_x = [pos[1] + 0.5 for pos in path[:frame+1]]\n",
    "          path_y = [env.dimensions - pos[0] - 0.5 for pos in path[:frame+1]]\n",
    "          ax.plot(path_x, path_y, color='orange', linewidth=2, alpha=0.5)\n",
    "\n",
    "          ax.set_title(f\"{'Trained' if is_trained else 'Untrained'} Agent - Step: {frame + 1}\")\n",
    "\n",
    "        if frame == 0:\n",
    "          ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        return ax.patches + ax.lines\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(path), interval=500, blit=False, repeat=False)\n",
    "    return anim\n",
    "\n",
    "\n",
    "new_env = Environment(size= grid_size)\n",
    "\n",
    "\n",
    "untrained_agent = untrainedAgent(possible_moves=new_env.possible_moves)\n",
    "\n",
    "\n",
    "untrained_animation = create_untrained_movement_animation(new_env, untrained_agent, is_trained=False)\n",
    "\n",
    "\n",
    "display(HTML(untrained_animation.to_jshtml()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUtZk2JBU-uA"
   },
   "source": [
    "### Conslusion and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EQoa6YrVM5W"
   },
   "source": [
    "Observation:\n",
    "\n",
    "  - **Circumstance 1** (Figure 1): In the stage 1, we used the average Manhattan distance line (red line in Figure 1) to represent the default shortest distance. However, since the initial coordinate points in the map generated during each training session are random, the single value of the average Manhattan distance cannot be generalized, and it cannot well represent whether each training session has reached the optimal step count standard. So we choose to calculate and store the Manhattan distance of each training session as the shortest distance to verify whether it meets the expected standard (Figure 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn_GRhEaVOKK"
   },
   "source": [
    " - ***Figure 1***:\n",
    "\n",
    " - ![Figure1 _2_.png](https://s2.loli.net/2024/09/14/BFAlmSIqMHNKbcn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRUE-hbWVWVc"
   },
   "source": [
    " - **Circumstance 2** (Figure 2):\n",
    " ![348b14c4b5519c1321bb580b2411c0c.png](https://s2.loli.net/2024/09/15/2N3SKVvx71Rhi8Y.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whIbID_xVXzo"
   },
   "source": [
    "  - **Circumstance 2** After 10000 rounds of training, use the trained agent to test 100 randomly generated maps. The method for generating starting, picking, and ending points within the test map is consistent with the training method. In the comparison after testing(Figure 3), it was founded that the actual reward obtained from 100 test values was exactly the same as the best reward value calculated through calculation and the best number of steps calculated by Manhattan distance function. This indicates that training with DQN was very successful, and both the steps and rewards were consistent with the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0JIsvjBVaVt"
   },
   "source": [
    "- Figure 3:\n",
    "\n",
    "    ![0857424fe118a4288319001acddcdcf.png](https://s2.loli.net/2024/09/15/h5JeluTEfo3xBgd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE5B0lTxiz6u"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBDjgPhEVe3V"
   },
   "source": [
    "### Conclusion:\n",
    "\n",
    "After 10000 rounds of training, the performance of finish trained DQN network have a great performance during the testing process indeed proves its ability to select optimal paths, which can help agents choose the shortest path and achieve the expected path selection of the model in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ghNB80iV3Ef"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C74VMRz9VKmu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w0REAXfVThm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
